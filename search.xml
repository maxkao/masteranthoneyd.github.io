<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Spring与任务调度]]></title>
    <url>%2F2018%2Fspring-boot-scheduler%2F</url>
    <content type="text"><![CDATA[Preface 本篇主要记录任务调度相关框架知识. 任务调度这个在日常开发中非常经典, 比如每天固定时刻同步用户信息、或者是动态的活动开始与结束时间, 亦或者每天早上8点发条短信鼓励一下自己今天努力填坑之类的. . . Quartz 官方文档 Quartz是一个功能丰富的开源作业调度库, 几乎可以集成在任何Java应用程序中 - 从最小的独立应用程序到最大的电子商务系统. Quartz可用于创建简单或复杂的计划, 以执行数十, 数百甚至数万个作业;将任务定义为标准Java组件的作业, 这些组件可以执行几乎任何可以编程的程序. Quartz Scheduler包含许多企业级功能, 例如支持JTA事务和集群. 主要成员 Scheduler - 与调度器交互的主要API. Job - 需要被调度器调度的任务必须实现的接口. JobDetail - 用于定义任务的实例. Trigger - 用于定义调度器何时调度任务执行的组件. JobBuilder - 用于定义或创建JobDetail的实例 . TriggerBuilder - 用于定义或创建触发器实例. 构建流程 定义ScheduleFactory, Schedule实例对象通过该工厂接口的实现类获取. 定义JobDetail实例对象, 该对象需要指定名称、组和Job接口的Class信息. 定义Trigger实例对象, 通过该对象设置触发任务的相关信息, 如起始时间、重复次数等. 向Schedule中注册JobDetail和Trigger, 有两种方式: 通过Schedule的schedule方法注册, 此时它自动让Trigger和JobDetail绑定. 通过addJob和scheduleJob方法注册, 此时需要手动设置 Trigger的关联的Job组名和Job名称, 让Trigger和JobDetail绑定. 启动调度器（调用Schedule对象的start方法）. 运行模式 内部运行图: 与Spring集成在Spring中使用Quartz有两种方式实现: MethodInvokingJobDetailFactoryBean和QuartzJobBean. 其中MethodInvokingJobDetailFactoryBean不支持存储到数据库, 会报java.io.NotSerializableException. xml方式声明JobMethodInvokingJobDetailFactoryBean先来看一下MethodInvokingJobDetailFactoryBean的方式（指定targetObject与targetMethod再通过反射调用）: 12345678910111213141516&lt;!-- 使用MethodInvokingJobDetailFactoryBean, 任务类可以不实现Job接口, 通过targetMethod指定调用方法--&gt;&lt;bean id="taskJob" class="com.xxx.DataConversionTask"/&gt;&lt;bean id="jobDetail" class="org.springframework.scheduling.quartz.MethodInvokingJobDetailFactoryBean"&gt; &lt;property name="group" value="job_work"/&gt; &lt;property name="name" value="job_work_name"/&gt; &lt;!--false表示等上一个任务执行完后再开启新的任务--&gt; &lt;property name="concurrent" value="false"/&gt; &lt;!-- 指定bean --&gt; &lt;property name="targetObject"&gt; &lt;ref bean="taskJob"/&gt; &lt;/property&gt; &lt;!-- 指定执行方法 --&gt; &lt;property name="targetMethod"&gt; &lt;value&gt;run&lt;/value&gt; &lt;/property&gt;&lt;/bean&gt; QuartzJobBean一般很少会使用上述方式, 一般是使用QuartzJobBean: 123456789101112131415161718192021222324&lt;bean name="redisKeySpaceMetricReportJob" class="org.springframework.scheduling.quartz.JobDetailFactoryBean"&gt; &lt;property name="jobClass" value="com.iba.boss.schedule.RedisKeySpaceMetricReportScheduleJob"/&gt; &lt;property name="durability" value="true" /&gt; &lt;!-- 向jobDataMap中注入依赖, Spring会通过反射将这些属性注入到RedisKeySpaceMetricReportScheduleJob中 --&gt; &lt;property name="jobDataMap"&gt; &lt;map&gt; &lt;entry key="contextUtil" value-ref="applicationContextUtil" /&gt; &lt;!-- 定时任务执行开关 --&gt; &lt;entry key="isOpen" value="true"&gt;&lt;/entry&gt; &lt;/map&gt; &lt;/property&gt;&lt;/bean&gt;&lt;bean id="redisMetricReportTrigger" class="org.springframework.scheduling.quartz.CronTriggerFactoryBean"&gt; &lt;property name="jobDetail" ref="redisKeySpaceMetricReportJob" /&gt; &lt;property name="cronExpression" value="0 30 9 * * ?" /&gt;&lt;/bean&gt;&lt;bean id="schedulerFactoryBean" class="org.springframework.scheduling.quartz.SchedulerFactoryBean"&gt; &lt;property name="triggers"&gt; &lt;list&gt; &lt;ref bean="redisMetricReportTrigger"/&gt; &lt;/list&gt; &lt;/property&gt;&lt;/bean&gt; 12345678910111213141516171819public class RedisKeySpaceMetricReportScheduleJob extends QuartzJobBean &#123; private Boolean isOpen; private ApplicationContext context; @Override protected void executeInternal(JobExecutionContext ctx) &#123; if (!isOpen) &#123; return; &#125; // Do something &#125; public void setIsOpen(Boolean isOpen) &#123; this.isOpen = isOpen; &#125; public void setContextUtil(ApplicationContextUtil contextUtil)&#123; this.context = contextUtil.getContext(); &#125;&#125; JobFactoryQuartz是通过JobFactory#newJob()接口返回Job实例的, 默认实现SimpleJobFactory是通过jobClass.newInstance()反射构建实例的. 在Spring中, 也是类似地通过反射构建Job实例, 不同的是在此实例上做了扩展（注入Spring Bean）. AdaptableJobFactory只是简单地通过反射构建Job, SpringBeanJobFactory继承AdaptableJobFactory并重写createJobInstance方法, 把jobDataMap跟triggerDataMap中的bean注入到Job实例当中: 12345678910111213141516171819202122232425@Overrideprotected Object createJobInstance(TriggerFiredBundle bundle) throws Exception &#123; Object job = super.createJobInstance(bundle); BeanWrapper bw = PropertyAccessorFactory.forBeanPropertyAccess(job); if (isEligibleForPropertyPopulation(bw.getWrappedInstance())) &#123; MutablePropertyValues pvs = new MutablePropertyValues(); if (this.schedulerContext != null) &#123; pvs.addPropertyValues(this.schedulerContext); &#125; pvs.addPropertyValues(getJobDetailDataMap(bundle)); pvs.addPropertyValues(getTriggerDataMap(bundle)); if (this.ignoredUnknownProperties != null) &#123; for (String propName : this.ignoredUnknownProperties) &#123; if (pvs.contains(propName) &amp;&amp; !bw.isWritableProperty(propName)) &#123; pvs.removePropertyValue(propName); &#125; &#125; bw.setPropertyValues(pvs); &#125; else &#123; bw.setPropertyValues(pvs, true); &#125; &#125; return job;&#125; 其中isEligibleForPropertyPopulation(): 123protected boolean isEligibleForPropertyPopulation(Object jobObject) &#123; return (!(jobObject instanceof QuartzJobBean));&#125; 所以要获得注入bean的支持, 有两步, 第一继承QuartzJobBean, 在构建JobDetail时在jobDataMap中注入Spring Bean. 不过这种方法也有缺点, 理论上我们是不应该关注Job中依赖了哪些Spring Bean, 这样耦合度太大. 所以在Spring Boot中已经优化掉了这一点. Spring Boot自动配置在Spring Boot 中通过QuartzAutoConfiguration自动配置Quartz相关类并对SpringBeanJobFactory进行了扩展: 123456789101112131415161718class AutowireCapableBeanJobFactory extends SpringBeanJobFactory &#123; private final AutowireCapableBeanFactory beanFactory; AutowireCapableBeanJobFactory(AutowireCapableBeanFactory beanFactory) &#123; Assert.notNull(beanFactory, "Bean factory must not be null"); this.beanFactory = beanFactory; &#125; @Override protected Object createJobInstance(TriggerFiredBundle bundle) throws Exception &#123; Object jobInstance = super.createJobInstance(bundle); this.beanFactory.autowireBean(jobInstance); this.beanFactory.initializeBean(jobInstance, null); return jobInstance; &#125;&#125; 这样我们只需要在Job实现类中用@Autowired或@Resource注解声明需要注入的Spring Bean即可. Spring Boot提供SchedulerFactoryBeanCustomizer定制SchedulerFactoryBean, 比如换一个JobFactory（从Spring IoC容器中获取无状态Job）: 1234567891011@Componentpublic class QuartzScheduleFactoryBeanCustomizer implements SchedulerFactoryBeanCustomizer &#123; @Resource private CustomizedActivitySchedulerFactory customizedSchedulerFactory; @Override public void customize(SchedulerFactoryBean schedulerFactoryBean) &#123; schedulerFactoryBean.setJobFactory(customizedSchedulerFactory); &#125;&#125; 12345678910111213141516@Componentpublic class CustomizedActivitySchedulerFactory implements JobFactory, ApplicationContextAware &#123; private ApplicationContext applicationContext; @Override public Job newJob(TriggerFiredBundle bundle, Scheduler scheduler) &#123; return applicationContext.getBean(bundle.getJobDetail().getJobClass()); &#125; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; this.applicationContext = applicationContext; &#125;&#125; Job的增删改123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114/** * @author ybd * @date 18-11-22 * @contact yangbingdong1994@gmail.com */public class SpringQuartzJobTemplate implements ScheduleJobOperations, InitializingBean &#123; private static final Logger log = LoggerFactory.getLogger(SpringQuartzJobTemplate.class); @Autowired(required = false) @Qualifier("customizedSchedulerFactoryBean") private SchedulerFactoryBean schedulerFactoryBean; private Scheduler scheduler; @Override public void addOrUpdateScheduleJob(BaseJobDetail baseJobDetail) &#123; try &#123; TriggerKey triggerKey = parseTriggerKey(baseJobDetail); JobKey jobKey = parseJobKey(baseJobDetail); boolean jobExists = scheduler.checkExists(jobKey); boolean triggerExists = scheduler.checkExists(triggerKey); CronScheduleBuilder cronScheduleBuilder = CronScheduleBuilder.cronSchedule(baseJobDetail.getCron()); CronTrigger cronTrigger = TriggerBuilder.newTrigger() .withIdentity(triggerKey) .withSchedule(cronScheduleBuilder) .build(); if (!jobExists &amp;&amp; !triggerExists) &#123; JobDetail jobDetail = buildJobDetail(baseJobDetail, jobKey); scheduler.scheduleJob(jobDetail, cronTrigger); &#125; else if (jobExists &amp;&amp; triggerExists) &#123; if (baseJobDetail.getJobDataMap() != null) &#123; JobDetail jobDetail = buildJobDetail(baseJobDetail, jobKey); scheduler.addJob(jobDetail, true, true); &#125; scheduler.rescheduleJob(triggerKey, cronTrigger); &#125; else &#123; throw new ScheduleJobException("Illegal state -&gt; jobExists: " + jobExists + ", triggerExists: " + triggerExists); &#125; &#125; catch (Exception e) &#123; throw new ScheduleJobException(e); &#125; &#125; private JobDetail buildJobDetail(BaseJobDetail baseJobDetail, JobKey jobKey) throws ClassNotFoundException &#123; Class&lt;? extends Job&gt; jobClass = Class.forName(baseJobDetail.getJobClass()).asSubclass(Job.class); JobDetail jobDetail = JobBuilder.newJob(jobClass) .withIdentity(jobKey) .build(); if (baseJobDetail.getId() != null) &#123; jobDetail.getJobDataMap().put(JOB_DETAIL_ID_KEY, baseJobDetail.getId()); &#125; if (baseJobDetail.getJobDataMap() != null) &#123; jobDetail.getJobDataMap().putAll(baseJobDetail.getJobDataMap()); &#125; return jobDetail; &#125; @Override public void deleteScheduleJob(BaseJobDetail baseJobDetail) &#123; try &#123; TriggerKey triggerKey = parseTriggerKey(baseJobDetail); if (scheduler.checkExists(triggerKey)) &#123; scheduler.pauseTrigger(triggerKey); scheduler.unscheduleJob(triggerKey); JobKey jobKey = parseJobKey(baseJobDetail); if (scheduler.checkExists(jobKey)) &#123; scheduler.deleteJob(parseJobKey(baseJobDetail)); &#125; log.info("Success [CREATE] quartz job: " + triggerKey.toString()); &#125; else &#123; log.info("Fail to [DELETE] schedule job, job not exist: " + triggerKey); &#125; &#125; catch (SchedulerException e) &#123; throw new ScheduleJobException(e); &#125; &#125; @Override public void trigger(BaseJobDetail baseJobDetail) &#123; try &#123; JobKey jobKey = parseJobKey(baseJobDetail); if (scheduler.checkExists(jobKey)) &#123; scheduler.triggerJob(jobKey); &#125; else &#123; JobDetail jobDetail = buildJobDetail(baseJobDetail, jobKey); scheduler.addJob(jobDetail, false, true); scheduler.triggerJob(jobKey); &#125; &#125; catch (Exception e) &#123; throw new ScheduleJobException(e); &#125; &#125; @Override public void afterPropertiesSet() &#123; this.scheduler = schedulerFactoryBean.getScheduler(); &#125; private TriggerKey parseTriggerKey(BaseJobDetail baseJobDetail) &#123; requireNameAndGroupNonNull(baseJobDetail); return TriggerKey.triggerKey(baseJobDetail.getJobName(), baseJobDetail.getJobGroup()); &#125; private JobKey parseJobKey(BaseJobDetail baseJobDetail) &#123; requireNameAndGroupNonNull(baseJobDetail); return JobKey.jobKey(baseJobDetail.getJobName(), baseJobDetail.getJobGroup()); &#125; private void requireNameAndGroupNonNull(BaseJobDetail baseJobDetail) &#123; requireNonNull(baseJobDetail.getJobName()); requireNonNull(baseJobDetail.getJobGroup()); &#125;&#125; 信息类: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110@Datapublic class BaseJobDetail &#123; /** * field comment: 主键 */ private Long id; /** * field comment: 任务组 */ private String jobGroup; /** * field comment: 任务名 */ private String jobName; /** * field comment: 任务类 */ private String jobClass; /** * field comment: cron表达式 */ private String cron; /** * field comment: 冗余, cron表达式对应执行时间 */ private Date cronTime; /** * field comment: 触发次数 */ private Integer fireTimes; /** * field comment: 最后一次触发时间 */ private Date lastFireTime; /** * field comment: 最后一次触发的任务耗时, 单位: 毫秒 */ private Long lastFireConsume; /** * field comment: 状态, 0:待执行 1:已执行 2:已取消 3:执行异常 */ private Byte status; /** * field comment: 作业数据 */ private String jobData; /** * field comment: 创建时间 */ private Date createTime; /** * field comment: 更新时间 */ private Date updateTime; private transient Map&lt;String, ?&gt; jobDataMap; public BaseJobDetail incrFireTimes() &#123; fireTimes++; return this; &#125; public BaseJobDetail withJobData(Object jobData) &#123; return setJobData(BaseJobData.of(jobData).toJsonString()); &#125; public static BaseJobDetail of(String jobGroup, String jobName, Class&lt;? extends Job&gt; jobClass, Date cronTime) &#123; return new BaseJobDetail().setCron(DateUtil.parseToCron(cronTime)) .setCronTime(cronTime) .setJobGroup(jobGroup) .setJobName(jobName) .setJobClass(jobClass.getName()); &#125; @Data public static class BaseJobData &#123; private Class dataClass; private JSON jsonData; public static BaseJobData resolve(String jsonData) &#123; return parseObject(jsonData, BaseJobData.class); &#125; public static BaseJobData of(Object data) &#123; return new BaseJobData().setDataClass(data.getClass()) .setJsonData((JSON) toJSON(data)); &#125; @SuppressWarnings("unchecked") public &lt;T&gt; T parseData() &#123; return (T) parseObject(this.jsonData.toJSONString(), this.dataClass); &#125; public String toJsonString() &#123; return toJSONString(this); &#125; &#125;&#125; 其他问题Durability当设置了JobDetail.setDurability(true), 当job不再有trigger引用它的时候, Quartz也不要删除job. Misfire由于某些原因（比如Worker线程池满了）导致任务没有及时执行, 此时扫描Misfire的线程就会把它们找出来并按照Misfire指令处理这个任务. 比如CronTrigger的默认策略是CronTrigger.MISFIRE_INSTRUCTION_FIRE_ONCE_NOW,也可以自己指定: 1234567CronScheduleBuilder cronScheduleBuilder = CronScheduleBuilder.cronSchedule(scheduleJobInfo.getCron()).withMisfireHandlingInstructionDoNothing();TriggerKey oldTriggerKey = parseTriggerKey(scheduleJobInfo);CronTrigger newTrigger = TriggerBuilder.newTrigger() .withIdentity(oldTriggerKey) .withSchedule(cronScheduleBuilder) .build();scheduler.rescheduleJob(oldTriggerKey, newTrigger); maxBatchSize一次拉取trigger的最大数量, 默认是1, 可通过org.quartz.scheduler.batchTriggerAcquisitionMaxCount改写. 但是在集群环境下, 不建议设置为很大值. 如果值 &gt; 1, 并且使用了 JDBC JobStore的话, org.quartz.jobStore.acquireTriggersWithinLock属性必须设置为true, 以避免”弄脏”数据. 更多参数配置: https://blog.csdn.net/zixiao217/article/details/53091812 性能问题由于Quartz的集群是通过底层调度依赖数据库的悲观锁, 谁先抢到谁调度, 这样会导致节点负载不均衡, 并且影响性能. Spring Scheduler Spring Scheduler相对Quartz来说比较轻量级, 通过简单的配置就可以使用了, 但灵活度不如Quartz 开启配置Xml方式1&lt;task:scheduler id="scheduler" pool-size="50"/&gt; 如果不设置pool-size, 默认是1, 会导致任务单线程执行. Java配置方式123456789101112131415161718@Configuration@EnableSchedulingpublic class SpringScheduleConfig implements SchedulingConfigurer &#123; @Override public void configureTasks(ScheduledTaskRegistrar taskRegistrar) &#123; taskRegistrar.setScheduler(taskExecutor()); &#125; @Bean public Executor taskExecutor() &#123; return new ScheduledThreadPoolExecutor(4, new BasicThreadFactory .Builder() .namingPattern("schedule-pool-thread-%d") .build()); &#125;&#125; @EnableScheduling表示告诉Spring开启Scheduler 实现SchedulingConfigurer是为了配置线程池 使用Xml方式123&lt;task:scheduled-tasks scheduler="myScheduler"&gt; &lt;task:scheduled ref="doSomethingTask" method="doSomething" cron="0 * * * * *"/&gt;&lt;/task:scheduled-tasks&gt; 1234567@Componentpublic class DoSomethingTask &#123; @Scheduled(cron="0 * * * * *") public void doSomething() &#123; System.out.println("do something"); &#125;&#125; 注解声明方式使用@Scheduled可以非常简单地就声明一个任务: 1234567@Componentpublic class DoSomethingTask &#123; @Scheduled(cron="0 * * * * *") public void doSomething() &#123; System.out.println("do something"); &#125;&#125; @Scheduled有几个参数: cron: cron表达式, 指定任务在特定时间执行； fixedDelay: 表示上一次任务执行完成后多久再次执行, 参数类型为long, 单位ms； fixedDelayString: 与fixedDelay含义一样, 只是参数类型变为String； fixedRate: 表示按一定的频率执行任务, 参数类型为long, 单位ms； fixedRateString: 与fixedRate的含义一样, 只是将参数类型变为String； initialDelay: 表示延迟多久再第一次执行任务, 参数类型为long, 单位ms； initialDelayString: 与initialDelay的含义一样, 只是将参数类型变为String； zone: 时区, 默认为当前时区, 一般没有用到. Cron表达式想了解Cron最好的方法是看Quartz的官方文档. 本节也会大致介绍一下. Cron表达式由6~7项组成, 中间用空格分开. 从左到右依次是: 秒、分、时、日、月、周几、年（可省略）. 值可以是数字, 也可以是以下符号:*: 所有值都匹配?: 无所谓, 不关心, 通常放在“周几”里,: 或者/: 增量值-: 区间 下面举几个例子, 看了就知道了:0 * * * * *: 每分钟（当秒为0的时候）0 0 * * * *: 每小时（当秒和分都为0的时候）*/10 * * * * *: 每10秒0 5/15 * * * *: 每小时的5分、20分、35分、50分0 0 9,13 * * *: 每天的9点和13点0 0 8-10 * * *: 每天的8点、9点、10点0 0/30 8-10 * * *: 每天的8点、8点半、9点、9点半、10点0 0 9-17 * * MON-FRI: 每周一到周五的9点、10点…直到17点（含）0 0 0 25 12 ?: 每年12约25日圣诞节的0点0分0秒（午夜）0 30 10 * * ? 2016: 2016年每天的10点半 其中的?在用法上其实和*是相同的. 但是*语义上表示全匹配, 而?并不代表全匹配, 而是不关心. 比如对于0 0 0 5 8 ? 2016来说, 2016年8月5日是周五, ?表示我不关心它是周几. 而0 0 0 5 8 * 2016中的*表示周一也行, 周二也行……语义上和2016年8月5日冲突了, 你说谁优先生效呢. 不记得也没关系, 记住Cron Maker也可以, 它可以在线生成cron表达式. 时间轮 https://github.com/ifesdjeen/hashed-wheel-timer 分布式任务调度Elastic Job Elastic Job Elastic Job 与 Sping Cloud 集成解决依赖冲突问题由于Elastic Job自身的 curator-client,curator-framework,curator-recipes与Spring Cloud组件中的curator-client,curator-framework,curator-recipes有版本冲突，在启动过程会报如下错误： 12018-07-06 18:19:34.403 | epms | WARN | IP: | main | AnnotationConfigServletWebServerApplicationContext | 558 | refresh | Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name &apos;reqAspect&apos; defined in file [/home/ybd/data/git-repo/bitbucket/epms/epms-core/target/classes/com/yanglaoban/epms/core/aop/ReqAspect.class]: Unsatisfied dependency expressed through constructor parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name &apos;disruptorConfig&apos;: Injection of resource dependencies failed; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name &apos;delayHandler&apos; defined in file [/home/ybd/data/git-repo/bitbucket/epms/epms-core/target/classes/com/yanglaoban/epms/core/pubsub/disruptor/handler/DelayHandler.class]: Unsatisfied dependency expressed through constructor parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name &apos;delayService&apos; defined in file [/home/ybd/data/git-repo/bitbucket/epms/epms-core/target/classes/com/yanglaoban/epms/core/domain/service/DelayService.class]: Unsatisfied dependency expressed through constructor parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name &apos;elasticJobService&apos; defined in file [/home/ybd/data/git-repo/bitbucket/epms/epms-core/target/classes/com/yanglaoban/epms/core/elasticjob/ElasticJobService.class]: Unsatisfied dependency expressed through constructor parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name &apos;regCenter&apos; defined in class path resource [com/yanglaoban/epms/core/elasticjob/config/ElasticJobConfig.class]: Invocation of init method failed; nested exception is java.lang.NoClassDefFoundError: org/apache/curator/connection/StandardConnectionHandlingPolicy 解决方式是排除Elastic Job中curator相关依赖，重新导入： 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;properties&gt; &lt;elastic-job.version&gt;2.1.5&lt;/elastic-job.version&gt; &lt;curator.version&gt;2.10.0&lt;/curator.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.dangdang&lt;/groupId&gt; &lt;artifactId&gt;elastic-job-lite-core&lt;/artifactId&gt; &lt;version&gt;$&#123;elastic-job.version&#125;&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;curator-client&lt;/artifactId&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;artifactId&gt;curator-framework&lt;/artifactId&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;artifactId&gt;curator-recipes&lt;/artifactId&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-framework&lt;/artifactId&gt; &lt;version&gt;$&#123;curator.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-client&lt;/artifactId&gt; &lt;version&gt;$&#123;curator.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-recipes&lt;/artifactId&gt; &lt;version&gt;$&#123;curator.version&#125;&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt;]]></content>
      <categories>
        <category>Programming</category>
        <category>Java</category>
        <category>Spring Boot</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring Boot</tag>
        <tag>Scheduler</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis拾遗与Spring Boot整合]]></title>
    <url>%2F2018%2Fspring-boot-learning-redis%2F</url>
    <content type="text"><![CDATA[Preface Redis是一个开源的使用ANSI C语言编写、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库, 并提供多种语言的API. 相比Memcached它支持存储的类型相对更多（字符、哈希、集合、有序集合、列表、GEO）, 同时Redis是线程安全的. 2010年3月15日起, Redis的开发工作由VMware主持, 2013年5月开始, Redis的开发由Pivotal赞助. 安装与配置安装基于Docker安装拉取镜像: 1docker pull redis:latest 运行实例: 123456REDIS=/home/ybd/data/docker/redis &amp;&amp; \docker run -p 6379:6379 --restart=always \-v $REDIS/redis.conf:/usr/local/etc/redis/redis.conf \-v $REDIS/data:/data \--name redis -d redis \redis-server /usr/local/etc/redis/redis.conf --appendonly yes 安装链接工具: 1234sudo apt install redis-tools// 连接redis-cli -h 127.0.0.1 -p 6379 或者docker-compose启动: 12345678910111213141516171819202122version: &apos;3&apos;services: redis: image: redis:latest# command: [&quot;redis-server&quot;, &quot;--appendonly&quot;, &quot;yes&quot;] command: [&quot;redis-server&quot;, &quot;/usr/local/etc/redis/redis.conf&quot;] restart: always ports: - &quot;6379:6379&quot; networks: backend-swarm: aliases: - redis volumes: - ./data:/data - ./config/redis.conf:/usr/local/etc/redis/redis.conf# docker network create -d=overlay --attachable backendnetworks: backend-swarm: external: name: backend-swarm Ubuntu Apt安装终端执行:1234567sudo apt update &amp;&amp; sudo apt install redis-server# 启动redis-server# 连接redis-cli -h 127.0.0.1 -p 6379 配置相关 稳定版本配置文件: http://download.redis.io/redis-stable/redis.conf /etc/redis: 存放redis配置文件/var/redis/端口号: 存放redis的持久化文件 通过下面的命令停止/启动/重启redis:123/etc/init.d/redis-server stop/etc/init.d/redis-server start/etc/init.d/redis-server restart 如果是通过源码安装的redis, 则可以通过redis的客户端程序redis-cli的shutdown命令来重启redis1redis-cli -h 127.0.0.1 -p 6379 shutdown 如果上述方式都没有成功停止redis, 则可以使用终极武器 kill -9 开启远程访问找到redis.conf文件, 一般在/etc下面: 找到bind 127.0.0.1注释掉注释掉本机,局域网内的所有计算机都能访问.band localhost 只能本机访问,局域网内计算机不能访问.bind 局域网IP 只能局域网内IP的机器访问, 本地localhost都无法访问. 博主选择将bind 127.0.0.1 改成了bind 0.0.0.0 开启发布订阅监听 Redis自2.8.0之后版本提供Keyspace Notifications功能, 允许客户订阅Pub / Sub频道, 以便以某种方式接收影响Redis数据集的事件. Redis默认关闭, 键空间通知通常是不启用的, 因为这个过程会产生额外消耗 还是修改redis.conf文件, 找到notify-keyspace-events &quot;&quot;, 修改为notify-keyspace-events Ex或者notify-keyspace-events AKE, 然后重启. 字符 发送通知 K 键空间通知, 所有通知以 keyspace@ 为前缀, 针对Key E 键事件通知, 所有通知以 keyevent@ 为前缀, 针对event g DEL 、 EXPIRE 、 RENAME 等类型无关的通用命令的通知 $ 字符串命令的通知 l 列表命令的通知 s 集合命令的通知 h 哈希命令的通知 z 有序集合命令的通知 x 过期事件: 每当有过期键被删除时发送 e 驱逐(evict)事件: 每当有键因为 maxmemory 政策而被删除时发送 A 参数 g$lshzxe 的别名, 相当于是All SUBSCRIBE与PSUBSCRIBE都可以订阅事件, 后者可以通过正则表达匹配对应的Channel, 比如__keyevent*__:expired订阅所有数据库的过期事件 打开一个终端订阅key过期事件: 12345192.168.6.113:6379&gt; PSUBSCRIBE __keyevent*__:expiredReading messages... (press Ctrl-C to quit)1) &quot;psubscribe&quot;2) &quot;__keyevent*__:expired&quot;3) (integer) 1 再开一个终端设置一个会过期的kv: 12192.168.6.113:6379&gt; set test ybd EX 10OK 10秒后在第一个终端将会受到如下信息: 12341) &quot;pmessage&quot;2) &quot;__keyevent*__:expired&quot;3) &quot;__keyevent@0__:expired&quot;4) &quot;test&quot; GUIhttps://github.com/uglide/RedisDesktopManager https://rdbtools.com/ Redis常用命令 最新命令参考: http://redisdoc.com 连接操作命令 quit: 关闭连接（connection） auth: 简单密码认证 help cmd: 查看cmd帮助, 例如: help quit 持久化 save: 将数据同步保存到磁盘 bgsave: 将数据异步保存到磁盘 lastsave: 返回上次成功将数据保存到磁盘的Unix时戳 shutdown: 将数据同步保存到磁盘, 然后关闭服务 远程服务控制 info: 提供服务器的信息和统计 monitor: 实时转储收到的请求 slaveof: 改变复制策略设置 config: 在运行时配置Redis服务器 对key操作的命令 exists(key): 确认一个key是否存在 del(key): 删除一个key type(key): 返回值的类型 keys(pattern): 返回满足给定pattern的所有key randomkey: 随机返回key空间的一个 keyrename(oldname, newname): 重命名key dbsize: 返回当前数据库中key的数目 expire: 设定一个key的活动时间（s） ttl: 获得一个key的活动时间 select(index): 按索引查询 move(key, dbindex): 移动当前数据库中的key到dbindex数据库 flushdb: 删除当前选择数据库中的所有key flushall: 删除所有数据库中的所有key String set(key, value [EX seconds] [PX milliseconds] [NX|XX]): 给数据库中名称为key的string赋予值value, EX与PX都是过期时间, 前者是秒为单位, 后者是毫秒, NX表示当key不存在时赋值, XX表示当key存在时赋值 get(key): 返回数据库中名称为key的string的value getset(key, value): 给名称为key的string赋予上一次的value mget(key1, key2,…, key N): 返回库中多个string的value setnx(key, value): 添加string, 名称为key, 值为value setex(key, time, value): 向库中添加string, 设定过期时间time mset(key N, value N): 批量设置多个string的值 msetnx(key N, value N): 如果所有名称为key i的string都不存在 incr(key): 名称为key的string增1操作 incrby(key, integer): 名称为key的string增加integer decr(key): 名称为key的string减1操作 decrby(key, integer): 名称为key的string减少integer append(key, value): 名称为key的string的值附加value substr(key, start, end): 返回名称为key的string的value的子串 List rpush(key, value): 在名称为key的list尾添加一个值为value的元素 lpush(key, value): 在名称为key的list头添加一个值为value的 元素 llen(key): 返回名称为key的list的长度 lrange(key, start, end): 返回名称为key的list中start至end之间的元素 ltrim(key, start, end): 截取名称为key的list lindex(key, index): 返回名称为key的list中index位置的元素 lset(key, index, value): 给名称为key的list中index位置的元素赋值 lrem(key, count, value): 删除count个key的list中值为value的元素 lpop(key): 返回并删除名称为key的list中的首元素 rpop(key): 返回并删除名称为key的list中的尾元素 blpop(key1, key2,… key N, timeout): lpop命令的block版本. brpop(key1, key2,… key N, timeout): rpop的block版本. rpoplpush(srckey, dstkey): 返回并删除名称为srckey的list的尾元素, 并将该元素添加到名称为dstkey的list的头部 Set sadd(key, member): 向名称为key的set中添加元素member srem(key, member) : 删除名称为key的set中的元素member spop(key) : 随机返回并删除名称为key的set中一个元素 smove(srckey, dstkey, member) : 移到集合元素 scard(key) : 返回名称为key的set的基数 sismember(key, member) : member是否是名称为key的set的元素 sinter(key1, key2,…key N) : 求交集 sinterstore(dstkey, (keys)) : 求交集并将交集保存到dstkey的集合 sunion(key1, (keys)) : 求并集 sunionstore(dstkey, (keys)) : 求并集并将并集保存到dstkey的集合 sdiff(key1, (keys)) : 求差集 sdiffstore(dstkey, (keys)) : 求差集并将差集保存到dstkey的集合 smembers(key) : 返回名称为key的set的所有元素 srandmember(key) : 随机返回名称为key的set的一个元素 Hash hset(key, field, value): 向名称为key的hash中添加元素field hget(key, field): 返回名称为key的hash中field对应的value hmget(key, (fields)): 返回名称为key的hash中field i对应的value hmset(key, (fields)): 向名称为key的hash中添加元素field hincrby(key, field, integer): 将名称为key的hash中field的value增加integer hexists(key, field): 名称为key的hash中是否存在键为field的域 hdel(key, field): 删除名称为key的hash中键为field的域 hlen(key): 返回名称为key的hash中元素个数 hkeys(key): 返回名称为key的hash中所有键 hvals(key): 返回名称为key的hash中所有键对应的value hgetall(key): 返回名称为key的hash中所有的键（field）及其对应的value 不同数据类型的常见应用场景 为缓存而生的Redis, 其所有数据都在内存中, 固其最大的应用场景就是缓存了, 但这只是个大的概念, 其不同的数据类型都有对应的应用场景. String对象存储这应该是最最最常用的场景了, 将对象序列化后再set进去, 所以选择一个好的序列化方案很重要, 需要从时间复杂度以及空间复杂度这两个维度综合考虑. 个人觉得Protostuff选当不错, 基于Google的Protobuff. 详情请看下面的序列化一节. 计数INCRBY可以原子性地递增, 通常用作分布式计数器, 也可以用作生成ID. 分布式锁正由于Redis是单线程客户端, 这不单单是一个特性, 更是一个应用场景, 最常用的就是分布式锁了. 1SET key value [EX seconds] [PX milliseconds] [NX|XX] 利用上面命令, 可以做到加锁与过期的原子性. 释放锁可以利用LUA脚本完成: 123456if redis.call(&quot;get&quot;,KEYS[1]) == ARGV[1]then return redis.call(&quot;del&quot;,KEYS[1])else return 0end 超大数量的布尔统计比如要统计几亿人的在线情况、数十亿的布尔存储（布尔标识符）都可以使用GETBIT、SETBIT、BITCOUNT来完成. List显示最新的分页列表一种很常见的需求, 分页, 比如列出最新的5页评论、列出最新的某活动5页商品, 在QPS高的时候, 采用传统的RDBS查询往往会有性能问题. BUT, 结合Redis的LPUSH与LTRIM可以优雅地缓存最新的数据并做到分页, 一般大部分用户只关注前几页数据, 那么后面的数据可以用数据库补上. 这时候前5页的数据是走缓存的, QPS可以提高几个数量级 消息队列Redis 的 list 数据类型对于大部分使用者来说, 是实现队列服务的最经济, 最简单的方式. Set共同好友列表（求交集系列）社交类应用中, 获取两个人或多个人的共同好友, 两个人或多个人共同关注的微博这样类似的功能, 用 MySQL 的话操作很复杂, 可以把每个人的好友 id 存到集合中, 获取共同好友的操作就可以简单到一个取交集的命令就搞定. 123456789101112131415161718sadd user:wade james melo paul kobesadd user:james wade melo paul kobesadd user:paul wade james melo kobesadd user:melo wade james paul kobe// 获取 wade 和 james 的共同好友sinter user:wade user:james/* 输出: * 1) &quot;kobe&quot; * 2) &quot;paul&quot; * 3) &quot;melo&quot; */ // 获取香蕉四兄弟的共同好友 sinter user:wade user:james user:paul user:melo /* 输出: * 1) &quot;kobe&quot; */ 类似的需求还有很多 , 必须把每个标签下的文章 id 存到集合中, 可以很容易的求出几个不同标签下的共同文章； 把每个人的爱好存到集合中, 可以很容易的求出几个人的共同爱好. SortedSet排行榜SortedSet 是在 Set 的基础上给集合中每个元素关联了一个分数, 往有序集合中插入数据时会自动根据这个分数排序, 很适合排行榜之类的需求: – 列出前100名高分选手 – 列出某用户当前的全球排名 慢查询查看 Redis 通过 slowlog-log-slower-than 和 slowlog-max-len 分别配置慢查询的阈值, 以及慢查询记录的日志长度. slowlog-log-slower-than 默认值 101000 *微秒, 当命令执行时间查过设定时, 那么将会被记录在慢查询日志中. 如果slowlog-log-slower-than=0会记录所有的命令, slowlog-log-slower-than&lt;0 对于任何命令都不会进行记录. 参数设定: 123config set slowlog-log-slower-than 20000config set slowlog-max-len 1000config rewrite 如果要 Redis 将配置持久化到本地配置文件, 需要执行 config rewrite 命令. 获取慢查询日志: 1slowlog get [n] // n 表示返回的日志记录条数 每个慢查询日志有 4 个属性组成, 分别是慢查询日志的标识 id、发生时间戳、命令耗时、执行命令和参数, 慢查询列表如下: 123456789127.0.0.1:6378&gt; slowlog get1) 1) (integer) 0 //标识 id 2) (integer) 1501750261 //时间戳 3) (integer) 19 // 命令耗时 4) 1) &quot;config&quot; // 执行命令 2) &quot;set&quot; 3) &quot;slowlog-log-slower-than&quot; 4) &quot;0&quot;127.0.0.1:6378&gt; 获取慢查询日志列表当前的长度: 123127.0.0.1:6378&gt; slowlog len(integer) 2127.0.0.1:6378&gt; 慢查询最佳实践 slowlog-max-len 配置建议: 线上建议调大慢查询列表, 记录慢查询时 Redis 会对长命令做截断操作, 并不会占用大量内存. 增大慢查询列表可以减缓慢查询被剔除的可能, 例如线上可设置为 1000 以上. slowlog-log-slower-than 配置建议: 默认值超过 10 毫秒判定为慢查询, 需要根据 Redis 并发量调整该值. 由于 Redis 采用单线程响应命令, 对于高流量的场景, 如果命令执行时间在 1 毫秒以上, 那么 Redis 最多可支撑 OPS 不到 1000. 因此对于高 OPS （operation per second）场景的 Redis 建议设置为 1 毫秒. 慢查询只记录命令执行时间, 并不包括命令排队和网络传输时间. 因此客户端执行命令的时间会大于命令实际执行时间. 因为命令执行排队机制, 慢查询会导致其他命令级联阻塞, 因此当客户端出现请求超时, 需要检查该时间点是否有对应的慢查询, 从而分析出是否为慢查询导致的命令级联阻塞. 由于慢查询日志是一个先进先出的队列, 也就是说如果慢查询比较多的情况下, 可能会丢失部分慢查询命令, 为了防止这种情况发生, 可以定期执行 slow get 命令将慢查询日志持久化到其他存储中（例如 MySQL）, 然后可以制作可视化界面进行查询. rdb文件分析redis-rdb-toolshttps://github.com/sripathikrishnan/redis-rdb-tools rdr https://github.com/xueqiu/rdr 首先查看Redis的dump目录设置: 1CONFIG GET dir 再使用bgsave命令导出dump.rdb, 将dump.rdb复制出来, 再使用 rdr 分析: 1./rdr show -p 8080 *.rdb 效果图: Spring Boot整合核心依赖123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt;&lt;/dependency&gt; 使用连接池需要用到commons-pool2 配置12345678910111213141516spring: redis: host: 127.0.0.1 port: 6379 lettuce: pool: #最大连接数 max-active: 128 #最大阻塞等待时间(负数表示没限制) max-wait: 5s #最大空闲 max-idle: 16 #最小空闲 min-idle: 0 #连接超时时间 timeout: 10s 客户端序列化选择 https://github.com/masteranthoneyd/serializer 以下是序列化框架性能对比（纳秒） 操作系统: Ubuntu 18.04 64位 CPU: I7-8700 内存: 32G Protostuff不能直接序列化集合, 需要用包装类封装起来. String类型还是建议直接使用StringRedisSerializer, 速度最快. Spring监听Redis Keyspace Event在Spring Boot应用中, 可使用方式一和二, 集成非常快. 1234567891011121314151617&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; 方式一、通过RedisMessageListenerContainer这个类是使用线程池监听并执行后续动作的, 可以添加多个监听者. 配置类: 123456789101112131415@Configurationpublic class RedisConfig &#123; @Resource private LettuceConnectionFactory lettuceConnectionFactory @Bean public RedisMessageListenerContainer redisMessageListenerContainer() &#123; RedisMessageListenerContainer redisMessageListenerContainer = new RedisMessageListenerContainer(); redisMessageListenerContainer.setConnectionFactory(lettuceConnectionFactory); redisMessageListenerContainer.addMessageListener(new KeyExpireListener(), new PatternTopic("__keyevent@*__:expired")); return redisMessageListenerContainer; &#125;&#125; 监听类: 123456789public class KeyExpireListener implements MessageListener &#123; private RedisSerializer&lt;String&gt; stringRedisSerializer = new StringRedisSerializer(); @Override public void onMessage(Message message, byte[] pattern) &#123; Thread thread = Thread.currentThread(); System.out.println(thread.getId() + " " + thread.getName() + " -&gt; " + stringRedisSerializer.deserialize(pattern) + ": " + message); &#125;&#125; 如此简单的几行代码就可以监听Redis Key过期事件, 但RedisMessageListenerContainer默认使用SimpleAsyncTaskExecutor作为线程池, 这个线程池比较坑的地方在于每次都是用新的线程去执行任务, 不重用线程, 不是真正意义上的线程池. 方式二、监听RedisKeyspaceEvent通过创建并注册KeyExpirationEventMessageListener, 监听到过期事件后, 会发布一个RedisKeyExpiredEvent. KeyExpirationEventMessageListener继承KeyspaceEventMessageListener, KeyspaceEventMessageListener实现MessageListener, 在onMessage(...)方法中提供了doHandleMessage(message)抽象方法, 最终由KeyExpirationEventMessageListener实现. 配之类: 12345678910111213141516171819@Configurationpublic class RedisConfig &#123; @Resource private LettuceConnectionFactory lettuceConnectionFactory; @Bean public KeyExpirationEventMessageListener keyExpirationEventMessageListener() &#123; return new KeyExpirationEventMessageListener(redisMessageListenerContainer()); &#125; @Bean public RedisMessageListenerContainer redisMessageListenerContainer() &#123; RedisMessageListenerContainer redisMessageListenerContainer = new RedisMessageListenerContainer(); redisMessageListenerContainer.setConnectionFactory(lettuceConnectionFactory); return redisMessageListenerContainer; &#125;&#125; 事件监听类: 1234567@Componentpublic class KeyExpireApplicationEventListener implements ApplicationListener&lt;RedisKeyExpiredEvent&gt; &#123; @Override public void onApplicationEvent(RedisKeyExpiredEvent event) &#123; System.out.println(event); &#125;&#125; 实际上KeyExpirationEventMessageListener也是MessageListener的实现, 最终还是由RedisMessageListenerContainer管理, 没有设置线程池的话, 还是使用SimpleAsyncTaskExecutor. . . 两种方式最终都是RedisPubSubCommands.pSubscribe(MessageListener listener, byte[]... patterns); 方式三、结合Disruptor上面两种方式操作简单, 但是如果每天有上千万的过期通知, 在一个链接的情况下可能会影响吞吐量, 某些业务处理比较慢, 阻塞后面的通知, 这种情况下我们可以结合高性能队列框架Disruptor异步处理. 先定义Event: 123456789101112131415161718192021222324252627282930313233343536373839import org.springframework.data.redis.connection.Message;/** * @author ybd * @date 18-10-19 * @contact yangbingdong1994@gmail.com */public class RedisKeyExpireEvent implements CleanEvent &#123; private Message message; private byte[] pattern; public Message getMessage() &#123; return message; &#125; public RedisKeyExpireEvent setMessage(Message message) &#123; this.message = message; return this; &#125; public byte[] getPattern() &#123; return pattern; &#125; public RedisKeyExpireEvent setPattern(byte[] pattern) &#123; this.pattern = pattern; return this; &#125; @Override public void clean() &#123; this.message = null; this.pattern = null; &#125;&#125;public interface CleanEvent &#123; void clean();&#125; 这个Event是由用户自己定义的. 定义Event处理类: 12345678910111213141516171819202122232425import com.lmax.disruptor.WorkHandler;import lombok.extern.slf4j.Slf4j;import org.springframework.data.redis.serializer.RedisSerializer;import org.springframework.data.redis.serializer.StringRedisSerializer;import org.springframework.stereotype.Component;/** * @author ybd * @date 18-10-19 * @contact yangbingdong1994@gmail.com */@Slf4j@Componentpublic class RedisKeyExpireEventHandler implements WorkHandler&lt;RedisKeyExpireEvent&gt; &#123; private RedisSerializer&lt;String&gt; stringRedisSerializer = new StringRedisSerializer(); @Override public void onEvent(RedisKeyExpireEvent event) &#123; try &#123; Thread thread = Thread.currentThread(); log.info(thread.getId() + " " + thread.getName() + " -&gt; " + stringRedisSerializer.deserialize(event.getPattern()) + ": " + event.getMessage()); &#125; finally &#123; event.clean(); &#125; &#125;&#125; 实现的是WorkHandler而不是EventHandler, 因为我们调用的是disruptor.handleEventsWithWorkerPool, 区别是WorkerPool可以达到Sharding的效果. 异常处理类: 12345678910111213141516171819202122232425262728import com.lmax.disruptor.ExceptionHandler;import lombok.extern.slf4j.Slf4j;import org.springframework.data.redis.serializer.StringRedisSerializer;/** * @author ybd * @date 18-10-19 * @contact yangbingdong1994@gmail.com */@Slf4jpublic class RedisKeyExpireEventExceptionHandler implements ExceptionHandler&lt;RedisKeyExpireEvent&gt; &#123; private StringRedisSerializer strSerial = new StringRedisSerializer(); @Override public void handleEventException(Throwable ex, long sequence, RedisKeyExpireEvent event) &#123; String msgBody = strSerial.deserialize(event.getMessage().getBody()); log.error("处理Redis Key过期事件失败: " + msgBody, ex); &#125; @Override public void handleOnStartException(Throwable ex) &#123; log.error("Disruptor&lt;RedisKeyExpireEvent&gt; handleOnStartException:", ex); &#125; @Override public void handleOnShutdownException(Throwable ex) &#123; log.error("Disruptor&lt;RedisKeyExpireEvent&gt; handleOnShutdownException:", ex); &#125;&#125; 用于发布事件的Disruptor: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566import com.lmax.disruptor.BlockingWaitStrategy;import com.lmax.disruptor.EventTranslatorTwoArg;import com.lmax.disruptor.RingBuffer;import com.lmax.disruptor.dsl.Disruptor;import com.lmax.disruptor.dsl.ProducerType;import lombok.extern.slf4j.Slf4j;import org.springframework.beans.factory.InitializingBean;import org.springframework.context.ApplicationListener;import org.springframework.context.event.ContextClosedEvent;import org.springframework.data.redis.connection.Message;import org.springframework.stereotype.Component;import javax.annotation.Resource;import java.util.stream.IntStream;/** * @author ybd * @date 18-10-19 * @contact yangbingdong1994@gmail.com */@Slf4j@Componentpublic class RedisKeyExpireDisruptor implements InitializingBean, ApplicationListener&lt;ContextClosedEvent&gt; &#123; private static final int TOTAL_SHARDING = 1 &lt;&lt; 2; private Disruptor&lt;RedisKeyExpireEvent&gt; disruptor; private EventTranslatorTwoArg&lt;RedisKeyExpireEvent, Message, byte[]&gt; translatorTwoArg; private RingBuffer&lt;RedisKeyExpireEvent&gt; ringBuffer; @Resource private RedisKeyExpireEventHandler redisKeyExpireEventHandler; @Override public void afterPropertiesSet() &#123; initDisruptor(); RedisKeyExpireEventHandler[] handlers = buildHandler(); disruptor.handleEventsWithWorkerPool(handlers); disruptor.start(); ringBuffer = disruptor.getRingBuffer(); translatorTwoArg = (event, sequence, message, pattern) -&gt; event.setMessage(message).setPattern(pattern); log.info("RedisKeyExpireDisruptor initialized"); &#125; private RedisKeyExpireEventHandler[] buildHandler() &#123; return IntStream.range(0, TOTAL_SHARDING) .mapToObj(i -&gt; redisKeyExpireEventHandler) .toArray(RedisKeyExpireEventHandler[]::new); &#125; private void initDisruptor() &#123; disruptor = new Disruptor&lt;&gt;(RedisKeyExpireEvent::new, 1 &lt;&lt; 10, DisruptorUtil.getThreadFactory("keyspace-disruptor-%d"), ProducerType.SINGLE, new BlockingWaitStrategy()); disruptor.setDefaultExceptionHandler(new RedisKeyExpireEventExceptionHandler()); &#125; @Override public void onApplicationEvent(ContextClosedEvent event) &#123; DisruptorUtil.shutDownDisruptor(disruptor); &#125; public void publish(Message message, byte[] pattern) &#123; ringBuffer.publishEvent(translatorTwoArg, message, pattern); &#125;&#125; 工具类: 12345678910111213141516171819202122232425262728293031import com.lmax.disruptor.TimeoutException;import com.lmax.disruptor.dsl.Disruptor;import lombok.extern.slf4j.Slf4j;import org.apache.commons.lang3.concurrent.BasicThreadFactory;import java.util.concurrent.TimeUnit;/** * @author ybd * @date 18-9-29 * @contact yangbingdong1994@gmail.com */@Slf4jpublic final class DisruptorUtil &#123; public static BasicThreadFactory getThreadFactory(String pattern) &#123; return new BasicThreadFactory.Builder().namingPattern(pattern) .daemon(true) .build(); &#125; public static void shutDownDisruptor(Disruptor disruptor) &#123; if (disruptor != null) &#123; try &#123; disruptor.shutdown(5, TimeUnit.SECONDS); &#125; catch (TimeoutException e) &#123; log.error("Disruptor shutdown error!", e); &#125; &#125; &#125;&#125; 效果图: 缺点 Timing of expired eventsKeys with a time to live associated are expired by Redis in two ways: When the key is accessed by a command and is found to be expired. Via a background system that looks for expired keys in background, incrementally, in order to be able to also collect keys that are never accessed. The expired events are generated when a key is accessed and is found to be expired by one of the above systems, as a result there are no guarantees that the Redis server will be able to generate the expired event at the time the key time to live reaches the value of zero. If no command targets the key constantly, and there are many keys with a TTL associated, there can be a significant delay between the time the key time to live drops to zero, and the time the expired event is generated. Basically expired events are generated when the Redis server deletes the key and not when the time to live theoretically reaches the value of zero. 上面是官方文档的原文, 在删除key的时候发送事件, 而删除key不是实时的, 而是后台逐步删除的, 所有可能会与TTL时间存在误差. 在客户端链接丢失期间（比如项目迭代发布版本）, 也是会丢失消息的.]]></content>
      <categories>
        <category>Programming</category>
        <category>Java</category>
        <category>Spring Boot</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式锁的几种实现方式]]></title>
    <url>%2F2018%2Fdistribution-lock%2F</url>
    <content type="text"><![CDATA[Preface 在现代互联网, 通常都是伴随着分布式、高并发等, 在某些业务中例如下订单扣减库存, 如果不对库存资源做临界处理, 在并发量大的时候会出现库存不准确的情况. 在单个服务的情况下可以通过Java自带的一些锁对临界资源进行处理, 例如synchronized、Reentrantlock, 甚至是通过无锁技术（比如RangeBuffer）都可以实现同一个JVM内的锁. But, 在能够弹性伸缩的分布式环境下, Java内置的锁显然不能够满足需求, 需要借助外部进程实现分布式锁. 几种实现方式分布式环境下, 数据一致性问题一直是一个比较重要的话题, 而又不同于单进程的情况. 分布式与单机情况下最大的不同在于其不是多线程而是多进程. 多线程由于可以共享堆内存, 因此可以简单的采取内存作为标记存储位置. 而进程之间甚至可能都不在同一台物理机上, 因此需要将标记存储在一个所有进程都能看到的地方. 常见的是秒杀场景, 订单服务部署了多个实例. 如秒杀商品有4个, 第一个用户购买3个, 第二个用户购买2个, 理想状态下第一个用户能购买成功, 第二个用户提示购买失败, 反之亦可. 而实际可能出现的情况是, 两个用户都得到库存为4, 第一个用户买到了3个, 更新库存之前, 第二个用户下了2个商品的订单, 更新库存为2, 导致出错. 在上面的场景中, 商品的库存是共享变量, 面对高并发情形, 需要保证对资源的访问互斥. 在单机环境中, Java中其实提供了很多并发处理相关的API, 但是这些API在分布式场景中就无能为力了. 也就是说单纯的Java API并不能提供分布式锁的能力. 分布式系统中, 由于分布式系统的分布性, 即多线程和多进程并且分布在不同机器中, synchronized和lock这两种锁将失去原有锁的效果, 需要我们自己实现分布式锁. 常见的锁方案如下: 基于数据库实现分布式锁（基本用来玩的） 基于缓存, 实现分布式锁, 如Redis（业界常用方式） 基于Zookeeper实现分布式锁（性能低） 下面我们简单介绍下这几种锁的实现. 基于数据库 虽然这种方式基本上不会被用于生产环境 基于数据库的锁实现也有两种方式, 一是基于数据库表, 另一种是基于数据库排他锁. 基于数据库表的增删基于数据库表增删是最简单的方式, 首先创建一张锁的表主要包含下列字段: 方法名, 时间戳等字段. 具体使用的方法, 当需要锁住某个方法时, 往该表中插入一条相关的记录. 这边需要注意, 方法名是有唯一性约束的, 如果有多个请求同时提交到数据库的话, 数据库会保证只有一个操作可以成功, 那么我们就可以认为操作成功的那个线程获得了该方法的锁, 可以执行方法体内容. 执行完毕, 需要delete该记录. 当然, 这边只是简单介绍一下. 对于上述方案可以进行优化, 如应用主从数据库, 数据之间双向同步. 一旦挂掉快速切换到备库上；做一个定时任务, 每隔一定时间把数据库中的超时数据清理一遍；使用while循环, 直到insert成功再返回成功, 虽然并不推荐这样做；还可以记录当前获得锁的机器的主机信息和线程信息, 那么下次再获取锁的时候先查询数据库, 如果当前机器的主机信息和线程信息在数据库可以查到的话, 直接把锁分配给他就可以了, 实现可重入锁. 可重入锁: 可以再次进入方法A, 就是说在释放锁前此线程可以再次进入方法A（方法A递归）. 不可重入锁（自旋锁）: 不可以再次进入方法A, 也就是说获得锁进入方法A是此线程在释放锁钱唯一的一次进入方法A. 基于数据库排他锁我们还可以通过数据库的排他锁来实现分布式锁. 基于MySql的InnoDB引擎, 可以使用以下方法来实现加锁操作: 12345678910111213141516171819public void lock()&#123; connection.setAutoCommit(false) int count = 0; while(count &lt; 4)&#123; try&#123; select * from lock where lock_name=xxx for update; if(结果不为空)&#123; //代表获取到锁 return; &#125; &#125;catch(Exception e)&#123; &#125; //为空或者抛异常的话都表示没有获取到锁 sleep(1000); count++; &#125; throw new LockException();&#125; 在查询语句后面增加for update, 数据库会在查询过程中给数据库表增加排他锁. 当某条记录被加上排他锁之后, 其他线程无法再在该行记录上增加排他锁. 其他没有获取到锁的就会阻塞在上述select语句上, 可能的结果有2种, 在超时之前获取到了锁, 在超时之前仍未获取到锁. 获得排它锁的线程即可获得分布式锁, 当获取到锁之后, 可以执行方法的业务逻辑, 执行完方法之后, 释放锁connection.commit(). 存在的问题主要是性能不高和sql超时的异常. 基于数据库锁的优缺点上面两种方式都是依赖数据库的一张表, 一种是通过表中的记录的存在情况确定当前是否有锁存在, 另外一种是通过数据库的排他锁来实现分布式锁. 优点是直接借助数据库, 简单容易理解. 缺点是操作数据库需要一定的开销, 性能问题需要考虑. 基于Zookeeper基于Zookeeper临时有序节点可以实现的分布式锁. 每个客户端对某个方法加锁时, 在Zookeeper上的与该方法对应的指定节点的目录下, 生成一个唯一的瞬时有序节点. 判断是否获取锁的方式很简单, 只需要判断有序节点中序号最小的一个. 当释放锁的时候, 只需将这个瞬时节点删除即可. 同时, 其可以避免服务宕机导致的锁无法释放, 而产生的死锁问题. 提供的第三方库有curator, 具体使用读者可以自行去看一下. Curator提供的InterProcessMutex是分布式锁的实现. acquire方法获取锁, release方法释放锁. 另外, 锁释放、阻塞锁、可重入锁等问题都可以有有效解决. 讲下阻塞锁的实现, 客户端可以通过在ZK中创建顺序节点, 并且在节点上绑定监听器, 一旦节点有变化, Zookeeper会通知客户端, 客户端可以检查自己创建的节点是不是当前所有节点中序号最小的, 如果是就获取到锁, 便可以执行业务逻辑. 根据Zookeeper的这些特性, 我们来看看如何利用这些特性来实现分布式锁: 创建一个锁目录lock 线程A获取锁会在lock目录下, 创建临时顺序节点 获取锁目录下所有的子节点, 然后获取比自己小的兄弟节点, 如果不存在, 则说明当前线程顺序号最小, 获得锁 线程B创建临时节点并获取所有兄弟节点, 判断自己不是最小节点, 设置监听(watcher)比自己次小的节点 线程A处理完, 删除自己的节点, 线程B监听到变更事件, 判断自己是最小的节点, 获得锁 最后, Zookeeper实现的分布式锁其实存在一个缺点, 那就是性能上可能并没有缓存服务那么高. 因为每次在创建锁和释放锁的过程中, 都要动态创建、销毁瞬时节点来实现锁功能. ZK中创建和删除节点只能通过Leader服务器来执行, 然后将数据同不到所有的Follower机器上. 并发问题, 可能存在网络抖动, 客户端和ZK集群的session连接断了, zk集群以为客户端挂了, 就会删除临时节点, 这时候其他客户端就可以获取到分布式锁了. 下面是简单例子: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class CuratorTest &#123; private static String address = &quot;127.0.0.1:2181&quot;; public static void main(String[] args) &#123; RetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3); CuratorFramework client = CuratorFrameworkFactory.newClient(address, retryPolicy); client.start(); //创建分布式锁, 锁空间的根节点路径为/curator/lock InterProcessMutex mutex = new InterProcessMutex(client, &quot;/curator/lock&quot;); ExecutorService fixedThreadPool = Executors.newFixedThreadPool(5); CompletionService&lt;Object&gt; completionService = new ExecutorCompletionService&lt;&gt;(fixedThreadPool); for (int i = 0; i &lt; 5; i++) &#123; completionService.submit(() -&gt; &#123; boolean flag = false; try &#123; //尝试获取锁, 最多等待5秒 flag = mutex.acquire(5, TimeUnit.SECONDS); Thread currentThread = Thread.currentThread(); if (flag) &#123; System.out.println(&quot;线程&quot; + currentThread.getId() + &quot;获取锁成功&quot;); &#125; else &#123; System.out.println(&quot;线程&quot; + currentThread.getId() + &quot;获取锁失败&quot;); &#125; //模拟业务逻辑, 延时4秒 Thread.sleep(4000); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; if (flag) &#123; try &#123; mutex.release(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125; return null; &#125;); &#125; // 等待线程跑完 int count = 0; while (count &lt; 5) &#123; if (completionService.poll() != null) &#123; count++; &#125; &#125; System.out.println(&quot;========= Complete!&quot;); client.close(); fixedThreadPool.shutdown(); &#125;&#125; 基于缓存相对于基于数据库实现分布式锁的方案来说, 基于缓存来实现在性能方面会表现的更好一点, 存取速度快很多. 而且很多缓存是可以集群部署的, 可以解决单点问题. 基于缓存的锁有好几种, 如Memcached、Redis, 下面主要讲解基于Redis的分布式实现. 基于Redis的分布式锁实现 首先, 为了确保分布式锁可用, 我们至少要确保锁的实现同时满足以下四个条件: 互斥性. 在任意时刻, 只有一个客户端能持有锁. 不会发生死锁. 即使有一个客户端在持有锁的期间崩溃而没有主动解锁, 也能保证后续其他客户端能加锁. 具有容错性. 只要大部分的Redis节点正常运行, 客户端就可以加锁和解锁. 解铃还须系铃人. 加锁和解锁必须是同一个客户端, 客户端自己不能把别人加的锁给解了. 基于Spring Data Redis下面是正确的实现姿势. （使用Spring Data Redis） 依赖123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt;&lt;/dependency&gt; 加锁姿势123456789@Autowiredprivate StringRedisTemplate stringRedisTemplate;private Boolean setNxEx(String key, String value) &#123; return stringRedisTemplate.execute((RedisCallback&lt;Boolean&gt;) connection -&gt; &#123; StringRedisConnection stringRedisConn = (StringRedisConnection) connection; return stringRedisConn.set(key, value, Expiration.from(1L, TimeUnit.MINUTES), SET_IF_ABSENT); &#125;);&#125; 执行上面的setNxEx()方法就只会导致两种结果: 当前没有锁（key不存在）, 那么就进行加锁操作, 并对锁设置个有效期, 同时value表示加锁的客户端. 已有锁存在, 不做任何操作. 网上有许多教程在加锁的步骤都不是原子性的, 有些是先加锁, 成功后再设置过期时间；有些将过期时间设置为value, 获取锁失败会判断value是否小于当前时间, 是则删除在设置新的值. 这些方法由于不是原子性, 在极端情况（比如多线程, 或者代码执行到某一行就宕机了等等）必然会导致锁失效或死锁等情况… 在上面stringRedisConn.set(...)方法中, 确保了上锁与设置过期时间的原子性. 解锁姿势配置类: 12345678@Beanpublic RedisScript&lt;Boolean&gt; releaseLockScript(DLockConfigProperty dLockConfigProperty) &#123; DefaultRedisScript&lt;Boolean&gt; redisScript = new DefaultRedisScript&lt;&gt;(); String scriptLocation = &quot;scripts/release_lock.lua&quot;; redisScript.setScriptSource(new ResourceScriptSource(new ClassPathResource(scriptLocation))); redisScript.setResultType(Boolean.class); return redisScript;&#125; Lua脚本: 12345if redis.call(&apos;GET&apos;, KEYS[1]) == ARGV[1] then return 1 == redis.call(&apos;DEL&apos;, KEYS[1])else return falseend 核心代码: 123456789@Resourceprivate StringRedisTemplate stringRedisTemplate;@Resourceprivate RedisScript&lt;Boolean&gt; script;public void release(String key, String value) &#123; stringRedisTemplate.execute(script, singletonList(key), value)&#125; 除了配置, 解锁就一行代码搞定, 虽然简洁, 里面也是有很多学问滴. . . 为什么要用Lua脚本？确保原子性, 如何保证, 请看官网对eval命令的相关解释. 上面脚本表达的意思很简单, 对比传进来的value是否相等, 是则删除锁. value可使用UUID作为当前线程的标识符, 只有但前线程才能解锁. 网上的错误姿势一般都是执行完业务代码直接删除锁, 这样会导致删除了其他线程获的锁. 上面实现的分布式锁是不支持可重入的, 需要额外的编码, 业界当然早就开源了类似的框架, 比如下面介绍的Redisson. 基于Redisson Redisson 是一个在Redis的基础上实现的Java驻内存数据网格（In-Memory Data Grid）. 它不仅提供了一系列的分布式的Java常用对象, 还提供了许多分布式服务. 其中包括(BitSet, Set, Multimap, SortedSet, Map, List, Queue, BlockingQueue, Deque, BlockingDeque, Semaphore, Lock, AtomicLong, CountDownLatch, Publish / Subscribe, Bloom filter, Remote service, Spring cache, Executor service, Live Object service, Scheduler service) Redisson提供了使用Redis的最简单和最便捷的方法. Redisson的宗旨是促进使用者对Redis的关注分离（Separation of Concern）, 从而让使用者能够将精力更集中地放在处理业务逻辑上. Redisson提供的众多功能中有一项就是可重入锁（Reentrant Lock）, 具体用法可参考 文档 依赖1234567891011&lt;dependency&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;artifactId&gt;netty-transport-native-epoll&lt;/artifactId&gt; &lt;classifier&gt;linux-x86_64&lt;/classifier&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.redisson&lt;/groupId&gt; &lt;artifactId&gt;redisson&lt;/artifactId&gt; &lt;version&gt;3.7.5&lt;/version&gt;&lt;/dependency&gt; 核心代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384@Data@Slf4jpublic class RedissonDLock implements DLock &#123; private final Long waitTime; private final Long leaseTime; private final TimeUnit timeUnit; private final RedissonClient redisson; public RedissonDLock(DLockConfigProperty property) &#123; // 设置一些基本属性 this.waitTime = property.getWaitTime(); this.leaseTime = property.getLeaseTime(); this.timeUnit = property.getTimeUnit(); Config config = new Config(); SingleServerConfig singleServerConfig = config.useSingleServer(); singleServerConfig.setAddress(&quot;redis://&quot; + property.getHost() + &quot;:&quot; + property.getPort()); if (property.getPassword() != null &amp;&amp; property.getPassword().trim().length() &gt; 0) &#123; singleServerConfig.setPassword(property.getPassword()); &#125; try &#123; Class.forName(&quot;io.netty.channel.epoll.Epoll&quot;); // 如果是Linux系统可采用Epoll算法, 需要引入 netty-transport-native-epoll if (Epoll.isAvailable()) &#123; config.setTransportMode(TransportMode.EPOLL); log.info(&quot;Starting with optional epoll library&quot;); &#125; else &#123; log.info(&quot;Starting without optional epoll library&quot;); &#125; &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; redisson = Redisson.create(config); &#125; @Override public void tryLockAndAction(LockKeyGenerator lockKeyGenerator, AfterAcquireAction acquireAction) &#123; tryLockAndAction(lockKeyGenerator, acquireAction, waitTime, leaseTime, timeUnit); &#125; @Override public void tryLockAndAction(LockKeyGenerator lockKeyGenerator, AfterAcquireAction acquireAction, Long waitTime, Long leaseTime, TimeUnit timeUnit) &#123; tryLockAndAction(lockKeyGenerator, acquireAction, DEFAULT_FAIL_ACQUIRE_ACTION, waitTime, leaseTime, timeUnit); &#125; @Override public void tryLockAndAction(LockKeyGenerator lockKeyGenerator, AfterAcquireAction acquireAction, FailAcquireAction failAcquireAction, Long waitTime, Long leaseTime, TimeUnit timeUnit) &#123; try (LockHolder holder = new LockHolder(redisson.getLock(lockKeyGenerator.getLockKey()))) &#123; boolean acquire = holder.getLock().tryLock(waitTime, leaseTime, timeUnit); if (acquire) &#123; acquireAction.doAction(); &#125; else &#123; failAcquireAction.doOnFail(); &#125; &#125; catch (InterruptedException e) &#123; throw new RuntimeException(e); &#125; &#125; @Override public &lt;T&gt; T tryLockAndExecuteCommand(LockKeyGenerator lockKeyGenerator, AfterAcquireCommand&lt;T&gt; command, FailAcquireAction failAcquireAction, Long waitTime, Long leaseTime, TimeUnit timeUnit) throws Throwable &#123; try (LockHolder holder = new LockHolder(redisson.getLock(lockKeyGenerator.getLockKey()))) &#123; boolean acquire = holder.getLock().tryLock(waitTime, leaseTime, timeUnit); if (acquire) &#123; return command.executeCommand(); &#125; failAcquireAction.doOnFail(); &#125; return null; &#125; @Data @Accessors(chain = true) @AllArgsConstructor private static class LockHolder implements AutoCloseable &#123; private RLock lock; @Override public void close() &#123; lock.unlockAsync(); &#125; &#125;&#125; 一般服务器都是Linux系统, 引入io.netty.channel.epoll.Epoll采用Epoll方式有助于提升性能 使用try-with-resource方式提高代码优雅性… 注解驱动Lock注解: 1234567891011121314151617181920@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)@Documented@Inheritedpublic @interface Lock &#123; String namespace() default &quot;default&quot;; String key(); Class&lt;?&gt; prefixClass(); String separator() default &quot;:&quot;; long waitTime() default 2L; long leaseTime() default 5L; TimeUnit timeUnit() default TimeUnit.SECONDS;&#125; 切面类: 1234567891011121314151617181920212223242526272829303132@Slf4j@Component@Aspect@Order(1)public class DLockAspect &#123; @Resource private DLock dLock; @Value(&quot;$&#123;spring.application.name&#125;&quot;) private String namespace; @Around(value = &quot;@annotation(lock)&quot;) public Object doAround(ProceedingJoinPoint pjp, Lock lock) throws Throwable &#123; Method method = ((MethodSignature) pjp.getSignature()).getMethod(); Object[] args = pjp.getArgs(); String keySpEL = lock.key(); String resourceKey = parseSpel(method, args, keySpEL, String.class); String finalKey = buildFinalKey(lock, resourceKey); return dLock.tryLockAndExecuteCommand(() -&gt; finalKey, () -&gt; pjp.proceed(pjp.getArgs()), DEFAULT_FAIL_ACQUIRE_ACTION, lock.waitTime(), lock.leaseTime(), lock.timeUnit()); &#125; private String buildFinalKey(Lock lock, String key) &#123; return namespace == null || namespace.length() == 0 ? lock.namespace() : namespace + lock.separator() + lock.prefixClass().getSimpleName() + lock.separator() + key; &#125;&#125; 使用了 SpEL 解析锁的Key: 123456789101112131415161718192021public final class SpelHelper &#123; private static final ExpressionParser PARSER = new SpelExpressionParser(); private static final LocalVariableTableParameterNameDiscoverer DISCOVERER = new LocalVariableTableParameterNameDiscoverer(); public static &lt;T&gt; T parseSpel(Method method, Object[] args, String spel, Class&lt;T&gt; clazz) &#123; String[] parameterNames = DISCOVERER.getParameterNames(method); requireNonNull(parameterNames); EvaluationContext context = buildSpelContext(parameterNames, args); Expression expression = PARSER.parseExpression(spel); return expression.getValue(context, clazz); &#125; private static EvaluationContext buildSpelContext(String[] parameterNames, Object[] args) &#123; EvaluationContext context = new StandardEvaluationContext(); for (int len = 0; len &lt; parameterNames.length; len++) &#123; context.setVariable(parameterNames[len], args[len]); &#125; context.setVariable(&quot;args&quot;, args); return context; &#125;&#125; 使用: 12345// @Lock(prefixClass = TestService.class, key = &quot;#id&quot;)@Lock(prefixClass = TestService.class, key = &quot;#args[0]&quot;)public void lockTest(Long id) &#123; doSomething();&#125; 如果锁被早被别的线程使用, 一般我们使用线程Sleep的方式等待锁释放, 但Redisson的底层采用了更优雅的等待策略, 通过发布订阅通知其他线程, 所以性能也会有所提高. Finally Redisson官方文档: https://github.com/redisson/redisson/wiki/%E7%9B%AE%E5%BD%95 示例代码: https://github.com/masteranthoneyd/starter/tree/master/dlock]]></content>
      <categories>
        <category>Programming</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Redis</tag>
        <tag>Zookeeper</tag>
        <tag>Spring Boot</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot学习之测试篇]]></title>
    <url>%2F2018%2Fspring-boot-learning-testing%2F</url>
    <content type="text"><![CDATA[Preface 测试已经是贯穿我们程序员的日常开发流程了, 无论写个main方法, 还是使用测试框架Junit、AssertJ, 或者压测, 都是我们日常开发的一部分. 也有很多互联网公司推崇TDD（测试驱动开发）的. 下面主要介绍AssertJ、JMH、Gatling以及ContPerf. 使用AssertJAseertJ: JAVA 流式断言器, 什么是流式, 常见的断言器一条断言语句只能对实际值断言一个校验点, 而流式断言器, 支持一条断言语句对实际值同时断言多个校验点. AssertJ Core features highlight 如果是Spring Boot 1.x版本, 在spring-boot-starter-test模块中, AssertJ的版本依然停留在2.x, 为了可以使用新功能, 我们可以引入新版本的AssertJ（Spring Boot 2已经是最新版的AssertJ）: 1234567891011121314151617&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.assertj&lt;/groupId&gt; &lt;artifactId&gt;assertj-core&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.assertj&lt;/groupId&gt; &lt;artifactId&gt;assertj-core&lt;/artifactId&gt; &lt;version&gt;3.9.0&lt;/version&gt;&lt;/dependency&gt; 字符串断言123456789101112131415161718@Testpublic void testString() &#123; String str = null; // 断言null或为空字符串 assertThat(str).isNullOrEmpty(); // 断言空字符串 assertThat("").isEmpty(); // 断言字符串相等 断言忽略大小写判断字符串相等 assertThat("Frodo").isEqualTo("Frodo").isEqualToIgnoringCase("frodo"); // 断言开始字符串 结束字符穿 字符串长度 assertThat("Frodo").startsWith("Fro").endsWith("do").hasSize(5); // 断言包含字符串 不包含字符串 assertThat("Frodo").contains("rod").doesNotContain("fro"); // 断言字符串只出现过一次 assertThat("Frodo").containsOnlyOnce("do"); // 判断正则匹配 assertThat("Frodo").matches("..o.o").doesNotMatch(".*d");&#125; 数字断言123456789101112131415161718@Testpublic void testNumber() &#123; Integer num = null; // 断言空 assertThat(num).isNull(); // 断言相等 assertThat(42).isEqualTo(42); // 断言大于 大于等于 assertThat(42).isGreaterThan(38).isGreaterThanOrEqualTo(38); // 断言小于 小于等于 assertThat(42).isLessThan(58).isLessThanOrEqualTo(58); // 断言0 assertThat(0).isZero(); // 断言正数 非负数 assertThat(1).isPositive().isNotNegative(); // 断言负数 非正数 assertThat(-1).isNegative().isNotPositive();&#125; 时间断言12345678910111213141516171819202122232425262728293031323334353637383940@Testpublic void testDate() &#123; // 断言与指定日期相同 不相同 在指定日期之后 在指定日期之钱 assertThat(parse("2014-02-01")).isEqualTo("2014-02-01").isNotEqualTo("2014-01-01") .isAfter("2014-01-01").isBefore(parse("2014-03-01")); // 断言 2014 在指定年份之前 在指定年份之后 assertThat(new Date()).isBeforeYear(2020).isAfterYear(2013); // 断言时间再指定范围内 不在指定范围内 assertThat(parse("2014-02-01")).isBetween("2014-01-01", "2014-03-01").isNotBetween( parse("2014-02-02"), parse("2014-02-28")); // 断言两时间相差100毫秒 Date d1 = new Date(); Date d2 = new Date(d1.getTime() + 100); assertThat(d1).isCloseTo(d2, 100); // sets dates differing more and more from date1 Date date1 = parseDatetimeWithMs("2003-01-01T01:00:00.000"); Date date2 = parseDatetimeWithMs("2003-01-01T01:00:00.555"); Date date3 = parseDatetimeWithMs("2003-01-01T01:00:55.555"); Date date4 = parseDatetimeWithMs("2003-01-01T01:55:55.555"); Date date5 = parseDatetimeWithMs("2003-01-01T05:55:55.555"); // 断言 日期忽略毫秒, 与给定的日期相等 assertThat(date1).isEqualToIgnoringMillis(date2); // 断言 日期与给定的日期具有相同的年月日时分秒 assertThat(date1).isInSameSecondAs(date2); // 断言 日期忽略秒, 与给定的日期时间相等 assertThat(date1).isEqualToIgnoringSeconds(date3); // 断言 日期与给定的日期具有相同的年月日时分 assertThat(date1).isInSameMinuteAs(date3); // 断言 日期忽略分, 与给定的日期时间相等 assertThat(date1).isEqualToIgnoringMinutes(date4); // 断言 日期与给定的日期具有相同的年月日时 assertThat(date1).isInSameHourAs(date4); // 断言 日期忽略小时, 与给定的日期时间相等 assertThat(date1).isEqualToIgnoringHours(date5); // 断言 日期与给定的日期具有相同的年月日 assertThat(date1).isInSameDayAs(date5);&#125; 集合断言1234567891011121314@Testpublic void testList() &#123; // 断言 列表是空的 assertThat(newArrayList()).isEmpty(); // 断言 列表的开始 结束元素 assertThat(newArrayList(1, 2, 3)).startsWith(1).endsWith(3); // 断言 列表包含元素 并且是排序的 assertThat(newArrayList(1, 2, 3)).contains(1, atIndex(0)).contains(2, atIndex(1)).contains(3) .isSorted(); // 断言 被包含与给定列表 assertThat(newArrayList(3, 1, 2)).isSubsetOf(newArrayList(1, 2, 3, 4)); // 断言 存在唯一元素 assertThat(newArrayList("a", "b", "c")).containsOnlyOnce("a");&#125; Map断言123456789101112131415@Testpublic void testMap() &#123; Map&lt;String, Object&gt; foo = Maps.newHashMap("A", 1); foo.put("B", 2); foo.put("C", 3); // 断言 map 不为空 size assertThat(foo).isNotEmpty().hasSize(3); // 断言 map 包含元素 assertThat(foo).contains(entry("A", 1), entry("B", 2)); // 断言 map 包含key assertThat(foo).containsKeys("A", "B", "C"); // 断言 map 包含value assertThat(foo).containsValue(3);&#125; 类断言12345678910111213141516171819202122232425262728293031@Testpublic void testClass() &#123; // 断言 是注解 assertThat(Magical.class).isAnnotation(); // 断言 不是注解 assertThat(Ring.class).isNotAnnotation(); // 断言 存在注解 assertThat(Ring.class).hasAnnotation(Magical.class); // 断言 不是借口 assertThat(Ring.class).isNotInterface(); // 断言 是否为指定Class实例 assertThat("string").isInstanceOf(String.class); // 断言 类是给定类的父类 assertThat(Person1.class).isAssignableFrom(Employee.class);&#125;@Magicalpublic enum Ring &#123; oneRing, vilya, nenya, narya, dwarfRing, manRing;&#125;@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)public @interface Magical &#123;&#125;public class Person1 &#123;&#125;public class Employee extends Person1 &#123;&#125; 异常断言123456789101112131415161718192021@Testpublic void testException() &#123; assertThatThrownBy(() -&gt; &#123; throw new Exception("boom!"); &#125;).isInstanceOf(Exception.class) .hasMessageContaining("boom"); assertThatExceptionOfType(IOException.class).isThrownBy(() -&gt; &#123; throw new IOException("boom!"); &#125;) .withMessage("%s!", "boom") .withMessageContaining("boom") .withNoCause(); /* * assertThatNullPointerException * assertThatIllegalArgumentException * assertThatIllegalStateException * assertThatIOException */ assertThatIOException().isThrownBy(() -&gt; &#123; throw new IOException("boom!"); &#125;) .withMessage("%s!", "boom") .withMessageContaining("boom") .withNoCause();&#125; 文件断言12345678910111213141516171819202122@Testpublic void testFile() throws Exception &#123; File xFile = writeFile("xFile", "The Truth Is Out There"); assertThat(xFile).exists().isFile().isRelative(); assertThat(xFile).canRead().canWrite(); assertThat(contentOf(xFile)).startsWith("The Truth").contains("Is Out").endsWith("There");&#125;private File writeFile(String fileName, String fileContent) throws Exception &#123; return writeFile(fileName, fileContent, Charset.defaultCharset());&#125;private File writeFile(String fileName, String fileContent, Charset charset) throws Exception &#123; File file = new File("target/" + fileName); BufferedWriter out = new BufferedWriter(new OutputStreamWriter(new FileOutputStream(file), charset)); out.write(fileContent); out.close(); return file;&#125; 对象列表断言1234567891011@Testpublic void personListTest() &#123; List&lt;Person&gt; personList = Arrays.asList(new Person("A", 1), new Person("B", 2), new Person("C", 3)); assertThat(personList).extracting(Person::getName).contains("A", "B").doesNotContain("D");&#125;@Testpublic void personListTest1() &#123; List&lt;Person&gt; personList = Arrays.asList(new Person("A", 1), new Person("B", 2), new Person("C", 3)); assertThat(personList).flatExtracting(Person::getName).contains("A", "B").doesNotContain("D");&#125; 断言添加描述12345@Testpublic void addDesc() &#123; Person person = new Person("ybd", 18); assertThat(person.getAge()).as("check %s's age", person.getName()).isEqualTo(18);&#125; 官方例子https://github.com/joel-costigliola/assertj-examples JMH基准测试 JMH 是一个由 OpenJDK/Oracle 里面那群开发了 Java 编译器的大牛们所开发的 Micro Benchmark Framework . 何谓 Micro Benchmark 呢？简单地说就是在 method 层面上的 benchmark, 精度可以精确到微秒级. 可以看出 JMH 主要使用在当你已经找出了热点函数, 而需要对热点函数进行进一步的优化时, 就可以使用 JMH 对优化的效果进行定量的分析. 比较典型的使用场景还有: 想定量地知道某个函数需要执行多长时间, 以及执行时间和输入 n 的相关性 一个函数有两种不同实现（例如实现 A 使用了 FixedThreadPool, 实现 B 使用了 ForkJoinPool）, 不知道哪种实现性能更好 尽管 JMH 是一个相当不错的 Micro Benchmark Framework, 但很无奈的是网上能够找到的文档比较少, 而官方也没有提供比较详细的文档, 对使用造成了一定的障碍. 但是有个好消息是官方的 Code Sample 写得非常浅显易懂, 导入Jar包1234567891011&lt;dependency&gt; &lt;groupId&gt;org.openjdk.jmh&lt;/groupId&gt; &lt;artifactId&gt;jmh-core&lt;/artifactId&gt; &lt;version&gt;1.21&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.openjdk.jmh&lt;/groupId&gt; &lt;artifactId&gt;jmh-generator-annprocess&lt;/artifactId&gt; &lt;version&gt;1.21&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 例子我们来测试一下Snowflake的性能: 12345678910111213141516171819202122232425@BenchmarkMode(Mode.Throughput)@Warmup(iterations = 3, time = 1)@Measurement(iterations = 4, time = 2)@Threads(10)@Fork(1)@OutputTimeUnit(TimeUnit.SECONDS)public class SnowflakeTest &#123; private static final Snowflake[] SNOWFLAKES = IntStream.rangeClosed(1, 8) .mapToObj(Snowflake::create) .toArray(Snowflake[]::new); private static final AtomicLong ATOMIC_LONG = new AtomicLong(0); @Benchmark public long getId() &#123; return SNOWFLAKES[(int) (ATOMIC_LONG.incrementAndGet() &amp; (1 &lt;&lt; 3) - 1)].nextId(); &#125; public static void main(String[] args) throws RunnerException &#123; Options options = new OptionsBuilder().include(SnowflakeTest.class.getSimpleName()) .build(); new Runner(options).run(); &#125;&#125; 输出结果: 12Benchmark Mode Cnt Score Error UnitsSnowflakeTest.getId thrpt 4 32751461.735 ± 88155.402 ops/s 注解都可以换成方法的方式在main方法中指定, 比如这样: 1234567Options opt = new OptionsBuilder().include(SnowflakeTest.class.getSimpleName()) .forks(1) .measurementIterations(3) .measurementTime(TimeValue.seconds(1)) .warmupIterations(3) .warmupTime(TimeValue.seconds(1)) .build(); 注解分析下面我把一些常用的注解全部分析一遍, 看完之后你就可以得心应手的使用了. @BenchmarkMode基准测试类型, 对应Mode选项, 可用于类或者方法上. 需要注意的是, 这个注解的value是一个数组, 可以把几种Mode集合在一起执行, 如: @BenchmarkMode({Mode.SampleTime, Mode.AverageTime}) Throughput: 整体吞吐量, 每秒执行了多少次调用. AverageTime: 用的平均时间, 每次操作的平均时间. SampleTime: 随机取样, 最后输出取样结果的分布, 例如“99%的调用在xxx毫秒以内, 99.99%的调用在xxx毫秒以内”. SingleShotTime: 上模式都是默认一次 iteration 是 1s, 唯有 SingleShotTime 是只运行一次. 往往同时把 warmup 次数设为0, 用于测试冷启动时的性能. All: 上面的所有模式都执行一次, 适用于内部JMH测试. @Warmup预热所需要配置的一些基本测试参数. 可用于类或者方法上. 一般我们前几次进行程序测试的时候都会比较慢, 所以要让程序进行几轮预热, 保证测试的准确性. 为什么需要预热？因为 JVM 的 JIT 机制的存在, 如果某个函数被调用多次之后, JVM 会尝试将其编译成为机器码从而提高执行速度. 所以为了让 benchmark 的结果更加接近真实情况就需要进行预热. iterations: 预热的次数. time: 每次预热的时间. timeUnit: 时间的单位, 默认秒. batchSize: 批处理大小, 每次操作调用几次方法. @Measurement实际调用方法所需要配置的一些基本测试参数. 可用于类或者方法上. 参数和@Warmup一样. @Threads每个进程中的测试线程, 可用于类或者方法上. 一般选择为cpu乘以2. 如果配置了 Threads.MAX , 代表使用 Runtime.getRuntime().availableProcessors() 个线程. @Fork进行 fork 的次数. 可用于类或者方法上. 如果 fork 数是2的话, 则 JMH 会 fork 出两个进程来进行测试. @Benchmark方法级注解, 表示该方法是需要进行 benchmark 的对象, 用法和 JUnit 的 @Test 类似. @Param@Param 可以用来指定某项参数的多种情况. 只能作用在字段上. 特别适合用来测试一个函数在不同的参数输入的情况下的性能. 使用该注解必须定义 @State 注解. 12@Param(value = &#123;"a", "b", "c"&#125;)private String param; 最后的结果可能是这个样子的: 1234Benchmark (param) Mode Cnt Score Error UnitsFirstBenchMark.stringConcat a ss 330.752 us/opFirstBenchMark.stringConcat b ss 186.050 us/opFirstBenchMark.stringConcat c ss 222.559 us/op @Setup&amp;@TearDown@Setup主要实现测试前的初始化工作, 只能作用在方法上. 用法和Junit一样. 使用该注解必须定义 @State 注解. @TearDown主要实现测试完成后的垃圾回收等工作, 只能作用在方法上. 用法和Junit一样. 使用该注解必须定义 @State 注解. 这两个注解都有一个 Level 的枚举value, 它有三个值（默认的是Trial）: Trial: 在每次Benchmark的之前/之后执行. Iteration: 在每次Benchmark的iteration的之前/之后执行. Invocation: 每次调用Benchmark标记的方法之前/之后都会执行. 可见, Level的粒度从Trial到Invocation越来越细. 123456789101112131415@TearDown(Level.Iteration)public void check() &#123; assert x &gt; Math.PI : &quot;Nothing changed?&quot;;&#125;@Benchmarkpublic void measureRight() &#123; x++;&#125;@Benchmarkpublic void measureWrong() &#123; double x = 0; x++;&#125; @State该注解定义了给定类实例的可用范围. JMH可以在多线程同时运行的环境测试, 因此需要选择正确的状态. 只能作用在类上. 被该注解定义的类通常作为 @Benchmark 标记的方法的入参, JMH根据scope来进行实例化和共享操作, 当然@State可以被继承使用, 如果父类定义了该注解, 子类则无需定义. Scope有如下3种值: Benchmark: 同一个benchmark在多个线程之间共享实例. Group: 同一个线程在同一个group里共享实例. group定义参考注解 @Group . Thread: 不同线程之间的实例不共享. 首先说一下Benchmark, 对于同一个@Benchmark, 所有线程共享实例, 也就是只会new Person 1次 12345678910111213141516171819202122@State(Scope.Benchmark)public static class BenchmarkState &#123; Person person = new Person(21, "ben", "benchmark"); volatile double x = Math.PI;&#125;@Benchmarkpublic void measureShared(BenchmarkState state) &#123; state.x++;&#125;public static void main(String[] args) throws RunnerException &#123; Options opt = new OptionsBuilder() .include(JMHSample_03_States.class.getSimpleName()) .threads(8) .warmupTime(TimeValue.seconds(1)) .measurementTime(TimeValue.seconds(1)) .forks(1) .build(); new Runner(opt).run();&#125; 再说一下Thread, 这个比较好理解, 不同线程之间的实例不共享. 对于上面我们设定的线程数为8个, 也就是会new Person 8次. 12345678910@State(Scope.Thread)public static class ThreadState &#123; Person person = new Person(21, "ben", "thread"); volatile double x = Math.PI;&#125;@Benchmarkpublic void measureUnshared(ThreadState state) &#123; state.x++;&#125; 而对于Group来说, 同一个group的作为一个执行单元, 所以 measureGroup 和 measureGroup2 共享8个线程, 所以一个方法也就会执行new Person 4次. 1234567891011121314151617@State(Scope.Group)public static class GroupState &#123; Person person = new Person(21, "ben", "group"); volatile double x = Math.PI;&#125;@Benchmark@Group("ben")public void measureGroup(GroupState state) &#123; state.x++;&#125;@Benchmark@Group("ben")public void measureGroup2(GroupState state) &#123; state.x++;&#125; @Group结合@Benchmark一起使用, 把多个基准方法归为一类, 只能作用在方法上. 同一个组中的所有测试设置相同的名称(否则这些测试将独立运行——没有任何警告提示！) @GroupThreads定义了多少个线程参与在组中运行基准方法. 只能作用在方法上. @OutputTimeUnit这个比较简单了, 基准测试结果的时间类型. 可用于类或者方法上. 一般选择秒、毫秒、微秒. @CompilerControl该注解可以控制方法编译的行为, 可用于类或者方法或者构造函数上. 它内部有6种模式, 这里我们只关心三种重要的模式: CompilerControl.Mode.INLINE: 强制使用内联. CompilerControl.Mode.DONT_INLINE: 禁止使用内联. CompilerControl.Mode.EXCLUDE: 禁止编译方法. 1234567891011121314151617181920212223242526272829303132333435363738public void target_blank() &#123;&#125;@CompilerControl(CompilerControl.Mode.DONT_INLINE)public void target_dontInline() &#123;&#125;@CompilerControl(CompilerControl.Mode.INLINE)public void target_inline() &#123;&#125;@CompilerControl(CompilerControl.Mode.EXCLUDE)public void target_exclude() &#123;&#125;@Benchmarkpublic void baseline() &#123;&#125;@Benchmarkpublic void blank() &#123; target_blank();&#125;@Benchmarkpublic void dontinline() &#123; target_dontInline();&#125;@Benchmarkpublic void inline() &#123; target_inline();&#125;@Benchmarkpublic void exclude() &#123; target_exclude();&#125; 最后得出的结果也表名, 使用内联优化会影响实际的结果: 123456Benchmark Mode Cnt Score Error UnitsJMHSample_16_CompilerControl.baseline avgt 3 0.338 ± 0.475 ns/opJMHSample_16_CompilerControl.blank avgt 3 0.343 ± 0.213 ns/opJMHSample_16_CompilerControl.dontinline avgt 3 2.247 ± 0.421 ns/opJMHSample_16_CompilerControl.exclude avgt 3 82.814 ± 7.333 ns/opJMHSample_16_CompilerControl.inline avgt 3 0.322 ± 0.023 ns/op 避免JIT优化我们在测试的时候, 一定要避免JIT优化. 对于有一些代码, 编译器可以推导出一些计算是多余的, 并且完全消除它们. 如果我们的基准测试里有部分代码被清除了, 那测试的结果就不准确了. 比如下面这一段代码: 123456789101112131415161718private double x = Math.PI;@Benchmarkpublic void baseline() &#123; // do nothing, this is a baseline&#125;@Benchmarkpublic void measureWrong() &#123; // This is wrong: result is not used and the entire computation is optimized away. Math.log(x);&#125;@Benchmarkpublic double measureRight() &#123; // This is correct: the result is being used. return Math.log(x);&#125; 由于 measureWrong 方法被编译器优化了, 导致效果和 baseline 方法一样变成了空方法, 结果也证实了这一点: 1234Benchmark Mode Cnt Score Error UnitsJMHSample_08_DeadCode.baseline avgt 5 0.311 ± 0.018 ns/opJMHSample_08_DeadCode.measureRight avgt 5 23.702 ± 0.320 ns/opJMHSample_08_DeadCode.measureWrong avgt 5 0.306 ± 0.003 ns/op 如果我们想方法返回值还是void, 但是需要让Math.log(x)的耗时加入到基准运算中, 我们可以使用JMH提供给我们的类 Blackhole , 使用它的 consume来避免JIT的优化消除. 1234@Benchmarkpublic void measureRight_2(Blackhole bh) &#123; bh.consume(Math.log(x));&#125; 但是有返回值的方法就不会被优化了吗？你想的太多了. . . 重新改改刚才的代码, 让字段 x 变成final的. 1private final double x = Math.PI; 运行后的结果发现 measureRight 被JIT进行了优化, 从 23.7ns/op 降到了 2.5ns/op 1JMHSample_08_DeadCode.measureRight avgt 5 2.587 ± 0.081 ns/op 当然 Math.log(Math.PI ); 这种返回写法和字段定义成final一样, 都会被进行优化. 优化的原因是因为JVM认为每次计算的结果都是相同的, 于是就会把相同代码移到了JMH的循环之外. 结论: 基准测试方法一定不要返回void. 如果要使用void返回, 可以使用 Blackhole 的 consume 来避免JIT的优化消除. 计算不要引用常量, 否则会被优化到JMH的循环之外. IDEA插件在插件中直接搜JMH, 该插件可以右键生成JMH方法, 不用写main方法也能执行@Benchmark的方法 参考 http://benjaminwhx.com/2018/06/15/%E4%BD%BF%E7%94%A8JMH%E5%81%9A%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95/ Gatling性能测试 性能测试的两种类型, 负载测试和压力测试: 负载测试（Load Testing）: 负载测试是一种主要为了测试软件系统是否达到需求文档设计的目标, 譬如软件在一定时期内, 最大支持多少并发用户数, 软件请求出错率等, 测试的主要是软件系统的性能. 压力测试（Stress Testing）: 压力测试主要是为了测试硬件系统是否达到需求文档设计的性能目标, 譬如在一定时期内, 系统的cpu利用率, 内存使用率, 磁盘I/O吞吐率, 网络吞吐量等, 压力测试和负载测试最大的差别在于测试目的不同. Gatling 简介 Gatling 是一个功能强大的负载测试工具. 它是为易用性、可维护性和高性能而设计的. 开箱即用, Gatling 带有对 HTTP 协议的出色支持, 使其成为负载测试任何 HTTP 服务器的首选工具. 由于核心引擎实际上是协议不可知的, 所以完全可以实现对其他协议的支持, 例如, Gatling 目前也提供JMS 支持. 只要底层协议（如 HTTP）能够以非阻塞的方式实现, Gatling 的架构就是异步的. 这种架构可以将虚拟用户作为消息而不是专用线程来实现. 因此, 运行数千个并发的虚拟用户不是问题. 使用Recorder快速开始官方提供了GUI界面的录制器, 可以监听对应端口记录请求操作并转化为Scala脚本 1、进入 下载页面 下载最新版本2、解压并进入 $GATLING_HOME/bin ($GATLING_HOME为解压目录), 运行recorder.sh 上图监听8000端口（若被占用请更换端口）, 需要在浏览器设置代理, 以FireFox为例: Output folder为Scala脚本输出路径, 例如设置为 /home/ybd/data/application/gatling-charts-highcharts-bundle-2.3.0/user-files/simulations, 会在该路经下面生成一个RecordedSimulation.scala的文件（上面指定的Class Name）: 3、点击record并在Firefox进行相应操作, 然后点击Stop, 会生成类似下面的脚本: 12345678910111213141516171819202122232425package computerdatabase import io.gatling.core.Predef._ import io.gatling.http.Predef._import scala.concurrent.duration._class BasicSimulation extends Simulation &#123; val httpConf = http .baseURL("http://computer-database.gatling.io") .acceptHeader("text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8") .doNotTrackHeader("1") .acceptLanguageHeader("en-US,en;q=0.5") .acceptEncodingHeader("gzip, deflate") .userAgentHeader("Mozilla/5.0 (Windows NT 5.1; rv:31.0) Gecko/20100101 Firefox/31.0") val scn = scenario("BasicSimulation") .exec(http("request_1") .get("/")) .pause(5) setUp( scn.inject(atOnceUsers(1)) ).protocols(httpConf)&#125; 4、然后运行 $GATLING_HOME/bin/gatling.sh, 选择 [0] RecordedSimulation, 随后的几个选项直接回车即可生成测试结果: 注意看上图最下面那一行, 就是生成测试结果的入口. 具体请看官方文档: https://gatling.io/docs/current/quickstart 使用IDEA编写1、首先安装Scala插件: 2、安装 scala SDK: 3、编写测试脚本 12345678910111213141516171819class ApiGatlingSimulationTest extends Simulation &#123; val scn: ScenarioBuilder = scenario("AddAndFindPersons").repeat(100, "n") &#123; exec( http("AddPerson-API") .post("http://localhost:8080/persons") .header("Content-Type", "application/json") .body(StringBody("""&#123;"firstName":"John$&#123;n&#125;","lastName":"Smith$&#123;n&#125;","birthDate":"1980-01-01", "address": &#123;"country":"pl","city":"Warsaw","street":"Test$&#123;n&#125;","postalCode":"02-200","houseNo":$&#123;n&#125;&#125;&#125;""")) .check(status.is(200)) ).pause(Duration.apply(5, TimeUnit.MILLISECONDS)) &#125;.repeat(1000, "n") &#123; exec( http("GetPerson-API") .get("http://localhost:8080/persons/$&#123;n&#125;") .check(status.is(200)) ) &#125; setUp(scn.inject(atOnceUsers(30))).maxDuration(FiniteDuration.apply(10, "minutes")) 4、配置pom 12345678910111213141516171819202122232425262728293031323334353637&lt;properties&gt; &lt;gatling-plugin.version&gt;2.2.4&lt;/gatling-plugin.version&gt; &lt;gatling-charts-highcharts.version&gt;2.3.0&lt;/gatling-charts-highcharts.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;!-- 性能测试 Gatling --&gt; &lt;dependency&gt; &lt;groupId&gt;io.gatling.highcharts&lt;/groupId&gt; &lt;artifactId&gt;gatling-charts-highcharts&lt;/artifactId&gt; &lt;version&gt;$&#123;gatling-charts-highcharts.version&#125;&lt;/version&gt; &lt;!-- 由于配置了log4j2, 运行Gatling时需要**注释**以下的 exclusions, 否则会抛异常, 但貌似不影响测试结果 --&gt; &lt;!--&lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;--&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;build&gt; &lt;plugins&gt; &lt;!-- Gatling Maven 插件, 使用: mvn gatling:execute 命令运行 --&gt; &lt;plugin&gt; &lt;groupId&gt;io.gatling&lt;/groupId&gt; &lt;artifactId&gt;gatling-maven-plugin&lt;/artifactId&gt; &lt;version&gt;$&#123;gatling-plugin.version&#125;&lt;/version&gt; &lt;configuration&gt; &lt;!-- 测试脚本 --&gt; &lt;simulationClass&gt;com.yangbingdong.springbootgatling.gatling.DockerTest&lt;/simulationClass&gt; &lt;!-- 结果输出地址 --&gt; &lt;resultsFolder&gt;/home/ybd/test/gatling&lt;/resultsFolder&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 5、运行 Spring Boot 应用 6、运行测试 1mvn gatling:execute 我们打开结果中的index.html: 遇到问题途中出现了以下错误 这是由于使用了Log4J2, 把Gatling自带的Logback排除了（同一个项目）, 把&lt;exclusions&gt;这一段注释掉就没问题了: 123456789101112&lt;dependency&gt; &lt;groupId&gt;io.gatling.highcharts&lt;/groupId&gt; &lt;artifactId&gt;gatling-charts-highcharts&lt;/artifactId&gt; &lt;version&gt;$&#123;gatling-charts-highcharts.version&#125;&lt;/version&gt; &lt;!-- 由于配置了log4j2, 运行Gatling时需要**注释**以下的 exclusions, 否则会抛异常, 但貌似不影响测试结果 --&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt; 囧. . . . . . 参考: http://www.spring4all.com/article/584 代码: https://github.com/masteranthoneyd/spring-boot-learning/tree/master/spring-boot-gatling 官方教程: https://gatling.io/docs/current/advanced_tutorial/ ContPerfContiPerf是一个轻量级的测试工具, 基于JUnit4 开发, 可用于接口级的性能测试, 快速压测. 引入依赖: 1234567&lt;!-- 性能测试 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.databene&lt;/groupId&gt; &lt;artifactId&gt;contiperf&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;version&gt;2.1.0&lt;/version&gt;&lt;/dependency&gt; ContiPerf介绍可以指定在线程数量和执行次数, 通过限制最大时间和平均执行时间来进行效率测试, 一个简单的例子如下: 1234567891011public class ContiPerfTest &#123; @Rule public ContiPerfRule i = new ContiPerfRule(); @Test @PerfTest(invocations = 1000, threads = 40) @Required(max = 1200, average = 250, totalTime = 60000) publicvoidtest1() throwsException &#123; Thread.sleep(200); &#125; &#125; 使用@Rule注释激活ContiPerf, 通过@Test指定测试方法, @PerfTest指定调用次数和线程数量, @Required指定性能要求（每次执行的最长时间, 平均时间, 总时间等）. 也可以通过对类指定@PerfTest和@Required, 表示类中方法的默认设置, 如下: 1234567891011@PerfTest(invocations = 1000, threads = 40) @Required(max = 1200, average = 250, totalTime = 60000) public class ContiPerfTest &#123; @Rule public ContiPerfRule i = new ContiPerfRule(); @Test public void test1() throws Exception &#123; Thread.sleep(200); &#125; &#125; 主要参数介绍1）PerfTest参数 @PerfTest(invocations = 300): 执行300次, 和线程数量无关, 默认值为1, 表示执行1次； @PerfTest(threads=30): 并发执行30个线程, 默认值为1个线程； @PerfTest(duration = 20000): 重复地执行测试至少执行20s. 三个属性可以组合使用, 其中Threads必须和其他两个属性组合才能生效. 当Invocations和Duration都有指定时, 以执行次数多的为准. 例, @PerfTest(invocations = 300, threads = 2, duration = 100), 如果执行方法300次的时候执行时间还没到100ms, 则继续执行到满足执行时间等于100ms, 如果执行到50次的时候已经100ms了, 则会继续执行之100次. 如果你不想让测试连续不间断的跑完, 可以通过注释设置等待时间, 例, @PerfTest(invocations = 1000, threads = 10, timer = RandomTimer.class, timerParams = { 30, 80 }) , 每执行完一次会等待30~80ms然后才会执行下一次调用. 在开多线程进行并发压测的时候, 如果一下子达到最大进程数有些系统可能会受不了, ContiPerf还提供了“预热”功能, 例, @PerfTest(threads = 10, duration = 60000, rampUp = 1000) , 启动时会先起一个线程, 然后每个1000ms起一线程, 到9000ms时10个线程同时执行, 那么这个测试实际执行了69s, 如果只想衡量全力压测的结果, 那么可以在注释中加入warmUp, 即@PerfTest(threads = 10, duration = 60000, rampUp = 1000, warmUp = 9000) , 那么统计结果的时候会去掉预热的9s. 2）Required参数 @Required(throughput = 20): 要求每秒至少执行20个测试； @Required(average = 50): 要求平均执行时间不超过50ms； @Required(median = 45): 要求所有执行的50%不超过45ms； @Required(max = 2000): 要求没有测试超过2s； @Required(totalTime = 5000): 要求总的执行时间不超过5s； @Required(percentile90 = 3000): 要求90%的测试不超过3s； @Required(percentile95 = 5000): 要求95%的测试不超过5s； @Required(percentile99 = 10000): 要求99%的测试不超过10s; @Required(percentiles = &quot;66:200,96:500&quot;): 要求66%的测试不超过200ms, 96%的测试不超过500ms. 测试结果测试结果除了会在控制台显示之外, 还会生成一个结果文件target/contiperf-report/index.html]]></content>
      <categories>
        <category>Programming</category>
        <category>Java</category>
        <category>Spring Boot</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring Boot</tag>
        <tag>AssertJ</tag>
        <tag>JMH</tag>
        <tag>Gatling</tag>
        <tag>ContPerf</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之创建型(Creational)]]></title>
    <url>%2F2018%2Fdesign-pattern-creational%2F</url>
    <content type="text"><![CDATA[Preface 创建型模式(Creational Pattern)对类的实例化过程进行了抽象, 能够将软件模块中对象的创建和对象的使用分离. 为了使软件的结构更加清晰, 外界对于这些对象只需要知道它们共同的接口, 而不清楚其具体的实现细节, 使整个系统的设计更加符合单一职责原则. 创建型模式在创建什么(What), 由谁创建(Who), 何时创建(When)等方面都为软件设计者提供了尽可能大的灵活性. 创建型模式隐藏了类的实例的创建细节, 通过隐藏对象如何被创建和组合在一起达到使整个系统独立的目的. Singleton Pattern 单例模式可以说简单, 也可以说不简单. . . 使用不当就是小学生了 这么说吧, 一个城市只能有一个市长, 每当需要他的时候他总会出现, 并且每次都是同一个人. 总不能一个城市有两个市长吧？那么单例模式就是保证一个类只有一个实例化对象, 并提供一个全局访问入口.本质就是控制实例的数量. 小学生式单例模式现在来看一个最原始的单例:12345678910111213141516171819202122package com.yangbingdong.singleton;/** * @author ybd * @date 17-10-16 * * 小学生式单例模式 */public class SimpleSingleton &#123; private static SimpleSingleton instance; private SimpleSingleton() &#123;&#125; public static SimpleSingleton getInstance() &#123; if (instance == null) &#123; instance = new SimpleSingleton(); &#125; return instance; &#125;&#125; 如果是刚入门的程序猿这可以得到101分（多一份骄傲）但若是已出来工作的写出这样的代码. . . 那是找群殴. . . 单例模式中注重的是单字, 上面代码有可能造成多个实例, 来一段多线程测试代码:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package com.yangbingdong.singleton;import java.util.HashSet;import java.util.Set;import java.util.concurrent.CountDownLatch;import java.util.concurrent.CyclicBarrier;import java.util.concurrent.ExecutorService;import static java.util.Collections.synchronizedSet;import static java.util.concurrent.Executors.newCachedThreadPool;/** * @author ybd * @date 17-10-18 */public class SingletonTest &#123; private static final int NUM = 1000; public static void main(String[] args) throws Exception &#123; ExecutorService executorService = newCachedThreadPool(); try &#123; CyclicBarrier cyclicBarrier = new CyclicBarrier(NUM); CountDownLatch countDownLatch = new CountDownLatch(NUM); Set&lt;String&gt; set = synchronizedSet(new HashSet&lt;String&gt;()); for (int i = 0; i &lt; NUM; i++) &#123; executorService.execute(() -&gt; &#123; try &#123; /* 阻塞并等待所有线程加载完毕再同时run */ cyclicBarrier.await(); SimpleSingleton singleton = SimpleSingleton.getInstance(); set.add(singleton.toString()); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; /* 计数器用于阻塞主线程 */ countDownLatch.countDown(); &#125; &#125;); &#125; /* 阻塞主线程, 等待所有线程跑完再执行下面 */ countDownLatch.await(); System.out.println("------并发情况下我们取到的实例------"); set.forEach(System.out::println); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; executorService.shutdown(); &#125; &#125;&#125; 执行结果: 1234------并发情况下我们取到的实例------com.yangbingdong.singleton.SimpleSingleton@3bf59e6dcom.yangbingdong.singleton.SimpleSingleton@4e593af6com.yangbingdong.singleton.SimpleSingleton@7eac491e 很明显的产生了多个实例, 三个线程同时通过了instance == null条件. 饿汉式1234567891011121314151617package com.yangbingdong.singleton;/** * @author ybd * @date 17-10-19 * * 饿汉式 */public class EagerSingleton &#123; private static EagerSingleton instance = new EagerSingleton(); private EagerSingleton() &#123;&#125; public static EagerSingleton getInstance() &#123; return instance; &#125;&#125; 通过类加载保证了线程安全, 空间换时间. 懒汉式1234567891011121314151617181920212223242526272829package com.yangbingdong.singleton;import java.util.concurrent.locks.ReentrantLock;/** * @author ybd * @date 17-10-19 * * 懒汉式 */public class LazySingleton &#123; private static ReentrantLock reentrantLock = new ReentrantLock(); private static LazySingleton instance = null; private LazySingleton() &#123;&#125; public static LazySingleton getInstance() &#123; try &#123; /* 可重入所保证线程安全 */ reentrantLock.lock(); if (instance == null) &#123; instance = new LazySingleton(); &#125; return instance; &#125; finally &#123; reentrantLock.unlock(); &#125; &#125;&#125; 每一次获取实例都需要同步, 性能极差, 不可取. 双重检查加锁123456789101112131415161718192021222324252627282930313233343536package com.yangbingdong.singleton;import java.util.concurrent.locks.ReentrantLock;/** * @author ybd * @date 17-10-19. * * 双重检查加锁 */public class DoubleCheckSingleton &#123; private static ReentrantLock reentrantLock = new ReentrantLock(); /** * 1.5后加上 volatile 关键字使得double check变得有意义 */ private static volatile DoubleCheckSingleton instance = null; private DoubleCheckSingleton() &#123;&#125; public static DoubleCheckSingleton getInstance() &#123; try &#123; if (instance == null) &#123; reentrantLock.lock(); if (instance == null) &#123; instance = new DoubleCheckSingleton(); &#125; &#125; return instance; &#125;finally &#123; if(reentrantLock.isHeldByCurrentThread())&#123; reentrantLock.unlock(); &#125; &#125; &#125;&#125; double check模式需要在给instance加上volatile关键字, 作用是当线程中的变量发生变化时, 会强制写回主存, 其他线程发现主存的变量地址发生改变, 也会强制读取主存的变量. 如果不加volatile关键字, 则有可能出现这样的情况: 线程A、B同时进入并通过了第一个if (instance == null), 然后A获取了锁, A把instance实例化并释放锁, B获取锁, 但此时B自己的内存里的instance还是空（因为没有强制读取主存并不知道instance已经被实例化了）, 所以又实例化了一个对象. . . Lazy initialization holder class模式12345678910111213141516171819package com.yangbingdong.singleton;/** * @author ybd * @date 17-10-19. * * Lazy initialization holder class模式 */public class InnerClassSingleton &#123; private InnerClassSingleton() &#123;&#125; private static class SingletonHolder &#123; private static InnerClassSingleton singleton = new InnerClassSingleton(); &#125; public static InnerClassSingleton getInstance() &#123; return SingletonHolder.singleton; &#125;&#125; 在JVM进行类加载的时候会保证数据是同步的, 我们采用内部类实现: 在内部类里面去创建对象实例.只要应用中不使用内部类 JVM 就不会去加载这个单例类, 也就不会创建单例对象, 从而实现延迟加载和线程安全. 枚举123456789101112131415161718package com.yangbingdong.singleton;import java.util.function.Supplier;/** * @author ybd * @date 17-10-19. * * 枚举就是一个单例 */public enum SingletonEnum implements Supplier&lt;String&gt; &#123; SINGLETON &#123; @Override public String get() &#123; return "I'm singleton"; &#125; &#125;&#125; 枚举天生就是一个单例, 并且是线程安全的, 自由序列化的, 这意味着反序列化之后它还是原来的那个单例. 而其他的单例模式需要定义readResolve()方法, 反序列化的时候会调用此方法: 123private Object readResolve() &#123; return instance; &#125; Java标准库中的单例模式java.lang.Runtime#getRuntime()就是一个典型的代表.1234567891011class Runtime &#123; private static Runtime currentRuntime = new Runtime(); public static Runtime getRuntime() &#123; return currentRuntime; &#125; private Runtime() &#123;&#125; //... &#125; 这个currentRuntime就是在初始化就已经加载了的. Simple Factory Pattern 简单工厂模式又被称为静态工厂方法模式, 由一个工厂类根据传入的参数, 动态决定应该创建哪一个产品类（这些产品类继承自一个父类或接口）的实例. 将“类实例化的操作”与“使用对象的操作”分开, 让使用者不用知道具体参数就可以实例化出所需要的“产品”类, 从而避免了在客户端代码中显式指定, 实现了解耦；即使用者可直接消费产品而不需要知道其生产的细节 代码定义人类接口:123456public interface Human &#123; /** * 是个人都会讲话 */ void talk();&#125; 实现类（男人和女人）:12345678910111213public class Man implements Human &#123; @Override public void talk() &#123; System.out.println("I'm man! \n"); &#125;&#125;public class Woman implements Human &#123; @Override public void talk() &#123; System.out.println("I'm woman! \n"); &#125;&#125; 工厂类:123456789101112131415161718192021222324252627282930313233343536package com.yangbingdong.simplefactory;import static com.yangbingdong.simplefactory.HumanFactory.HumanEnum.MAN;import static com.yangbingdong.simplefactory.HumanFactory.HumanEnum.WOMAN;/** * @author ybd * @date 17-10-19. */public class HumanFactory &#123; private HumanFactory() &#123;&#125; /** * 工厂获取实例静态方法 * @param humanEnum 根据传进来的枚举获取对应的实例 * @return 返回的实例 */ public static Human getInstance(HumanEnum humanEnum) &#123; if (MAN.equals(humanEnum)) &#123; System.out.println("生产了男人"); return new Man(); &#125;else if (WOMAN.equals(humanEnum)) &#123; System.out.println("生产了女人"); return new Woman(); &#125;else &#123; System.out.println("什么都没有生产"); return null; &#125; &#125; public enum HumanEnum &#123; MAN,WOMAN &#125;&#125; 现在来测试一下:1234567891011121314151617181920212223package com.yangbingdong.simplefactory;import java.util.Optional;import static com.yangbingdong.simplefactory.HumanFactory.HumanEnum.*;/** * @author ybd * @date 17-10-19. */public class SimpleFactoryTest &#123; public static void main(String[] args) &#123; invokeTalkIfNotNull(MAN); invokeTalkIfNotNull(WOMAN); invokeTalkIfNotNull(null); &#125; private static void invokeTalkIfNotNull(HumanFactory.HumanEnum man) &#123; Optional.ofNullable(HumanFactory.getInstance(man)).ifPresent(Human::talk); &#125;&#125; 运行结果:1234567生产了男人I'm man! 生产了女人I'm woman! 什么都没有生产 特点将创建实例的工作与使用实例的工作分开, 使用者不必关心类对象如何创建, 只需要传入工厂需要的参数即可, 但也有弊端: 工厂类集中了所有实例（产品）的创建逻辑, 一旦这个工厂不能正常工作, 整个系统都会受到影响, 违背“开放 - 关闭原则”, 一旦添加新产品就不得不修改工厂类的逻辑, 这样就会造成工厂逻辑过于复杂, 对于系统维护和扩展不够友好. Java标准库中的简单工厂模式123456java.util.Calendar - getInstance()java.util.Calendar - getInstance(TimeZone zone)java.util.Calendar - getInstance(Locale aLocale)java.util.Calendar - getInstance(TimeZone zone, Locale aLocale)java.text.NumberFormat - getInstance()java.text.NumberFormat - getInstance(Locale inLocale) Factory Method 工厂方法模式, 又称工厂模式、多态工厂模式和虚拟构造器模式, 通过定义工厂父类负责定义创建对象的公共接口, 而子类则负责生成具体的对象. 就是一个工厂生产一个专一产品. 代码人类接口与实现类与上面的一样 主要是把工厂抽象成了接口, 具体的人类由具体的工厂实现类创建. 工厂接口定义统一的创建人类的借口 1234567public interface HumanFactory &#123; /** * 定义抽象工厂方法 * @return */ Human createHuman();&#125; 两个工厂实现类 123456789101112131415public class ManFactory implements HumanFactory &#123; @Override public Human createHuman() &#123; System.out.println("生产了男人"); return new Man(); &#125;&#125;public class WomanFactory implements HumanFactory &#123; @Override public Human createHuman() &#123; System.out.println("生产了女人"); return new Woman(); &#125;&#125; 测试类: 123456789101112131415package com.yangbingdong.factorymethod;/** * @author ybd * @date 17-10-25. */public class FactoryMethodTest &#123; public static void main(String[] args) &#123; HumanFactory humanFactory = new ManFactory(); humanFactory.createHuman().talk(); humanFactory = new WomanFactory(); humanFactory.createHuman().talk(); &#125;&#125; 运行结果: 12345生产了男人I'm man! 生产了女人I'm woman! 特点工厂方法模式把具体产品的创建推迟到工厂类的子类（具体工厂）中, 此时工厂类不再负责所有产品的创建, 而只是给出具体工厂必须实现的接口, 这样工厂方法模式在添加新产品的时候就不修改工厂类逻辑而是添加新的工厂子类, 符合开放封闭原则, 克服了简单工厂模式中缺点. 工厂模式可以说是简单工厂模式的进一步抽象和拓展, 在保留了简单工厂的封装优点的同时, 让扩展变得简单, 让继承变得可行, 增加了多态性的体现. 同时缺点也很明显, 多一个产品就多一个工厂, 开销变大了, 不适用与创建多种产品. Java中的工厂方法查找了一下, 数据库链接驱动就是一个典型的工厂方法模式, Java定义链接数据库以及其他操作的接口, 数据库厂商必须实现这些接口, 比如Mysql、Oracle. Abstract Factory 抽象工厂模式为创建一组对象提供了一种解决方案. 与工厂方法模式相比, 抽象工厂模式中的具体工厂不只是创建一种产品, 它负责创建一族产品. 比如AMD工厂负责生产AMD全家桶, Intel工厂负责生产Intel全家桶. 代码首先定义CPU接口以及实现类 12345678public interface CPU &#123;&#125;public class AMDCPU implements CPU &#123;&#125;public class IntelCPU implements CPU &#123;&#125; 主板接口以及实现类 12345678public interface MainBoard &#123;&#125;public class AMDMainBoard implements MainBoard &#123;&#125;public class IntelMainBoard implements MainBoard &#123;&#125; 定义抽象工厂与实现类 123456789101112131415161718192021222324252627282930313233public interface AbstractFactory &#123; CPU createCPU(); MainBoard createMainBoard();&#125;public class AMDFactory implements AbstractFactory &#123; @Override public CPU createCPU() &#123; System.out.println("生产了AMD的CPU"); return new AMDCPU(); &#125; @Override public MainBoard createMainBoard() &#123; System.out.println("生产了AMD的主板"); return new AMDMainBoard(); &#125;&#125;public class IntelFactory implements AbstractFactory &#123; @Override public CPU createCPU() &#123; System.out.println("生产了Intel的CPU"); return new IntelCPU(); &#125; @Override public MainBoard createMainBoard() &#123; System.out.println("生产了Intel的主板"); return new IntelMainBoard(); &#125;&#125; 测试类 1234567891011public class AbstractFactoryTest &#123; public static void main(String[] args) &#123; AbstractFactory abstractFactory = new AMDFactory(); abstractFactory.createCPU(); abstractFactory.createMainBoard(); abstractFactory = new IntelFactory(); abstractFactory.createCPU(); abstractFactory.createMainBoard(); &#125;&#125; 运行结果 1234生产了AMD的CPU生产了AMD的主板生产了Intel的CPU生产了Intel的主板 优缺点优点: 分离接口和实现: 客户端使用抽象工厂来创建需要的对象, 而客户端根本就不知道具体的实现是谁, 客户端只是面向产品的接口编程而已. 也就是说, 客户端从具体的产品实现中解耦. 使切换产品族变得容易: 因为一个具体的工厂实现代表的是一个产品族, 比如上面例子的从Intel系列到AMD系列只需要切换一下具体工厂. 缺点: 不太容易扩展新的产品: 如果需要给整个产品族添加一个新的产品, 那么就需要修改抽象工厂, 这样就会导致修改所有的工厂实现类 Java标准类库中的抽象工厂模式123456789101112131415package java.util;public interface List&lt;E&gt; extends Collection&lt;E&gt; &#123; Iterator&lt;E&gt; iterator();//一种产品 Object[] toArray(); &lt;T&gt; T[] toArray(T[] a); ListIterator&lt;E&gt; listIterator();//另外一种产品 ListIterator&lt;E&gt; listIterator(int index);&#125; Builder将一个复杂对象的构建与它的表示分离, 使得同样的构建过程可以创建不同的表示. 使用Lombok中的@Builder可以很简单地实现Builder模式, @Accessors(chain = true)也可以实现类似的模式. 代码12345678910111213141516171819202122232425262728293031323334353637383940414243public class Summoner &#123; private String name; private String type; private String innate; private Summoner(Builder builder) &#123; this.name = builder.name; this.type = builder.type; this.innate = builder.innate; &#125; protected static class Builder &#123; private String name; private String type; private String innate; protected Builder name(String name) &#123; this.name = name; return this; &#125; protected Builder type(String type) &#123; this.type = type; return this; &#125; protected Builder innate(String innate) &#123; this.innate = innate; return this; &#125; protected Summoner build() &#123; return new Summoner(this); &#125; &#125;&#125;public class BuilderDemo &#123; public static void main(String[] args) &#123; Summoner monkey = new Summoner.Builder().name("齐天大圣 - 孙悟空").type("上单 - AD").innate("基石天赋 - 战争雷霆").build(); System.out.println(monkey.toString());&#125; 优缺点优点: 封装性很好: 使用建造者模式可以有效的封装变化, 在使用建造者模式的场景中, 一般产品类和建造者类是比较稳定的, 因此, 将主要的业务逻辑封装在导演类中对整体而言可以取得比较好的稳定性. 扩展性很好: 建造者模式很容易进行扩展. 如果有新的需求, 通过实现一个新的建造者类就可以完成, 基本上不用修改之前已经测试通过的代码, 因此也就不会对原有功能引入风险. 可以有效控制细节风险: 由于具体的建造者是独立的, 因此可以对建造者过程逐步细化, 而不对其他的模块产生任何影响. 缺点: 建造者模式所创建的产品一般具有较多的共同点, 其组成部分相似, 如果产品之间的差异性很大, 则不适合使用建造者模式, 因此其使用范围受到一定的限制. 如果产品的内部变化复杂, 可能会导致需要定义很多具体建造者类来实现这种变化, 导致系统变得很庞大. Java类库中的建造者模式12345StringBuilder strBuilder= new StringBuilder();strBuilder.append("one");strBuilder.append("two");strBuilder.append("three");String str= strBuilder.toString(); Prototype原型模式是23GOF模式的一种, 其特点就是通过克隆/拷贝的方式来, 节约创建成本和资源, 被拷贝`的对象模型就称之为原型. JAVA中对原型模式提供了良好的支持, 我们只需要实现Cloneable接口即可, 它的目的就是将对象标记为可被复制. 一般的应用场景是, 对象的创建非常复杂, 可以使用原型模式快捷的创建对象；或在运行过程中不知道对象的具体类型, 可使用原型模式创建一个相同类型的对象, 或者在运行过程中动态的获取到一个对象的状态. 优缺点优点: 由于clone方法是由虚拟机直接复制内存块执行, 所以在速度上比使用new的方式创建对象要快. 可以基于原型, 快速的创建一个对象, 而无需知道创建的细节. 可以在运行时动态的获取对象的类型以及状态, 从而创建一个对象. 缺点: 需要实现 Cloneable接口, clone位于内部, 不易扩展, 容易违背开闭原则(程序扩展,不应该修改原有代码). 默认的 clone 只是浅克隆, 深度克隆需要额外编码比如: 统一实现Cloneable接口, 或者序列化方式. 代码就不贴了, 实际开发中估计用不到, 但有一句话说得很对: 存在即合理. 原型模式一般伴随这工厂模式, 代码可参考: https://github.com/masteranthoneyd/design-pattern-java/tree/master/creational/src/com/yangbingdong/prototype]]></content>
      <categories>
        <category>Programming</category>
        <category>Java</category>
        <category>Design Pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Design Pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud Stack Learning]]></title>
    <url>%2F2018%2Fspring-cloud-stack-learning%2F</url>
    <content type="text"><![CDATA[Preface Spring Cloud 是一系列框架的有序集合. 它利用 Spring Boot 的开发便利性巧妙地简化了分布式系统基础设施的开发, 如服务发现注册、配置中心、消息总线、负载均衡、断路器、数据监控等, 都可以用 Spring Boot 的开发风格做到一键启动和部署. Spring 并没有重复制造轮子, 它只是将目前各家公司开发的比较成熟、经得起实际考验的服务框架组合起来, 通过 Spring Boot 风格进行再封装屏蔽掉了复杂的配置和实现原理, 最终给开发者留出了一套简单易懂、易部署和易维护的分布式系统开发工具包. 至于各种框架组件的相关概念以及入门教程网上一大把, 此篇博文主要记录个人在使用Spring Cloud构建微服务的一些配置以及踩坑… 集成Docker部分请看 Spring Boot Docker Integration Eureka Eureka是Netflix开发的服务发现组件, 本身是一个基于REST的服务. Spring Cloud将它集成在其子项目spring-cloud-netflix中, 以实现Spring Cloud的服务发现功能. 单节点核心依赖123456789101112131415&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- Base认证需要, 前端账户密码登陆 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; application.yml1234567891011121314151617181920212223242526spring: application: name: discovery profiles: active: single security: ## http base security 帐号密码 user: name: ybd password: ybdeureka: client: # 以下两项默认为true fetch-registry: true register-with-eureka: true instance: prefer-ip-address: true ip-address: $&#123;eureka.instance.hostname&#125; instance-id: $&#123;spring.application.name&#125;:$&#123;spring.application.instance_id:$&#123;server.port&#125;&#125;management: # 暴露所有端点, Spring Boot Admin监控使用 endpoints: web: exposure: include: &quot;*&quot; endpoint: health: show-details: ALWAYS eureka.client.register-with-eureka: 表示是否将自己注册到 Eureka Server, 默认为 true. eureka.client.fetch-registry: 表示是否从 Eureka Server 获取注册信息, 默认为 true. eureka.client.service-url.defaultZone: 设置与 Eureka Server 交互的地址, 查询服务和注册服务都需要依赖这个地址. 默认是 http://localhost:8761/eureka ；多个地址可使用英文逗号（,）分隔. application-single.yml123456789101112131415161718server: port: 8761eureka: environment: dev instance: hostname: localhost prefer-ip-address: false metadata-map: # 由于配置了安全认证, Spring Boot Admin 通过拿到此信息获取Eureka的端点信息 user.name: ybd user.password: ybd client: fetch-registry: false register-with-eureka: true service-url: defaultZone: http://ybd:ybd@$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;/eureka/ server: enable-self-preservation: false # 禁用保护模式 eviction-interval-timer-in-ms: 15000 Security配置开启basic的认证需要添加依赖: 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt; 配置类: 1234567891011@EnableWebSecurityclass WebSecurityConfig extends WebSecurityConfigurerAdapter &#123; private static final String EUREKA = &quot;/eureka/**&quot;; @Override protected void configure(HttpSecurity http) throws Exception &#123; http.csrf().ignoringAntMatchers(EUREKA); super.configure(http); &#125;&#125; Docker构建HA Eureka Server基于Compose运行高可用的Eureka application.yml1234567891011121314151617181920212223242526272829303132333435spring: application: name: discovery profiles: active: single security: # 安全认证帐号密码 user: name: ybd password: ybd cloud: # 忽略以下网卡 inetutils: ignored-interfaces: - eth0 - eth1 - eth2 - eth3 - loeureka: environment: prod # 在Eureka控制面板中显示prod环境 client: # 以下两项默认为true fetch-registry: true register-with-eureka: true # 注册自己 instance: prefer-ip-address: true ip-address: $&#123;eureka.instance.hostname&#125; instance-id: $&#123;spring.application.name&#125;:$&#123;spring.application.instance_id:$&#123;server.port&#125;&#125;management: # Spring Boot Admin 使用的端点 endpoints: web: exposure: include: &quot;*&quot; endpoint: health: show-details: ALWAYS application-cluster1.yml123456789101112131415server: port: 8761eureka: instance: prefer-ip-address: true # 优先使用ip ip-address: eureka-cluster1 # ip地址, 这里对应的是docker compose文件中的网络别名aliases instance-id: $&#123;spring.application.name&#125;:$&#123;spring.application.instance_id:$&#123;server.port&#125;&#125; metadata-map: # spring boot admin 会通过eureka读取该信息从而通过认证拿到相关服务发现信息 user.name: ybd user.password: ybd client: service-url: defaultZone: http://ybd:ybd@eureka-cluster2:8762/eureka/,http://ybd:ybd@eureka-cluster3:8763/eureka/ server: enable-self-preservation: false # 关闭自我保护模式 application-cluster2.yml1234567891011121314server: port: 8762eureka: instance: prefer-ip-address: true # 优先使用ip ip-address: eureka-cluster2 # ip地址, 这里对应的是docker compose文件中的网络alias metadata-map: user.name: ybd user.password: ybd client: service-url: defaultZone: http://ybd:ybd@eureka-cluster1:8761/eureka/,http://ybd:ybd@eureka-cluster3:8763/eureka/ server: enable-self-preservation: false application-cluster3.yml1234567891011121314server: port: 8763eureka: instance: prefer-ip-address: true # 优先使用ip ip-address: eureka-cluster3 # ip地址, 这里对应的是docker compose文件中的网络alias metadata-map: user.name: ybd user.password: ybd client: service-url: defaultZone: http://ybd:ybd@eureka-cluster1:8761/eureka/,http://ybd:ybd@eureka-cluster2:8762/eureka/ server: enable-self-preservation: false docker-compose.yml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475version: &apos;3.4&apos;services: eureka-cluster1: image: eureka-cluster:latest environment: - ACTIVE=cluster1 - JAVA_OPTS=-Xms512m -Xmx512m ports: - 8761:8761 restart: always healthcheck: test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;-f&quot;, &quot;http://ybd:ybd@localhost:8761/actuator/health&quot;] interval: 30s timeout: 10s retries: 3 start_period: 15s deploy: placement: constraints: - node.hostname == node1 networks: backend: aliases: - eureka-cluster1 eureka-cluster2: image: eureka-cluster:latest environment: - ACTIVE=cluster2 - JAVA_OPTS=-Xms512m -Xmx512m ports: - 8762:8762 restart: always healthcheck: test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;-f&quot;, &quot;http://ybd:ybd@localhost:8762/actuator/health&quot;] interval: 30s timeout: 10s retries: 3 start_period: 15s deploy: placement: constraints: - node.hostname == node2 networks: backend: aliases: - eureka-cluster2 eureka-cluster3: image: eureka-cluster:latest environment: - ACTIVE=cluster3 - JAVA_OPTS=-Xms512m -Xmx512m ports: - 8763:8763 restart: always healthcheck: test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;-f&quot;, &quot;http://ybd:ybd@localhost:8763/actuator/health&quot;] interval: 30s timeout: 10s retries: 3 start_period: 15s deploy: placement: constraints: - node.hostname == node3 networks: backend: aliases: - eureka-cluster3networks: backend: external: name: backend Docker Compose启动启动前确保创建好了网络: 12docker network create -d=overlay --attachable --subnet 10.10.0.0/16 backenddocker-compse up -d 此时在Portainer中可以看到三个容器已经启动: 随意一个eureka端口都能看到另外两个服务: Docker Swarm启动由于目前使用stack方式启动是无法加载env_file的, 所以需要预先加载一下: 1export $(cat .env) &amp;&amp; docker stack deploy --compose-file=docker-compose.yml eureka-stack 我们的app通过合适的network交互应该是这样的: 注意事项（ip与hostname混乱）之前使用Docker Compose方式启动服务没什么问题, 后来换成Docker Swarm方式启动, 在Eureka的面板中发现有些服务是ip, 有些是hostname, 但都注册成功, 不过某些服务相互之间又访问不了. Google一番后的解决方案: Server端跟Client端都使用以下配置: 123456789101112131415spring: cloud: inetutils: ignored-interfaces: - eth0 - eth1 - eth2 - eth3 - lo eureka: instance: prefer-ip-address: true ip-address: eureka-cluster1 # 这里对应上面compose文件中的aliases instance-id: $&#123;spring.application.name&#125;:$&#123;spring.application.instance_id:$&#123;server.port&#125;&#125; 踩坑(容器中服务下线无法向注册中心注销服务)在Docker中程序, 如果PID不是1, 是接收不到docker-compose down发出的sigterm信号从而导致只能等待被Kill, 不能向注册中心注销. 解决方法是在Dockerfile中的入口使用ENTRYPOINT exec java -jar ...这种方式 Eureka Edgware.RELEASE版本注册优化在Edgware.RELEASE版本中相比之前的步骤, 省略了在主函数上添加@EnableDiscoveryClient注解这一过程. Spring Cloud默认认为客户端是要完成向注册中心进行注册的. 添加对应的pom依赖. properties文件进行配置 添加pom依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; properties文件进行配置 12spring.application.name=EUREKA-CLIENTeureka.client.service-url.defaultZone=http://localhost:8761/eureka 启动Eureka Client客户端, 访问http://localhost:8761/eureka可以看到EUEREKA-CLIENT已经注册到Eureka Server服务上了. 关闭自动注册功能Spring Cloud提供了一个参数, 该参数的作用是控制是否要向Eureka Server发起注册. 具体参数为: 12//默认为true,如果控制不需要向Eureka Server发起注册将该值设置为false.spring.cloud.service-registry.auto-registration.enabled = xxx 可以在JUnit测试中通过该变量关闭服务发现: 1234@BeforeClasspublic static void beforeClass() &#123; System.setProperty(&quot;spring.cloud.service-registry.auto-registration.enabled&quot;, &quot;false&quot;);&#125; Eureka的自我保护模式当Eureka提示下面一段话的时候, 就表示它已经进入保护模式: 12EMERGENCY! EUREKA MAY BE INCORRECTLY CLAIMING INSTANCES ARE UP WHEN THEY&apos;RE NOT.RENEWALS ARE LESSER THAN THRESHOLD AND HENCE THE INSTANCES ARE NOT BEING EXPIRED JUST TO BE SAFE. 保护模式主要用于一组客户端和Eureka Server之间存在网络分区场景下的保护. 一旦进入保护模式, Eureka Server将会尝试保护其服务注册表中的信息, 不再删除服务注册表中的数据（也就是不会注销任何微服务）. 解决方法如下: 服务器端配置: 1234eureka: server: enable-self-preservation: false eviction-interval-timer-in-ms: 15000 客户端配置: 1234eureka: instance: lease-expiration-duration-in-seconds: 30 lease-renewal-interval-in-seconds: 10 注意: 更改Eureka更新频率将打破服务器的自我保护功能, 生产环境下不建议自定义这些配置. 修改Eureka界面UI覆盖对应源码中的界面文件即可: 效果图: 注意事项: 如果pom.xml中的parent不是spring-boot-starter-parent, 这些样式文件需要新建一个项目另外打包成jar包再引入方可生效. RPC(Remote Procedure Call) 这里指针对Http协议调用 通过注册中心, 服务间的基本调用如下: 调用方式主要有三种（基本上在实际应用中都使用Feign） 前置条件: 集成服务注册中心 服务提供者（service-a）: 12345678910@RestController@RequestMapping(&quot;/service-a&quot;)public class HelloController &#123; @GetMapping(&quot;/&#123;name&#125;&quot;) public String sayHello(@PathVariable String name) throws UnknownHostException &#123; InetAddress localHost = InetAddress.getLocalHost(); return localHost + &quot;: Hello 『&quot; + name + &quot;』 , Date: &quot; + new Date(); &#125;&#125; LoadBalancerClient初始化RestTemplate, 用来发起 REST 请求. 1234@Beanpublic RestTemplate restTemplate() &#123; return new RestTemplate();&#125; 消费者（service-b）: 1234567891011121314151617@RestController@RequestMapping(&quot;/service-b&quot;)public class HelloController &#123; @Resource private LoadBalancerClient client; @Resource private RestTemplate restTemplate; @GetMapping(&quot;/&#123;name&#125;&quot;) public String hello(@PathVariable String name) &#123; name += &quot;!&quot;; ServiceInstance instance = client.choose(&quot;service-a&quot;); String url = &quot;http://&quot; + instance.getHost() + &quot;:&quot; + instance.getPort() + &quot;/service-a/&quot; + name; return restTemplate.getForObject(url, String.class); &#125;&#125; 访问http://127.0.0.1:8082/service-b/ybd, 返回: 1ybd-PC/127.0.1.1: Hello 『ybd!』 , Date: Wed Aug 08 18:30:48 CST 2018 Spring Cloud Ribbon 它是一个基于 HTTP 和 TCP 的客户端负载均衡器. 它可以通过在客户端中配置 ribbonServerList 来设置服务端列表去轮询访问以达到均衡负载的作用. 当 Ribbon 与 Eureka 联合使用时, ribbonServerList 会被 DiscoveryEnabledNIWSServerList 重写, 扩展成从 Eureka 注册中心中获取服务实例列表. 同时它也会用 NIWSDiscoveryPing 来取代 IPing, 它将职责委托给 Eureka 来确定服务端是否已经启动. 为RestTemplate添加@LoadBalanced注解: 12345@LoadBalanced@Beanpublic RestTemplate restTemplate() &#123; return new RestTemplate();&#125; Controller: 修改 controller, 去掉LoadBalancerClient, 并修改相应的方法, 直接用 RestTemplate发起请求 12345678910111213@RestController@RequestMapping(&quot;/service-b&quot;)public class HelloController &#123; @Resource private RestTemplate restTemplate; @GetMapping(&quot;/&#123;name&#125;&quot;) public String hello(@PathVariable String name) &#123; name += &quot;!&quot;; String url = &quot;http://service-a/service-a/&quot; + name; return restTemplate.getForObject(url, String.class); &#125;&#125; Spring Cloud Feign依赖（使用OkHttp组件）: 123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.github.openfeign&lt;/groupId&gt; &lt;artifactId&gt;feign-okhttp&lt;/artifactId&gt;&lt;/dependency&gt; 配置: 12345feign: httpclient: enabled: false okhttp: enabled: true 在启动类上加上@EnableFeignClients 12345678@EnableFeignClients@SpringBootApplicationpublic class ServiceBApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ServiceBApplication.class, args); &#125;&#125; Feign: 123456@FeignClient(value = &quot;service-a&quot;, path = &quot;/service-a&quot;)public interface HelloRemoteClient &#123; @GetMapping(&quot;/&#123;name&#125;&quot;) String sayHello(@PathVariable(&quot;name&quot;) String name);&#125; value指被调用方的服务名 path请求指定前缀, 例如上面的sayHello会请求/service-a/{name}这个url 调用: 12345678910111213@RestController@RequestMapping(&quot;/service-b&quot;)public class HelloController &#123; @Resource private HelloRemoteClient helloClient; @GetMapping(&quot;/&#123;name&#125;&quot;) public String hello(@PathVariable String name) &#123; name += &quot;!&quot;; return helloClient.sayHello(name); &#125;&#125; 踩坑1Caused by: java.lang.IllegalStateException: PathVariable annotation was empty on param 0. 这个大概的意思就是@PathVariable的第一个参数为空. . . 因为之前的写法是这样的: 12@GetMapping(&quot;/&#123;name&#125;&quot;)String sayHello(@PathVariable String name); 正确姿势是这样的: 12@GetMapping(&quot;/&#123;name&#125;&quot;)String sayHello(@PathVariable(&quot;name&quot;) String name); @PathVariable需要指定占位符的名字(&quot;name&quot;) Spring Cloud GatewaySpring Cloud Gateway 是 Spring Cloud 的一个全新项目, 该项目是基于 Spring 5.0, Spring Boot 2.0 和 Project Reactor 等技术开发的网关, 它旨在为微服务架构提供一种简单有效的统一的 API 路由管理方式. Spring Cloud Gateway 作为 Spring Cloud 生态系统中的网关, 目标是替代 Netflix Zuul, 其不仅提供统一的路由方式, 并且基于 Filter 链的方式提供了网关基本的功能, 例如: 安全、监控、埋点和限流等. Spring Cloud Gateway 的特征: 基于 Spring Framework 5, Project Reactor 和 Spring Boot 2.0 动态路由 Predicates 和 Filters 作用于特定路由 集成 Hystrix 断路器 集成 Spring Cloud DiscoveryClient 易于编写的 Predicates 和 Filters 限流 路径重写 流程图: Spring Boot Admin 依赖12345678910111213141516171819202122&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;de.codecentric&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-admin-starter-server&lt;/artifactId&gt; &lt;version&gt;2.0.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 主类添加注解12345678@EnableAdminServer@SpringBootApplicationpublic class AdminApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(AdminApplication.class, args); &#125;&#125; 配置application.yml: 12345678910111213141516171819server: port: 6010spring: application: name: admin profiles: active: dev security: user: name: ybd password: ybdmanagement: endpoints: web: exposure: include: &quot;*&quot; endpoint: health: show-details: ALWAYS application-dev.yml: 12345678eureka: client: service-url: defaultZone: http://ybd:ybd@127.0.0.1:8761/eureka/ instance: metadata-map: user.name: ybd user.password: ybd SecuritySecureConfig: 123456789101112131415161718192021222324252627@Configurationpublic class SecuritySecureConfig extends WebSecurityConfigurerAdapter &#123; private final String adminContextPath; public SecuritySecureConfig(AdminServerProperties adminServerProperties) &#123; this.adminContextPath = adminServerProperties.getContextPath(); &#125; @Override protected void configure(HttpSecurity http) throws Exception &#123; SavedRequestAwareAuthenticationSuccessHandler successHandler = new SavedRequestAwareAuthenticationSuccessHandler(); successHandler.setTargetUrlParameter(&quot;redirectTo&quot;); http.authorizeRequests()// .antMatchers(&quot;/actuator&quot;, &quot;/actuator/health&quot;, &quot;/actuator/info&quot;).permitAll() .antMatchers(adminContextPath + &quot;/assets/**&quot;).permitAll() .antMatchers(adminContextPath + &quot;/login&quot;).permitAll() .anyRequest().authenticated() .and() .formLogin().loginPage(adminContextPath + &quot;/login&quot;).successHandler(successHandler).and() .logout().logoutUrl(adminContextPath + &quot;/logout&quot;).and() .httpBasic() .and() .csrf().disable(); &#125;&#125; Finally 代码: https://github.com/masteranthoneyd/spring-cloud-learning]]></content>
      <categories>
        <category>Programming</category>
        <category>Java</category>
        <category>Spring Cloud</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring Cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot应用集成Docker并结合Log4j2、Kafka、ELK管理Docker日志]]></title>
    <url>%2F2018%2Fspring-boot-docker-elk%2F</url>
    <content type="text"><![CDATA[Preface 微服务架构下, 微服务在带来良好的设计和架构理念的同时, 也带来了运维上的额外复杂性, 尤其是在服务部署和服务监控上. 单体应用是集中式的, 就一个单体跑在一起, 部署和管理的时候非常简单, 而微服务是一个网状分布的, 有很多服务需要维护和管理, 对它进行部署和维护的时候则比较复杂. 集成Docker之后, 我们可以很方便地部署以及编排服务, ELK的集中式日志管理可以让我们很方便地聚合Docker日志. Log4j2 Related使用Log4j2下面是 Log4j2 官方性能测试结果: Maven配置123456789101112131415161718192021222324252627282930&lt;!-- Spring Boot 依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;!-- 去除 logback 依赖 --&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- 日志 Log4j2 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-log4j2&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- Log4j2 异步支持 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.lmax&lt;/groupId&gt; &lt;artifactId&gt;disruptor&lt;/artifactId&gt; &lt;version&gt;3.3.8&lt;/version&gt;&lt;/dependency&gt; 注意: 需要单独把spring-boot-starter里面的logging去除再引入spring-boot-starter-web, 否则后面引入的starter模块带有的logging不会自动去除 Disruptor需要3.3.8以及以上版本 开启全局异步以及Disruptor参数设置 官方说明: https://logging.apache.org/log4j/2.x/manual/async.html#AllAsync 添加Disruptor依赖后只需要添加启动参数: 1-Dlog4j2.contextSelector=org.apache.logging.log4j.core.async.AsyncLoggerContextSelector 也可以在程序启动时添加系统参数. 若想知道Disruptor是否生效, 可以在AsyncLogger#logMessage中断点 加大队列参数: 12-DAsyncLogger.RingBufferSize=262144-DAsyncLoggerConfig.RingBufferSize=262144 设置队列满了时的处理策略: 丢弃, 否则默认blocking, 异步就与同步无异了: 1-Dlog4j2.AsyncQueueFullPolicy=Discard application.yml简单配置1234logging: config: classpath:log4j2.xml # 指定log4j2配置文件的路径, 默认就是这个 pattern: console: &quot;%clr&#123;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125;&#125;&#123;faint&#125; | %clr&#123;%5p&#125; | %clr&#123;%15.15t&#125;&#123;faint&#125; | %clr&#123;%-50.50c&#123;1.&#125;&#125;&#123;cyan&#125; | %5L | %clr&#123;%M&#125;&#123;magenta&#125; | %msg%n%xwEx&quot; # 控制台日志输出格式 log4j2.xml完整配置上面是简单的打印, 生产环境需要采用以下xml的配置: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;configuration status=&quot;OFF&quot; monitorInterval=&quot;30&quot;&gt; &lt;properties&gt; &lt;Property name=&quot;UNKNOWN&quot; value=&quot;????&quot;/&gt; &lt;Property name=&quot;KAFKA_SERVERS&quot; value=&quot;$&#123;spring:ybd.kafka.bootstrap&#125;&quot;/&gt; &lt;Property name=&quot;SERVER_NAME&quot; value=&quot;$&#123;spring:spring.application.name&#125;&quot;/&gt; &lt;Property name=&quot;LOG_PATTERN&quot; value=&quot;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; | $&#123;SERVER_NAME&#125; | %5p | %X&#123;IP&#125; | %X&#123;UA&#125; | %t -&gt; %c&#123;1&#125;#%M:%L | %msg%n%xwEx&quot;/&gt; &lt;/properties&gt; &lt;Appenders&gt; &lt;Console name=&quot;console&quot; target=&quot;SYSTEM_OUT&quot;&gt; &lt;ThresholdFilter level=&quot;info&quot; onMatch=&quot;ACCEPT&quot; onMismatch=&quot;DENY&quot;/&gt; &lt;PatternLayout pattern=&quot;$&#123;LOG_PATTERN&#125;&quot; charset=&quot;UTF-8&quot;/&gt; &lt;/Console&gt; &lt;Kafka name=&quot;kafka&quot; topic=&quot;log-collect&quot; ignoreExceptions=&quot;false&quot;&gt; &lt;ThresholdFilter level=&quot;INFO&quot; onMatch=&quot;ACCEPT&quot; onMismatch=&quot;DENY&quot;/&gt; &lt;PatternLayout pattern=&quot;$&#123;LOG_PATTERN&#125;&quot; charset=&quot;UTF-8&quot;/&gt; &lt;Property name=&quot;bootstrap.servers&quot;&gt;$&#123;KAFKA_SERVERS&#125;&lt;/Property&gt; &lt;Property name=&quot;request.timeout.ms&quot;&gt;5000&lt;/Property&gt; &lt;Property name=&quot;transaction.timeout.ms&quot;&gt;5000&lt;/Property&gt; &lt;Property name=&quot;max.block.ms&quot;&gt;3000&lt;/Property&gt; &lt;/Kafka&gt; &lt;RollingFile name=&quot;failoverKafkaLog&quot; fileName=&quot;./failoverKafka/$&#123;SERVER_NAME&#125;.log&quot; filePattern=&quot;./failoverKafka/$&#123;SERVER_NAME&#125;.%d&#123;yyyy-MM-dd&#125;.log&quot;&gt; &lt;ThresholdFilter level=&quot;INFO&quot; onMatch=&quot;ACCEPT&quot; onMismatch=&quot;DENY&quot;/&gt; &lt;PatternLayout&gt; &lt;Pattern&gt;$&#123;LOG_PATTERN&#125;&lt;/Pattern&gt; &lt;/PatternLayout&gt; &lt;Policies&gt; &lt;TimeBasedTriggeringPolicy /&gt; &lt;/Policies&gt; &lt;/RollingFile&gt; &lt;Failover name=&quot;failover&quot; primary=&quot;kafka&quot; retryIntervalSeconds=&quot;300&quot;&gt; &lt;Failovers&gt; &lt;AppenderRef ref=&quot;failoverKafkaLog&quot;/&gt; &lt;/Failovers&gt; &lt;/Failover&gt; &lt;/Appenders&gt; &lt;Loggers&gt; &lt;Root level=&quot;INFO&quot; includeLocation=&quot;true&quot;&gt; &lt;AppenderRef ref=&quot;failover&quot;/&gt; &lt;AppenderRef ref=&quot;console&quot;/&gt; &lt;/Root&gt; &lt;/Loggers&gt;&lt;/configuration&gt; bootstrap.servers是kafka的地址, 接入Docker network之后可以配置成kafka:9092 topic要与Logstash中配置的一致 启用了全局异步需要将includeLocation设为true才能打印路径之类的信息 Kafka地址通过${spring:ybd.kafka.bootstrap}读取配置文件获取, 这个需要自己拓展Log4j, 具体请看下面的获取Application配置 LOG_PATTERN中的%X{IP}、%X{UA}, 通过MDC.put(key, value)放进去, 同时在&lt;Root&gt;中设置includeLocation=&quot;true&quot;才能获取%t、%c等信息 KafkaAppender结合FailoverAppender确保当Kafka Crash时, 日志触发Failover, 写到文件中, 不阻塞程序, 进而保证了吞吐. retryIntervalSeconds的默认值是1分钟, 是通过异常来切换的, 所以可以适量加大间隔. KafkaAppender ignoreExceptions 必须设置为false, 否则无法触发Failover KafkaAppender max.block.ms默认是1分钟, 当Kafka宕机时, 尝试写Kafka需要1分钟才能返回Exception, 之后才会触发Failover, 当请求量大时, log4j2 队列很快就会打满, 之后写日志就Blocking, 严重影响到主服务响应 日志的格式采用&quot; | &quot;作为分割符方便后面Logstash进行切分字段 也可以使用log4j2.yml需要引入依赖以识别: 12345&lt;!-- 加上这个才能辨认到log4j2.yml文件 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.dataformat&lt;/groupId&gt; &lt;artifactId&gt;jackson-dataformat-yaml&lt;/artifactId&gt;&lt;/dependency&gt; log4j2.yml: 1234567891011121314151617181920212223242526272829303132333435Configuration: status: &quot;OFF&quot; monitorInterval: 10 Properties: Property: - name: log.level.console value: debug - name: PID value: ???? - name: LOG_PATTERN value: &quot;%clr&#123;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125;&#125;&#123;faint&#125; | %clr&#123;%5p&#125; | %clr&#123;$&#123;sys:PID&#125;&#125;&#123;magenta&#125; | %clr&#123;%15.15t&#125;&#123;faint&#125; | %clr&#123;%-50.50c&#123;1.&#125;&#125;&#123;cyan&#125; | %5L | %clr&#123;%M&#125;&#123;magenta&#125; | %msg%n%xwEx&quot; Appenders: Console: #输出到控制台 name: CONSOLE target: SYSTEM_OUT ThresholdFilter: level: $&#123;sys:log.level.console&#125; # “sys:”表示: 如果VM参数中没指定这个变量值, 则使用本文件中定义的缺省全局变量值 onMatch: ACCEPT onMismatch: DENY PatternLayout: pattern: $&#123;LOG_PATTERN&#125; charset: UTF-8 Loggers: Root: level: info includeLocation: true AppenderRef: - ref: CONSOLE AsyncRoot: level: info includeLocation: true AppenderRef: - ref: CONSOLE 更多配置请参照: http://logging.apache.org/log4j/2.x/manual/layouts.html 日志配置文件中获取Application配置Logback方法1: 使用logback-spring.xml, 因为logback.xml加载早于application.properties, 所以如果你在logback.xml使用了变量时, 而恰好这个变量是写在application.properties时, 那么就会获取不到, 只要改成logback-spring.xml就可以解决. 方法2: 使用&lt;springProperty&gt;标签, 例如: 1&lt;springProperty scope=&quot;context&quot; name=&quot;LOG_HOME&quot; source=&quot;logback.file&quot;/&gt; Log4j2只能写一个Lookup: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788/** * @author ybd * @date 18-5-11 * @contact yangbingdong1994@gmail.com */@Plugin(name = LOOK_UP_PREFIX, category = StrLookup.CATEGORY)public class SpringEnvironmentLookup extends AbstractLookup &#123; public static final String LOOK_UP_PREFIX = &quot;spring&quot;; private static LinkedHashMap profileYmlData; private static LinkedHashMap metaYmlData; private static boolean profileExist; private static Map&lt;String, String&gt; map = new HashMap&lt;&gt;(16); private static final String PROFILE_PREFIX = &quot;application&quot;; private static final String PROFILE_SUFFIX = &quot;.yml&quot;; private static final String META_PROFILE = PROFILE_PREFIX + PROFILE_SUFFIX; private static final String SPRING_PROFILES_ACTIVE = &quot;spring.profiles.active&quot;; static &#123; try &#123; metaYmlData = new Yaml().loadAs(new ClassPathResource(META_PROFILE).getInputStream(), LinkedHashMap.class); Properties properties = System.getProperties(); String active = properties.getProperty(SPRING_PROFILES_ACTIVE); if (isBlank(active)) &#123; active = getValueFromData(SPRING_PROFILES_ACTIVE, metaYmlData); &#125; if (isNotBlank(active)) &#123; String configName = PROFILE_PREFIX + &quot;-&quot; + active + PROFILE_SUFFIX; ClassPathResource classPathResource = new ClassPathResource(configName); profileExist = classPathResource.exists(); if (profileExist) &#123; profileYmlData = new Yaml().loadAs(classPathResource.getInputStream(), LinkedHashMap.class); &#125; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); throw new RuntimeException(&quot;SpringEnvironmentLookup initialize fail&quot;); &#125; &#125; @Override public String lookup(LogEvent event, String key) &#123; return map.computeIfAbsent(key, SpringEnvironmentLookup::resolveYmlMapByKey); &#125; private static String resolveYmlMapByKey(String key) &#123; Assert.isTrue(isNotBlank(key), &quot;key can not be blank!&quot;); String[] keyChain = key.split(&quot;\\.&quot;); String value = null; if (profileExist) &#123; value = getValueFromData(key, profileYmlData); &#125; if (isBlank(value)) &#123; value = getValueFromData(key, metaYmlData); &#125; return value; &#125; private static String getValueFromData(String key, LinkedHashMap dataMap) &#123; String[] keyChain = key.split(&quot;\\.&quot;); int length = keyChain.length; if (length == 1) &#123; return getFinalValue(key, dataMap); &#125; String k; LinkedHashMap[] mapChain = new LinkedHashMap[length]; mapChain[0] = dataMap; for (int i = 0; i &lt; length; i++) &#123; if (i == length - 1) &#123; return getFinalValue(keyChain[i], mapChain[i]); &#125; k = keyChain[i]; Object o = mapChain[i].get(k); if (Objects.isNull(o)) &#123; return &quot;&quot;; &#125; if (o instanceof LinkedHashMap) &#123; mapChain[i + 1] = (LinkedHashMap) o; &#125; else &#123; throw new IllegalArgumentException(); &#125; &#125; return &quot;&quot;; &#125; private static String getFinalValue(String k, LinkedHashMap ymlData) &#123; return defaultIfNull((String) ymlData.get(k), &quot;&quot;); &#125;&#125; 然后在log4j2.xml中这样使用 ${spring:spring.application.name} 自定义字段可以利用MDC实现当前线程自定义字段 1MDC.put(&quot;IP&quot;, IpUtil.getIpAddr(request)); log4j2.xml中这样获取%X{IP} Spring Boot Docker Integration准备工作 Docker IDE（使用IDEA） Maven环境 Docker私有仓库, 可以使用Harbor(Ubuntu中安装Harbor) 集成Docker需要的插件docker-maven-plugin: https://github.com/spotify/docker-maven-plugin 安全认证配置 当我们 push 镜像到 Docker 仓库中时, 不管是共有还是私有, 经常会需要安全认证, 登录完成之后才可以进行操作. 当然, 我们可以通过命令行 docker login -u user_name -p password docker_registry_host 登录, 但是对于自动化流程来说, 就不是很方便了. 使用 docker-maven-plugin 插件我们可以很容易实现安全认证. 普通配置settings.xml: 12345678&lt;server&gt; &lt;id&gt;docker-registry&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;12345678&lt;/password&gt; &lt;configuration&gt; &lt;email&gt;yangbingdong1994@gmail.com&lt;/email&gt; &lt;/configuration&gt;&lt;/server&gt; Maven 密码加密配置settings.xml配置私有库的访问: 首先使用你的私有仓库访问密码生成主密码: 1mvn --encrypt-master-password &lt;password&gt; 其次在settings.xml文件的同级目录创建settings-security.xml文件, 将主密码写入: 1234&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;settingsSecurity&gt; &lt;master&gt;&#123;Ns0JM49fW9gHMTZ44n*****************=&#125;&lt;/master&gt;&lt;/settingsSecurity&gt; 最后使用你的私有仓库访问密码生成服务密码, 将生成的密码写入到settings.xml的&lt;services&gt;中（可能会提示目录不存在, 解决方法是创建一个.m2目录并把settings-security.xml复制进去） 12mvn --encrypt-password &lt;password&gt;&#123;D9YIyWYvtYsHayLjIenj***********=&#125; 12345678&lt;server&gt; &lt;id&gt;docker-registry&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;&#123;gKLNhblk/SQHBMooM******************=&#125;&lt;/password&gt; &lt;configuration&gt; &lt;email&gt;yangbingdong1994@gmail.com&lt;/email&gt; &lt;/configuration&gt;&lt;/server&gt; 构建基础镜像Dockerfile: 123456789101112FROM frolvlad/alpine-oraclejdk8:slimMAINTAINER ybd &lt;yangbingdong1994@gmail.com&gt;ARG TZ ARG HTTP_PROXYENV TZ=$&#123;TZ:-&quot;Asia/Shanghai&quot;&#125; http_proxy=$&#123;HTTP_PROXY&#125; https_proxy=$&#123;HTTP_PROXY&#125;RUN apk update &amp;&amp; \ apk add --no-cache &amp;&amp; \ apk add curl bash tree tzdata &amp;&amp; \ ln -snf /usr/share/zoneinfo/$TZ /etc/localtime &amp;&amp; \ echo $TZ &gt; /etc/timezone ENV http_proxy=ENV https_proxy= 构建: 1docker build --build-arg HTTP_PROXY=192.168.6.113:8118 -t yangbingdong/docker-oraclejdk8 . 其中HTTP_PROXY是http代理, 通过--build-arg参数传入, 注意不能是127.0.0.1或localhost. 开始集成编写Dockerfile在src/main下面新建docker文件夹, 并创建Dockerfile: 123456FROM yangbingdong/docker-oraclejdk8:latestMAINTAINER yangbingdong &lt;yangbingdong1994@gmail.com&gt;ENV PROJECT_NAME=&quot;@project.build.finalName@.@project.packaging@&quot; JAVA_OPTS=&quot;&quot;ADD $PROJECT_NAME app.jarRUN sh -c &apos;touch /app.jar&apos;ENTRYPOINT exec java $JAVA_OPTS -Djava.security.egd=file:/dev/./urandom -DLog4jContextSelector=org.apache.logging.log4j.core.async.AsyncLoggerContextSelector -Dspring.profiles.active=$&#123;ACTIVE:-docker&#125; -jar /app.jar 通过@@动态获取打包后的项目名（需要插件, 下面会介绍） Dspring.profiles.active=${ACTIVE:-docker}可以通过docker启动命令-e ACTIVE=docker参数修改配置 注意PID如果需要Java程序监听到sigterm信号, 那么Java程序的PID必须是1, 可以使用ENTRYPOINT exec java -jar ...这种方式实现. pom文件添加构建Docker镜像的相关插件 继承spring-boot-starter-parent, 除了docker-maven-plugin, 下面的3个插件都不用填写版本号, 因为parent中已经定义版本号 spring-boot-maven-plugin这个不用多介绍了, 打包Spring Boot Jar包的 1234567891011&lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;repackage&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; maven-resources-pluginresources插件, 使用@变量@形式获取Maven变量到Dockerfile中（同时拷贝构建的Jar包到Dockerfile同一目录中, 这种方式是方便手动构建镜像） 12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;prepare-dockerfile&lt;/id&gt; &lt;phase&gt;validate&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;copy-resources&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;!-- 编译后Dockerfile的输出位置 --&gt; &lt;outputDirectory&gt;$&#123;dockerfile.compiled.position&#125;&lt;/outputDirectory&gt; &lt;resources&gt; &lt;!-- Dockerfile位置 --&gt; &lt;resource&gt; &lt;directory&gt;$&#123;project.basedir&#125;/src/main/docker&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;!-- 将Jar复制到target的docker目录中, 因为真正的Dockerfile也是在里面, 方便使用docker build命令构建Docker镜像 --&gt; &lt;execution&gt; &lt;id&gt;copy-jar&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;copy-resources&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;outputDirectory&gt;$&#123;dockerfile.compiled.position&#125;&lt;/outputDirectory&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;$&#123;project.build.directory&#125;&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;*.jar&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; build-helper-maven-plugin这个是为了给镜像添加基于时间戳的版本号, maven也有自带的获取时间戳的变量maven.build.timestamp.format + maven.build.timestamp: 1234&lt;maven.build.timestamp.format&gt;yyyy-MM-dd_HH-mm-ss&lt;maven.build.timestamp.format&gt;# 获取时间戳$&#123;maven.build.timestamp&#125; 但是这个时区是UTC, 接近于格林尼治标准时间, 所以出来的时间会比但前的时间慢8个小时. 如果要使用GMT+8, 就需要build-helper-maven-plugin插件, 当然也有其他的实现方式, 这里不做展开. 12345678910111213141516171819202122&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt; &lt;artifactId&gt;build-helper-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;timestamp-property&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;timestamp-property&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;!-- 其他地方可通过$&#123;timestamp&#125;获取时间戳 --&gt; &lt;name&gt;timestamp&lt;/name&gt; &lt;pattern&gt;yyyyMMddHHmm&lt;/pattern&gt; &lt;timeZone&gt;GMT+8&lt;/timeZone&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 然后可以在pom中使用${timestamp}获取时间戳. 当然, 也可以使用另外一种方式实现, 打包前export一个格式化日期的环境变量, pom.xml中获取这个变量: export DOCKER_IMAGE_TAGE_DATE=yyyy-MM-dd_HH-mm mvn help:system可查看所有环境变量 所有的环境变量都可以用以env.开头的Maven属性引用: ${env.DOCKER_IMAGE_TAGE_DATE} docker-maven-plugin这也是集成并构建Docker镜像的关键 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657&lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;docker-maven-plugin&lt;/artifactId&gt; &lt;version&gt;$&#123;docker-maven-plugin.version&#125;&lt;/version&gt; &lt;!-- --&gt; &lt;!-- 绑定打包阶段执行Docker镜像操作 --&gt; &lt;executions&gt; &lt;execution&gt; &lt;!-- 打包阶段构建镜像 --&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;build&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;execution&gt; &lt;!-- 部署阶段Push镜像 --&gt; &lt;id&gt;push-image&lt;/id&gt; &lt;phase&gt;deploy&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;push&lt;/goal&gt; &lt;/goals&gt; &lt;!-- Push指定镜像 --&gt; &lt;configuration&gt; &lt;!--&lt;imageName&gt;$&#123;docker.registry.url&#125;/$&#123;docker.registry.name&#125;/$&#123;project.artifactId&#125;:$&#123;docker-latest-tag&#125;&lt;/imageName&gt;--&gt; &lt;!--suppress UnresolvedMavenProperty --&gt; &lt;imageName&gt;$&#123;docker.registry.url&#125;/$&#123;docker.registry.name&#125;/$&#123;project.artifactId&#125;:$&#123;timestamp&#125;&lt;/imageName&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;!-- 是否跳过所有构建Docker镜像阶段 --&gt; &lt;skipDocker&gt;$&#123;docker.skip.build&#125;&lt;/skipDocker&gt; &lt;!-- 是否跳过Push阶段 --&gt; &lt;skipDockerPush&gt;$&#123;docker.skip.push&#125;&lt;/skipDockerPush&gt; &lt;forceTags&gt;true&lt;/forceTags&gt; &lt;!-- 最大重试次数 --&gt; &lt;retryPushCount&gt;2&lt;/retryPushCount&gt; &lt;imageTags&gt; &lt;!-- 使用时间戳版本号 --&gt; &lt;!--suppress UnresolvedMavenProperty --&gt; &lt;imageTag&gt;$&#123;timestamp&#125;&lt;/imageTag&gt; &lt;/imageTags&gt; &lt;!-- 配置镜像名称, 遵循Docker的命名规范: springio/image --&gt;&lt;imageName&gt;$&#123;docker.registry.url&#125;/$&#123;docker.registry.name&#125;/$&#123;project.artifactId&#125;&lt;/imageName&gt; &lt;!-- Dockerfile位置, 由于配置了编译时动态获取Maven变量, 真正的Dockerfile位于位于编译后位置 --&gt; &lt;dockerDirectory&gt;$&#123;dockerfile.compiled.position&#125;&lt;/dockerDirectory&gt; &lt;resources&gt; &lt;resource&gt; &lt;targetPath&gt;/&lt;/targetPath&gt; &lt;directory&gt;$&#123;project.build.directory&#125;&lt;/directory&gt; &lt;include&gt;$&#123;project.build.finalName&#125;.jar&lt;/include&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;!-- 被推送服务器的配置ID, 与setting中的一直 --&gt; &lt;serverId&gt;docker-registry&lt;/serverId&gt; &lt;!--&lt;registryUrl&gt;$&#123;docker.registry.url&#125;&lt;/registryUrl&gt;--&gt; &lt;/configuration&gt;&lt;/plugin&gt; 主要properties: 1234567891011&lt;properties&gt; &lt;!-- ########## Docker 相关变量 ########## --&gt; &lt;docker-maven-plugin.version&gt;1.0.0&lt;/docker-maven-plugin.version&gt; &lt;!-- resource插件编译Dockerfile后的位置--&gt; &lt;dockerfile.compiled.position&gt;$&#123;project.build.directory&#125;/docker&lt;/dockerfile.compiled.position&gt; &lt;docker.skip.build&gt;false&lt;/docker.skip.build&gt; &lt;docker.skip.push&gt;false&lt;/docker.push.image&gt; &lt;docker.registry.url&gt;192.168.0.202:8080&lt;/docker.registry.url&gt; &lt;docker.registry.name&gt;dev-images&lt;/docker.registry.name&gt; &lt;docker-latest-tag&gt;latest&lt;/docker-latest-tag&gt;&lt;/properties&gt; 说明: 这里的serverId要与maven setting.xml里面的一样 Dockerfile构建文件在src/main/docker中 如果Dockerfile文件需要maven构建参数（比如需要构建后的打包文件名等）, 则使用@@占位符（如@project.build.finalName@）原因是Sping Boot 的pom将resource插件的占位符由${}改为@@, 非继承Spring Boot 的pom文件, 则使用${}占位符 如果不需要动态生成Dockerfile文件, 则可以将Dockerfile资源拷贝部分放入docker-maven-plugin插件的&lt;resources&gt;配置里 spring-boot-maven-plugin插件一定要在其他构建插件之上, 否则打包文件会有问题. docker-maven-plugin 插件还提供了很多很实用的配置, 稍微列举几个参数吧. 参数 说明 默认值 &lt;forceTags&gt;true&lt;/forceTags&gt; build 时强制覆盖 tag, 配合 imageTags 使用 false &lt;noCache&gt;true&lt;/noCache&gt; build 时, 指定 –no-cache 不使用缓存 false &lt;pullOnBuild&gt;true&lt;/pullOnBuild&gt; build 时, 指定 –pull=true 每次都重新拉取基础镜像 false &lt;pushImage&gt;true&lt;/pushImage&gt; build 完成后 push 镜像 false &lt;pushImageTag&gt;true&lt;/pushImageTag&gt; build 完成后, push 指定 tag 的镜像, 配合 imageTags 使用 false &lt;retryPushCount&gt;5&lt;/retryPushCount&gt; push 镜像失败, 重试次数 5 &lt;retryPushTimeout&gt;10&lt;/retryPushTimeout&gt; push 镜像失败, 重试时间 10s &lt;rm&gt;true&lt;/rm&gt; build 时, 指定 –rm=true 即 build 完成后删除中间容器 false &lt;useGitCommitId&gt;true&lt;/useGitCommitId&gt; build 时, 使用最近的 git commit id 前7位作为tag, 例如: image:b50b604, 前提是不配置 newName false 更多参数可查看插件中的定义. 命令构建如果&lt;skipDockerPush&gt;false&lt;/skipDockerPush&gt;则install阶段将不提交Docker镜像, 只有maven的deploy阶段才提交. 1mvn clean install 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364[INFO] --- spring-boot-maven-plugin:1.5.9.RELEASE:repackage (default) @ eureka-center-server ---[INFO] [INFO] --- docker-maven-plugin:1.0.0:build (default) @ eureka-center-server ---[INFO] Using authentication suppliers: [ConfigFileRegistryAuthSupplier, NoOpRegistryAuthSupplier][WARNING] Ignoring run because dockerDirectory is set[INFO] Copying /home/ybd/data/git-repo/bitbucket/ms-iba/eureka-center-server/target/eureka-center-server-0.0.1-SNAPSHOT.jar -&gt; /home/ybd/data/git-repo/bitbucket/ms-iba/eureka-center-server/target/docker/eureka-center-server-0.0.1-SNAPSHOT.jar[INFO] Copying /home/ybd/data/git-repo/bitbucket/ms-iba/eureka-center-server/target/docker/eureka-center-server-0.0.1-SNAPSHOT.jar -&gt; /home/ybd/data/git-repo/bitbucket/ms-iba/eureka-center-server/target/docker/eureka-center-server-0.0.1-SNAPSHOT.jar[INFO] Copying /home/ybd/data/git-repo/bitbucket/ms-iba/eureka-center-server/target/docker/Dockerfile -&gt; /home/ybd/data/git-repo/bitbucket/ms-iba/eureka-center-server/target/docker/Dockerfile[INFO] Building image 192.168.6.113:8888/discover-server/eureka-center-serverStep 1/7 : FROM frolvlad/alpine-oraclejdk8:slim ---&gt; 491f45037124Step 2/7 : MAINTAINER ybd &lt;yangbingdong1994@gmail.com&gt; ---&gt; Using cache ---&gt; 016c2033bd32Step 3/7 : VOLUME /tmp ---&gt; Using cache ---&gt; d2a287b6ed52Step 4/7 : ENV PROJECT_NAME=&quot;eureka-center-server-0.0.1-SNAPSHOT.jar&quot; JAVA_OPTS=&quot;&quot; ---&gt; Using cache ---&gt; 34565a7de714Step 5/7 : ADD $PROJECT_NAME app.jar ---&gt; 64d9055ce969Step 6/7 : RUN sh -c &apos;touch /app.jar&apos; ---&gt; Running in 66f4eb550a57Removing intermediate container 66f4eb550a57 ---&gt; 93486965cad9Step 7/7 : CMD [&quot;sh&quot;, &quot;-c&quot;, &quot;java $JAVA_OPTS -Djava.security.egd=file:/dev/./urandom -Dspring.profiles.active=$&#123;ACTIVE:-docker&#125; -jar /app.jar&quot;] ---&gt; Running in 8b42c471791fRemoving intermediate container 8b42c471791f ---&gt; 2eb3dbbab6c5ProgressMessage&#123;id=null, status=null, stream=null, error=null, progress=null, progressDetail=null&#125;Successfully built 2eb3dbbab6c5Successfully tagged 192.168.6.113:8888/discover-server/eureka-center-server:latest[INFO] Built 192.168.6.113:8888/discover-server/eureka-center-server[INFO] Tagging 192.168.6.113:8888/discover-server/eureka-center-server with 0.0.1-SNAPSHOT[INFO] Tagging 192.168.6.113:8888/discover-server/eureka-center-server with latest[INFO] Pushing 192.168.6.113:8888/discover-server/eureka-center-serverThe push refers to repository [192.168.6.113:8888/discover-server/eureka-center-server]40566d372b69: Pushed 40566d372b69: Layer already exists 4fd38f0d6712: Layer already exists d7cd646c41bd: Layer already exists ced237d13962: Layer already exists 2aebd096e0e2: Layer already exists null: null null: null [INFO] [INFO] --- maven-install-plugin:2.4:install (default-install) @ eureka-center-server ---[INFO] Installing /home/ybd/data/git-repo/bitbucket/ms-iba/eureka-center-server/target/eureka-center-server-0.0.1-SNAPSHOT.jar to /home/ybd/data/application/maven/maven-repo/com/iba/server/eureka-center-server/0.0.1-SNAPSHOT/eureka-center-server-0.0.1-SNAPSHOT.jar[INFO] Installing /home/ybd/data/git-repo/bitbucket/ms-iba/eureka-center-server/pom.xml to /home/ybd/data/application/maven/maven-repo/com/iba/server/eureka-center-server/0.0.1-SNAPSHOT/eureka-center-server-0.0.1-SNAPSHOT.pom[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 15.962 s[INFO] Finished at: 2017-12-25T13:33:39+08:00[INFO] Final Memory: 55M/591M[INFO] ------------------------------------------------------------------------ 可以看到本地以及私有仓库都多了一个镜像: 此处有个疑问, 很明显看得出来这里上传了两个一样大小的包, 不知道是不是同一个jar包, 但id又不一样: 运行Docker运行程序 1docker run --name some-server -e ACTIVE=docker -p 8080:8080 -d [IMAGE] 添加运行时JVM参数只需要在Docker启动命令中加上-e &quot;JAVA_OPTS=-Xmx128m&quot;即可 Docker Swarm环境下获取ClientIp在Docker Swarm环境中, 服务中获取到的ClientIp永远是10.255.0.X这样的Ip, 搜索了一大圈, 最终的解决方安是通过Nginx转发中添加参数, 后端再获取. 在location中添加 1proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; 后端获取第一个Ip. Demo地址https://github.com/masteranthoneyd/spring-boot-learning/tree/master/spring-boot-docker Kafka、ELK collect logs 传统的应用可以将日志存到日志中, 但集成Docker之后, 日志怎么处理？放到容器的某个目录然后挂在出来？这样也可以, 但这样就相当于给容器与外界绑定了一个状态, 弹性伸缩怎么办？个人还是觉得通过队列与ELK管理Docker日志比较合理, 而且Log4j2原生支持Kafka的Appender. 镜像准备Docker Hub中的ELK镜像并不是最新版本的, 我们需要到官方的网站获取最新的镜像: https://www.docker.elastic.co 12345docker pull zookeeperdocker pull wurstmeister/kafka:1.1.0docker pull docker.elastic.co/elasticsearch/elasticsearch:6.3.0docker pull docker.elastic.co/kibana/kibana:6.3.0docker pull docker.elastic.co/logstash/logstash:6.3.0 注意ELK版本最好保持一致 启动Kafka与Zookeeper这里直接使用docker-compose（需要先创建外部网络）: 1234567891011121314151617181920212223242526272829303132333435version: &apos;3.4&apos;services: zoo: image: zookeeper:latest ports: - &quot;2181:2181&quot; restart: always networks: backend: aliases: - zoo kafka: image: wurstmeister/kafka:1.1.0 ports: - &quot;9092:9092&quot; environment: - KAFKA_PORT=9092 - KAFKA_ADVERTISED_HOST_NAME=192.168.6.113 - KAFKA_ZOOKEEPER_CONNECT=zoo:2181 - KAFKA_ADVERTISED_PORT=9092 volumes: - /var/run/docker.sock:/var/run/docker.sock depends_on: - zoo restart: always networks: backend: aliases: - kafkanetworks: backend: external: name: backend KAFKA_ADVERTISED_HOST_NAME是内网IP, 本地调试用, Docker环境下换成kafka（与别名aliases的值保持一致）, 其他Docker应用可通过kafka:9092这个域名访问到Kafka. ELK配置以及启动X-Pack 破解复制Jar包先启动一个Elasticsearch的容器, 将Jar包copy出来: 123export CONTAINER_NAME=elk_elk-elasticsearch_1docker cp $&#123;CONTAINER_NAME&#125;:/usr/share/elasticsearch/modules/x-pack-core/x-pack-core-6.4.0.jar ./docker cp $&#123;CONTAINER_NAME&#125;:/usr/share/elasticsearch/lib ./lib 反编译并修改源码找到下面两个类:1org.elasticsearch.license.LicenseVerifier.class org.elasticsearch.xpack.core.XPackBuild.class 使用 Luyten 进行反编译 将两个类复制IDEA（需要引入上面copy出来的lib以及x-pack-core-6.4.0.jar本身）, 修改为如下样子: 123456789101112package org.elasticsearch.license;public class LicenseVerifier&#123; public static boolean verifyLicense(final License license, final byte[] publicKeyData) &#123; return true; &#125; public static boolean verifyLicense(final License license) &#123; return true; &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package org.elasticsearch.xpack.core;import org.elasticsearch.common.SuppressForbidden;import org.elasticsearch.common.io.PathUtils;import java.net.URISyntaxException;import java.net.URL;import java.nio.file.Path;public class XPackBuild&#123; public static final XPackBuild CURRENT; private String shortHash; private String date; @SuppressForbidden(reason = &quot;looks up path of xpack.jar directly&quot;) static Path getElasticsearchCodebase() &#123; final URL url = XPackBuild.class.getProtectionDomain().getCodeSource().getLocation(); try &#123; return PathUtils.get(url.toURI()); &#125; catch (URISyntaxException bogus) &#123; throw new RuntimeException(bogus); &#125; &#125; XPackBuild(final String shortHash, final String date) &#123; this.shortHash = shortHash; this.date = date; &#125; public String shortHash() &#123; return this.shortHash; &#125; public String date() &#123; return this.date; &#125; static &#123; final Path path = getElasticsearchCodebase(); String shortHash = null; String date = null; Label_0157: &#123; // 将try-catch去掉 shortHash = &quot;Unknown&quot;; date = &quot;Unknown&quot;; &#125; CURRENT = new XPackBuild(shortHash, date); &#125;&#125; 再编译放回jar包中: 配置文件Elasticsearchelasticsearch.yml: 12345cluster.name: &quot;docker-cluster&quot;network.host: 0.0.0.0discovery.zen.minimum_master_nodes: 1xpack.security.enabled: false # 不启用密码登陆xpack.monitoring.collection.enabled: true Logstashlogstash.conf配置文件(注意下面的topics要与上面log4j2.xml中的一样): 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273input &#123; kafka &#123; bootstrap_servers =&gt; [&quot;kafka:9092&quot;] auto_offset_reset =&gt; &quot;latest&quot; consumer_threads =&gt; 3 # 3个消费线程, 默认是1个 topics =&gt; [&quot;log-collect&quot;] &#125;&#125;filter &#123; mutate&#123; # 切分日志信息并添加相应字段 split =&gt; [ &quot;message&quot;,&quot; | &quot; ] add_field =&gt; &#123; &quot;timestamp&quot; =&gt; &quot;%&#123;[message][0]&#125;&quot; &#125; add_field =&gt; &#123; &quot;level&quot; =&gt; &quot;%&#123;[message][2]&#125;&quot; &#125; add_field =&gt; &#123; &quot;server_name&quot; =&gt; &quot;%&#123;[message][1]&#125;&quot; &#125; add_field =&gt; &#123; &quot;ip&quot; =&gt; &quot;%&#123;[message][3]&#125;&quot; &#125; add_field =&gt; &#123; &quot;device&quot; =&gt; &quot;%&#123;[message][4]&#125;&quot; &#125; add_field =&gt; &#123; &quot;thread_class_method&quot; =&gt; &quot;%&#123;[message][5]&#125;&quot; &#125; add_field =&gt; &#123; &quot;content&quot; =&gt; &quot;%&#123;[message][6]&#125;&quot; &#125; remove_field =&gt; [ &quot;message&quot; ] &#125; date &#123; # 将上面得到的日期信息, 也就是日志打印的时间作为时间戳 match =&gt; [ &quot;timestamp&quot;, &quot;yyyy-MM-dd HH:mm:ss.SSS&quot; ] locale =&gt; &quot;en&quot; target =&gt; [ &quot;@timestamp&quot; ] timezone =&gt; &quot;Asia/Shanghai&quot; # 这里如果不设置时区, 在Kibana中展示的时候会多了8个小时 &#125; geoip &#123; # 分析ip source =&gt; &quot;ip&quot; &#125; useragent &#123; # 分析User-Agent source =&gt; &quot;device&quot; target =&gt; &quot;userDevice&quot; remove_field =&gt; [ &quot;device&quot; ] &#125;&#125;output &#123; stdout&#123; codec =&gt; rubydebug &#125; # 输出到控制台 elasticsearch &#123; # 输出到 Elasticsearch action =&gt; &quot;index&quot; hosts =&gt; [&quot;elk-elasticsearch:9200&quot;] index =&gt; &quot;logstash-%&#123;server_name&#125;-%&#123;+yyyy.MM.dd&#125;&quot; document_type =&gt; &quot;%&#123;server_name&#125;&quot; # user =&gt; &quot;elastic&quot; # 如果选择开启xpack security需要输入帐号密码 # password =&gt; &quot;changeme&quot; &#125;&#125; logstash.yml: 12345http.host: &quot;0.0.0.0&quot;xpack.monitoring.elasticsearch.url: http://elk-elasticsearch:9200 # Docker版的Logstash此配置的默认地址是http://elasticsearch:9200# xpack.monitoring.elasticsearch.username: &quot;elastic&quot; # 如果选择开启xpack security需要输入帐号密码# xpack.monitoring.elasticsearch.password: &quot;changeme&quot; Kibanakibana.yml: 123456server.name: kibanaserver.host: &quot;0&quot;elasticsearch.url: http://elk-elasticsearch:9200xpack.monitoring.ui.container.elasticsearch.enabled: true#elasticsearch.username: &quot;elastic&quot;#elasticsearch.password: &quot;changeme&quot; 申请License转到 License申请地址 , 下载之后然后修改license中的type、max_nodes、expiry_date_in_millis: 12345678910111213&#123; &quot;license&quot;: &#123; &quot;uid&quot;: &quot;fe8c9a81-6651-4327-89a3-c9a33bfd8e3f&quot;, &quot;type&quot;: &quot;platinum&quot;, // 这个类型是白金会员 &quot;issue_date_in_millis&quot;: 1536883200000, &quot;expiry_date_in_millis&quot;: 2855980923000, // 过期时间 &quot;max_nodes&quot;: 100, // 集群节点数量 &quot;issued_to&quot;: &quot;xxxx&quot;, &quot;issuer&quot;: &quot;Web Form&quot;, &quot;signature&quot;: &quot;AAAAAwAAAA0imCa5T/HVBQyiUbSBAAABmC9ZN0hjZDBGYnVyRXpCOW5Bb3FjZDAxOWpSbTVoMVZwUzRxVk1PSmkxaktJRVl5MUYvUWh3bHZVUTllbXNPbzBUemtnbWpBbmlWRmRZb25KNFlBR2x0TXc2K2p1Y1VtMG1UQU9TRGZVSGRwaEJGUjE3bXd3LzRqZ05iLzRteWFNekdxRGpIYlFwYkJiNUs0U1hTVlJKNVlXekMrSlVUdFIvV0FNeWdOYnlESDc3MWhlY3hSQmdKSjJ2ZTcvYlBFOHhPQlV3ZHdDQ0tHcG5uOElCaDJ4K1hob29xSG85N0kvTWV3THhlQk9NL01VMFRjNDZpZEVXeUtUMXIyMlIveFpJUkk2WUdveEZaME9XWitGUi9WNTZVQW1FMG1DenhZU0ZmeXlZakVEMjZFT2NvOWxpZGlqVmlHNC8rWVVUYzMwRGVySHpIdURzKzFiRDl4TmM1TUp2VTBOUlJZUlAyV0ZVL2kvVk10L0NsbXNFYVZwT3NSU082dFNNa2prQ0ZsclZ4NTltbU1CVE5lR09Bck93V2J1Y3c9PQAAAQAWq5AoReLA+uTiRhQ8M0qYERXNidAAsVw0LeN5H7qRXFBAvB+rId4vZNj2DN5W5GuaxuiUhiytvV6maf4ArTsROCMUKGyO9RH24bYgnRbbf6MwB8EBHjSZ6+D8ysCVgfyqAAEKURGSMWszi2mR9R+DINtaeFJnb4B1GeAppbwl7qGGetAQm0vbF7ncyojIfjFthmMUomwo3vs0his5e3UPumItGc57LEk2s5gx95NNP8aFsJXSSFHgWDWwJs18XSl3NZItnEWNfy9lEJeAkR+LWISfizZIfViOTlcDBVGKR7w8u8D5QXFUVdsTi2XU5qfIWFb78BOtpCHIlU+AjB6m&quot;, &quot;start_date_in_millis&quot;: 1536883200000 &#125;&#125; 启动ELKdocker-compose.yml: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172version: &apos;3&apos;services: elk-elasticsearch: image: docker.elastic.co/elasticsearch/elasticsearch:6.4.0# ports:# - &quot;9200:9200&quot; restart: always environment: - discovery.type=single-node - ES_JAVA_OPTS=-Xms512m -Xmx512m volumes: - ./crack/x-pack-core-6.4.0.jar:/usr/share/elasticsearch/modules/x-pack-core/x-pack-core-6.4.0.jar - ./config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml - ./config/license.json:/usr/share/elasticsearch/license.json deploy: placement: constraints: - node.role == manager networks: backend: aliases: - elk-elasticsearch kibana: image: docker.elastic.co/kibana/kibana:6.4.0 ports: - &quot;5601:5601&quot; restart: always deploy: placement: constraints: - node.role == manager networks: backend: aliases: - kibana volumes: - ./config/kibana.yml:/usr/share/kibana/config/kibana.yml depends_on: - elk-elasticsearch logstash: image: docker.elastic.co/logstash/logstash:6.4.0# ports:# - &quot;4560:4560&quot; restart: always environment: - LS_JAVA_OPTS=-Xmx512m -Xms512m volumes: - ./config/logstash.conf:/etc/logstash.conf - ./config/logstash.yml:/usr/share/logstash/config/logstash.yml deploy: placement: constraints: - node.role == manager networks: backend: aliases: - logstash depends_on: - elk-elasticsearch entrypoint: - logstash - -f - /etc/logstash.conf# docker network create -d=overlay --attachable backend# docker network create --opt encrypted -d=overlay --attachable --subnet 10.10.0.0/16 backendnetworks: backend: external: name: backend 启动后需要手动请求更新License: 12docker-compose up -ddocker exec $&#123;CONTAINER_NAME&#125; curl -XPUT &apos;http://0.0.0.0:9200/_xpack/license&apos; -H &quot;Content-Type: application/json&quot; -d @license.json 大概是下面这个样子: 123456789101112131415# ybd @ ybd-PC in ~/data/git-repo/bitbucket/ms-base/docker-compose/elk on git:master x [20:52:51] $ docker-compose up -d Creating elk_elk-elasticsearch_1 ... doneCreating elk_elk-elasticsearch_1 ... Creating elk_logstash_1 ... doneCreating elk_kibana_1 ... done# ybd @ ybd-PC in ~/data/git-repo/bitbucket/ms-base/docker-compose/elk on git:master x [20:53:58] $ docker exec elk_elk-elasticsearch_1 curl -XPUT &apos;http://0.0.0.0:9200/_xpack/license&apos; -H &quot;Content-Type: application/json&quot; -d @license.json % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed100 1278 100 46 100 1232 328 8786 --:--:-- --:--:-- --:--:-- 8800&#123;&quot;acknowledged&quot;:true,&quot;license_status&quot;:&quot;valid&quot;&#125; Kibana相关设置显示所有插件在Kibana首页最下面找到: Discover每页显示行数找到Advanced Setting 点进去找到 discover:sampleSize再点击Edit修改: 时区Kibana默认读取浏览器时区, 可通过dateFormat:tz进行修改: ElasticSearch UI ElasticHD Dejavu Spring Boot 集成 Elastic APM运行APM Serverdocker-compose: 1234567891011121314151617181920212223version: &apos;3&apos;services: apm-server: image: docker.elastic.co/apm/apm-server:6.4.0 ports: - &quot;8200:8200&quot; volumes: - ./config/apm-server.yml:/usr/share/apm-server/apm-server.yml deploy: placement: constraints: - node.role == manager networks: backend-swarm: aliases: - apm-server# docker network create -d=overlay --attachable backend-swarm# docker network create --opt encrypted -d=overlay --attachable --subnet 10.10.0.0/16 backend-swarmnetworks: backend-swarm: external: name: backend-swarm apm-server.yml: 12345678910111213141516171819202122232425262728293031323334353637383940apm-server: host: &quot;0.0.0.0:8200&quot;setup.template.settings: index: number_of_shards: 1 codec: best_compression output.elasticsearch: hosts: [&quot;elk-elasticsearch:9200&quot;] indices: - index: &quot;apm-%&#123;[beat.version]&#125;-sourcemap&quot; when.contains: processor.event: &quot;sourcemap&quot; - index: &quot;apm-%&#123;[beat.version]&#125;-error-%&#123;+yyyy.MM.dd&#125;&quot; when.contains: processor.event: &quot;error&quot; - index: &quot;apm-%&#123;[beat.version]&#125;-transaction-%&#123;+yyyy.MM.dd&#125;&quot; when.contains: processor.event: &quot;transaction&quot; - index: &quot;apm-%&#123;[beat.version]&#125;-span-%&#123;+yyyy.MM.dd&#125;&quot; when.contains: processor.event: &quot;span&quot; - index: &quot;apm-%&#123;[beat.version]&#125;-metric-%&#123;+yyyy.MM.dd&#125;&quot; when.contains: processor.event: &quot;metric&quot; - index: &quot;apm-%&#123;[beat.version]&#125;-onboarding-%&#123;+yyyy.MM.dd&#125;&quot; when.contains: processor.event: &quot;onboarding&quot;logging.level: warninglogging.metrics.enabled: false 这个配置文件从容器中/usr/share/apm-server/apm-server.yml复制出来稍微改了一下Elasticsearch的Url. 若开启了X-Pack, 则需要在yml中配置帐号密码: 1234output.elasticsearch: hosts: [&quot;&lt;es_url&gt;&quot;] username: &lt;username&gt; password: &lt;password&gt; 集成到Spring Boot下载 APM代理依赖 在启动参数中添加: 12345java -javaagent:/path/to/elastic-apm-agent-&lt;version&gt;.jar \ -Delastic.apm.service_name=my-application \ -Delastic.apm.server_url=http://localhost:8200 \ -Delastic.apm.application_packages=org.example \ -jar my-application.jar 启动后在Kibana的APM模块中更新一下索引, 效果图大概是这样的: log-pilotGithub: https://github.com/AliyunContainerService/log-pilot 更多说明: https://yq.aliyun.com/articles/69382 这个是Ali开源的日志收集组件, 通过中间件的方式部署, 自动监听其他容器的日志, 非常方便: 1docker run --rm -it -v /var/run/docker.sock:/var/run/docker.sock -v /etc/localtime:/etc/localtime -v /:/host -e PILOT_TYPE=fluentd -e FLUENTD_OUTPUT=elasticsearch -e ELASTICSEARCH_HOST=192.168.6.113 -e ELASTICSEARCH_PORT=9200 -e TZ=Asia/Chongqing --privileged registry.cn-hangzhou.aliyuncs.com/acs-sample/log-pilot:latest 需要手机日志的容器: 1docker run --rm --label aliyun.logs.demo=stdout -p 8080:8080 192.168.0.202:8080/dev-images/demo:latest 通过--label aliyun.logs.demo=stdout告诉log-pilot需要收集日志, 索引为demo 然后打开Kibana就可以看到日志了. 问题: 日志稍微延迟 日志顺序混乱 异常堆栈不集中 Finally 参考: https://www.yinchengli.com/2016/09/16/logstash/ https://www.jianshu.com/p/ba1aa0c52942 https://www.jianshu.com/p/eb10c414a93f https://my.oschina.net/kkrgwbj/blog/734530]]></content>
      <categories>
        <category>Programming</category>
        <category>Java</category>
        <category>Spring Boot</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring Boot</tag>
        <tag>Spring</tag>
        <tag>Docker</tag>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[转载—自己动手写区块链]]></title>
    <url>%2F2018%2Fwrite-your-own-blockchain%2F</url>
    <content type="text"><![CDATA[Preface 区块链（英语: blockchain 或 block chain）是用分布式数据库识别、传播和记载信息的智能化对等网络, 也称为价值互联网. 中本聪在2008年, 于《比特币白皮书》中提出“区块链”概念, 并在2009年创立了比特币社会网络, 开发出第一个区块, 即“创世区块”. 区块链共享价值体系首先被众多的加密货币效仿, 并在工作量证明上和算法上进行了改进, 如采用权益证明和SCrypt算法. 随后, 区块链生态系统在全球不断进化, 出现了首次代币发售ICO；智能合约区块链以太坊；“轻所有权、重使用权”的资产代币化共享经济； 和区块链国家. 目前, 人们正在利用这一共享价值体系, 在各行各业开发去中心化电脑程序(Decentralized applications, Dapp), 在全球各地构建去中心化自主组织和去中心化自主社区(Decentralized autonomous society, DAS). ——来自维基百科 比特币UTXO和去中心化系统的设计 引用来自JoeCao大神的一段文章 起因刚进2018年, 区块链突然大火, 程序员们可能莫名其妙, 不就是一个分布式系统么, 怎么突然就要改变互联网了？趁着这个东风, 我们了解一些区块链基础知识. 看看是否可以改变世界. UTXO是什么是Unspent Transaction Output（未消费交易输出）简写. 这绝对是比特币的非常特殊的地方, 理解UTXO也就理解了比特币去中心化的含义. 说起UTXO必须先要介绍交易模型. 以我们平时对交易的理解, 我给张三转账了一笔100块钱, 那就是我的账上的钱少了100, 张三账上的钱多了100. 我们再把问题稍微复杂一些, 我和张三合起来买一个李四的一个商品390块钱. 我的账户支付100, 张三账户支付300, 李四的帐户获得390, 支付宝账户获得了10块钱的转账手续费. 那么对这比交易的记录应该是这样的: 这种记账方式常用在财务记账上. 不过作为一个去中心化的系统, 是没有一个中心化银行管理你的开户、销户、余额的. 没有余额, 怎么判断你的账上有100块钱？ 此时用户C必须将前面几次交易的比特币输出作为下一个关联交易的输入, 具体见下图的no 321笔交易, 用户C将前面获得的两次输出, 作为输入放在了交易中, 然后给自己输出1个比特币的找零（如果不给自己输出找零, 那么这个差额就被矿工当成小费了, 切记切记）. 比特币的程序会判定, 如果两个UTXO加在一起不够支付, 则交易不成功. 比特币UTXO使用有点像古代的银锭 五两的银锭付给别人二两, 需要通过夹剪将一整块银锭剪成两块, 二两的给别人, 三两的留给自己. 对比: 比特币在输出中重新创建一个新的UTXO作为给自己的找零 要付给别人五两, 手上有几块碎银子单都不足五两, 则需要将碎银子一起付给对方. 对比: 比特币在输入中同时引用多个输出UTXO. 这样的做法很繁琐, 所以银两在古代并不是一个很普遍的支付方式（别被武侠片给骗了, 大部分还是用铜钱）.比特币采用UTXO并不能很直观的去理解, 但是为什么要用呢？ 使用UTXO的动机那么我们站在系统设计的角度猜测一下为什么中本聪会考虑使用UTXO. 比特币是没有开户的过程的, 一个本地计算生成公私钥就能构成一个合法的帐户, 甚至有些用户为了一些“靓号”帐户, 通过暴力运算生成天量的再也不会使用的帐户. 去中心化系统无法跟踪每个账户的生成和销毁, 这样的系统里面的帐户数量远大于未消费的输出数量, 所以以UTXO来替代跟踪帐户交易的方式, 消耗的系统资源会比较少 ； 比特币有个比较好的特性是匿名性, 很多人每次交易就换一对公私钥, 交易输出的给自己的找零往往输出到一个另外的帐户下去, UTXO迎合了这种需求. 而使用帐户就没那么灵活了. 如果我使用余额系统, 那么在生成一笔交易的时候, 我首先要考虑的就是“幂等”问题, 因为发出去的交易是给某个帐户加减钱, 如果交易因为网络等原因重新发送, 变成两笔交易重复扣钱, 我就要哭了, 这是在区块链里面著名的“重放攻击”. 所以交易必须设计一个唯一的标识id让服务器知道这是同一笔交易. 但是在去中心化系统中没有一个超级服务器统一分配交易ID, 只能本地生成, 而且跟踪这些交易ID的状态, 也是一个很大的负担, 因为我需要将区块链从创世块到现在所有的交易都遍历一遍, 才能确定是是否是重复交易. 如果用UTXO就可以避免这个问题, UTXO相比交易数少了不止一个数量级, 而且UTXO只有两个状态—未消费、被消费, 比特币只能有一个操作— 将为消费的UTXO变为已消费状态. 不管我发送多少次交易, 都会得到一个结果. 在中本聪倡导每个cpu都是一票的去中心化社区, 让每个节点都有能力去做计算是需要特别重视的, 否则单个节点的计算能力要求过高, 整个系统将向着“中心化”趋势滑下去. 在比特币的实现中, 是把所有的UTXO保存在一个单独的UTXOSet缓存中, 截止2017年9月, 这个缓存大概2.7Gb, 与之对应, 整个区块链的交易数据达到140Gb, UTXO缓存像是一个只保存了最终一个状态的git, 整体的消耗负担小了很多很多. 但是中本聪没想到, 很多人现在把交易输出的脚本玩出花来了, 导致很多UTXO创建出来就是不为消费用的, 永远不会被消费掉, 节点的负担越来越重. 这才有了后续的BIP改进以及以太坊的账户模型. 那又是一个很长的故事了… 基础篇 也可以看一下这一篇: https://yemengying.com/2018/02/11/hash-blockchain/ 2018年开始区块链真是火啊. 一夜暴富的例子一直在传说. 今天我们就自己动手写一个基本的区块链. 先简单的说一下区块链是个什么（相信你早就知道了）. 区块链就是一个链表. 把一堆区块串起来就是区块链. 每个block有自己的数字签名（就是一串不规则看起来叼叼的字符串）, 同时包含有上一个block的数字签名, 然后包含一些其他的data. 大体就长这样: 是不是很熟悉, 链表. 好, 继续. 数字签名是什么？就是hash. 而且每个block含有前一个block的hash值, 而且每个block自己的hash也是由前一个的hash计算得来的. 如果前一个block（数据块）的数据发生改变, 那么前一个的hash值也改变了, 由此就会影响到之后的数据块的所有hash值. 所以, 通过计算和对比hash值这种方式我们就可以知道区块链是不是合法的, 是不是已经被篡改. 什么意思呢？意味着只要你修改了区块链中的任何一个块中的数据, 都将会改变hash, 从而破坏了整个链. 好, 不多说. 上代码: block块定义先新建个block块: 1234567891011121314public class Block &#123; public String hash; public String previousHash; private String data; //our data will be a simple message. private long timeStamp; //as number of milliseconds since 1/1/1970. //Block Constructor. public Block(String data,String previousHash ) &#123; this.data = data; this.previousHash = previousHash; this.timeStamp = new Date().getTime(); &#125;&#125; 你也看到了我们的Block里有四个字段, hash就是这个块自己的hash值, previousHash就是上一个块的hash值, data就是这个块所持有的数据, timeStamp就是一个时间记录. 数字签名生成接下来我们就需要生成数字签名. 有很多种的加密算法来生成数字签名. 这里我们就选择SHA256. 这里先新建一个工具类用来搞定这个件事情: 1234567891011121314151617181920212223242526272829303132333435363738import java.security.MessageDigest;//通过导入MessageDigest来使用SHA256public class StringUtil &#123; //Applies Sha256 to a string and returns the result. public static String applySha256(String input)&#123; try &#123; MessageDigest digest = MessageDigest.getInstance(&quot;SHA-256&quot;); //Applies sha256 to our input, byte[] hash = digest.digest(input.getBytes(&quot;UTF-8&quot;)); StringBuffer hexString = new StringBuffer(); // This will contain hash as hexidecimal for (int i = 0; i &lt; hash.length; i++) &#123; String hex = Integer.toHexString(0xff &amp; hash[i]); if(hex.length() == 1) hexString.append(&apos;0&apos;); hexString.append(hex); &#125; return hexString.toString(); &#125; catch(Exception e) &#123; throw new RuntimeException(e); &#125; &#125; //Short hand helper to turn Object into a json string public static String getJson(Object o) &#123; return new GsonBuilder().setPrettyPrinting().create().toJson(o); &#125; //Returns difficulty string target, to compare to hash. eg difficulty of 5 will return &quot;00000&quot; public static String getDificultyString(int difficulty) &#123; return new String(new char[difficulty]).replace(&apos;\0&apos;, &apos;0&apos;); &#125; &#125; 好, 现在我们在Block里添加生成hash的方法: 12345678910//Calculate new hash based on blocks contentspublic String calculateHash() &#123; String calculatedhash = StringUtil.applySha256( previousHash + Long.toString(timeStamp) + Integer.toString(nonce) + data ); return calculatedhash;&#125; 然后我们在构造函数里添加hash值的计算: 12345678//Block Constructor. public Block(String data,String previousHash ) &#123; this.data = data; this.previousHash = previousHash; this.timeStamp = new Date().getTime(); this.hash = calculateHash(); //Making sure we do this after we set the other values.&#125; 一试身手现在是时候一试身手了. 我们新建一个main类来玩耍一次: 1234567891011public static void main(String[] args) &#123; Block genesisBlock = new Block(&quot;Hi im the first block&quot;, &quot;0&quot;); System.out.println(&quot;block 1的hash值 : &quot; + genesisBlock.hash); Block secondBlock = new Block(&quot;Yo im the second block&quot;,genesisBlock.hash); System.out.println(&quot;block 2的hash值: &quot; + secondBlock.hash); Block thirdBlock = new Block(&quot;Hey im the third block&quot;,secondBlock.hash); System.out.println(&quot;block 3的hash值: &quot; + thirdBlock.hash);&#125; 输出结果如下: hash值是不一样的, 因为每个block的时间戳不同. 现在每个块都有了自己的数字签名, 并且这些数字签名都是基于每个块自身的信息以及前一个块的数字签名联合起来生成的数字签名. 但, 现在还不能叫区块链. 只是一个个区块. 接下来就让我们把这些块装入一个ArrayList中: 1234567891011public static ArrayList&lt;Block&gt; blockchain = new ArrayList&lt;Block&gt;();public static void main(String[] args) &#123; //add our blocks to the blockchain ArrayList: blockchain.add(new Block(&quot;Hi im the first block&quot;, &quot;0&quot;)); blockchain.add(new Block(&quot;Yo im the second block&quot;,blockchain.get(blockchain.size()-1).hash)); blockchain.add(new Block(&quot;Hey im the third block&quot;,blockchain.get(blockchain.size()-1).hash)); String blockchainJson = new GsonBuilder().setPrettyPrinting().create().toJson(blockchain); System.out.println(blockchainJson);&#125; 现在看起来就比较紧凑了, 也像个区块链的样子了: 检查区块链的完整性现在就让我们在ImportChain中创建一个isChainValid()方法, 它会遍历链中每个块, 然后对比hash值. 这个方法做的事情就是检查hash变量的值是否等于计算出来的hash值以及上一个块的hash是否等于previousHash变量的值. 12345678910111213141516171819202122232425262728public static Boolean isChainValid() &#123; Block currentBlock; Block previousBlock; String hashTarget = new String(new char[difficulty]).replace(&apos;\0&apos;, &apos;0&apos;); //循环遍历每个块检查hash for(int i=1; i &lt; blockchain.size(); i++) &#123; currentBlock = blockchain.get(i); previousBlock = blockchain.get(i-1); //比较注册的hash和计算的hash: if(!currentBlock.hash.equals(currentBlock.calculateHash()) )&#123; System.out.println(&quot;Current Hashes not equal&quot;); return false; &#125; //比较上一个块的hash和注册的上一个hash（也就是previousHash） if(!previousBlock.hash.equals(currentBlock.previousHash) ) &#123; System.out.println(&quot;Previous Hashes not equal&quot;); return false; &#125; //检查hash是否被处理 if(!currentBlock.hash.substring( 0, difficulty).equals(hashTarget)) &#123; System.out.println(&quot;This block hasn&apos;t been mined&quot;); return false; &#125; &#125; return true;&#125; 对区块链中的块的任何更改都将导致此方法返回false. On the bitcoin network nodes share their blockchains and the longest valid chain is accepted by the network. What’s to stop someone tampering with data in an old block then creating a whole new longer blockchain and presenting that to the network ? Proof of work. The hashcash proof of work system means it takes considerable time and computational power to create new blocks. Hence the attacker would need more computational power than the rest of the peers combined. 上面说的就是POW . 之后会介绍. 好, 上面基本上把区块链搞完了. 现在我们开始新的征程吧！ 挖矿我们将要求矿工们来做POW, 具体就是通过尝试不同的变量直到块的hash以几个0开头. 然后我们添加一个nonce（Number once）到calculateHash() 方法以及mineBlock()方法: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public class ImportChain &#123; public static ArrayList&lt;Block&gt; blockchain = new ArrayList&lt;Block&gt;(); public static int difficulty = 5; public static void main(String[] args) &#123; //add our blocks to the blockchain ArrayList: System.out.println(&quot;正在尝试挖掘block 1... &quot;); addBlock(new Block(&quot;Hi im the first block&quot;, &quot;0&quot;)); System.out.println(&quot;正在尝试挖掘block 2... &quot;); addBlock(new Block(&quot;Yo im the second block&quot;,blockchain.get(blockchain.size()-1).hash)); System.out.println(&quot;正在尝试挖掘block 3... &quot;); addBlock(new Block(&quot;Hey im the third block&quot;,blockchain.get(blockchain.size()-1).hash)); System.out.println(&quot;\nBlockchain is Valid: &quot; + isChainValid()); String blockchainJson = StringUtil.getJson(blockchain); System.out.println(&quot;\nThe block chain: &quot;); System.out.println(blockchainJson); &#125; public static Boolean isChainValid() &#123; Block currentBlock; Block previousBlock; String hashTarget = new String(new char[difficulty]).replace(&apos;\0&apos;, &apos;0&apos;); //loop through blockchain to check hashes: for(int i=1; i &lt; blockchain.size(); i++) &#123; currentBlock = blockchain.get(i); previousBlock = blockchain.get(i-1); //compare registered hash and calculated hash: if(!currentBlock.hash.equals(currentBlock.calculateHash()) )&#123; System.out.println(&quot;Current Hashes not equal&quot;); return false; &#125; //compare previous hash and registered previous hash if(!previousBlock.hash.equals(currentBlock.previousHash) ) &#123; System.out.println(&quot;Previous Hashes not equal&quot;); return false; &#125; //check if hash is solved if(!currentBlock.hash.substring( 0, difficulty).equals(hashTarget)) &#123; System.out.println(&quot;This block hasn&apos;t been mined&quot;); return false; &#125; &#125; return true; &#125; public static void addBlock(Block newBlock) &#123; newBlock.mineBlock(difficulty); blockchain.add(newBlock); &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041import java.util.Date;public class Block &#123; public String hash; public String previousHash; private String data; //our data will be a simple message. private long timeStamp; //as number of milliseconds since 1/1/1970. private int nonce; //Block Constructor. public Block(String data,String previousHash ) &#123; this.data = data; this.previousHash = previousHash; this.timeStamp = new Date().getTime(); this.hash = calculateHash(); //Making sure we do this after we set the other values. &#125; //Calculate new hash based on blocks contents public String calculateHash() &#123; String calculatedhash = StringUtil.applySha256( previousHash + Long.toString(timeStamp) + Integer.toString(nonce) + data ); return calculatedhash; &#125; //Increases nonce value until hash target is reached. public void mineBlock(int difficulty) &#123; String target = StringUtil.getDificultyString(difficulty); //Create a string with difficulty * &quot;0&quot; while(!hash.substring( 0, difficulty).equals(target)) &#123; nonce ++; hash = calculateHash(); &#125; System.out.println(&quot;Block已挖到!!! : &quot; + hash); &#125;&#125; 执行main, 输出如下: 挖掘每一个块都需要一些时间, 大概3秒钟. 你可以调整难度, 看看是如何影响挖矿时间的. 如果有人要窜改区块链中的数据, 那么他们的区块链将是无效的, invalid. 他们将无法创建更长的区块链. 在你的网络中诚实的区块链有更大的时间优势来创建一个最长的链. 被篡改的区块链将无法追上更长、更有效的链. 除非它们比网络中的所有其他节点具有更快的计算速度. 比如未来的量子计算机之类的东西. 好, 我们已经完成了一个基本的区块链！ 总结一下我们的这个区块链: 每个区块上携带数据. 有数字签名. 必须通过POW来挖掘来验证新的区块. 可以验证数据是否合法和是否被修改. 原文链接 发起一笔交易上一文我们已经学会了写一个基本的区块链: 自己动手写区块链（Java版）. 本文我们接着前文, 继续深入. 本文我们将会做以下事情: 1、创建一个钱包（wallet）. 2、使用我们的前面创建的区块链发送一笔签名的交易出去. 3、还有其他更叼的事情等等. 听起来是不是就让人心动. 最后的结果就是我们有了自己的加密货币, 是的, crypto coin. 前面我们已经构建了一个基本的区块链. 但目前这个区块链的区块中的message是一些没有什么实际用途和意义的数据. 本文我们就尝试让区块中能够存储一些交易数据（一个区块中可以存储多笔交易数据）, 这样我们就可以创建自己的加密货币（当然还是一个简单的）, 这里给我们的货币起个名字叫: “NoobCoin”. 1、创建钱包在加密货币（crypto-currencies）中, 货币所有权被作为交易（transaction）在区块链上进行转移, 参与者有一个收发资金的地址. 好, 现在让我们创建一个钱包（Wallet）来持有pubkey和private key: 1import java.security.*; 123456public class Wallet &#123; public PrivateKey privateKey; public PublicKey publicKey;&#125; 公钥和私钥的用途是什么？ 对于我们的“noobcoin”, 公钥（public key）就是我们的一个地址, address. 可以与其他人共享这个公钥, 来接受支付. 我们的私钥是用来签署（sign）我们的交易（transaction）, 所以除了私钥（private key）的所有者, 没有人可以花我们的钱. 用户将不得不对自己的私钥保密！我们还将公钥与交易（transaction）一起发送, 它可以用来验证我们的签名是否有效, 并且数据没有被篡改. 私钥用于对我们不希望被篡改的数据进行签名. 公钥用于验证签名. 我们在一个KeyPair中生成我们的私钥和公钥. 这里使用Elliptic-curve加密来生成KeyPair. 现在我们就去Wallet类中添加一个方法generateKeyPair(), 然后在构造函数中调用它: 1234567891011121314151617181920212223242526public class Wallet &#123; public PrivateKey privateKey; public PublicKey publicKey; public Wallet() &#123; generateKeyPair(); &#125; public void generateKeyPair() &#123; try &#123; KeyPairGenerator keyGen = KeyPairGenerator.getInstance(&quot;ECDSA&quot;,&quot;BC&quot;); SecureRandom random = SecureRandom.getInstance(&quot;SHA1PRNG&quot;); ECGenParameterSpec ecSpec = new ECGenParameterSpec(&quot;prime192v1&quot;); // Initialize the key generator and generate a KeyPair keyGen.initialize(ecSpec, random); //256 KeyPair keyPair = keyGen.generateKeyPair(); // Set the public and private keys from the keyPair privateKey = keyPair.getPrivate(); publicKey = keyPair.getPublic(); &#125;catch(Exception e) &#123; throw new RuntimeException(e); &#125; &#125;&#125; 这个方法就是负责生成公钥和私钥. 具体就是通过Java.security.KeyPairGenerator来生成Elliptic Curve key对. 然后把这个方法加入到Wallet的构造函数中. 现在我们已经有了一个大体的钱包类. 接下来我们看看交易（transaction）类. 2. 交易和签名（Transactions &amp; Signatures）每笔交易将会携带如下数据: 1、资金发送方的公钥（地址）. 2、资金接收方的公钥（地址）. 3、要转移的资金金额. 4、输入（Inputs）. 这个输入是对以前交易的引用, 这些交易证明发件人拥有要发送的资金. 5、输出（Outputs）, 显示交易中收到的相关地址量. （这些输出作为新交易中的输入引用） 6、一个加密签名. 证明地址的所有者是发起该交易的人, 并且数据没有被更改. （例如: 防止第三方更改发送的金额） 让我们创建交易类吧: 123456789101112131415161718192021222324252627282930313233import java.security.*;import java.util.ArrayList;public class Transaction &#123; public String transactionId; //Contains a hash of transaction* public PublicKey sender; //Senders address/public key. public PublicKey reciepient; //Recipients address/public key. public float value; //Contains the amount we wish to send to the recipient. public byte[] signature; //This is to prevent anybody else from spending funds in our wallet. public ArrayList&lt;TransactionInput&gt; inputs = new ArrayList&lt;TransactionInput&gt;(); public ArrayList&lt;TransactionOutput&gt; outputs = new ArrayList&lt;TransactionOutput&gt;(); private static int sequence = 0; //A rough count of how many transactions have been generated // Constructor: public Transaction(PublicKey from, PublicKey to, float value, ArrayList&lt;TransactionInput&gt; inputs) &#123; this.sender = from; this.reciepient = to; this.value = value; this.inputs = inputs; &#125; private String calulateHash() &#123; sequence++; //increase the sequence to avoid 2 identical transactions having the same hash return StringUtil.applySha256( StringUtil.getStringFromKey(sender) + StringUtil.getStringFromKey(reciepient) + Float.toString(value) + sequence ); &#125;&#125; 上面的TransactionInput和TransactionOutput类一会再新建. 我们的交易（Transaction）类还应该包含生成/验证签名和验证交易的相关方法. 注意这里, 既有验证签名的方法, 也有验证交易的方法. 但是, 稍等… 先来说说签名的目的是什么？它们是如何工作的？ 签名在我们的区块链上执行两个非常重要的任务: 首先, 它能只允许所有者使用其货币；其次, 在新区块被挖掘之前, 它能防止其他人篡改其提交的交易（在入口点）. 私钥用于对数据进行签名, 公钥可用于验证其完整性. 例如: Bob想给Sally发送2个NoobCoin, 然后他们的钱包软件生成了这个交易并将其提交给矿工, 以便将其包含在下一个块中. 一名矿工试图将2枚货币的接收人改为Josh. 不过, 幸运的是, Bob已经用他的私钥签署了交易数据, 允许任何人使用Bob的公钥去验证交易数据是否被更改（因为没有其他任何人的公钥能够验证交易）. 可以（从前面的代码块中）看到我们的签名就是一堆字节, 所以现在创建一个方法来生成签名. 我们首先需要的是StringUtil类中的几个helper方法: 1234567891011121314151617181920212223242526272829303132//Applies ECDSA Signature and returns the result ( as bytes ).public static byte[] applyECDSASig(PrivateKey privateKey, String input) &#123; Signature dsa; byte[] output = new byte[0]; try &#123; dsa = Signature.getInstance(&quot;ECDSA&quot;, &quot;BC&quot;); dsa.initSign(privateKey); byte[] strByte = input.getBytes(); dsa.update(strByte); byte[] realSig = dsa.sign(); output = realSig; &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; return output;&#125;//Verifies a String signaturepublic static boolean verifyECDSASig(PublicKey publicKey, String data, byte[] signature) &#123; try &#123; Signature ecdsaVerify = Signature.getInstance(&quot;ECDSA&quot;, &quot;BC&quot;); ecdsaVerify.initVerify(publicKey); ecdsaVerify.update(data.getBytes()); return ecdsaVerify.verify(signature); &#125;catch(Exception e) &#123; throw new RuntimeException(e); &#125;&#125;public static String getStringFromKey(Key key) &#123; return Base64.getEncoder().encodeToString(key.getEncoded());&#125; 不要过分担心这些方法具体的逻辑. 你只需要知道的是: applyECDSASig方法接收发送方的私钥和字符串输入, 对其进行签名并返回字节数组. verifyECDSASig接受签名、公钥和字符串数据, 如果签名是有效的, 则返回true, 否则false. getStringFromKey从任意key返回编码的字符串. 现在让我们在Transaction类中使用这些签名方法, 分别创建generateSignature()和verifiySignature()方法: 123456789public void generateSignature(PrivateKey privateKey) &#123; String data = StringUtil.getStringFromKey(sender) + StringUtil.getStringFromKey(reciepient) + Float.toString(value) ; signature = StringUtil.applyECDSASig(privateKey,data);&#125;public boolean verifySignature() &#123; String data = StringUtil.getStringFromKey(sender) + StringUtil.getStringFromKey(reciepient) + Float.toString(value) ; return StringUtil.verifyECDSASig(sender, data, signature);&#125; 在现实中, 你可能希望签署更多的信息, 比如使用的输出（outputs）/输入（inputs）和/或时间戳（time-stamp）（现在我们只签署了最基本的）. 在将新的交易添加到块中时, 矿工将对签名进行验证. 当我们检查区块链的合法性的时候, 其实也可以检查签名. 3.测试钱包（Wallets）和签名（Signatures）现在我们差不多完成了一半了, 先来测试下已经完成的是不是可以正常工作. 在NoobChain类中, 让我们添加一些新变量并替换main方法的内容如下: 1234567891011121314151617181920212223242526272829import java.security.Security;import java.util.ArrayList;public class NoobChain &#123; public static ArrayList&lt;Block&gt; blockchain = new ArrayList&lt;Block&gt;(); public static int difficulty = 5; public static Wallet walletA; public static Wallet walletB; public static void main(String[] args) &#123; //Setup Bouncey castle as a Security Provider Security.addProvider(new org.bouncycastle.jce.provider.BouncyCastleProvider()); //Create the new wallets walletA = new Wallet(); walletB = new Wallet(); //Test public and private keys System.out.println(&quot;Private and public keys:&quot;); System.out.println(StringUtil.getStringFromKey(walletA.privateKey)); System.out.println(StringUtil.getStringFromKey(walletA.publicKey)); //Create a test transaction from WalletA to walletB Transaction transaction = new Transaction(walletA.publicKey, walletB.publicKey, 5, null); transaction.generateSignature(walletA.privateKey); //Verify the signature works and verify it from the public key System.out.println(&quot;Is signature verified&quot;); System.out.println(transaction.verifySignature()); &#125;&#125; 可以发现我们使用了boncey castle来作为安全实现的提供者. 还创建了两个钱包, 钱包A和钱包B, 然后打印了钱包A的私钥和公钥. 还新建一笔交易. 然后使用钱包A的公钥对这笔交易进行了签名. 输出: 嗯, 签名验证是true, 符合期望. 现在是时候小开心一下了. 现在我们只需要创建和校验输出（outputs）和输入（inputs）然后把交易存储到区块链中. 4. 输入（Inputs）与输出（Outputs）1: 加密货币是如何拥有的…如果你想拥有1个比特币, 你必须收到1个比特币. 总账不会真的给你添加一个比特币, 从发送者那里减去一个比特币, 发送者提到他/她以前收到一个比特币, 然后创建一个交易输出, 显示1比特币被发送到你的地址. （交易输入是对以前交易输出的引用. ） 你的钱包余额是所有发送给你的未使用的交易输出的总和. ps: 这里略微有点绕, 总之你就记住进账和出账这回事情. 从现在开始, 我们将遵循比特币惯例并调用未使用的交易输出: UTXO. 好, 让我们创建一个TransactionInput类: 12345678public class TransactionInput &#123; public String transactionOutputId; //Reference to TransactionOutputs -transactionId public TransactionOutput UTXO; //Contains the Unspent transaction output public TransactionInput(String transactionOutputId) &#123; this.transactionOutputId = transactionOutputId; &#125;&#125; 这个类将用于引用尚未使用的TransactionOutputs的值. transactionOutputId将用于查找相关的TransactionOutput, 从而允许矿工检查你的所有权. 下面是TransactionOutput类: 12345678910111213141516171819202122import java.security.PublicKey;public class TransactionOutput &#123; public String id; public PublicKey reciepient; //also known as the new owner of these coins. public float value; //the amount of coins they own public String parentTransactionId; //the id of the transaction this output was created in //Constructor public TransactionOutput(PublicKey reciepient, float value, String parentTransactionId) &#123; this.reciepient = reciepient; this.value = value; this.parentTransactionId = parentTransactionId; this.id = StringUtil.applySha256(StringUtil.getStringFromKey(reciepient)+Float.toString(value)+parentTransactionId); &#125; //Check if coin belongs to you public boolean isMine(PublicKey publicKey) &#123; return (publicKey == reciepient); &#125;&#125; 交易输出将显示从交易发送到每一方的最终金额. 当在新的交易中作为输入引用时, 它们将作为你要发送的货币的证明, 能够证明你有钱可发送. 5. 输入（Inputs）与输出（Outputs）2: 处理交易……链中的块可能接收到许多交易, 而区块链可能非常非常长, 处理新交易可能需要数亿年的时间, 因为我们必须查找并检查它的输入. 要解决这个问题, 我们就需要存在一个额外的集合（collection）来保存所有未使用的可被作为输入（inputs）的交易. 在下面的ImportChain类中, 添加一个所有UTXO的集合: 123456789101112public class ImportChain &#123; public static ArrayList&lt;Block&gt; blockchain = new ArrayList&lt;Block&gt;(); public static HashMap&lt;String,TransactionOutput&gt; UTXOs = new HashMap&lt;String,TransactionOutput&gt;(); public static int difficulty = 3; public static float minimumTransaction = 0.1f; public static Wallet walletA; public static Wallet walletB; public static Transaction genesisTransaction; public static void main(String[] args) &#123; 现在我们把之前的那些实现放在一起来处理一笔交易吧. 先在Transaction类中的添加一个方法processTransaction: 12345678910111213141516171819202122232425262728293031323334353637public boolean processTransaction() &#123; if(verifySignature() == false) &#123; System.out.println(&quot;#Transaction Signature failed to verify&quot;); return false; &#125; //Gathers transaction inputs (Making sure they are unspent): for(TransactionInput i : inputs) &#123; i.UTXO = ImportChain.UTXOs.get(i.transactionOutputId); &#125; //Checks if transaction is valid: if(getInputsValue() &lt; ImportChain.minimumTransaction) &#123; System.out.println(&quot;Transaction Inputs to small: &quot; + getInputsValue()); return false; &#125; //Generate transaction outputs: float leftOver = getInputsValue() - value; //get value of inputs then the left over change: transactionId = calulateHash(); outputs.add(new TransactionOutput( this.reciepient, value,transactionId)); //send value to recipient outputs.add(new TransactionOutput( this.sender, leftOver,transactionId)); //send the left over &apos;change&apos; back to sender //Add outputs to Unspent list for(TransactionOutput o : outputs) &#123; ImportChain.UTXOs.put(o.id , o); &#125; //Remove transaction inputs from UTXO lists as spent: for(TransactionInput i : inputs) &#123; if(i.UTXO == null) continue; //if Transaction can&apos;t be found skip it ImportChain.UTXOs.remove(i.UTXO.id); &#125; return true;&#125; 还添加了getInputsValue方法. 使用此方法, 我们执行一些检查以确保交易是有效的, 然后收集输入并生成输出. （要了解更多信息, 请参阅代码中的注释行）. 重要的是, 在最后, 我们从UTXO的列表中删除input, 这意味着交易输出只能作为一个输入使用一次…而且必须使用完整的输入值, 因为发送方要将“更改”返回给自己. 红色箭头是输出. 请注意, 绿色输入是对以前输出的引用. 最后, 让我们将钱包类更新为: 可以汇总得到的余额（通过循环遍历UTXO列表并检查事务输出是否为Mine()） 并可以生成交易. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172import java.security.*;import java.security.spec.ECGenParameterSpec;import java.util.ArrayList;import java.util.HashMap;import java.util.Map;public class Wallet &#123; public PrivateKey privateKey; public PublicKey publicKey; public HashMap&lt;String,TransactionOutput&gt; UTXOs = new HashMap&lt;String,TransactionOutput&gt;(); public Wallet() &#123; generateKeyPair(); &#125; public void generateKeyPair() &#123; try &#123; KeyPairGenerator keyGen = KeyPairGenerator.getInstance(&quot;ECDSA&quot;,&quot;BC&quot;); SecureRandom random = SecureRandom.getInstance(&quot;SHA1PRNG&quot;); ECGenParameterSpec ecSpec = new ECGenParameterSpec(&quot;prime192v1&quot;); // Initialize the key generator and generate a KeyPair keyGen.initialize(ecSpec, random); //256 KeyPair keyPair = keyGen.generateKeyPair(); // Set the public and private keys from the keyPair privateKey = keyPair.getPrivate(); publicKey = keyPair.getPublic(); &#125;catch(Exception e) &#123; throw new RuntimeException(e); &#125; &#125; public float getBalance() &#123; float total = 0; for (Map.Entry&lt;String, TransactionOutput&gt; item: ImportChain.UTXOs.entrySet())&#123; TransactionOutput UTXO = item.getValue(); if(UTXO.isMine(publicKey)) &#123; //if output belongs to me ( if coins belong to me ) UTXOs.put(UTXO.id,UTXO); //add it to our list of unspent transactions. total += UTXO.value ; &#125; &#125; return total; &#125; public Transaction sendFunds(PublicKey _recipient,float value ) &#123; if(getBalance() &lt; value) &#123; System.out.println(&quot;#Not Enough funds to send transaction. Transaction Discarded.&quot;); return null; &#125; ArrayList&lt;TransactionInput&gt; inputs = new ArrayList&lt;TransactionInput&gt;(); float total = 0; for (Map.Entry&lt;String, TransactionOutput&gt; item: UTXOs.entrySet())&#123; TransactionOutput UTXO = item.getValue(); total += UTXO.value; inputs.add(new TransactionInput(UTXO.id)); if(total value) break; &#125; Transaction newTransaction = new Transaction(publicKey, _recipient , value, inputs); newTransaction.generateSignature(privateKey); for(TransactionInput input: inputs)&#123; UTXOs.remove(input.transactionOutputId); &#125; return newTransaction; &#125;&#125; 你还可以添加一些其他功能到你的钱包类, 比如保留记录你的交易历史记录等等. 6. 向块中添加交易现在已有了一个可以正常工作的交易处理系统, 我们需要将它实现到我们的区块链中. 我们把上一集中块里的无用的数据替换成一个交易列表, arraylist. 然而, 在一个块中可能有1000个交易, 太多的交易不能包括在散列计算中…… 没事, 别担心, 我们可以使用交易的merkle根, 就是下面的那个getMerkleRoot()方法. 现在在StringUtils中添加一个helper方法getMerkleRoot(): 123456789101112131415161718192021public static String getMerkleRoot(ArrayList&lt;Transaction&gt; transactions) &#123; int count = transactions.size(); List&lt;String&gt; previousTreeLayer = new ArrayList&lt;String&gt;(); for(Transaction transaction : transactions) &#123; previousTreeLayer.add(transaction.transactionId); &#125; List&lt;String&gt; treeLayer = previousTreeLayer; while(count 1) &#123; treeLayer = new ArrayList&lt;String&gt;(); for(int i=1; i &lt; previousTreeLayer.size(); i+=2) &#123; treeLayer.add(applySha256(previousTreeLayer.get(i-1) + previousTreeLayer.get(i))); &#125; count = treeLayer.size(); previousTreeLayer = treeLayer; &#125; String merkleRoot = (treeLayer.size() == 1) ? treeLayer.get(0) : &quot;&quot;; return merkleRoot;&#125; 现在, 我们把Block类加强一下: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859import java.util.ArrayList;import java.util.Date;public class Block &#123; public String hash; public String previousHash; public String merkleRoot; public ArrayList&lt;Transaction&gt; transactions = new ArrayList&lt;Transaction&gt;(); //our data will be a simple message. public long timeStamp; //as number of milliseconds since 1/1/1970. public int nonce; //Block Constructor. public Block(String previousHash ) &#123; this.previousHash = previousHash; this.timeStamp = new Date().getTime(); this.hash = calculateHash(); //Making sure we do this after we set the other values. &#125; //Calculate new hash based on blocks contents public String calculateHash() &#123; String calculatedhash = StringUtil.applySha256( previousHash + Long.toString(timeStamp) + Integer.toString(nonce) + merkleRoot ); return calculatedhash; &#125; //Increases nonce value until hash target is reached. public void mineBlock(int difficulty) &#123; merkleRoot = StringUtil.getMerkleRoot(transactions); String target = StringUtil.getDificultyString(difficulty); //Create a string with difficulty * &quot;0&quot; while(!hash.substring( 0, difficulty).equals(target)) &#123; nonce ++; hash = calculateHash(); &#125; System.out.println(&quot;Block Mined!!! : &quot; + hash); &#125; //Add transactions to this block public boolean addTransaction(Transaction transaction) &#123; //process transaction and check if valid, unless block is genesis block then ignore. if(transaction == null) return false; if((previousHash != &quot;0&quot;)) &#123; if((transaction.processTransaction() != true)) &#123; System.out.println(&quot;Transaction failed to process. Discarded.&quot;); return false; &#125; &#125; transactions.add(transaction); System.out.println(&quot;Transaction Successfully added to Block&quot;); return true; &#125;&#125; 上面我们更新了Block构造函数, 因为不再需要传入字符串数据（还记得上集中我们的Block构造函数传入了一个data的字符串, 这里我们往块里添加的是交易, 也就是transaction）, 并且在计算哈希方法中包含了merkle根. 并且新增了addTransaction方法来添加一笔交易, 并且只有在交易被成功添加时才返回true. ok, 我们的区块链上交易所需的每个零部件都实现了. 是时候运转一下了. 7. 大结局现在我们开始测试吧. 发送货币进出钱包, 并更新我们的区块链有效性检查. 但首先我们需要一个方法来引入新的币. 有许多方法可以创建新的币, 比如, 在比特币区块链上: 矿工可以将交易持有在自己手里, 作为对每个块被开采的奖励. 这里, 我们将只发行（release）我们希望拥有的所有货币, 在第一个块（起源块）. 就像比特币一样, 我们将对起源块进行硬编码. 现在把``类更新, 包含如下内容: 一个“创世纪”的块, 它向钱包A发行100个新币. 帐户交易中的“更新的链”的有效性检查. 一些测试信息, 让我们看到内部运行的细节信息. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148import java.security.Security;import java.util.ArrayList;import java.util.HashMap;//import java.util.Base64;//import com.google.gson.GsonBuilder;public class ImportChain &#123; public static ArrayList&lt;Block&gt; blockchain = new ArrayList&lt;Block&gt;(); public static HashMap&lt;String,TransactionOutput&gt; UTXOs = new HashMap&lt;String,TransactionOutput&gt;(); public static int difficulty = 3; public static float minimumTransaction = 0.1f; public static Wallet walletA; public static Wallet walletB; public static Transaction genesisTransaction; public static void main(String[] args) &#123; //add our blocks to the blockchain ArrayList: Security.addProvider(new org.bouncycastle.jce.provider.BouncyCastleProvider()); //Setup Bouncey castle as a Security Provider //Create wallets: walletA = new Wallet(); walletB = new Wallet(); Wallet coinbase = new Wallet(); //create genesis transaction, which sends 100 NoobCoin to walletA: genesisTransaction = new Transaction(coinbase.publicKey, walletA.publicKey, 100f, null); genesisTransaction.generateSignature(coinbase.privateKey); //manually sign the genesis transaction genesisTransaction.transactionId = &quot;0&quot;; //manually set the transaction id genesisTransaction.outputs.add(new TransactionOutput(genesisTransaction.reciepient, genesisTransaction.value, genesisTransaction.transactionId)); //manually add the Transactions Output UTXOs.put(genesisTransaction.outputs.get(0).id, genesisTransaction.outputs.get(0)); //its important to store our first transaction in the UTXOs list. System.out.println(&quot;Creating and Mining Genesis block... &quot;); Block genesis = new Block(&quot;0&quot;); genesis.addTransaction(genesisTransaction); addBlock(genesis); //testing Block block1 = new Block(genesis.hash); System.out.println(&quot;\nWalletA&apos;s balance is: &quot; + walletA.getBalance()); System.out.println(&quot;\nWalletA is Attempting to send funds (40) to WalletB...&quot;); block1.addTransaction(walletA.sendFunds(walletB.publicKey, 40f)); addBlock(block1); System.out.println(&quot;\nWalletA&apos;s balance is: &quot; + walletA.getBalance()); System.out.println(&quot;WalletB&apos;s balance is: &quot; + walletB.getBalance()); Block block2 = new Block(block1.hash); System.out.println(&quot;\nWalletA Attempting to send more funds (1000) than it has...&quot;); block2.addTransaction(walletA.sendFunds(walletB.publicKey, 1000f)); addBlock(block2); System.out.println(&quot;\nWalletA&apos;s balance is: &quot; + walletA.getBalance()); System.out.println(&quot;WalletB&apos;s balance is: &quot; + walletB.getBalance()); Block block3 = new Block(block2.hash); System.out.println(&quot;\nWalletB is Attempting to send funds (20) to WalletA...&quot;); block3.addTransaction(walletB.sendFunds( walletA.publicKey, 20)); System.out.println(&quot;\nWalletA&apos;s balance is: &quot; + walletA.getBalance()); System.out.println(&quot;WalletB&apos;s balance is: &quot; + walletB.getBalance()); isChainValid(); &#125; public static Boolean isChainValid() &#123; Block currentBlock; Block previousBlock; String hashTarget = new String(new char[difficulty]).replace(&apos;\0&apos;, &apos;0&apos;); HashMap&lt;String,TransactionOutput&gt; tempUTXOs = new HashMap&lt;String,TransactionOutput&gt;(); //a temporary working list of unspent transactions at a given block state. tempUTXOs.put(genesisTransaction.outputs.get(0).id, genesisTransaction.outputs.get(0)); //loop through blockchain to check hashes: for(int i=1; i &lt; blockchain.size(); i++) &#123; currentBlock = blockchain.get(i); previousBlock = blockchain.get(i-1); //compare registered hash and calculated hash: if(!currentBlock.hash.equals(currentBlock.calculateHash()) )&#123; System.out.println(&quot;#Current Hashes not equal&quot;); return false; &#125; //compare previous hash and registered previous hash if(!previousBlock.hash.equals(currentBlock.previousHash) ) &#123; System.out.println(&quot;#Previous Hashes not equal&quot;); return false; &#125; //check if hash is solved if(!currentBlock.hash.substring( 0, difficulty).equals(hashTarget)) &#123; System.out.println(&quot;#This block hasn&apos;t been mined&quot;); return false; &#125; //loop thru blockchains transactions: TransactionOutput tempOutput; for(int t=0; t &lt;currentBlock.transactions.size(); t++) &#123; Transaction currentTransaction = currentBlock.transactions.get(t); if(!currentTransaction.verifySignature()) &#123; System.out.println(&quot;#Signature on Transaction(&quot; + t + &quot;) is Invalid&quot;); return false; &#125; if(currentTransaction.getInputsValue() != currentTransaction.getOutputsValue()) &#123; System.out.println(&quot;#Inputs are note equal to outputs on Transaction(&quot; + t + &quot;)&quot;); return false; &#125; for(TransactionInput input: currentTransaction.inputs) &#123; tempOutput = tempUTXOs.get(input.transactionOutputId); if(tempOutput == null) &#123; System.out.println(&quot;#Referenced input on Transaction(&quot; + t + &quot;) is Missing&quot;); return false; &#125; if(input.UTXO.value != tempOutput.value) &#123; System.out.println(&quot;#Referenced input Transaction(&quot; + t + &quot;) value is Invalid&quot;); return false; &#125; tempUTXOs.remove(input.transactionOutputId); &#125; for(TransactionOutput output: currentTransaction.outputs) &#123; tempUTXOs.put(output.id, output); &#125; if( currentTransaction.outputs.get(0).reciepient != currentTransaction.reciepient) &#123; System.out.println(&quot;#Transaction(&quot; + t + &quot;) output reciepient is not who it should be&quot;); return false; &#125; if( currentTransaction.outputs.get(1).reciepient != currentTransaction.sender) &#123; System.out.println(&quot;#Transaction(&quot; + t + &quot;) output &apos;change&apos; is not sender.&quot;); return false; &#125; &#125; &#125; System.out.println(&quot;Blockchain is valid&quot;); return true; &#125; public static void addBlock(Block newBlock) &#123; newBlock.mineBlock(difficulty); blockchain.add(newBlock); &#125;&#125; 运行结果: 代码链接: https://github.com/importsource/blockchain-samples-transaction/tree/master 原文链接 最热门的3个基于Java的Blockchain库大家应该都听说过比特币、以太币或其他加密货币, 这些名字在新闻中经常出现, 但是作为Java开发人员, 你们知道如何轻松地与Blockchain技术进行交互吗?下面是可以利用Blockchain的三大Java项目. 这个列表是基于GitHub存储库的星序排列的. 非常感谢你的评论和意见. BitcoinJ你有没有觉得这个名字很有描述性呢?如果你想知道如何创建一个比特币钱包, 并且管理节点之间的事务, 那么你应该尝试一下BitcoinJ. 这个项目有一个不断扩大的社区, 里面包含非常好的文档资料, 这对每个开发人员都是非常有利的. 当然, 作为一个试图获得声望的开源项目, 它也存在一定的局限性. 现在已经有几个已知的开放漏洞的安全问题, 以及可扩展性问题. 不过, 如果你想了解比特币协议是如何运作的, 这个项目将是非常有帮助的. 个人意见:这并不适用于生产应用. Web3j一个词——Ethereum（以太币）, 这是基于尖端技术的第二大加密货币. Web3j项目允许你使用Ethereum区块链, 同时不必为平台编写集成代码. 同样, 核心功能是创建钱包, 管理事务, 以及智能合约包装器. Ethereum项目的一部分是一种称为Solidity的特殊语言, 它是创建智能合约的实际标准. 如果你想避免使用智能合约的底层实现细节, 那就使用Web3j的智能合约包装器. 如果这对一名开发人员来说还不够, 那我需要告诉你, 它包含很多好的文档和大量的例子, 这也是使web3j成为我个人最爱的原因. HyperLedger FabricHyperLedger Fabric是企业会用到的. Linux基金会的框架是区块链解决方案的主干. 所以无论你想创建一个简单的PoC, 还是一个生产应用程序, 它都是一个强大的工具. 该项目正在由Linux基金会成员积极组织开发. 它的重点是创建和管理智能合约. 主要特点是: 管理共享机密信息的渠道支持政策事务一致地向网络中的对等节点交付事务 如果你在软件区块链堆栈中包括了HyperLedger Fabric, 那么我的建议是熟悉其他的HyperLedger项目. 根据你的需要, 可以选择各种不同的HyperLedger项目, 这些项目将保证一个连贯的、可扩展的、易于维护的区块链基础设施. 对于许多人来说, 区块链将改变整个互联网, 难道你不想成为其中的一部分吗?]]></content>
      <categories>
        <category>Programming</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Blockchain</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot学习之MVC与Validation]]></title>
    <url>%2F2018%2Fspring-boot-mvc-validation%2F</url>
    <content type="text"><![CDATA[Preface 此篇大部分是对Spring MVC的一个回顾以及JSR303中bean validation规范的学习 Spring MVC 相关Spring MVC 流程 1、 用户发送请求至前端控制器DispatcherServlet. 2、 DispatcherServlet收到请求调用HandlerMapping处理器映射器. 3、 处理器映射器找到具体的处理器(可以根据xml配置、注解进行查找), 生成处理器对象及处理器拦截器(如果有则生成)一并返回给DispatcherServlet. 4、 DispatcherServlet调用HandlerAdapter处理器适配器. 5、 HandlerAdapter经过适配调用具体的处理器(Controller, 也叫后端控制器). 6、 Controller执行完成返回ModelAndView. 7、 HandlerAdapter将controller执行结果ModelAndView返回给DispatcherServlet. 8、 DispatcherServlet将ModelAndView传给ViewReslover视图解析器. 9、 ViewReslover解析后返回具体View. 10、DispatcherServlet根据View进行渲染视图（即将模型数据填充至视图中）. 11、 DispatcherServlet响应用户. Spring MVC集成FastJson https://github.com/alibaba/fastjson/wiki/%E5%9C%A8-Spring-%E4%B8%AD%E9%9B%86%E6%88%90-Fastjson 12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.54&lt;/version&gt;&lt;/dependency&gt; 123456789101112131415161718192021222324252627@Configurationpublic class WebMvcMessageConvertConfig implements WebMvcConfigurer &#123; @Autowired StringHttpMessageConverter stringHttpMessageConverter; @Override public void configureMessageConverters(List&lt;HttpMessageConverter&lt;?&gt;&gt; converters) &#123; FastJsonHttpMessageConverter fastConverter = new FastJsonHttpMessageConverter(); SerializeConfig serializeConfig = SerializeConfig.globalInstance; serializeConfig.put(BigInteger.class, ToStringSerializer.instance); serializeConfig.put(Long.class, ToStringSerializer.instance); serializeConfig.put(Long.TYPE, ToStringSerializer.instance); FastJsonConfig fastJsonConfig = new FastJsonConfig(); fastJsonConfig.setCharset(StandardCharsets.UTF_8); fastJsonConfig.setSerializeConfig(serializeConfig);// fastJsonConfig.setSerializerFeatures(SerializerFeature.PrettyFormat); fastJsonConfig.setDateFormat(Constant.DATE_FORMAT); fastConverter.setFastJsonConfig(fastJsonConfig); fastConverter.setSupportedMediaTypes(Collections.singletonList(MediaType.APPLICATION_JSON_UTF8)); converters.add(0, stringHttpMessageConverter); converters.add(1, fastConverter); &#125;&#125; 注意: SpringBoot 2.0.1版本中加载WebMvcConfigurer的顺序发生了变动，故需使用converters.add(0, converter);指定FastJsonHttpMessageConverter在converters内的顺序，否则在SpringBoot 2.0.1及之后的版本中将优先使用Jackson处理。详情：WebMvcConfigurer is overridden by WebMvcAutoConfiguration #12389 在FastJsonHttpMessageConverter之前插入一个StringHttpMessageConverter是为了在Controller层返回String类型不会再次被FastJson序列化. WebFlux上面针对的是Web MVC, 对于Webflux目前不支持这种方式. Spring Boot JSON （Date类型入参、格式化, 以及如何处理null）12345spring: jackson: default-property-inclusion: non_null # 忽略 json 中值为null的属性 date-format: "yyyy-MM-dd HH:mm:ss" # 设置 pattern time-zone: GMT+8 # 修正时区 时间格式可以在实体上使用该注解: @JsonFormat(timezone = &quot;GMT+8&quot;,pattern = &quot;yyyy-MM-dd&quot;) 忽略null属性可以在实体上使用: @JsonInclude(JsonInclude.Include.NON_NULL) Spring Boot MVC特性Spring boot 在spring默认基础上, 自动配置添加了以下特性 包含了ContentNegotiatingViewResolver和BeanNameViewResolver beans. 对静态资源的支持, 包括对WebJars的支持. 自动注册Converter, GenericConverter, Formatter beans. 对HttpMessageConverters的支持. 自动注册MessageCodeResolver. 对静态index.html的支持. 对自定义Favicon的支持. 主动使用ConfigurableWebBindingInitializer bean @RequestBody与@ModelAttribute@RequestBody: 用于接收http请求中body的字符串信息, 可在直接接收转换到Pojo. @ModelAttribute: 用于直接接受url?后面的参数 如url?id=123&amp;name=456, 可在直接接收转换到Pojo. 模板引擎的选择 FreeMarker Thymeleaf Velocity (1.4版本之后弃用, Spring Framework 4.3版本之后弃用) Groovy Mustache 注: jsp应该尽量避免使用, 原因如下: jsp只能打包为: war格式, 不支持jar格式, 只能在标准的容器里面跑（tomcat, jetty都可以） 内嵌的Jetty目前不支持JSP Undertow不支持jsp jsp自定义错误页面不能覆盖spring boot 默认的错误页面 开启GZIP算法压缩响应流1234server: compression: enabled: true # 启用压缩 min-response-size: 2048 # 对应Content-Length, 超过这个值才会压缩 全局异常处理方式一: 添加自定义的错误页面 html静态页面: 在resources/public/error/ 下定义. 如添加404页面: resources/public/error/404.html页面, 中文注意页面编码 模板引擎页面: 在templates/error/下定义. 如添加5xx页面: templates/error/5xx.ftl 注: templates/error/ 这个的优先级比较resources/public/error/高 方式二: 通过@ControllerAdvice12345678910111213141516171819202122232425@Slf4j@ControllerAdvice//@RestControllerAdvicepublic class ErrorExceptionHandler &#123; @ExceptionHandler(&#123; RuntimeException.class &#125;) @ResponseStatus(HttpStatus.OK) public ModelAndView processException(RuntimeException exception) &#123; log.info("自定义异常处理-RuntimeException"); ModelAndView m = new ModelAndView(); m.addObject("roncooException", exception.getMessage()); m.setViewName("error/500"); return m; &#125; @ExceptionHandler(&#123; Exception.class &#125;) @ResponseStatus(HttpStatus.OK) public ModelAndView processException(Exception exception) &#123; log.info("自定义异常处理-Exception"); ModelAndView m = new ModelAndView(); m.addObject("roncooException", exception.getMessage()); m.setViewName("error/500"); return m; &#125;&#125; 或者继承ResponseEntityExceptionHandler更灵活地控制状态码、Header等信息: 12345678910111213@ControllerAdvicepublic class RestResponseEntityExceptionHandler extends ResponseEntityExceptionHandler &#123;// @ResponseStatus(HttpStatus.OK) @ExceptionHandler(value = &#123; Exception.class &#125;) @Nullable protected ResponseEntity&lt;Object&gt; handleConflict(Exception ex, WebRequest request) &#123; String bodyOfResponse = ex.getMessage(); HttpHeaders headers = new HttpHeaders(); headers.set(CONTENT_TYPE, MediaType.APPLICATION_JSON_UTF8_VALUE); return handleExceptionInternal(ex, bodyOfResponse, headers, HttpStatus.INTERNAL_SERVER_ERROR, request); &#125;&#125; 更多方式请看: http://www.baeldung.com/exception-handling-for-rest-with-spring 静态资源设置静态资源放到指定路径下 1spring.resources.static-locations=classpath:/META-INF/resources/,classpath:/static/ 自定义消息转化器12345@Bean public StringHttpMessageConverter stringHttpMessageConverter() &#123; StringHttpMessageConverter converter = new StringHttpMessageConverter(Charset.forName("UTF-8")); return converter; &#125; 自定义SpringMVC的拦截器有些时候我们需要自己配置SpringMVC而不是采用默认, 比如增加一个拦截器 1234567891011121314151617181920212223public class MyInterceptor implements HandlerInterceptor &#123; @Override public void afterCompletion(HttpServletRequest arg0, HttpServletResponse arg1, Object arg2, Exception arg3) throws Exception &#123; System.out.println("拦截器MyInterceptor-------&gt;3、请求结束之后被调用, 主要用于清理工作. "); &#125; @Override public void postHandle(HttpServletRequest arg0, HttpServletResponse arg1, Object arg2, ModelAndView arg3) throws Exception &#123; System.out.println("拦截器MyInterceptor-------&gt;2、请求之后调用, 在视图渲染之前, 也就是Controller方法调用之后"); &#125; @Override public boolean preHandle(HttpServletRequest arg0, HttpServletResponse arg1, Object arg2) throws Exception &#123; System.out.println("拦截器MyInterceptor-------&gt;1、请求之前调用, 也就是Controller方法调用之前. "); return true;//返回true则继续向下执行, 返回false则取消当前请求 &#125;&#125; 1234567891011121314@Configurationpublic class InterceptorConfigurerAdapter extends WebMvcConfigurer &#123; /** * 该方法用于注册拦截器 * 可注册多个拦截器, 多个拦截器组成一个拦截器链 */ @Override public void addInterceptors(InterceptorRegistry registry) &#123; // addPathPatterns 添加路径 // excludePathPatterns 排除路径 registry.addInterceptor(new MyInterceptor()).addPathPatterns("/*.*"); super.addInterceptors(registry); &#125;&#125; 或者可以使用继承HandlerInterceptorAdapter的方式, 这种方式可以按需覆盖父类方法. 创建 Servlet、 Filter、Listener注解方式 直接通过@WebServlet、@WebFilter、@WebListener 注解自动注册 1234567891011121314@WebFilter(filterName = "customFilter", urlPatterns = "/*")public class CustomFilter implements Filter &#123; ...&#125;@WebListenerpublic class CustomListener implements ServletContextListener &#123; ...&#125;@WebServlet(name = "customServlet", urlPatterns = "/roncoo")public class CustomServlet extends HttpServlet &#123; ...&#125; 然后需要在**Application.java 加上@ServletComponentScan注解, 否则不会生效. 注意: 如果同时添加了@WebFilter以及@Component, 那么会初始化两次Filter, 并且会过滤所有路径+自己指定的路径 , 便会出现对没有指定的URL也会进行过滤 通过编码注册1234567891011121314151617181920212223242526272829303132333435363738@Configurationpublic class WebConfig &#123; @Bean public FilterRegistrationBean myFilter()&#123; FilterRegistrationBean registrationBean = new FilterRegistrationBean(); MyFilter filter = new MyFilter(); registrationBean.setFilter(filter); List&lt;String&gt; urlPatterns = new ArrayList&lt;&gt;(); urlPatterns.add("/*"); registrationBean.setUrlPatterns(urlPatterns); registrationBean.setOrder(1); return registrationBean; &#125; @Bean public ServletRegistrationBean myServlet() &#123; MyServlet demoServlet = new MyServlet(); ServletRegistrationBean registrationBean = new ServletRegistrationBean(); registrationBean.setServlet(demoServlet); List&lt;String&gt; urlMappings = new ArrayList&lt;String&gt;(); urlMappings.add("/myServlet");////访问, 可以添加多个 registrationBean.setUrlMappings(urlMappings); registrationBean.setLoadOnStartup(1); return registrationBean; &#125; @Bean public ServletListenerRegistrationBean myListener() &#123; ServletListenerRegistrationBean registrationBean = new ServletListenerRegistrationBean&lt;&gt;(); registrationBean.setListener(new MyListener()); registrationBean.setOrder(1); return registrationBean; &#125;&#125; Spring Interceptor与Servlet Filter的区别 Filter是基于函数回调的, 而Interceptor则是基于Java反射的. Filter依赖于Servlet容器, 而Interceptor不依赖于Servlet容器. Filter对几乎所有的请求起作用, 而Interceptor只能对action请求起作用. Interceptor可以访问Action的上下文, 值栈里的对象, 而Filter不能. 在action的生命周期里, Interceptor可以被多次调用, 而Filter只能在容器初始化时调用一次. RequestBodyAdvice和ResponseBodyAdvice应用场景 对Request请求参数解密, 对Response返回参数进行加密 自定义返回信息（业务无关性的） 使用先看一下ResponseBodyAdvice 12345678910111213141516171819202122232425262728public interface ResponseBodyAdvice&lt;T&gt; &#123; /** * Whether this component supports the given controller method return type * and the selected &#123;@code HttpMessageConverter&#125; type. * @param returnType the return type * @param converterType the selected converter type * @return &#123;@code true&#125; if &#123;@link #beforeBodyWrite&#125; should be invoked; * &#123;@code false&#125; otherwise */ boolean supports(MethodParameter returnType, Class&lt;? extends HttpMessageConverter&lt;?&gt;&gt; converterType); /** * Invoked after an &#123;@code HttpMessageConverter&#125; is selected and just before * its write method is invoked. * @param body the body to be written * @param returnType the return type of the controller method * @param selectedContentType the content type selected through content negotiation * @param selectedConverterType the converter type selected to write to the response * @param request the current request * @param response the current response * @return the body that was passed in or a modified (possibly new) instance */ T beforeBodyWrite(T body, MethodParameter returnType, MediaType selectedContentType, Class&lt;? extends HttpMessageConverter&lt;?&gt;&gt; selectedConverterType, ServerHttpRequest request, ServerHttpResponse response);&#125; 其中supports方法指定是否需要执行beforeBodyWrite, 其中参数returnType可以拿到Controller对应方法中的方法注解以及参数注解: returnType.getMethodAnnotation(XXXAnnotation.class)、returnType.getParameterAnnotation(XXXAnnotation.class). beforeBodyWrite可以对返回的body进行包装或加密: 1234567891011121314151617181920212223242526/** * @author ybd * @date 18-5-15 * @contact yangbingdong1994@gmail.com */@RestControllerAdvice(annotations = Rest.class)public class GlobalControllerAdvisor implements ResponseBodyAdvice &#123; private static final String VOID = "void"; /** * String 类型不支持 */ @Override public boolean supports(MethodParameter returnType, Class converterType) &#123; return !(returnType.getGenericParameterType() instanceof Class) || !((Class&lt;?&gt;) returnType.getGenericParameterType()).isAssignableFrom(String.class); &#125; @Override public Object beforeBodyWrite(Object body, MethodParameter returnType, MediaType selectedContentType, Class selectedConverterType, ServerHttpRequest request, ServerHttpResponse response) &#123; return isVoidMethod(returnType) ? Response.ok() : Response.ok(body); &#125; private boolean isVoidMethod(MethodParameter returnType) &#123; return VOID.equals(returnType.getGenericParameterType().getTypeName()); &#125;&#125; 需要在类上面添加@ControllerAdvice或@RestControllerAdvice才能生效 RequestBodyAdvice的beforeBodyRead在拦截器之后执行, 所以可以在拦截器做签名检验, 然后在RequestBodyAdvice中解密请求参数 Spring Boot和Feign中使用Java 8时间日期API（LocalDate等）的序列化问题http://blog.didispace.com/Spring-Boot-And-Feign-Use-localdate/ Validation常用注解（大部分JSR中已有） 注解 类型 说明 @AssertFalse Boolean,boolean 验证注解的元素值是false @AssertTrue Boolean,boolean 验证注解的元素值是true @NotNull 任意类型 验证注解的元素值不是null @Null 任意类型 验证注解的元素值是null @Min(value=值) BigDecimal, BigInteger, byte,short, int, long, 等任何Number或CharSequence（存储的是数字）子类型 验证注解的元素值大于等于@Min指定的value值 @Max（value=值） 和@Min要求一样 验证注解的元素值小于等于@Max指定的value值 @DecimalMin(value=值) 和@Min要求一样 验证注解的元素值大于等于@ DecimalMin指定的value值 @DecimalMax(value=值) 和@Min要求一样 验证注解的元素值小于等于@ DecimalMax指定的value值 @Digits(integer=整数位数, fraction=小数位数) 和@Min要求一样 验证注解的元素值的整数位数和小数位数上限 @Size(min=下限, max=上限) 字符串、Collection、Map、数组等 验证注解的元素值的在min和max（包含）指定区间之内, 如字符长度、集合大小 @Past java.util.Date,java.util.Calendar;Joda Time类库的日期类型 验证注解的元素值（日期类型）比当前时间早 @Future 与@Past要求一样 验证注解的元素值（日期类型）比当前时间晚 @NotBlank CharSequence子类型 验证注解的元素值不为空（不为null、去除首位空格后长度为0）, 不同于@NotEmpty, @NotBlank只应用于字符串且在比较时会去除字符串的首位空格 @Length(min=下限, max=上限) CharSequence子类型 验证注解的元素值长度在min和max区间内 @NotEmpty CharSequence子类型、Collection、Map、数组 验证注解的元素值不为null且不为空（字符串长度不为0、集合大小不为0） @Range(min=最小值, max=最大值) BigDecimal,BigInteger,CharSequence, byte, short, int, long等原子类型和包装类型 验证注解的元素值在最小值和最大值之间 @Email(regexp=正则表达式,flag=标志的模式) CharSequence子类型（如String） 验证注解的元素值是Email, 也可以通过regexp和flag指定自定义的email格式 @Pattern(regexp=正则表达式,flag=标志的模式) String, 任何CharSequence的子类型 验证注解的元素值与指定的正则表达式匹配 @Valid 任何非原子类型 指定递归验证关联的对象；如用户对象中有个地址对象属性, 如果想在验证用户对象时一起验证地址对象的话, 在地址对象上加@Valid注解即可级联验证 简单使用实体: 123456789101112131415@Datapublic class Foo &#123; @NotBlank private String name; @Min(18) private Integer age; @Pattern(regexp = "^1([34578])\\d&#123;9&#125;$",message = "手机号码格式错误") @NotBlank(message = "手机号码不能为空") private String phone; @Email(message = "邮箱格式错误") private String email;&#125; Controller: 12345678910111213141516@RestController@Slf4jpublic class FooController &#123; @PostMapping("/foo") public String foo(@Validated Foo foo, BindingResult bindingResult) &#123; log.info("foo: &#123;&#125;", foo); if (bindingResult.hasErrors()) &#123; for (FieldError fieldError : bindingResult.getFieldErrors()) &#123; log.error("valid fail: field = &#123;&#125;, message = &#123;&#125;", fieldError.getField(), fieldError.getDefaultMessage()); &#125; return "fail"; &#125; return "success"; &#125;&#125; 快速失效一般情况下, Validator并不会应为第一个校验失败为停止, 而是一直校验完所有参数. 我们可以通过设置快速失效: 123456789101112@Configurationpublic class ValidatorConfiguration &#123; @Bean public Validator validator()&#123; ValidatorFactory validatorFactory = Validation.byProvider( HibernateValidator.class ) .configure() .failFast( true )// .addProperty( "hibernate.validator.fail_fast", "true" ) .buildValidatorFactory(); return validatorFactory.getValidator(); &#125;&#125; 这样在遇到第一个校验失败的时候就会停止对之后的参数校验. 分组校验 如果同一个类, 在不同的使用场景下有不同的校验规则, 那么可以使用分组校验. 未成年人是不能喝酒的, 而在其他场景下我们不做特殊的限制, 这个需求如何体现同一个实体, 不同的校验规则呢？ 添加分组: 12345678Class Foo&#123; @Min(value = 18,groups = &#123;Adult.class&#125;) private Integer age; public interface Adult&#123;&#125; public interface Minor&#123;&#125;&#125; Controller: 12345678910@RequestMapping("/drink")public String drink(@Validated(&#123;Foo.Adult.class&#125;) Foo foo, BindingResult bindingResult) &#123; if(bindingResult.hasErrors())&#123; for (FieldError fieldError : bindingResult.getFieldErrors()) &#123; //... &#125; return "fail"; &#125; return "success";&#125; 自定义校验业务需求总是比框架提供的这些简单校验要复杂的多, 我们可以自定义校验来满足我们的需求. 自定义spring validation非常简单, 主要分为两步. 1 自定义校验注解我们尝试添加一个“字符串不能包含空格”的限制. 123456789101112131415161718192021222324@Target(&#123;METHOD, FIELD, ANNOTATION_TYPE, CONSTRUCTOR, PARAMETER&#125;)@Retention(RUNTIME)@Documented@Constraint(validatedBy = &#123;CannotHaveBlankValidator.class&#125;)&lt;1&gt;public @interface CannotHaveBlank &#123; //默认错误消息 String message() default "不能包含空格"; //分组 Class&lt;?&gt;[] groups() default &#123;&#125;; //负载 Class&lt;? extends Payload&gt;[] payload() default &#123;&#125;; //指定多个时使用 @Target(&#123;FIELD, METHOD, PARAMETER, ANNOTATION_TYPE&#125;) @Retention(RUNTIME) @Documented @interface List &#123; CannotHaveBlank[] value(); &#125;&#125; 我们不需要关注太多东西, 使用spring validation的原则便是便捷我们的开发, 例如payload, List , groups, 都可以忽略. &lt;1&gt; 自定义注解中指定了这个注解真正的验证者类. 2 编写真正的校验者类 1234567891011121314151617181920212223public class CannotHaveBlankValidator implements &lt;1&gt; ConstraintValidator&lt;CannotHaveBlank, String&gt; &#123; @Override public void initialize(CannotHaveBlank constraintAnnotation) &#123; &#125; @Override public boolean isValid(String value, ConstraintValidatorContext context &lt;2&gt;) &#123; //null时不进行校验 if (value != null &amp;&amp; value.contains(" ")) &#123; &lt;3&gt; //获取默认提示信息 String defaultConstraintMessageTemplate = context.getDefaultConstraintMessageTemplate(); System.out.println("default message :" + defaultConstraintMessageTemplate); //禁用默认提示信息 context.disableDefaultConstraintViolation(); //设置提示语 context.buildConstraintViolationWithTemplate("can not contains blank").addConstraintViolation(); return false; &#125; return true; &#125;&#125; &lt;1&gt; 所有的验证者都需要实现ConstraintValidator接口, 它的接口也很形象, 包含一个初始化事件方法, 和一个判断是否合法的方法 1234public interface ConstraintValidator&lt;A extends Annotation, T&gt; &#123; void initialize(A constraintAnnotation); boolean isValid(T value, ConstraintValidatorContext context);&#125; &lt;2&gt; ConstraintValidatorContext 这个上下文包含了认证中所有的信息, 我们可以利用这个上下文实现获取默认错误提示信息, 禁用错误提示信息, 改写错误提示信息等操作. &lt;3&gt; 一些典型校验操作, 或许可以对你产生启示作用. 值得注意的一点是, 自定义注解可以用在METHOD, FIELD, ANNOTATION_TYPE, CONSTRUCTOR, PARAMETER之上, ConstraintValidator的第二个泛型参数T, 是需要被校验的类型. 手动校验可能在某些场景下需要我们手动校验, 即使用校验器对需要被校验的实体发起validate, 同步获得校验结果. 理论上我们既可以使用Hibernate Validation提供Validator, 也可以使用Spring对其的封装. 在spring构建的项目中, 提倡使用经过spring封装过后的方法, 这里两种方法都介绍下: Hibernate Validation: 123456789Foo foo = new Foo();foo.setAge(22);foo.setEmail("000");ValidatorFactory vf = Validation.buildDefaultValidatorFactory();Validator validator = vf.getValidator();Set&lt;ConstraintViolation&lt;Foo&gt;&gt; set = validator.validate(foo);for (ConstraintViolation&lt;Foo&gt; constraintViolation : set) &#123; System.out.println(constraintViolation.getMessage());&#125; 由于依赖了Hibernate Validation框架, 我们需要调用Hibernate相关的工厂方法来获取validator实例, 从而校验. 在spring framework文档的Validation相关章节, 可以看到如下的描述: Spring provides full support for the Bean Validation API. This includes convenient support for bootstrapping a JSR-303/JSR-349 Bean Validation provider as a Spring bean. This allows for a javax.validation.ValidatorFactory or javax.validation.Validator to be injected wherever validation is needed in your application. Use the LocalValidatorFactoryBean to configure a default Validator as a Spring bean: bean id=”validator” class=”org.springframework.validation.beanvalidation.LocalValidatorFactoryBean” The basic configuration above will trigger Bean Validation to initialize using its default bootstrap mechanism. A JSR-303/JSR-349 provider, such as Hibernate Validator, is expected to be present in the classpath and will be detected automatically. 上面这段话主要描述了spring对validation全面支持JSR-303、JSR-349的标准, 并且封装了LocalValidatorFactoryBean作为validator的实现. 值得一提的是, 这个类的责任其实是非常重大的, 他兼容了spring的validation体系和hibernate的validation体系, 也可以被开发者直接调用, 代替上述的从工厂方法中获取的hibernate validator. 由于我们使用了springboot, 会触发web模块的自动配置, LocalValidatorFactoryBean已经成为了Validator的默认实现, 使用时只需要自动注入即可. 12345678910111213141516@AutowiredValidator globalValidator; &lt;1&gt;@RequestMapping("/validate")public String validate() &#123; Foo foo = new Foo(); foo.setAge(22); foo.setEmail("000"); Set&lt;ConstraintViolation&lt;Foo&gt;&gt; set = globalValidator.validate(foo);&lt;2&gt; for (ConstraintViolation&lt;Foo&gt; constraintViolation : set) &#123; System.out.println(constraintViolation.getMessage()); &#125; return "success";&#125; &lt;1&gt; 真正使用过Validator接口的读者会发现有两个接口, 一个是位于javax.validation包下, 另一个位于org.springframework.validation包下, 注意我们这里使用的是前者javax.validation, 后者是spring自己内置的校验接口, LocalValidatorFactoryBean同时实现了这两个接口. &lt;2&gt; 此处校验接口最终的实现类便是LocalValidatorFactoryBean. 基于方法校验12345678910111213141516171819202122@RestController@Validated &lt;1&gt;public class BarController &#123; @RequestMapping("/bar") public @NotBlank &lt;2&gt; String bar(@Min(18) Integer age &lt;3&gt;) &#123; System.out.println("age : " + age); return ""; &#125; @ExceptionHandler(ConstraintViolationException.class) public Map handleConstraintViolationException(ConstraintViolationException cve)&#123; Set&lt;ConstraintViolation&lt;?&gt;&gt; cves = cve.getConstraintViolations();&lt;4&gt; for (ConstraintViolation&lt;?&gt; constraintViolation : cves) &#123; System.out.println(constraintViolation.getMessage()); &#125; Map map = new HashMap(); map.put("errorCode",500); return map; &#125;&#125; &lt;1&gt; 为类添加@Validated注解 &lt;2&gt; &lt;3&gt; 校验方法的返回值和入参 &lt;4&gt; 添加一个异常处理器, 可以获得没有通过校验的属性相关信息 基于方法的校验, 个人不推荐使用, 感觉和项目结合的不是很好. 统一处理验证异常 异常类型 描述 ConstraintViolationException 违反约束，javax扩展定义 BindException 绑定失败，如表单对象参数违反约束 MethodArgumentNotValidException 参数无效，如JSON请求参数违反约束 MissingServletRequestParameterException 参数缺失 TypeMismatchException 参数类型不匹配 1234567891011121314151617181920212223242526272829303132@RestControllerAdvicepublic class GlobalExceptionHandler &#123; @ExceptionHandler(value = &#123; MethodArgumentNotValidException.class, BindException.class, ConstraintViolationException.class&#125;) @ResponseStatus(HttpStatus.OK) public Response&lt;Void&gt; handleValidException(Exception ex) &#123; String validateFailReason; if (ex instanceof MethodArgumentNotValidException) &#123; validateFailReason = ((MethodArgumentNotValidException) ex).getBindingResult() .getFieldError() .getDefaultMessage(); &#125; else if (ex instanceof BindException) &#123; validateFailReason = ((BindException) ex).getFieldError().getDefaultMessage(); &#125; else if (ex instanceof ConstraintViolationException) &#123; validateFailReason = ((ConstraintViolationException) ex).getConstraintViolations().stream() .findAny() .map(ConstraintViolation::getMessage) .orElse("Unknown error message"); &#125; else &#123; validateFailReason = "Unknown error message"; &#125; return Response.error(validateFailReason); &#125; @ExceptionHandler(value = &#123;Exception.class&#125;) public Response&lt;Void&gt; handle(Exception exception) &#123; return Response.error(exception.getMessage()); &#125;&#125; 参考:https://www.cnkirito.moe/2017/08/16/%E4%BD%BF%E7%94%A8spring%20validation%E5%AE%8C%E6%88%90%E6%95%B0%E6%8D%AE%E5%90%8E%E7%AB%AF%E6%A0%A1%E9%AA%8C/ 相关代码: https://github.com/masteranthoneyd/spring-boot-learning]]></content>
      <categories>
        <category>Programming</category>
        <category>Java</category>
        <category>Spring Boot</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring Boot</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot学习之杂记篇]]></title>
    <url>%2F2018%2Fspring-boot-learning-hodgepodge%2F</url>
    <content type="text"><![CDATA[Preface Spring Boot作为当下最流行的微服务项目构建基础, 有的时候我们根本不需要额外的配置就能够干很多的事情, 这得益于它的一个核心理念: “习惯优于配置”. . . 说白的就是大部分的配置都已经按照最佳实践的编程规范配置好了 本文基于 Spring Boot 2的学习杂记, 还是与1.X版本还是有一定区别的 构建依赖版本管理工程学习Demo: https://github.com/masteranthoneyd/spring-boot-learning 为什么要分开为两个工程？因为考虑到common工程也需要版本控制, 但parent工程中依赖了common工程, 所以common工程不能依赖parent工程（循环依赖）, 故例外抽离出一个dependencies的工程, 专门用作依赖版本管理, 而parent工程用作其他子工程的公共依赖. 依赖版本管理工程跟下面父工程一样只有一个pom.xml https://github.com/masteranthoneyd/spring-boot-learning/tree/master/spring-boot-parent-dependencies 父工程 https://github.com/masteranthoneyd/spring-boot-learning/blob/master/spring-boot-parent/pom.xml 说明: &lt;packaging&gt; 为 pom 表示此会被打包成 pom 文件被其他子项目依赖. 由于 Spring Boot 以及集成了 maven-surefire-plugin 插件, 跳过测试只需要在 properties中添加 &lt;maven.test.skip&gt;true&lt;/maven.test.skip&gt;即可, 等同 mvn package -Dmaven.test.skip=true, 也可使用 &lt;skipTests&gt;true&lt;/skipTests&gt;, 两者的区别在于 &lt;maven.test.skip&gt; 标签连 .class 文件都不会生成, 而 &lt;skipTests&gt; 会编译生成 .class 文件 子项目会继承父项目的 properties, 若子项目重新定义属性, 则会覆盖父项目的属性. &lt;dependencyManagement&gt; 管理依赖版本, 不使用 &lt;parent&gt; 来依赖 Spring Boot, 可以使用上面方式, 添加 &lt;type&gt; 为 pom 以及 &lt;scope&gt; 为 import. &lt;pluginManagement&gt; 的功能类似于 &lt;dependencyManagement&gt;, 在父项目中设置好插件属性, 在子项目中直接依赖就可以, 不需要每个子项目都配置一遍, 当然了, 子项目也可以覆盖插件属性. 打包打包成可执行的Jar默认情况下Spring Boot打包出来的jar包是不可执行的, 需要这样配置: 1234567891011121314&lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-boot.version&#125;&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;repackage&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt;&lt;/plugins&gt; 打包之后会发现有两个jar, 一个是本身的代码, 一个是集成了Spring Boot的可运行jar: 打包依赖了Spring Boot的工具库只需要在打包插件spring-boot-maven-plugin中这样配置: 12345678910111213&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;none&lt;/phase&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 打包契约类12345678910111213141516171819202122&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;includes&gt; &lt;include&gt;com/yangbingdong/server/**/contract/**/*.class&lt;/include&gt; &lt;/includes&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;none&lt;/phase&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 然后指定该pom文件构建: 1mvn -f pom_own.xml package 配置文件: Properties 和 YAML配置文件的生效顺序, 会对值进行覆盖 @TestPropertySource 注解 命令行参数 Java系统属性（System.getProperties()） 操作系统环境变量 只有在random.*里包含的属性会产生一个RandomValuePropertySource 在打包的jar外的应用程序配置文件（application.properties, 包含YAML和profile变量） 在打包的jar内的应用程序配置文件（application.properties, 包含YAML和profile变量） 在@Configuration类上的@PropertySource注解 默认属性（使用SpringApplication.setDefaultProperties指定） 配置随机值1234567roncoo.secret=$&#123;random.value&#125;roncoo.number=$&#123;random.int&#125;roncoo.bignumber=$&#123;random.long&#125;roncoo.number.less.than.ten=$&#123;random.int(10)&#125;roncoo.number.in.range=$&#123;random.int[1024,65536]&#125;读取使用注解: @Value(value = &quot;$&#123;roncoo.secret&#125;&quot;) 应用简单配置12345678#端口配置: server.port=8090#应用名spring.application.name=test-demo#时间格式化spring.jackson.date-format=yyyy-MM-dd HH:mm:ss#时区设置spring.jackson.time-zone=Asia/Chongqing 导入其他配置123spring: profiles: include: docker-log4j2 此时在项目或其他JAR包中应该存在application-docker-log4j2.yml. 配置文件-多环境配置多环境配置的好处 不同环境配置可以配置不同的参数 便于部署, 提高效率, 减少出错 Properties多环境配置123456781. 配置激活选项spring.profiles.active=dev2.添加其他配置文件application.propertiesapplication-dev.propertiesapplication-prod.propertiesapplication-test.properties YAML多环境配置123456781.配置激活选项spring: profiles: active: dev2.在配置文件添加三个英文状态下的短横线即可区分---spring: profiles: dev 两种配置方式的比较 Properties配置多环境, 需要添加多个配置文件, YAML只需要一个配件文件 书写格式的差异, yaml相对比较简洁, 优雅 YAML的缺点: 不能通过@PropertySource注解加载. 如果需要使用@PropertySource注解的方式加载值, 那就要使用properties文件. 启动时指定环境1java -Dspring.profiles.active=dev -jar myapp.jar 热部署pom.xml添加依赖: 1234567891011121314151617181920&lt;dependencies&gt; &lt;!--支持热启动jar包--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;!-- optional=true,依赖不会传递, 该项目依赖devtools；之后依赖该项目的项目如果想要使用devtools, 需要重新引入 --&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;fork&gt;true&lt;/fork&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; application.yml配置文件中添加: 1234567spring: devtools: restart: #热部署生效 默认就是为true enabled: true #classpath目录下的WEB-INF文件夹内容修改不重启 exclude: WEB-INF/** 关于DevTools的键值如下:1234567891011121314151617181920# DEVTOOLS (DevToolsProperties)spring.devtools.livereload.enabled=true # Enable a livereload.com compatible server.spring.devtools.livereload.port=35729 # Server port.spring.devtools.restart.additional-exclude= # Additional patterns that should be excluded from triggering a full restart.spring.devtools.restart.additional-paths= # Additional paths to watch for changes.spring.devtools.restart.enabled=true # Enable automatic restart.spring.devtools.restart.exclude=META-INF/maven/**,META-INF/resources/**,resources/**,static/**,public/**,templates/**,**/*Test.class,**/*Tests.class,git.properties # Patterns that should be excluded from triggering a full restart.spring.devtools.restart.poll-interval=1000 # Amount of time (in milliseconds) to wait between polling for classpath changes.spring.devtools.restart.quiet-period=400 # Amount of quiet time (in milliseconds) required without any classpath changes before a restart is triggered.spring.devtools.restart.trigger-file= # Name of a specific file that when changed will trigger the restart check. If not specified any classpath file change will trigger the restart.# REMOTE DEVTOOLS (RemoteDevToolsProperties)spring.devtools.remote.context-path=/.~~spring-boot!~ # Context path used to handle the remote connection.spring.devtools.remote.debug.enabled=true # Enable remote debug support.spring.devtools.remote.debug.local-port=8000 # Local remote debug server port.spring.devtools.remote.proxy.host= # The host of the proxy to use to connect to the remote application.spring.devtools.remote.proxy.port= # The port of the proxy to use to connect to the remote application.spring.devtools.remote.restart.enabled=true # Enable remote restart.spring.devtools.remote.secret= # A shared secret required to establish a connection (required to enable remote support).spring.devtools.remote.secret-header-name=X-AUTH-TOKEN # HTTP header used to transfer the shared secret. 当我们修改了java类后, IDEA默认是不自动编译的, 而spring-boot-devtools又是监测classpath下的文件发生变化才会重启应用, 所以需要设置IDEA的自动编译: （1）File-Settings-Compiler-Build Project automatically （2）ctrl + shift + alt + /,选择Registry,勾上 Compiler autoMake allow when app running OK了, 重启一下项目, 然后改一下类里面的内容, IDEA就会自动去make了. 热部署可能会牺牲一定的系统性能, 因为是动态的编译 使用为Undertow作为Web容器 Spring Boot内嵌容器支持Tomcat、Jetty、Undertow.根据 Tomcat vs. Jetty vs. Undertow: Comparison of Spring Boot Embedded Servlet Containers 这篇文章统计, Undertow的综合性能更好. 在Spring Boot 2中, 已经把netty作为webflux的默认容器 与Tomcat性能对比以下是Undertow与Tomcat简单的性能测试（同样是默认配置） Tomcat: Undertow: 显然Undertow的吞吐量要比Tomcat高 Maven配置123456789101112131415161718192021222324252627282930&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;!-- 移除默认web容器, 使用undertow --&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;如果是webflux, 默认的容器的netty&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-webflux&lt;/artifactId&gt; &lt;exclusions&gt; &lt;!-- 移除默认web容器, 使用undertow --&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-reactor-netty&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;!-- 使用高性能 Web 容器 undertow --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-undertow&lt;/artifactId&gt;&lt;/dependency&gt; 监听多个端口与HTTP2支持123456789101112131415// 在@Configuration的类中添加@bean@BeanUndertowEmbeddedServletContainerFactory embeddedServletContainerFactory() &#123; UndertowEmbeddedServletContainerFactory factory = new UndertowEmbeddedServletContainerFactory(); // 这里也可以做其他配置 // 支持HTTP2 factory.addBuilderCustomizers(builder -&gt; &#123; builder.setServerOption(UndertowOptions.ENABLE_HTTP2, true); // 监听多个端口 builder.addHttpListener(8080, "0.0.0.0"); &#125;); return factory;&#125; Undertow相关配置1234567891011121314151617181920212223# Undertow 日志存放目录server.undertow.accesslog.dir# 是否启动日志server.undertow.accesslog.enabled=false # 日志格式server.undertow.accesslog.pattern=common# 日志文件名前缀server.undertow.accesslog.prefix=access_log# 日志文件名后缀server.undertow.accesslog.suffix=log# HTTP POST请求最大的大小server.undertow.max-http-post-size=0 # 设置IO线程数, 它主要执行非阻塞的任务,它们会负责多个连接, 默认设置每个CPU核心一个线程server.undertow.io-threads=4# 阻塞任务线程池, 当执行类似servlet请求阻塞操作, undertow会从这个线程池中取得线程,它的值设置取决于系统的负载, 默认数量为 CPU核心*8server.undertow.worker-threads=20# 以下的配置会影响buffer,这些buffer会用于服务器连接的IO操作,有点类似netty的池化内存管理# 每块buffer的空间大小,越小的空间被利用越充分server.undertow.buffer-size=1024# 每个区分配的buffer数量 , 所以pool的大小是buffer-size * buffers-per-regionserver.undertow.buffers-per-region=1024# 是否分配的直接内存server.undertow.direct-buffers=true 查看依赖树如果引入了某些jar包带有logback依赖, log4j2会失效, 需要通过IDEA或Maven查找排除依赖: 1mvn dependency:tree 创建异步方法启动异步12345@Configuration@EnableAsyncpublic class SpringAsyncConfig &#123; &#125; 配置完这个就已经具备异步方法功能了, 只需要在方法上面添加@Async即可 如果被@Async注解的方法所在类是基于接口实现的, 想要直接注入实现类, 需要添加: @EnableAsync(proxyTargetClass = true) 以使用CGLIB代理 编写异步方法1234@Asyncpublic void asyncMethodWithVoidReturnType() throws InterruptedException &#123; System.out.println("Execute method asynchronously. " + Thread.currentThread().getName());&#125; 配置线程池在不配置线程池的情况下, Spring默认使用SimpleAsyncTaskExecutor, 每一次的执行任务都会使用新的线程, 性能不太好, 所以我们可以自定义线程池 直接声明线程池12345678910111213141516@Configuration@EnableAsyncpublic class SpringAsyncConfig &#123; @Bean public Executor threadPoolTaskExecutor() &#123; ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor(); executor.setCorePoolSize(10); executor.setMaxPoolSize(20); executor.setQueueCapacity(500); executor.setKeepAliveSeconds(60); executor.setThreadNamePrefix("asyncExecutor-"); executor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy()); executor.initialize(); return executor; &#125;&#125; 通过使用ThreadPoolTaskExecutor创建了一个线程池, 同时设置了以下这些参数: 核心线程数10: 线程池创建时候初始化的线程数 最大线程数20: 线程池最大的线程数, 只有在缓冲队列满了之后才会申请超过核心线程数的线程 缓冲队列500: 用来缓冲执行任务的队列 允许线程的空闲时间60秒: 当超过了核心线程出之外的线程在空闲时间到达之后会被销毁 线程池名的前缀: 设置好了之后可以方便我们定位处理任务所在的线程池 线程池对拒绝任务的处理策略: 这里采用了CallerRunsPolicy策略, 当线程池没有处理能力的时候, 该策略会直接在 execute 方法的调用线程中运行被拒绝的任务；如果执行程序已关闭, 则会丢弃该任务 实现AsyncConfigurer 通过这种方式, 可以对异常进行处理 AsyncConfigurer接口有两个方法: getAsyncExecutor(): 提供线程池 getAsyncUncaughtExceptionHandler(): 异步任务异常处理 1234567891011121314151617181920212223242526@Configuration@EnableAsyncpublic class SpringAsyncConfig implements AsyncConfigurer &#123; @Override public Executor getAsyncExecutor() &#123; ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor(); executor.setCorePoolSize(8); executor.setMaxPoolSize(42); executor.setQueueCapacity(500); executor.setThreadNamePrefix("MyExecutor-"); executor.initialize(); return executor; &#125; @Override public AsyncUncaughtExceptionHandler getAsyncUncaughtExceptionHandler()&#123; return (ex, method, params) -&gt; &#123; ExceptionUtils.printRootCauseStackTrace(ex); System.out.println("Exception message - " + ex.getMessage()); System.out.println("Method name - " + method.getName()); for (Object param : params) &#123; System.out.println("Parameter value - " + param); &#125; &#125;; &#125;&#125; 优雅关闭线程池有时候, 存在关闭程序但还有异步任务在执行的情况, 这时候, 我们需要优雅地关闭线程池, 只需要两个参数: 12executor.setWaitForTasksToCompleteOnShutdown(true);executor.setAwaitTerminationSeconds(60); Async使用指定线程池如果同时实现了AsyncConfigurer以及配置线程池, 那么@Async默认使用AsyncConfigurer.getAsyncExecutor的线程池. 如果需要指定线程池可以这样 12@Async("threadPoolTaskExecutor")public void someMethod()&#123;...&#125; 获取异步执行结果Service: 123456@Async("threadPoolTaskExecutor")@Overridepublic Future&lt;String&gt; asyncMethodWithVoidReturnType() throws InterruptedException &#123; Thread.sleep(2000L); return AsyncResult.forValue("Execute method asynchronously. " + Thread.currentThread().getName());&#125; Controller: 12345678910@GetMapping("/hello")public Mono&lt;String&gt; syaHello() throws InterruptedException, ExecutionException &#123; Future&lt;String&gt; stringFuture = someService.asyncMethodWithVoidReturnType(); while (!stringFuture.isDone())&#123; System.out.println("wait..."); Thread.sleep(500L); &#125; System.out.println(stringFuture.get()); return Mono.just("Hello World");&#125; 执行结果: 123456wait...wait...wait...wait...wait...Execute method asynchronously. asyncExecutor-1 Spring启动后执行程序的几种方式@PostConstruct 或 InitializingBean通过@PostConstruct或实现InitializingBean实现初始化bean的时候干一些事情, 两者区别在于InitializingBean是在属性设置完之后执行的, 所以执行顺序是在@PostConstruct之前 由于此接口的方法afterPropertiesSet是在对象的所有属性被初始化后才会调用. 当Spring的配置文件中设置类初始默认为”延迟初始”（default-lazy-init=&quot;true&quot;, 此值默认为false）时, 类对象如果不被使用, 则不会实例化该类对象. 所以 InitializingBean子类不能用于在容器启动时进行初始化的工作, 则应使用Spring提供的ApplicationListener接口来进行程序的初始化工作. 另外, 如果需要InitializingBean子类对象在Spring容器启动时就初始化并则容器调用afterPropertiesSet方法则需要在类上增加org.springframework.context.annotation.Lazy注解并设置为false即可（也可通过spring配置bean时添加lazy-init=&quot;false&quot;). 监听ContextRefreshedEvent通过监听ContextRefreshedEvent事件: 123456789101112public class ApplicationContextRefreshedEventListener implements ApplicationListener&lt;ContextRefreshedEvent&gt; &#123; @Override public void onApplicationEvent(ContextRefreshedEvent event) &#123; System.out.println("ContextRefreshedEvent process..."); &#125;&#125;或者@EventListenerpublic void processContextRefreshedEvent(ContextRefreshedEvent event) throws InterruptedException &#123; log.info("ContextRefreshedEvent process...");&#125; Spring的事件处理是单线程的, 所以如果一个事件被触发, 除非所有的接收者得到消息, 否则这些进程被阻止, 流程将不会继续. 因此, 如果要使用事件处理, 在设计应用程序时应小心. Spring内置事件以下是Spring的内置事件 Spring 内置事件 描述 ContextRefreshedEvent ApplicationContext被初始化或刷新时, 该事件被发布. 这也可以在ConfigurableApplicationContext接口中使用refresh()方法来发生. ContextStartedEvent 当使用ConfigurableApplicationContext接口中的start()方法启动ApplicationContext时, 该事件被触发. 你可以查询你的数据库, 或者你可以在接受到这个事件后重启任何停止的应用程序. ContextStoppedEvent 当使用ConfigurableApplicationContext接口中的stop()方法停止ApplicationContext时, 该事件被触发. 你可以在接受到这个事件后做必要的清理的工作. ContextClosedEvent 当使用ConfigurableApplicationContext接口中的close()方法关闭ApplicationContext时, 该事件被触发. 一个已关闭的上下文到达生命周期末端；它不能被刷新或重启. RequestHandledEvent 这是一个web-specific事件, 告诉所有bean HTTP请求已经被服务. Spring Boot 2.0新增事件在Spring Boot 2.0中对事件模型做了一些增强, 主要就是增加了ApplicationStartedEvent事件, 所以在2.0版本中所有的事件按执行的先后顺序如下: ApplicationStartingEvent ApplicationEnvironmentPreparedEvent ApplicationPreparedEvent ApplicationStartedEvent &lt;= 新增的事件 ApplicationReadyEvent ApplicationFailedEvent ApplicationRunner 或 CommandLineRunner实现ApplicationRunner或CommandLineRunner 1234567891011121314151617@SpringBootApplicationpublic class ProdSyncLayerApplication implements ApplicationRunner,CommandLineRunner&#123; public static void main(String[] args) &#123; SpringApplication.run(ProdSyncLayerApplication.class, args); &#125; @Override public void run(ApplicationArguments args) throws Exception &#123; System.out.println("ApplicationRunner..."); &#125; @Override public void run(String... args) throws Exception &#123; System.out.println("CommandLineRunner..."); &#125;&#125; ApplicationRunner比CommandLineRunner先执行 总结: 以上三种方式的顺序跟其序号一样 onApplicationEvent执行两次问题applicationontext和使用MVC之后的webApplicationontext会两次调用上面的方法, 如何区分这个两种容器呢？ 但是这个时候, 会存在一个问题, 在web 项目中（spring mvc）, 系统会存在两个容器, 一个是root application context ,另一个就是我们自己的 projectName-servlet context（作为root application context的子容器）. 这种情况下, 就会造成onApplicationEvent方法被执行两次. 为了避免上面提到的问题, 我们可以只在root application context初始化完成后调用逻辑代码, 其他的容器的初始化完成, 则不做任何处理, 修改后代码 123456@Override public void onApplicationEvent(ContextRefreshedEvent event) &#123; if(event.getApplicationContext().getParent() == null)&#123;//root application context 没有parent, 他就是老大. //需要执行的逻辑代码, 当spring容器初始化完成后就会执行该方法. &#125; &#125; 后续发现加上以上判断还是能执行两次, 不加的话三次, 最终研究结果使用以下判断更加准确: event.getApplicationContext().getDisplayName().equals(&quot;Root WebApplicationContext&quot;) Spring应用停止前执行程序的几种方式 监听ContextClosedEvent 实现DisposableBean或使用@PostConstruct, 执行顺序: @PostConstruct &gt; DisposableBean 使用ShutdownHook: 12345678910111213141516171819202122public class ShutdownHook &#123; public static void main(String[] args) throws InterruptedException &#123; Runtime.getRuntime().addShutdownHook(new Thread(() -&gt; &#123; try (FileWriter fw = new FileWriter("hook.log")) &#123; // 假设记录日志/或者发送消息 fw.write("完成销毁操作,回收内存! " + (new Date()).toString()); System.out.println("退出程序..."); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;)); IntStream.range(0, 10).forEach(i -&gt; &#123; try &#123; System.out.println("正在工作..."); Thread.sleep(2000L); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); &#125;&#125; 元注解与组合注解元注解Spring4.0的许多注解都可以用作meta annotation（元注解）. 元注解是一种使用在别的注解上的注解. 这意味着我们可以使用Spring的注解组合成一个我们自己的注解. 类似于: @Documented, @Component, @RequestMapping, @Controller, @ResponseBody等等 对于元注解, 是Spring框架中定义的部分, 都有特定的含义. 我们并不能修改, 但是对于组合注解, 我们完全可以基于自己的定义进行实现. 组合注解自定义注解或组合注解是从其他的Spring元注解创建的, 我们先看一下@SpringBootApplication这个神奇的注解（去除注释）: 123456789101112131415161718192021222324@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@SpringBootConfiguration@EnableAutoConfiguration@ComponentScan(excludeFilters = &#123; @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class), @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) &#125;)public @interface SpringBootApplication &#123; @AliasFor(annotation = EnableAutoConfiguration.class) Class&lt;?&gt;[] exclude() default &#123;&#125;; @AliasFor(annotation = EnableAutoConfiguration.class) String[] excludeName() default &#123;&#125;; @AliasFor(annotation = ComponentScan.class, attribute = "basePackages") String[] scanBasePackages() default &#123;&#125;; @AliasFor(annotation = ComponentScan.class, attribute = "basePackageClasses") Class&lt;?&gt;[] scanBasePackageClasses() default &#123;&#125;;&#125; 发现这个注解中有含有大量其他注解, 并使用了@AliasFor这个注解传递注解属性值. 自定义组合注解12345678910@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@RestController@RequestMapping(produces = MediaType.APPLICATION_JSON_UTF8_VALUE)public @interface Rest &#123; @AliasFor(annotation = RequestMapping.class, attribute = "value") String[] value() default &#123;&#125;;&#125; 使用: 1234@Rest(&quot;/ex&quot;)public class ExampleController &#123;&#125; Spring AOP AOP为Aspect Oriented Programming的缩写, 意为: 面向切面编程, 通过预编译方式和运行期动态代理实现程序功能的统一维护的一种技术. AOP是Spring框架中的一个重要内容, 它通过对既有程序定义一个切入点, 然后在其前后切入不同的执行内容, 比如常见的有: 打开数据库连接/关闭数据库连接、打开事务/关闭事务、记录日志等. 基于AOP不会破坏原来程序逻辑, 因此它可以很好的对业务逻辑的各个部分进行隔离, 从而使得业务逻辑各部分之间的耦合度降低, 提高程序的可重用性, 同时提高了开发的效率. 注解说明实现AOP的切面主要有以下几个要素: 使用@Aspect注解将一个java类定义为切面类 使用@Pointcut定义一个切入点, 可以是一个规则表达式, 比如下例中某个package下的所有函数, 也可以是一个注解等. 根据需要在切入点不同位置的切入内容 使用@Before在切入点开始处切入内容 使用@After在切入点结尾处切入内容 使用@AfterReturning在切入点return内容之后切入内容（可以用来对处理返回值做一些加工处理） 使用@Around在切入点前后切入内容, 并自己控制何时执行切入点自身的内容 使用@AfterThrowing用来处理当切入内容部分抛出异常之后的处理逻辑 引入依赖与其他模块一样, 使用需要引入pom依赖: 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt;&lt;/dependency&gt; 引入依赖程序将自动启用AOP, 只要引入了AOP依赖后, 默认已经增加了@EnableAspectJAutoProxy, 并且默认启用Cglib代理: AOP顺序由于通过AOP实现, 程序得到了很好的解耦, 但是也会带来一些问题, 比如: 我们可能会对Web层做多个切面, 校验用户, 校验头信息等等, 这个时候经常会碰到切面的处理顺序问题. 所以, 我们需要定义每个切面的优先级, 我们需要@Order(i)注解来标识切面的优先级. i的值越小, 优先级越高. AOP记录Web访问日志用例日志注解1234567@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)@Documented@Inheritedpublic @interface ReqLog &#123; String value() default "";&#125; 别忘了加上@Retention(RetentionPolicy.RUNTIME) 声明Pointcut12345678@Pointcut("execution(public * com.yangbingdong.docker.controller..*.*(..))")public void path() &#123;&#125;@Pointcut("@annotation(ReqLog)")public void annotation() &#123;&#125;@Pointcut("path() &amp;&amp; annotation()")public void logHttp() &#123;&#125; 然后这样使用: 1234@Before("path() &amp;&amp; @annotation(reqLog)")public void before(JoinPoint joinPoint) &#123; ...&#125; 如果要很方便地获取@ReqLog的value, 我们可以将其绑定为参数: 1234567@Pointcut("execution(public * com.yangbingdong.docker.controller..*.*(..))")public void path()&#123;&#125;@Before("path() &amp;&amp; @annotation(reqLog)")public void doBefore(JoinPoint joinPoint, ReqLog reqLog) &#123; ...&#125; Pointcut匹配表达式详解可以参考: https://blog.csdn.net/elim168/article/details/78150438 如果是使用@Around, 则方法参数应该使用ProceedingJoinPoint,因为ProceedingJoinPoint.proceed()可获取方法返回值, 且必须返回Object: 1234@Around(&quot;logHttp()&quot;)public Object around(final ProceedingJoinPoint joinPoint) throws Throwable &#123; ...&#125; 函数式方式动态注册 Bean Spring 5 支持在应用程序上下文中以函数式方式注册 bean. 简单地说, 您可以通过在 GenericApplicationContext 类中定义的一个新 registerBean() 方法重载来完成. 看一下有哪些方法重载: 注入GenericWebApplicationContext: 12@Autowiredprivate GenericWebApplicationContext context; 注册并设置bean: 123String beanName = lowercaseInitial(handler.getClass().getSimpleName()) + "-" + j;context.registerBean(beanName, handler.getClass());AbstractShardingHandler&lt;AopLogEvent&gt; shardingBean = (AbstractShardingHandler&lt;AopLogEvent&gt;) context.getBean(beanName); 自动配置的原理与自定义starter在自定义starter之前, 先看一下Spring Boot的一些原理 Spring Boot实现自动配置的原理入口注解类@EnableAutoConfiguration@SpringBootApplication注解中包含了自动配置的入口注解: 123456789101112@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@SpringBootConfiguration@EnableAutoConfiguration@ComponentScan(excludeFilters = &#123; @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class), @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) &#125;)public @interface SpringBootApplication &#123; // ...&#125; 12345678910@SuppressWarnings("deprecation")@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@AutoConfigurationPackage@Import(EnableAutoConfigurationImportSelector.class)public @interface EnableAutoConfiguration &#123; // ...&#125; 这个注解的Javadoc内容还是不少, 所有就不贴在文章里面了, 概括一下: 自动配置基于应用的类路径以及你定义了什么Beans 如果使用了@SpringBootApplication注解, 那么自动就启用了自动配置 可以通过设置注解的excludeName属性或者通过spring.autoconfigure.exclude配置项来指定不需要自动配置的项目 自动配置的发生时机在用户定义的Beans被注册之后 如果没有和@SpringBootApplication一同使用, 最好将@EnableAutoConfiguration注解放在root package的类上, 这样就能够搜索到所有子packages中的类了 自动配置类就是普通的Spring @Configuration类, 通过SpringFactoriesLoader机制完成加载, 实现上通常使用@Conditional(比如@ConditionalOnClass或者@ConditionalOnMissingBean) @AutoConfigurationPackage12345678@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@Import(AutoConfigurationPackages.Registrar.class)public @interface AutoConfigurationPackage &#123;&#125; 这个注解的职责就是引入了另外一个配置类: AutoConfigurationPackages.Registrar. 123456789101112131415161718/** * ImportBeanDefinitionRegistrar用来从导入的Config中保存base package */@Order(Ordered.HIGHEST_PRECEDENCE)static class Registrar implements ImportBeanDefinitionRegistrar, DeterminableImports &#123; @Override public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry) &#123; register(registry, new PackageImport(metadata).getPackageName()); &#125; @Override public Set&lt;Object&gt; determineImports(AnnotationMetadata metadata) &#123; return Collections.&lt;Object&gt;singleton(new PackageImport(metadata)); &#125;&#125; 这个注解实现的功能已经比较底层了, 调试看看上面的register方法什么会被调用: 调用参数中的packageNames数组中仅包含一个值: com.example.demo, 也就是项目的root package名. 从调用栈来看的话, 调用register方法的时间在容器刷新期间: refresh -&gt; invokeBeanFactoryPostProcessors -&gt; invokeBeanDefinitionRegistryPostProcessors -&gt; postProcessBeanDefinitionRegistry -&gt; processConfigBeanDefinitions(开始处理配置Bean的定义) -&gt; loadBeanDefinitions -&gt; loadBeanDefinitionsForConfigurationClass(读取配置Class中的Bean定义) -&gt; loadBeanDefinitionsFromRegistrars(这里开始准备进入上面的register方法) -&gt; registerBeanDefinitions(即上述方法) 这个过程已经比较复杂了, 目前暂且不深入研究了. 它的功能简单说就是将应用的root package给注册到Spring容器中, 供后续使用. 相比而言, 下面要讨论的几个类型才是实现自动配置的关键. @Import(EnableAutoConfigurationImportSelector.class)@EnableAutoConfiguration注解的另外一个作用就是引入了EnableAutoConfigurationImportSelector: 它的类图如下所示: 可以发现它除了实现几个Aware类接口外, 最关键的就是实现了DeferredImportSelector(继承自ImportSelector)接口. 所以我们先来看看ImportSelector以及DeferredImportSelector接口的定义: 12345678public interface ImportSelector &#123; /** * 基于被引入的Configuration类的AnnotationMetadata信息选择并返回需要引入的类名列表 */ String[] selectImports(AnnotationMetadata importingClassMetadata);&#125; 这个接口的Javadoc比较长, 还是捡重点说明一下: 主要功能通过selectImports方法实现, 用于筛选需要引入的类名 实现了ImportSelector的类也可以实现一系列Aware接口, 这些Aware接口中的相应方法会在selectImports方法之前被调用(这一点通过上面的类图也可以佐证, EnableAutoConfigurationImportSelector确实实现了四个Aware类型的接口) ImportSelector的实现和通常的@Import在处理方式上是一致的, 然而还是可以在所有@Configuration类都被处理后再进行引入筛选(具体看下面即将介绍的DeferredImportSelector) 123public interface DeferredImportSelector extends ImportSelector &#123;&#125; 这个接口是一个标记接口, 它本身没有定义任何方法. 那么这个接口的含义是什么呢: 它是ImportSelector接口的一个变体, 在所有的@Configuration被处理之后才会执行. 在需要筛选的引入类型具备@Conditional注解的时候非常有用 实现类同样也可以实现Ordered接口, 来定义多个DeferredImportSelector的优先级别(同样地, EnableAutoConfigurationImportSelector也实现了Ordered接口) 明确了这两个接口的意义, 下面来看看是如何实现的: 12345678910111213141516171819202122232425262728293031@Overridepublic String[] selectImports(AnnotationMetadata annotationMetadata) &#123; if (!isEnabled(annotationMetadata)) &#123; return NO_IMPORTS; &#125; try &#123; // Step1: 得到注解信息 AutoConfigurationMetadata autoConfigurationMetadata = AutoConfigurationMetadataLoader .loadMetadata(this.beanClassLoader); // Step2: 得到注解中的所有属性信息 AnnotationAttributes attributes = getAttributes(annotationMetadata); // Step3: 得到候选配置列表 List&lt;String&gt; configurations = getCandidateConfigurations(annotationMetadata, attributes); // Step4: 去重 configurations = removeDuplicates(configurations); // Step5: 排序 configurations = sort(configurations, autoConfigurationMetadata); // Step6: 根据注解中的exclude信息去除不需要的 Set&lt;String&gt; exclusions = getExclusions(annotationMetadata, attributes); checkExcludedClasses(configurations, exclusions); configurations.removeAll(exclusions); configurations = filter(configurations, autoConfigurationMetadata); // Step7: 派发事件 fireAutoConfigurationImportEvents(configurations, exclusions); return configurations.toArray(new String[configurations.size()]); &#125; catch (IOException ex) &#123; throw new IllegalStateException(ex); &#125;&#125; 很明显, 核心就在于上面的步骤3: 123456789protected List&lt;String&gt; getCandidateConfigurations(AnnotationMetadata metadata, AnnotationAttributes attributes) &#123; List&lt;String&gt; configurations = SpringFactoriesLoader.loadFactoryNames( getSpringFactoriesLoaderFactoryClass(), getBeanClassLoader()); Assert.notEmpty(configurations, "No auto configuration classes found in META-INF/spring.factories. If you " + "are using a custom packaging, make sure that file is correct."); return configurations;&#125; 它将实现委托给了SpringFactoriesLoader的loadFactoryNames方法: 1234567891011121314151617181920212223// 传入的factoryClass: org.springframework.boot.autoconfigure.EnableAutoConfigurationpublic static List&lt;String&gt; loadFactoryNames(Class&lt;?&gt; factoryClass, ClassLoader classLoader) &#123; String factoryClassName = factoryClass.getName(); try &#123; Enumeration&lt;URL&gt; urls = (classLoader != null ? classLoader.getResources(FACTORIES_RESOURCE_LOCATION) : ClassLoader.getSystemResources(FACTORIES_RESOURCE_LOCATION)); List&lt;String&gt; result = new ArrayList&lt;String&gt;(); while (urls.hasMoreElements()) &#123; URL url = urls.nextElement(); Properties properties = PropertiesLoaderUtils.loadProperties(new UrlResource(url)); String factoryClassNames = properties.getProperty(factoryClassName); result.addAll(Arrays.asList(StringUtils.commaDelimitedListToStringArray(factoryClassNames))); &#125; return result; &#125; catch (IOException ex) &#123; throw new IllegalArgumentException("Unable to load [" + factoryClass.getName() + "] factories from location [" + FACTORIES_RESOURCE_LOCATION + "]", ex); &#125;&#125;// 相关常量public static final String FACTORIES_RESOURCE_LOCATION = "META-INF/spring.factories"; 这段代码的意图很明确, 在第一篇文章讨论Spring Boot启动过程的时候就已经接触到了. 它会从类路径中拿到所有名为META-INF/spring.factories的配置文件, 然后按照factoryClass的名称取到对应的值. 那么我们就来找一个META-INF/spring.factories配置文件看看. META-INF/spring.factories比如spring-boot-autoconfigure包: 12345678910# Auto Configureorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration,\org.springframework.boot.autoconfigure.aop.AopAutoConfiguration,\org.springframework.boot.autoconfigure.amqp.RabbitAutoConfiguration,\org.springframework.boot.autoconfigure.batch.BatchAutoConfiguration,\org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration,\org.springframework.boot.autoconfigure.cassandra.CassandraAutoConfiguration,\org.springframework.boot.autoconfigure.cloud.CloudAutoConfiguration,\# ... 列举了非常多的自动配置候选项, 挑一个AOP相关的AopAutoConfiguration看看究竟: 1234567891011121314151617181920212223// 如果设置了spring.aop.auto=false, 那么AOP不会被配置// 需要检测到@EnableAspectJAutoProxy注解存在才会生效// 默认使用JdkDynamicAutoProxyConfiguration, 如果设置了spring.aop.proxy-target-class=true, 那么使用CglibAutoProxyConfiguration@Configuration@ConditionalOnClass(&#123; EnableAspectJAutoProxy.class, Aspect.class, Advice.class &#125;)@ConditionalOnProperty(prefix = "spring.aop", name = "auto", havingValue = "true", matchIfMissing = true)public class AopAutoConfiguration &#123; @Configuration @EnableAspectJAutoProxy(proxyTargetClass = false) @ConditionalOnProperty(prefix = "spring.aop", name = "proxy-target-class", havingValue = "false", matchIfMissing = true) public static class JdkDynamicAutoProxyConfiguration &#123; &#125; @Configuration @EnableAspectJAutoProxy(proxyTargetClass = true) @ConditionalOnProperty(prefix = "spring.aop", name = "proxy-target-class", havingValue = "true", matchIfMissing = false) public static class CglibAutoProxyConfiguration &#123; &#125;&#125; 这个自动配置类的作用是判断是否存在配置项: 1spring.aop.proxy-target-class=true 如果存在并且值为true的话使用基于CGLIB字节码操作的动态代理方案, 否则使用JDK自带的动态代理机制. 下面列举所有由Spring Boot提供的条件注解: @ConditionalOnBean @ConditionalOnClass @ConditionalOnCloudPlatform @ConditionalOnExpression @ConditionalOnJava @ConditionalOnJndi @ConditionalOnMissingBean @ConditionalOnMissingClass @ConditionalOnNotWebApplication @ConditionalOnProperty @ConditionalOnResource @ConditionalOnSingleCandidate @ConditionalOnWebApplication 一般的模式, 就是一个条件注解对应一个继承自SpringBootCondition的具体实现类. 自定义starter看完上面描述之后, 应该不难发现, 自定义starter的关键就是META-INF/spring.factories了, Spring Boot会在启动时加载这个文件中声明的第三方类. 自定义properties为了给可配置的bean属性生成元数据, 我们需要引入如下jar包: 123456&lt;!-- 将被@ConfigurationProperties注解的类的属性注入到元数据 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt; application.properties: 12345ybd.datasource.driver-class-name=com.mysql.jdbc.Driverybd.datasource.url=jdbc:mysql://192.168.0.200:3306/transaction_message_test?useUnicode=true&amp;characterEncoding=utf8&amp;useSSL=falseybd.datasource.username=xxxybd.datasource.password=xxxybd.datasource.dbcp2.validation-query=select &apos;x&apos; 生成的元数据位于jar文件中的META-INF/spring-configurationmetadata. json. 元数据本身并不会修改被@ConfigurationProperties修饰的类属性, 在我的理解里元数据仅仅只是表示配置类的默认值以及java doc, 供调用者便利的了解默认配置有哪些以及默认配置的含义, 在idea里面如果有元数据则可以提供良好的代码提示功能以方便了解默认的配置. properties接收类123456789101112131415161718192021222324252627282930@Data@ConfigurationProperties(DataSourceProperties.DATASOURCE_PREFIX)public class DataSourceProperties &#123; public static final String DATASOURCE_PREFIX = "ybd.datasource"; private Boolean tcc; private String driverClassName = "com.mysql.jdbc.Driver"; private String url; private String username = "root"; private String password = "root"; private Dbcp2 dbcp2; @Data public static class Dbcp2 &#123; private Integer maxTotal = 50; private Integer initialSize = 20; private Long maxWaitMillis = 60000L; private Integer minIdle = 6; private Boolean logAbandoned = true; private Boolean removeAbandonedOnBorrow = true; private Boolean removeAbandonedOnMaintenance = true; private Integer removeAbandonedTimeout = 1800; private Boolean testWhileIdle = true; private Boolean testOnBorrow = false; private Boolean testOnReturn = false; private String validationQuery; private Integer validationQueryTimeout = 1; private Long timeBetweenEvictionRunsMillis = 30000L; private Integer numTestsPerEvictionRun = 20; &#125;&#125; @ConfigurationProperties会将application.properties中指定的前缀的属性注入到bean中 Config类123456789101112131415161718192021222324252627282930313233343536373839404142434445@Configuration@Import(SpringCloudConfiguration.class)@ConditionalOnClass(&#123;LocalXADataSource.class&#125;)@EnableConfigurationProperties(&#123;DataSourceProperties.class&#125;)public class DataSourceConfiguration &#123; private final DataSourceProperties dataSourceProperties; @Autowired public DataSourceConfiguration(DataSourceProperties dataSourceProperties) &#123; this.dataSourceProperties = dataSourceProperties; &#125; @Bean("dataSource") @ConditionalOnProperty(prefix = DATASOURCE_PREFIX, value = "tcc", havingValue = "true", matchIfMissing = true) public DataSource getTccDataSource() &#123; LocalXADataSource dataSource = new LocalXADataSource(); dataSource.setDataSource(this.resolveDbcp2DataSource()); return dataSource; &#125; private DataSource resolveDbcp2DataSource() &#123; BasicDataSource dataSource = new BasicDataSource(); dataSource.setDriverClassName(dataSourceProperties.getDriverClassName()); dataSource.setUrl(dataSourceProperties.getUrl()); dataSource.setUsername(dataSourceProperties.getUsername()); dataSource.setPassword(dataSourceProperties.getPassword()); dataSource.setMaxTotal(dataSourceProperties.getDbcp2().getMaxTotal()); dataSource.setInitialSize(dataSourceProperties.getDbcp2().getInitialSize()); dataSource.setMaxWaitMillis(dataSourceProperties.getDbcp2().getMaxWaitMillis()); dataSource.setMinIdle(dataSourceProperties.getDbcp2().getMinIdle()); dataSource.setLogAbandoned(dataSourceProperties.getDbcp2().getLogAbandoned()); dataSource.setRemoveAbandonedOnBorrow(dataSourceProperties.getDbcp2().getRemoveAbandonedOnBorrow()); dataSource.setRemoveAbandonedOnMaintenance(dataSourceProperties.getDbcp2().getRemoveAbandonedOnMaintenance()); dataSource.setRemoveAbandonedTimeout(dataSourceProperties.getDbcp2().getRemoveAbandonedTimeout()); dataSource.setTestWhileIdle(dataSourceProperties.getDbcp2().getTestWhileIdle()); dataSource.setTestOnBorrow(dataSourceProperties.getDbcp2().getTestOnBorrow()); dataSource.setTestOnReturn(dataSourceProperties.getDbcp2().getTestOnReturn()); dataSource.setValidationQuery(dataSourceProperties.getDbcp2().getValidationQuery()); dataSource.setValidationQueryTimeout(dataSourceProperties.getDbcp2().getValidationQueryTimeout()); dataSource.setTimeBetweenEvictionRunsMillis(dataSourceProperties.getDbcp2().getTimeBetweenEvictionRunsMillis()); dataSource.setNumTestsPerEvictionRun(dataSourceProperties.getDbcp2().getNumTestsPerEvictionRun()); return dataSource; &#125;&#125; @Import引入其他配置类 @ConditionalOnClass在指定类存在时该配置类生效 @EnableConfigurationProperties启用配置接受类, 通过Spring字段注入或构造器注入properties配置Bean 使Spring Boot可以自动加载配置类在/resource目录创建META-INF/spring.factories: 12org.springframework.boot.autoconfigure.EnableAutoConfiguration=\com.yangbingdong.configuration.WebMvcMessageConvertConfiguration 然后打包成Jar, 第三方Spring Boot系统通过引入这个Jar包, 会自动加载该类. 如果有需要, 可以配合@AutoConfigureAfter, @ConditionalOnBean, @ConditionalOnProperty等注解控制配置是否需要加载以及加载顺序. 需要更灵活的配置可以实现Condition或SpringBootCondition通过@Conditional(XXXCondition.class)实现类加载判断. 自定义Banner新建一个banner.txt到resources目录下: 1234567891011121314151617181920212223$&#123;AnsiColor.BRIGHT_GREEN&#125; $&#123;AnsiColor.BRIGHT_YELLOW&#125;_ooOoo_$&#123;AnsiColor.BRIGHT_YELLOW&#125; $&#123;AnsiColor.BRIGHT_YELLOW&#125;o8888888o$&#123;AnsiColor.BRIGHT_YELLOW&#125; $&#123;AnsiColor.BRIGHT_YELLOW&#125;88$&#123;AnsiColor.BRIGHT_GREEN&#125;&quot; $&#123;AnsiStyle.BOLD&#125;$&#123;AnsiColor.BRIGHT_RED&#125;. $&#123;AnsiColor.BRIGHT_GREEN&#125;&quot;$&#123;AnsiColor.BRIGHT_YELLOW&#125;88$&#123;AnsiColor.BRIGHT_GREEN&#125; (| -_- |) $&#123;AnsiColor.BRIGHT_YELLOW&#125;O$&#123;AnsiColor.BRIGHT_GREEN&#125;\ = /$&#123;AnsiColor.BRIGHT_YELLOW&#125;O$&#123;AnsiColor.BRIGHT_GREEN&#125; ____/`---&apos;\____ .&apos; \\| |// `. / \\||| : |||// \ / _||||| -:- |||||- \ | | \\\ - /// | | | \_| &apos;&apos;\---/&apos;&apos; | | \ .-\__ `-` ___/-. / ___`. .&apos; /--.--\ `. . __ .&quot;&quot; &apos;&lt; `.___\_&lt;|&gt;_/___.&apos; &gt;&apos;&quot;&quot;. | | : `- \`.;`\ _ /`;.`/ - ` : | | \ \ `-. \_ __\ /__ _/ .-` / /======`-.____`-.___\_____/___.-`____.-&apos;====== `=---=&apos;^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ $&#123;spring-boot.formatted-version&#125; $&#123;AnsiStyle.BOLD&#125;$&#123;AnsiColor.BRIGHT_GREEN&#125;佛祖保佑 永无BUG$&#123;AnsiStyle.NORMAL&#125; 自定义favico将自己的favicon.ico放到src/main/resources即可. 发送邮件 各个厂商的STMP服务以及端口请自行搜索. . . 主要pom依赖: 123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-mail&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;&lt;/dependency&gt; 邮件模板: 12345678910&lt;!DOCTYPE html&gt;&lt;html lang="zh" xmlns:th="http://www.thymeleaf.org"&gt;&lt;head&gt; &lt;meta charset="UTF-8"/&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt;您好,恭喜您中得【一等奖】,这是验证邮件,请点击下面的链接完成验证并领奖 -&gt; &lt;a href="#" th:href="@&#123; https://yangbingdong.com/&#123;id&#125;(id=$&#123;id&#125;) &#125;"&gt;领取奖品&lt;/a&gt;&lt;/body&gt;&lt;/html&gt; yml: 123456789spring: application: name: mail mail: protocol: smtp host: smtp.qq.com port: 587 username: 730493388@qq.com password: 123123 发送邮件: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758@RunWith(SpringRunner.class)@SpringBootTest@ActiveProfiles("qq")public class SpringBootMailApplicationTests &#123; @Autowired private JavaMailSender javaMailSender; @Autowired private TemplateEngine templateEngine; @Test public void contextLoads() &#123; &#125; @Test public void testSendSimple() &#123; SimpleMailMessage message = new SimpleMailMessage(); message.setFrom("730493388@qq.com"); message.setTo("masteranthoneyd@163.com"); message.setSubject("标题: 测试标题"); message.setText("测试内容部份"); javaMailSender.send(message); &#125; @Test public void testSendTemplateByQQ() throws MessagingException &#123; Context context = new Context(); context.setVariable("id", "/archives"); String email = templateEngine.process("email", context); MimeMessage message = javaMailSender.createMimeMessage(); MimeMessageHelper helper = new MimeMessageHelper(message); helper.setFrom("730493388@qq.com"); helper.setTo("masteranthoneyd@163.com"); helper.setSubject("标题: 测试标题"); helper.setText(email, true); javaMailSender.send(message); &#125; @Test public void testSendTemplateBy163() throws MessagingException &#123; Context context = new Context(); context.setVariable("id", "/archives"); String email = templateEngine.process("email", context); MimeMessage message = javaMailSender.createMimeMessage(); MimeMessageHelper helper = new MimeMessageHelper(message); helper.setFrom("masteranthoneyd@163.com"); helper.setTo("730493388@qq.com"); helper.setSubject("标题: 测试标题"); helper.setText(email, true); javaMailSender.send(message); &#125;&#125; 优雅停机可参考: http://www.spring4all.com/article/1022 1234567891011121314151617181920212223242526package com.yangbingdong.docker.config.shutdown;import io.undertow.server.HandlerWrapper;import io.undertow.server.HttpHandler;import io.undertow.server.handlers.GracefulShutdownHandler;/** * @author ybd * @date 18-4-19 * @contact yangbingdong1994@gmail.com */public class GracefulShutdownWrapper implements HandlerWrapper &#123; private GracefulShutdownHandler gracefulShutdownHandler; @Override public HttpHandler wrap(HttpHandler handler) &#123; if(gracefulShutdownHandler == null) &#123; this.gracefulShutdownHandler = new GracefulShutdownHandler(handler); &#125; return gracefulShutdownHandler; &#125; public GracefulShutdownHandler getGracefulShutdownHandler() &#123; return gracefulShutdownHandler; &#125;&#125; 123456789101112131415161718192021222324252627282930package com.yangbingdong.docker.config.shutdown;import io.undertow.server.handlers.GracefulShutdownHandler;import lombok.RequiredArgsConstructor;import lombok.extern.slf4j.Slf4j;import org.springframework.context.ApplicationListener;import org.springframework.context.event.ContextClosedEvent;/** * @author ybd * @date 18-4-19 * @contact yangbingdong1994@gmail.com */@RequiredArgsConstructor@Slf4jpublic class GracefulShutdownListener implements ApplicationListener&lt;ContextClosedEvent&gt; &#123; private final GracefulShutdownWrapper gracefulShutdownWrapper; @Override public void onApplicationEvent(ContextClosedEvent event) &#123; GracefulShutdownHandler gracefulShutdownHandler = gracefulShutdownWrapper.getGracefulShutdownHandler(); try &#123; gracefulShutdownHandler.shutdown(); gracefulShutdownHandler.awaitShutdown(5000L); &#125; catch (InterruptedException e) &#123; log.error("Graceful shutdown container error:", e); &#125; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142package com.yangbingdong.springboot.common.config.shutdown;import io.undertow.server.HandlerWrapper;import org.springframework.boot.autoconfigure.condition.ConditionalOnClass;import org.springframework.boot.web.embedded.undertow.UndertowServletWebServerFactory;import org.springframework.boot.web.server.WebServerFactoryCustomizer;import org.springframework.boot.web.servlet.server.ConfigurableServletWebServerFactory;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * @author ybd * @date 18-4-19 * @contact yangbingdong1994@gmail.com */@Configuration@ConditionalOnClass(HandlerWrapper.class)public class GracefulShutdownConfiguration &#123; @Bean public GracefulShutdownWrapper gracefulShutdownWrapper() &#123; return new GracefulShutdownWrapper(); &#125; @Bean public WebServerFactoryCustomizer&lt;ConfigurableServletWebServerFactory&gt; gracefulWebServerFactoryCustomizer() &#123; return factory -&gt; &#123; if (factory instanceof UndertowServletWebServerFactory) &#123; UndertowServletWebServerFactory undertowServletWebServerFactory = (UndertowServletWebServerFactory) factory; undertowServletWebServerFactory .addDeploymentInfoCustomizers(deploymentInfo -&gt; deploymentInfo.addOuterHandlerChainWrapper(gracefulShutdownWrapper()));// undertowServletWebServerFactory.addBuilderCustomizers(builder -&gt; builder.setServerOption(UndertowOptions.ENABLE_STATISTICS, true)); &#125; &#125;; &#125; @Bean public GracefulShutdownListener gracefulShutdown() &#123; return new GracefulShutdownListener(gracefulShutdownWrapper()); &#125;&#125;]]></content>
      <categories>
        <category>Programming</category>
        <category>Java</category>
        <category>Spring Boot</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring Boot</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL杂记]]></title>
    <url>%2F2018%2Fmysql-related-learning%2F</url>
    <content type="text"><![CDATA[Preface MySQL是什么就多说了. . . 安装传统安装请见博主之前的一篇博文 Docker版安装直接贴出docker-compose.yml: 123456789101112131415161718192021version: '3.5'services: mysql: image: mysql:latest container_name: mysql ports: - "3306:3306" volumes: - ../data:/var/lib/mysql - ../conf:/etc/mysql/conf.d environment: - MYSQL_ROOT_PASSWORD=root - TZ=Asia/Shanghai restart: always networks: - backendnetworks: backend: external: true 配置文件（config-file.cnf, 放在上面volumes中提到的../conf里）: 123456[mysqld]sql_mode = STRICT_TRANS_TABLES,NO_ENGINE_SUBSTITUTIONlower_case_table_names = 1character-set-server = utf8mb4collation-server = utf8mb4_unicode_ci 遇到问题配置文件权限虽然启动成功, 但发现MySQL实例是关闭的, 在启动日志中发现这一条信息 大概意思是权限全局可写, 任何一个用户都可以写. MySQL担心这种文件被其他用户恶意修改, 所以忽略掉这个配置文件. 结论: 配置文件权限过大, 会影响实例不能启动, 或者不能关闭, 需要修改为 644 问题得以解决~！ Docker时区通过Docker启动的MySql, 默认读取的是Docker中的时区UTC, 只要在docker compose文件中指定时区就行了: 123 environment: - MYSQL_ROOT_PASSWORD=root+ - TZ=Asia/Shanghai 或者在MySql配置文件中加入: 123[mysqld]...default-time-zone=&apos;+8:00&apos; 连接不上若抛出酱紫的错误: 1ERROR 2002 (HY000): Can&apos;t connect to local MySQL server through socket &apos;/var/run/mysqld/mysqld.sock&apos; (2) 那么你可能使用了 localhost 链接, 改为 127.0.0.1 或内网地址则OK. 客户端以及GUI传统终端客户端1234sudo apt-get install mysql-client// 链接mysql -h 127.0.0.1 -P 3306 -u root -p 智能补全命令客户端这个一个智能补全并且高亮语法的终端客户端 mycli 安装: 1sudo apt install mycli 使用: 1234567891011121314151617181920212223242526272829303132333435363738394041424344$ mycli --helpUsage: mycli [OPTIONS] [DATABASE] A MySQL terminal client with auto-completion and syntax highlighting. Examples: - mycli my_database - mycli -u my_user -h my_host.com my_database - mycli mysql://my_user@my_host.com:3306/my_databaseOptions: -h, --host TEXT Host address of the database. -P, --port INTEGER Port number to use for connection. Honors $MYSQL_TCP_PORT. -u, --user TEXT User name to connect to the database. -S, --socket TEXT The socket file to use for connection. -p, --password TEXT Password to connect to the database. --pass TEXT Password to connect to the database. --ssl-ca PATH CA file in PEM format. --ssl-capath TEXT CA directory. --ssl-cert PATH X509 cert in PEM format. --ssl-key PATH X509 key in PEM format. --ssl-cipher TEXT SSL cipher to use. --ssl-verify-server-cert Verify server&apos;s &quot;Common Name&quot; in its cert against hostname used when connecting. This option is disabled by default. -v, --version Output mycli&apos;s version. -D, --database TEXT Database to use. -R, --prompt TEXT Prompt format (Default: &quot;\t \u@\h:\d&gt; &quot;). -l, --logfile FILENAME Log every query and its results to a file. --defaults-group-suffix TEXT Read MySQL config groups with the specified suffix. --defaults-file PATH Only read MySQL options from the given file. --myclirc PATH Location of myclirc file. --auto-vertical-output Automatically switch to vertical output mode if the result is wider than the terminal width. -t, --table Display batch output in table format. --csv Display batch output in CSV format. --warn / --no-warn Warn before running a destructive query. --local-infile BOOLEAN Enable/disable LOAD DATA LOCAL INFILE. --login-path TEXT Read this path from the login file. -e, --execute TEXT Execute command and quit. --help Show this message and exit. Navicat Premium安装以及破解在另一篇博文里面. WorkbenchMySQL官方开源GUI 下载地址: https://dev.mysql.com/downloads/workbench/ 索引相关如何判断数据库索引是否生效使用explain ... \G分析语句 (使用\G可格式化结果) 表结构: 不使用索引: 使用索引: 可以看到, 使用explain显示了很多列, 各个关键字的含义如下: table: 顾名思义, 显示这一行的数据是关于哪张表的； type: 这是重要的列, 显示连接使用了何种类型. 从最好到最差的连接类型为: const、eq_reg、ref、range、indexhe和ALL（详情: https://dev.mysql.com/doc/refman/5.7/en/explain-output.html#explain-join-types）； possible_keys: 显示可能应用在这张表中的索引. 如果为空, 没有可能的索引. 可以为相关的域从where语句中选择一个合适的语句； key: 实际使用的索引. 如果为NULL, 则没有使用索引. 很少的情况下, MySQL会选择优化不足的索引. 这种情况下, 可以在Select语句中使用USE INDEX（indexname）来强制使用一个索引或者用IGNORE INDEX（indexname）来强制MySQL忽略索引； key_len: 使用的索引的长度. 在不损失精确性的情况下, 长度越短越好； ref: 显示索引的哪一列被使用了, 如果可能的话, 是一个常数； rows: MySQL认为必须检查的用来返回请求数据的行数； Extra: 关于MySQL如何解析查询的额外信息. 以下是Extra返回含义: Distinct:一旦MYSQL找到了与行相联合匹配的行, 就不再搜索了 Not exists: MYSQL优化了LEFT JOIN, 一旦它找到了匹配LEFT JOIN标准的行, 就不再搜索了 Range checked for each Record（index map:#）:没有找到理想的索引, 因此对于从前面表中来的每一个行组合, MYSQL检查使用哪个索引, 并用它来从表中返回行. 这是使用索引的最慢的连接之一 Using filesort: 看到这个的时候, 查询就需要优化了. MYSQL需要进行额外的步骤来发现如何对返回的行排序. 它根据连接类型以及存储排序键值和匹配条件的全部行的行指针来排序全部行 Using index: 列数据是从仅仅使用了索引中的信息而没有读取实际的行动的表返回的, 这发生在对表的全部的请求列都是同一个索引的部分的时候 Using temporary 看到这个的时候, 查询需要优化了. 这里, MYSQL需要创建一个临时表来存储结果, 这通常发生在对不同的列集进行ORDER BY上, 而不是GROUP BY上 Where used 使用了WHERE从句来限制哪些行将与下一张表匹配或者是返回给用户. 如果不想返回表中的全部行, 并且连接类型ALL或index, 这就会发生, 或者是查询有问题不同连接类型的解释（按照效率高低的顺序排序） system 表只有一行: system表. 这是const连接类型的特殊情况 const:表中的一个记录的最大值能够匹配这个查询（索引可以是主键或惟一索引）. 因为只有一行, 这个值实际就是常数, 因为MYSQL先读这个值然后把它当做常数来对待 eq_ref:在连接中, MYSQL在查询时, 从前面的表中, 对每一个记录的联合都从表中读取一个记录, 它在查询使用了索引为主键或惟一键的全部时使用 ref:这个连接类型只有在查询使用了不是惟一或主键的键或者是这些类型的部分（比如, 利用最左边前缀）时发生. 对于之前的表的每一个行联合, 全部记录都将从表中读出. 这个类型严重依赖于根据索引匹配的记录多少—越少越好 range:这个连接类型使用索引返回一个范围中的行, 比如使用&gt;或&lt;查找东西时发生的情况 index: 这个连接类型对前面的表中的每一个记录联合进行完全扫描（比ALL更好, 因为索引一般小于表数据） ALL:这个连接类型对于前面的每一个记录联合进行完全扫描, 这一般比较糟糕, 应该尽量避免 具体的各个列所能表示的值以及含义可以参考MySQL官方文档介绍, 地址: https://dev.mysql.com/doc/refman/5.7/en/explain-output.html 哪些场景会造成索引失效 应尽量避免在 where 子句中使用 != 或 &lt;&gt; 操作符, 否则引擎将放弃使用索引而进行全表扫描 尽量避免在 where 子句中使用 or 来连接条件, 否则将导致引擎放弃使用索引而进行全表扫描, 即使其中有条件带索引也不会使用, 这也是为什么尽量少用 or 的原因 对于多列索引, 不是使用的第一部分, 则不会使用索引 如果列类型是字符串, 那一定要在条件中将数据使用引号引用起来, 否则不会使用索引 like的模糊查询以 % 开头, 索引失效 应尽量避免在 where 子句中对字段进行表达式操作, 这将导致引擎放弃使用索引而进行全表扫描 如: 1select id from t where num/2 = 100 1 应改为: 1select id from t where num = 100*2；1 应尽量避免在 where 子句中对字段进行函数操作, 这将导致引擎放弃使用索引而进行全表扫描 例如: 1select id from t where substring(name,1,3) = &apos;abc&apos; – name;1 以abc开头的, 应改成: 1select id from t where name like ‘abc%’ 1 例如: 1select id from t where datediff(day, createdate, &apos;2005-11-30&apos;) = 0 – &apos;2005-11-30&apos;;1 应改为: 1select id from t where createdate &gt;= &apos;2005-11-30&apos; and createdate &lt; &apos;2005-12-1&apos;; 不要在 where 子句中的 = 左边进行函数、算术运算或其他表达式运算, 否则系统将可能无法正确使用索引 如果MySQL估计使用全表扫描要比使用索引快, 则不使用索引 不适合键值较少的列（重复数据较多的列） 假如索引列TYPE有5个键值, 如果有1万条数据, 那么 WHERE TYPE = 1将访问表中的2000个数据块. 再加上访问索引块, 一共要访问大于2000个的数据块. 如果全表扫描, 假设10条数据一个数据块, 那么只需访问1000个数据块, 既然全表扫描访问的数据块少一些, 肯定就不会利用索引了. 参考: http://blog.csdn.net/xlgen157387/article/details/79572598 JSON相关JSON支持 在MySQL 5.7.8中, MySQL支持由RFC 7159定义的本地JSON数据类型, 它支持对JSON(JavaScript对象标记)文档中的数据进行有效访问. MySQL会对DML JSON数据自动验证. 无效的DML JSON数据操作会产生错误. 优化的存储格式. 存储在JSON列中的JSON文档转换为一种内部格式, 允许对Json元素进行快速读取访问. MySQL Json类型支持通过虚拟列方式建立索引, 从而增加查询性能提升. 函数语法mysql在json类型中增加了一些json相关的函数 可以参考如下 Name Description JSON_APPEND() (deprecated 5.7.9) Append data to JSON document JSON_ARRAY() Create JSON array JSON_ARRAY_APPEND() Append data to JSON document JSON_ARRAY_INSERT() Insert into JSON array -&gt; Return value from JSON column after evaluating path; equivalent to JSON_EXTRACT(). JSON_CONTAINS() Whether JSON document contains specific object at path JSON_CONTAINS_PATH() Whether JSON document contains any data at path JSON_DEPTH() Maximum depth of JSON document JSON_EXTRACT() Return data from JSON document -&gt;&gt; Return value from JSON column after evaluating path and unquoting the result; equivalent to JSON_UNQUOTE(JSON_EXTRACT()). JSON_INSERT() Insert data into JSON document JSON_KEYS() Array of keys from JSON document JSON_LENGTH() Number of elements in JSON document JSON_MERGE() (deprecated 5.7.22) Merge JSON documents, preserving duplicate keys. Deprecated synonym for JSON_MERGE_PRESERVE() JSON_MERGE_PATCH() Merge JSON documents, replacing values of duplicate keys JSON_MERGE_PRESERVE() Merge JSON documents, preserving duplicate keys JSON_OBJECT() Create JSON object JSON_PRETTY() Prints a JSON document in human-readable format, with each array element or object member printed on a new line, indented two spaces with respect to its parent. JSON_QUOTE() Quote JSON document JSON_REMOVE() Remove data from JSON document JSON_REPLACE() Replace values in JSON document JSON_SEARCH() Path to value within JSON document JSON_SET() Insert data into JSON document JSON_STORAGE_SIZE() Space used for storage of binary representation of a JSON document; for a JSON column, the space used when the document was inserted, prior to any partial updates JSON_TYPE() Type of JSON value JSON_UNQUOTE() Unquote JSON value JSON_VALID() Whether JSON value is valid 常见的就是JSON_EXTRACT()等 表结构 插入数据12INSERT INTO `user_json` VALUES (1, &apos;&#123;\&quot;name\&quot;: \&quot;yang\&quot;, \&quot;address\&quot;: \&quot;shenyang\&quot;&#125;&apos;);... JSON校验: 查询123select * from user_json where json_extract(data,&apos;$.name&apos;)=&apos;yang&apos;;select json_extract(data,&apos;$.name&apos;) from user_json where json_extract(data,&apos;$.name&apos;)=&apos;yang&apos;;select data-&gt;&apos;$.name&apos; from user_json where data-&gt;&apos;$.name&apos;=&apos;yang&apos;; 发现结果集是带有双引号的: 如果想要去除双引号一般来说我们这样: 12select JSON_UNQUOTE(json_extract(data,&apos;$.name&apos;))from user_json where json_extract(data,&apos;$.name&apos;)=&apos;yang&apos;;select data-&gt;&gt;&apos;$.name&apos; from user_json where data-&gt;&apos;$.name&apos;=&apos;yang&apos;; JSON如何建立索引json类型并不能建立索引, 但我们可以通过虚拟列来建立索引 123ALTER TABLE user_json ADD COLUMN `virtual_name` varchar(20) GENERATED ALWAYS AS (data-&gt;&gt;&apos;$.name&apos;) VIRTUAL NULL AFTER `data`;ALTER TABLE user_json ADD KEY (virtual_name); 可以看到索引起作用了~ 像时间这些要把周一到周日建索引也是可以的: 1`dayofweek` tinyint(4) GENERATED ALWAYS AS (dayofweek(SomeDate)) VIRTUAL, 或者某些很麻烦的条件: 12alter table ApiLog add verb_url_hash varbinary(16) GENERATED ALWAYS AS (unhex(md5(CONCAT(verb, &apos; - &apos;, replace(url,&apos;.xml&apos;,&apos;&apos;))))) VIRTUAL;alter table ApiLog add key (verb_url_hash); MySQL存储引擎MyISAM与InnoDB区别MySQL默认存储引擎的变迁在MySQL 5.1之前的版本中, 默认的搜索引擎是MyISAM, 从MySQL 5.5之后的版本中, 默认的搜索引擎变更为InnoDB. MyISAM与InnoDB存储引擎的主要特点MyISAM存储引擎的特点是: 表级锁、不支持事务和全文索引, 适合一些CMS内容管理系统作为后台数据库使用, 但是使用大并发、重负荷生产系统上, 表锁结构的特性就显得力不从心； 以下是MySQL 5.7 MyISAM存储引擎的版本特性: InnoDB存储引擎的特点是: 行级锁、事务安全（ACID兼容）、支持外键、不支持FULLTEXT类型的索引(5.6.4以后版本开始支持FULLTEXT类型的索引). InnoDB存储引擎提供了具有提交、回滚和崩溃恢复能力的事务安全存储引擎. InnoDB是为处理巨大量时拥有最大性能而设计的. 它的CPU效率可能是任何其他基于磁盘的关系数据库引擎所不能匹敌的. 以下是MySQL 5.7 InnoDB存储引擎的版本特性: 注意: InnoDB表的行锁也不是绝对的, 假如在执行一个SQL语句时MySQL不能确定要扫描的范围, InnoDB表同样会锁全表, 例如update table set num=1 where name like “a%”. 两种类型最主要的差别就是InnoDB支持事务处理与外键和行级锁. 而MyISAM不支持. 所以MyISAM往往就容易被人认为只适合在小项目中使用. MyISAM与InnoDB性能测试下边两张图是官方提供的MyISAM与InnoDB的压力测试结果 可以看出, 随着CPU核数的增加, InnoDB的吞吐量反而越好, 而MyISAM, 其吞吐量几乎没有什么变化, 显然, MyISAM的表锁定机制降低了读和写的吞吐量. 事务支持与否MyISAM是一种非事务性的引擎, 使得MyISAM引擎的MySQL可以提供高速存储和检索, 以及全文搜索能力, 适合数据仓库等查询频繁的应用； InnoDB是事务安全的； 事务是一种高级的处理方式, 如在一些列增删改中只要哪个出错还可以回滚还原, 而MyISAM就不可以了. MyISAM与InnoDB构成上的区别（1）每个MyISAM在磁盘上存储成三个文件: 第一个文件的名字以表的名字开始, 扩展名指出文件类型, .frm文件存储表定义.第二个文件是数据文件, 其扩展名为.MYD (MYData).第三个文件是索引文件, 其扩展名是.MYI (MYIndex). （2）基于磁盘的资源是InnoDB表空间数据文件和它的日志文件, InnoDB 表的 大小只受限于操作系统文件的大小, 一般为 2GB. MyISAM与InnoDB表锁和行锁的解释MySQL表级锁有两种模式: 表共享读锁（Table Read Lock）和表独占写锁（Table Write Lock）. 什么意思呢, 就是说对MyISAM表进行读操作时, 它不会阻塞其他用户对同一表的读请求, 但会阻塞对同一表的写操作；而对MyISAM表的写操作, 则会阻塞其他用户对同一表的读和写操作. InnoDB行锁是通过给索引项加锁来实现的, 即只有通过索引条件检索数据, InnoDB才使用行级锁, 否则将使用表锁！行级锁在每次获取锁和释放锁的操作需要消耗比表锁更多的资源. 在InnoDB两个事务发生死锁的时候, 会计算出每个事务影响的行数, 然后回滚行数少的那个事务. 当锁定的场景中不涉及Innodb的时候, InnoDB是检测不到的. 只能依靠锁定超时来解决. 是否保存数据库表中表的具体行数InnoDB 中不保存表的具体行数, 也就是说, 执行select count(*) from table 时, InnoDB要扫描一遍整个表来计算有多少行, 但是MyISAM只要简单的读出保存好的行数即可. 注意的是, 当count(*)语句包含where条件时, 两种表的操作是一样的. 也就是 上述“6”中介绍到的InnoDB使用表锁的一种情况. 如何选择MyISAM适合:（1）做很多count 的计算；（2）插入不频繁, 查询非常频繁, 如果执行大量的SELECT, MyISAM是更好的选择；（3）没有事务. InnoDB适合:（1）可靠性要求比较高, 或者要求事务；（2）表更新和查询都相当的频繁, 并且表锁定的机会比较大的情况指定数据引擎的创建；（3）如果你的数据执行大量的INSERT或UPDATE, 出于性能方面的考虑, 应该使用InnoDB表；（4）DELETE FROM table时, InnoDB不会重新建立表, 而是一行一行的 删除；（5）LOAD TABLE FROM MASTER操作对InnoDB是不起作用的, 解决方法是首先把InnoDB表改成MyISAM表, 导入数据后再改成InnoDB表, 但是对于使用的额外的InnoDB特性（例如外键）的表不适用. 要注意, 创建每个表格的代码是相同的, 除了最后的 TYPE参数, 这一参数用来指定数据引擎. 其他区别1、对于AUTO_INCREMENT类型的字段, InnoDB中必须包含只有该字段的索引, 但是在MyISAM表中, 可以和其他字段一起建立联合索引. 2、DELETE FROM table时, InnoDB不会重新建立表, 而是一行一行的删除. 3、LOAD TABLE FROMMASTER操作对InnoDB是不起作用的, 解决方法是首先把InnoDB表改成MyISAM表, 导入数据后再改成InnoDB表, 但是对于使用的额外的InnoDB特性(例如外键)的表不适用. 4、 InnoDB存储引擎被完全与MySQL服务器整合, InnoDB存储引擎为在主内存中缓存数据和索引而维持它自己的缓冲池. 5、对于自增长的字段, InnoDB中必须包含只有该字段的索引, 但是在MyISAM表中可以和其他字段一起建立联合索引. 6、清空整个表时, InnoDB是一行一行的删除, 效率非常慢. MyISAM则会重建表. 通过SQL查看表信息查看创建表1SHOW CREATE TABLE test_table; 查看表信息1SHOW TABLE STATUS WHERE NAME IN('test_table', 'person'); 更详细信息: 1SELECT * FROM information_schema.tables WHERE table_schema='test_db' AND table_name='test_table'; 查看字段信息1SHOW FULL FIELDS FROM `test_table`; 更详细信息: 1SELECT * FROM information_schema.COLUMNS WHERE table_schema='test_db' AND table_name='test_table'; 查看表索引123SHOW INDEX FROM test_table;-- 或者SHOW KEYS from test_table; 备份数据与恢复从Navicat中导入导出数据是比较慢的, 我们可以通过 mysqldump (安装 mysql-client 后自带)备份. mysqldump 备份备份一个数据库: 1mysqldump -u [uname] -p[pass] db_name &gt; db_backup.sql 备份所有数据库: 1mysqldump -u [uname] -p[pass] --all-databases &gt; all_db_backup.sql 备份特定的表: 1mysqldump -u [uname] -p[pass] db_name table1 table2 &gt; table_backup.sql 导出压缩一步到位: 1mysqldump -u [uname] -p[pass] db_name | gzip &gt; db_backup.sql.gz 远程数据库: 1mysqldump -P 3306 -h [ip_address] -u [uname] -p[pass] db_name &gt; db_backup.sql 遇到 mysqldump: Got error: 1044: Access denied for user 解决办法: 加上 --single-transaction 即可, 网上有人说使用 --skip-lock-tables, 这个会影响数据的一致性(可能比丢数据还要遭糕)，故不推荐使用这个方法: 1mysqldump --single-transaction -P 3306 -h [ip_address] -u [uname] -p[pass] db_name &gt; db_backup.sql 恢复恢复一个数据库: 1mysql -h [host] -P [port] -u [uname] -p[pass] db_name &lt; db_backup.sql 恢复全部数据库: 1mysql -h [host] -P [port] -u [uname] -p[pass] &lt; db_backup_all.sql Finally看到一片美团技术团队的博文非常好: https://tech.meituan.com/mysql-index.html]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[极致的追求, 高性能并发框架 Disruptor]]></title>
    <url>%2F2018%2Fdisruptor-learning%2F</url>
    <content type="text"><![CDATA[Preface Disruptor是英国外汇交易公司LMAX开发的一个高性能队列, 研发的初衷是解决内存队列的延迟问题（在性能测试中发现竟然与I/O操作处于同样的数量级）. 基于Disruptor开发的系统单线程能支撑每秒600万订单, 2010年在QCon演讲后, 获得了业界关注. 2011年, 企业应用软件专家Martin Fowler专门撰写长文介绍. 同年它还获得了Oracle官方的Duke大奖. 目前, 包括Apache Storm、Camel、Log4j2、Reactor在内的很多知名项目都应用或参考了Disruptor以获取高性能. 其实Disruptor与其说是一个框架, 不如说是一种设计思路, 这个设计思路对于存在“并发、缓冲区、生产者—消费者模型、事务处理”这些元素的程序来说, Disruptor提出了一种大幅提升性能（TPS）的方案. 听说小米也是用这个东东把亚马逊搞挂了: http://bbs.xiaomi.cn/t-13417592 核心概念在理解Disruptor之前, 我们需要看一下它的核心概念 Ring Buffer: Ring Buffer通常被认为是Disruptor的主要方面, 然而从3.0开始, Ring Buffer只负责存储和更新通过Disruptor的数据（Events）. 而且对于一些高级用例可以完全由用户替换. Sequence: Disruptor使用序列作为一种手段来确定特定组件的位置. 每个消费者（EventProcessor）都像Disruptor本身一样维护一个Sequence. 大部分并发代码依赖于这些Sequence值的移动, 因此Sequence支持AtomicLong的许多当前特性. 事实上, 与2版本之间唯一真正的区别是序列包含额外的功能, 以防止序列和其他值之间的错误共享. Sequencer: Sequencer是Disruptor的真正核心. 这个接口的2个实现（单生产者, 多生产者）实现了所有的并发算法, 用于在生产者和消费者之间快速正确地传递数据. Sequence Barrier: 序列屏障由序列发生器产生, 并包含对序列发生器的主要发布序列和任何相关消费者的序列的引用. 它包含确定消费者是否有任何事件可供处理的逻辑. Wait Strategy: 等待策略决定了消费者如何等待事件被生产者置于Disruptor中. Event: 从生产者到消费者的数据单位. 事件没有特定的代码表示, 因为它完全由用户定义. EventProcessor: 用于处理来自Disruptor的事件的主事件循环, 并拥有消费者序列的所有权. 有一个称为BatchEventProcessor的表示, 它包含一个有效的事件循环实现, 并将回调到EventHandler接口的已用提供的实现上. EventHandler: 由用户实现的界面, 代表Disruptor的使用者. Producer: 这是调用Disruptor排入事件的用户代码. 这个概念在代码中也没有表示. Java内置队列 以下内容来自美团点评技术团队博文 Java的内置队列如下表所示. 队列 有界性 锁 数据结构 ArrayBlockingQueue bounded 加锁 arraylist LinkedBlockingQueue optionally-bounded 加锁 linkedlist ConcurrentLinkedQueue unbounded 无锁 linkedlist LinkedTransferQueue unbounded 无锁 linkedlist PriorityBlockingQueue unbounded 加锁 heap DelayQueue unbounded 加锁 heap 队列的底层一般分成三种: 数组、链表和堆. 其中, 堆一般情况下是为了实现带有优先级特性的队列, 暂且不考虑. 我们就从数组和链表两种数据结构来看, 基于数组线程安全的队列, 比较典型的是ArrayBlockingQueue, 它主要通过加锁的方式来保证线程安全；基于链表的线程安全队列分成LinkedBlockingQueue和ConcurrentLinkedQueue两大类, 前者也通过锁的方式来实现线程安全, 而后者以及上面表格中的LinkedTransferQueue都是通过原子变量compare and swap（以下简称“CAS”）这种不加锁的方式来实现的. 通过不加锁的方式实现的队列都是无界的（无法保证队列的长度在确定的范围内）；而加锁的方式, 可以实现有界队列. 在稳定性要求特别高的系统中, 为了防止生产者速度过快, 导致内存溢出, 只能选择有界队列；同时, 为了减少Java的垃圾回收对系统性能的影响, 会尽量选择array/heap格式的数据结构. 这样筛选下来, 符合条件的队列就只有ArrayBlockingQueue. ArrayBlockingQueue的问题ArrayBlockingQueue在实际使用过程中, 会因为加锁和伪共享等出现严重的性能问题, 我们下面来分析一下. 加锁现实编程过程中, 加锁通常会严重地影响性能. 线程会因为竞争不到锁而被挂起, 等锁被释放的时候, 线程又会被恢复, 这个过程中存在着很大的开销, 并且通常会有较长时间的中断, 因为当一个线程正在等待锁时, 它不能做任何其他事情. 如果一个线程在持有锁的情况下被延迟执行, 例如发生了缺页错误、调度延迟或者其它类似情况, 那么所有需要这个锁的线程都无法执行下去. 如果被阻塞线程的优先级较高, 而持有锁的线程优先级较低, 就会发生优先级反转. Disruptor论文中讲述了一个实验: 这个测试程序调用了一个函数, 该函数会对一个64位的计数器循环自增5亿次. 机器环境: 2.4G 6核 运算: 64位的计数器累加5亿次 Method Time (ms) Single thread 300 Single thread with CAS 5,700 Single thread with lock 10,000 Single thread with volatile write 4,700 Two threads with CAS 30,000 Two threads with lock 224,000 CAS操作比单线程无锁慢了1个数量级；有锁且多线程并发的情况下, 速度比单线程无锁慢3个数量级. 可见无锁速度最快. 单线程情况下, 不加锁的性能 &gt; CAS操作的性能 &gt; 加锁的性能. 在多线程情况下, 为了保证线程安全, 必须使用CAS或锁, 这种情况下, CAS的性能超过锁的性能, 前者大约是后者的8倍. 综上可知, 加锁的性能是最差的. 关于锁和CAS保证线程安全一般分成两种方式: 锁和原子变量. 锁 采取加锁的方式, 默认线程会冲突, 访问数据时, 先加上锁再访问, 访问之后再解锁. 通过锁界定一个临界区, 同时只有一个线程进入. 如上图所示, Thread2访问Entry的时候, 加了锁, Thread1就不能再执行访问Entry的代码, 从而保证线程安全. 下面是ArrayBlockingQueue通过加锁的方式实现的offer方法, 保证线程安全. 123456789101112131415public boolean offer(E e) &#123; checkNotNull(e); final ReentrantLock lock = this.lock; lock.lock(); try &#123; if (count == items.length) return false; else &#123; insert(e); return true; &#125; &#125; finally &#123; lock.unlock(); &#125;&#125; 原子变量原子变量能够保证原子性的操作, 意思是某个任务在执行过程中, 要么全部成功, 要么全部失败回滚, 恢复到执行之前的初态, 不存在初态和成功之间的中间状态. 例如CAS操作, 要么比较并交换成功, 要么比较并交换失败. 由CPU保证原子性. 通过原子变量可以实现线程安全. 执行某个任务的时候, 先假定不会有冲突, 若不发生冲突, 则直接执行成功；当发生冲突的时候, 则执行失败, 回滚再重新操作, 直到不发生冲突. 如图所示, Thread1和Thread2都要把Entry加1. 若不加锁, 也不使用CAS, 有可能Thread1取到了myValue=1, Thread2也取到了myValue=1, 然后相加, Entry中的value值为2. 这与预期不相符, 我们预期的是Entry的值经过两次相加后等于3. CAS会先把Entry现在的value跟线程当初读出的值相比较, 若相同, 则赋值；若不相同, 则赋值执行失败. 一般会通过while/for循环来重新执行, 直到赋值成功. 代码示例是AtomicInteger的getAndAdd方法. CAS是CPU的一个指令, 由CPU保证原子性. 123456789101112131415161718192021222324252627/** * Atomically adds the given value to the current value. * * @param delta the value to add * @return the previous value */public final int getAndAdd(int delta) &#123; for (;;) &#123; int current = get(); int next = current + delta; if (compareAndSet(current, next)) return current; &#125;&#125;/** * Atomically sets the value to the given updated value * if the current value &#123;@code ==&#125; the expected value. * * @param expect the expected value * @param update the new value * @return true if successful. False return indicates that * the actual value was not equal to the expected value. */public final boolean compareAndSet(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, valueOffset, expect, update);&#125; 在高度竞争的情况下, 锁的性能将超过原子变量的性能, 但是更真实的竞争情况下, 原子变量的性能将超过锁的性能. 同时原子变量不会有死锁等活跃性问题. 伪共享什么是共享下图是计算的基本结构. L1、L2、L3分别表示一级缓存、二级缓存、三级缓存, 越靠近CPU的缓存, 速度越快, 容量也越小. 所以L1缓存很小但很快, 并且紧靠着在使用它的CPU内核；L2大一些, 也慢一些, 并且仍然只能被一个单独的CPU核使用；L3更大、更慢, 并且被单个插槽上的所有CPU核共享；最后是主存, 由全部插槽上的所有CPU核共享. 当CPU执行运算的时候, 它先去L1查找所需的数据、再去L2、然后是L3, 如果最后这些缓存中都没有, 所需的数据就要去主内存拿. 走得越远, 运算耗费的时间就越长. 所以如果你在做一些很频繁的事, 你要尽量确保数据在L1缓存中. 另外, 线程之间共享一份数据的时候, 需要一个线程把数据写回主存, 而另一个线程访问主存中相应的数据. 下面是从CPU访问不同层级数据的时间概念: 从CPU到 大约需要的CPU周期 大约需要的时间 主存 约60-80ns QPI 总线传输(between sockets, not drawn) 约20ns L3 cache 约40-45 cycles 约15ns L2 cache 约10 cycles 约3ns L1 cache 约3-4 cycles 约1ns 寄存器 1 cycle 可见CPU读取主存中的数据会比从L1中读取慢了近2个数量级. 缓存行Cache是由很多个cache line组成的. 每个cache line通常是64字节, 并且它有效地引用主内存中的一块儿地址. 一个Java的long类型变量是8字节, 因此在一个缓存行中可以存8个long类型的变量. CPU每次从主存中拉取数据时, 会把相邻的数据也存入同一个cache line. 在访问一个long数组的时候, 如果数组中的一个值被加载到缓存中, 它会自动加载另外7个. 因此你能非常快的遍历这个数组. 事实上, 你可以非常快速的遍历在连续内存块中分配的任意数据结构. 下面的例子是测试利用cache line的特性和不利用cache line的特性的效果对比. 123456789101112131415161718192021222324252627282930public class CacheLineEffect &#123; //考虑一般缓存行大小是64字节, 一个 long 类型占8字节 static long[][] arr; public static void main(String[] args) &#123; arr = new long[1024 * 1024][]; for (int i = 0; i &lt; 1024 * 1024; i++) &#123; arr[i] = new long[8]; for (int j = 0; j &lt; 8; j++) &#123; arr[i][j] = 0L; &#125; &#125; long sum = 0L; long marked = System.currentTimeMillis(); for (int i = 0; i &lt; 1024 * 1024; i+=1) &#123; for(int j =0; j&lt; 8;j++)&#123; sum = arr[i][j]; &#125; &#125; System.out.println(&quot;Loop times:&quot; + (System.currentTimeMillis() - marked) + &quot;ms&quot;); marked = System.currentTimeMillis(); for (int i = 0; i &lt; 8; i+=1) &#123; for(int j =0; j&lt; 1024 * 1024;j++)&#123; sum = arr[j][i]; &#125; &#125; System.out.println(&quot;Loop times:&quot; + (System.currentTimeMillis() - marked) + &quot;ms&quot;); &#125;&#125; 在2G Hz、2核、8G内存的运行环境中测试, 速度差一倍. 结果:Loop times:30msLoop times:65ms 什么是伪共享ArrayBlockingQueue有三个成员变量: takeIndex: 需要被取走的元素下标 putIndex: 可被元素插入的位置的下标 count: 队列中元素的数量 这三个变量很容易放到一个缓存行中, 但是之间修改没有太多的关联. 所以每次修改, 都会使之前缓存的数据失效, 从而不能完全达到共享的效果. 如上图所示, 当生产者线程put一个元素到ArrayBlockingQueue时, putIndex会修改, 从而导致消费者线程的缓存中的缓存行无效, 需要从主存中重新读取. 这种无法充分使用缓存行特性的现象, 称为伪共享. 对于伪共享, 一般的解决方案是, 增大数组元素的间隔使得由不同线程存取的元素位于不同的缓存行上, 以空间换时间. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public class FalseSharing implements Runnable&#123; public final static long ITERATIONS = 500L * 1000L * 100L; private int arrayIndex = 0; private static ValuePadding[] longs; public FalseSharing(final int arrayIndex) &#123; this.arrayIndex = arrayIndex; &#125; public static void main(final String[] args) throws Exception &#123; for(int i=1;i&lt;10;i++)&#123; System.gc(); final long start = System.currentTimeMillis(); runTest(i); System.out.println(&quot;Thread num &quot;+i+&quot; duration = &quot; + (System.currentTimeMillis() - start)); &#125; &#125; private static void runTest(int NUM_THREADS) throws InterruptedException &#123; Thread[] threads = new Thread[NUM_THREADS]; longs = new ValuePadding[NUM_THREADS]; for (int i = 0; i &lt; longs.length; i++) &#123; longs[i] = new ValuePadding(); &#125; for (int i = 0; i &lt; threads.length; i++) &#123; threads[i] = new Thread(new FalseSharing(i)); &#125; for (Thread t : threads) &#123; t.start(); &#125; for (Thread t : threads) &#123; t.join(); &#125; &#125; public void run() &#123; long i = ITERATIONS + 1; while (0 != --i) &#123; longs[arrayIndex].value = 0L; &#125; &#125; public final static class ValuePadding &#123; protected long p1, p2, p3, p4, p5, p6, p7; protected volatile long value = 0L; protected long p9, p10, p11, p12, p13, p14; protected long p15; &#125; public final static class ValueNoPadding &#123; // protected long p1, p2, p3, p4, p5, p6, p7; protected volatile long value = 0L; // protected long p9, p10, p11, p12, p13, p14, p15; &#125;&#125; 在2G Hz, 2核, 8G内存, jdk 1.7.0_45 的运行环境下, 使用了共享机制比没有使用共享机制, 速度快了4倍左右. 结果:Thread num 1 duration = 447Thread num 2 duration = 463Thread num 3 duration = 454Thread num 4 duration = 464Thread num 5 duration = 561Thread num 6 duration = 606Thread num 7 duration = 684Thread num 8 duration = 870Thread num 9 duration = 823 把代码中ValuePadding都替换为ValueNoPadding后的结果:Thread num 1 duration = 446Thread num 2 duration = 2549Thread num 3 duration = 2898Thread num 4 duration = 3931Thread num 5 duration = 4716Thread num 6 duration = 5424Thread num 7 duration = 4868Thread num 8 duration = 4595Thread num 9 duration = 4540 备注: 在jdk1.8中, 有专门的注解@Contended来避免伪共享, 更优雅地解决问题. Disruptor的设计方案Disruptor通过以下设计来解决队列速度慢的问题: 环形数组结构 为了避免垃圾回收, 采用数组而非链表. 同时, 数组对处理器的缓存机制更加友好. 元素位置定位 数组长度2^n, 通过位运算, 加快定位的速度. 下标采取递增的形式. 不用担心index溢出的问题. index是long类型, 即使100万QPS的处理速度, 也需要30万年才能用完. 无锁设计 每个生产者或者消费者线程, 会先申请可以操作的元素在数组中的位置, 申请到之后, 直接在该位置写入或者读取数据. 下面忽略数组的环形结构, 介绍一下如何实现无锁设计. 整个过程通过原子变量CAS, 保证操作的线程安全. 一个生产者写数据生产者单线程写数据的流程比较简单: 申请写入m个元素； 若是有m个元素可以写入, 则返回最大的序列号. 这儿主要判断是否会覆盖未读的元素； 若是返回的正确, 则生产者开始写入元素. 图5 单个生产者生产过程示意图 多个生产者多个生产者的情况下, 会遇到“如何防止多个线程重复写同一个元素”的问题. Disruptor的解决方法是, 每个线程获取不同的一段数组空间进行操作. 这个通过CAS很容易达到. 只需要在分配元素的时候, 通过CAS判断一下这段空间是否已经分配出去即可. 但是会遇到一个新问题: 如何防止读取的时候, 读到还未写的元素. Disruptor在多个生产者的情况下, 引入了一个与Ring Buffer大小相同的buffer: available Buffer. 当某个位置写入成功的时候, 便把availble Buffer相应的位置置位, 标记为写入成功. 读取的时候, 会遍历available Buffer, 来判断元素是否已经就绪. 下面分读数据和写数据两种情况介绍. 读数据生产者多线程写入的情况会复杂很多: 申请读取到序号n； 若writer cursor &gt;= n, 这时仍然无法确定连续可读的最大下标. 从reader cursor开始读取available Buffer, 一直查到第一个不可用的元素, 然后返回最大连续可读元素的位置； 消费者读取元素. 如下图所示, 读线程读到下标为2的元素, 三个线程Writer1/Writer2/Writer3正在向RingBuffer相应位置写数据, 写线程被分配到的最大元素下标是11. 读线程申请读取到下标从3到11的元素, 判断writer cursor&gt;=11. 然后开始读取availableBuffer, 从3开始, 往后读取, 发现下标为7的元素没有生产成功, 于是WaitFor(11)返回6. 然后, 消费者读取下标从3到6共计4个元素. 写数据多个生产者写入的时候: 申请写入m个元素； 若是有m个元素可以写入, 则返回最大的序列号. 每个生产者会被分配一段独享的空间； 生产者写入元素, 写入元素的同时设置available Buffer里面相应的位置, 以标记自己哪些位置是已经写入成功的. 如下图所示, Writer1和Writer2两个线程写入数组, 都申请可写的数组空间. Writer1被分配了下标3到下表5的空间, Writer2被分配了下标6到下标9的空间. Writer1写入下标3位置的元素, 同时把available Buffer相应位置置位, 标记已经写入成功, 往后移一位, 开始写下标4位置的元素. Writer2同样的方式. 最终都写入完成. 防止不同生产者对同一段空间写入的代码, 如下所示: 123456789101112131415161718192021222324public long tryNext(int n) throws InsufficientCapacityException&#123; if (n &lt; 1) &#123; throw new IllegalArgumentException(&quot;n must be &gt; 0&quot;); &#125; long current; long next; do &#123; current = cursor.get(); next = current + n; if (!hasAvailableCapacity(gatingSequences, n, current)) &#123; throw InsufficientCapacityException.INSTANCE; &#125; &#125; while (!cursor.compareAndSet(current, next)); return next;&#125; 通过do/while循环的条件cursor.compareAndSet(current, next), 来判断每次申请的空间是否已经被其他生产者占据. 假如已经被占据, 该函数会返回失败, While循环重新执行, 申请写入空间. 消费者的流程与生产者非常类似, 这儿就不多描述了. Disruptor通过精巧的无锁设计实现了在高并发情形下的高性能. 等待策略生产者的等待策略暂时只有休眠1ns. 1LockSupport.parkNanos(1); 消费者的等待策略 名称 说明 适用场景 BlockingWaitStrategy 默认等待策略. 和BlockingQueue的实现很类似, 通过使用锁和条件（Condition）进行线程阻塞的方式, 等待生产者唤醒(线程同步和唤醒). 此策略对于线程切换来说, 最节约CPU资源, 但在高并发场景下性能有限 CPU资源紧缺, 吞吐量和延迟并不重要的场景 BusySpinWaitStrategy 死循环策略. 消费者线程会尽最大可能监控缓冲区的变化, 会占用所有CPU资源,线程一直自旋等待, 比较耗CPU 通过不断重试, 减少切换线程导致的系统调用, 而降低延迟. 推荐在线程绑定到固定的CPU的场景下使用 LiteBlockingWaitStrategy 通过线程阻塞的方式, 等待生产者唤醒, 比BlockingWaitStrategy要轻, 某些情况下可以减少阻塞的次数 PhasedBackoffWaitStrategy 根据指定的时间段参数和指定的等待策略决定采用哪种等待策略 CPU资源紧缺, 吞吐量和延迟并不重要的场景 SleepingWaitStrategy CPU友好型策略. 会在循环中不断等待数据. 可通过参数设置,首先进行自旋等待, 若不成功, 则使用Thread.yield()让出CPU, 并使用LockSupport.parkNanos(1)进行线程睡眠, 通过线程调度器重新调度；或一直自旋等待, 所以, 此策略数据处理数据可能会有较高的延迟, 适合用于对延迟不敏感的场景, 优点是对生产者线程影响小, 典型应用场景是异步日志 性能和CPU资源之间有很好的折中. 延迟不均匀 TimeoutBlockingWaitStrategy 通过参数设置阻塞时间, 如果超时则抛出异常 CPU资源紧缺, 吞吐量和延迟并不重要的场景 YieldingWaitStrategy 低延时策略. 消费者线程会不断循环监控RingBuffer的变化, 在循环内部使用Thread.yield()让出CPU给其他线程, 通过线程调度器重新调度 性能和CPU资源之间有很好的折中. 延迟比较均匀 核心对象 RingBuffer: 环形的一个数据结构, 对象初始化时, 会使用事件Event进行填充. Buffer的大小必须是2的幂次方, 方便移位操作. Event: 无指定具体接口, 用户自己实现, 可以携带任何业务数据. EventFactory: 产生事件Event的工厂, 由用户自己实现. EventTranslator: 事件发布的回调接口, 由用户实现, 负责将业务参数设置到事件中. Sequencer: 序列产生器, 也是协调生产者和消费者及实现高并发的核心. 有MultiProducerSequencer 和 SingleProducerSequencer两个实现类. SequenceBarrier: 拥有RingBuffer的发布事件Sequence引用和消费者依赖的Sequence引用. 决定消费者消费可消费的Sequence. EventHandler: 事件的处理者, 由用户自己实现. EventProcessor: 事件的处理器, 单独在一个线程中运行. WorkHandler: 事件的处理者, 由用户自己实现. WorkProcessor: 事件的处理器, 单独在一个线程中运行. WorkerPool: 一组WorkProcessor的处理. WaitStrategy: 在消费者比生产者快时, 消费者处理器的等待策略. 用例按照官方的指南, 一般套路如下: 自定义事件类: 例如 LongEvent 实现EventFactory&lt;T&gt;: 例如LongEventFactory implements EventFactory&lt;LongEvent&gt; 实现EventHandler&lt;T&gt;（消费者）: 例如LongEventHandler implements EventHandler&lt;LongEvent&gt; 实现EventTranslatorOneArg&lt;T, E&gt;作为生产者, 将业务转换为事件: 例如LongEventTranslatorOneArg implements EventTranslatorOneArg&lt;LongEvent, ByteBuffer&gt; 提供线程池或线程工厂 定义buffer大小, 它必须是2的幂, 否则会在初始化时抛出异常. 因为重点在于使用逻辑二进制运算符有着更好的性能；(例如:mod运算) 构建Disruptor&lt;T&gt; 启动disruptor, disruptor.start() 发布事件, 驱动自行流转 基础事件生产与消费自定义事件12345678910111213package com.yangbingdong.springbootdisruptor.basic;import lombok.Data;/** * @author ybd * @date 18-1-31 * @contact yangbingdong@1994.gmail */@Datapublic class LongEvent &#123; private long value;&#125; 定义事件工厂12345678910111213141516171819package com.yangbingdong.springbootdisruptor.basic;import com.lmax.disruptor.EventFactory;import lombok.extern.slf4j.Slf4j;/** * @author ybd * @date 18-1-31 * @contact yangbingdong@1994.gmail */@Slf4jpublic class LongEventFactory implements EventFactory&lt;LongEvent&gt; &#123; @Override public LongEvent newInstance() &#123; log.info(&quot;logEventFactory create LongEvent...&quot;); return new LongEvent(); &#125;&#125; 定义消费者123456789101112131415161718package com.yangbingdong.springbootdisruptor.basic;import com.lmax.disruptor.EventHandler;import lombok.extern.slf4j.Slf4j;/** * @author ybd * @date 18-1-31 * @contact yangbingdong@1994.gmail */@Slf4jpublic class LongEventHandler implements EventHandler&lt;LongEvent&gt; &#123; @Override public void onEvent(LongEvent event, long sequence, boolean endOfBatch) &#123; log.info(&quot;handle event: &quot; + event); &#125;&#125; 定义生产者3.0版本之前123456789101112131415161718192021222324252627282930313233package com.yangbingdong.springbootdisruptor.basic;import com.lmax.disruptor.RingBuffer;import java.nio.ByteBuffer;/** * @author ybd * @date 18-1-31 * @contact yangbingdong@1994.gmail */public class LongEventProducer &#123; private final RingBuffer&lt;LongEvent&gt; ringBuffer; public LongEventProducer(RingBuffer&lt;LongEvent&gt; ringBuffer) &#123; this.ringBuffer = ringBuffer; &#125; public void onData(ByteBuffer bb) &#123; // Grab the next sequence long sequence = ringBuffer.next(); try &#123; // Get the entry in the Disruptor LongEvent event = ringBuffer.get(sequence); // for the sequence // Fill with data event.setValue(bb.getLong(0)); &#125; finally &#123; ringBuffer.publish(sequence); &#125; &#125;&#125; 3.0版本之后使用Translators123456789101112131415161718package com.yangbingdong.springbootdisruptor.basic;import com.lmax.disruptor.EventTranslatorOneArg;import java.nio.ByteBuffer;/** * @author ybd * @date 18-1-31 * @contact yangbingdong@1994.gmail */public class LongEventProducerWithTranslator implements EventTranslatorOneArg&lt;LongEvent, ByteBuffer&gt;&#123; @Override public void translateTo(LongEvent event, long sequence, ByteBuffer bb) &#123; event.setValue(bb.getLong(0)); &#125;&#125; 测试实例单生产者, 单消费者1234567891011121314151617181920212223242526272829303132@Testpublic void singleProducerLongEventDefaultTest() throws InterruptedException &#123; // Executor that will be used to construct new threads for consumers Executor executor = Executors.newCachedThreadPool(); // The factory for the event LongEventFactory factory = new LongEventFactory(); // Specify the size of the ring buffer, must be power of 2. int bufferSize = 1 &lt;&lt; 3; // Construct the Disruptor Disruptor&lt;LongEvent&gt; disruptor = new Disruptor&lt;&gt;(factory, bufferSize, executor, ProducerType.SINGLE, new BlockingWaitStrategy()); // Connect the handler disruptor.handleEventsWith(new LongEventHandler()); // Start the Disruptor, starts all threads running disruptor.start(); // Get the ring buffer from the Disruptor to be used for publishing. RingBuffer&lt;LongEvent&gt; ringBuffer = disruptor.getRingBuffer(); LongEventProducer producer = new LongEventProducer(ringBuffer); ByteBuffer bb = ByteBuffer.allocate(8); for (long l = 0; l &lt; 100; l++) &#123; bb.putLong(0, l); producer.onData(bb); Thread.sleep(10); &#125;&#125; 新版的Disruptor不建议我们使用Executor, 而使用ThreadFactory代替: 12345678910111213141516171819202122232425262728293031@Testpublic void singleProducerLongEventUseThreadFactoryTest() throws InterruptedException &#123; ThreadFactory threadFactory = new ThreadFactory() &#123; private final AtomicInteger index = new AtomicInteger(1); @Override public Thread newThread(Runnable r) &#123; return new Thread(null, r, &quot;disruptor-thread-&quot; + index.getAndIncrement()); &#125; &#125;; LongEventFactory factory = new LongEventFactory(); int bufferSize = 1 &lt;&lt; 3; Disruptor&lt;LongEvent&gt; disruptor = new Disruptor&lt;&gt;(factory, bufferSize, threadFactory, ProducerType.SINGLE, new BlockingWaitStrategy()); disruptor.handleEventsWith(new LongEventHandler()); disruptor.start(); RingBuffer&lt;LongEvent&gt; ringBuffer = disruptor.getRingBuffer(); LongEventProducer producer = new LongEventProducer(ringBuffer); ByteBuffer bb = ByteBuffer.allocate(8); for (long l = 0; l &lt; 100; l++) &#123; bb.putLong(0, l); producer.onData(bb); Thread.sleep(10); &#125;&#125; 新版Disruptor使用Translators: 12345678910111213141516171819202122232425262728293031@Testpublic void singleProducerLongEventUseTranslatorsTest() throws InterruptedException &#123; ThreadFactory threadFactory = new ThreadFactory() &#123; private final AtomicInteger index = new AtomicInteger(1); @Override public Thread newThread(Runnable r) &#123; return new Thread(null, r, &quot;disruptor-thread-&quot; + index.getAndIncrement()); &#125; &#125;; LongEventFactory factory = new LongEventFactory(); int bufferSize = 1 &lt;&lt; 3; Disruptor&lt;LongEvent&gt; disruptor = new Disruptor&lt;&gt;(factory, bufferSize, threadFactory, ProducerType.SINGLE, new BlockingWaitStrategy()); disruptor.handleEventsWith(new LongEventHandler()); disruptor.start(); RingBuffer&lt;LongEvent&gt; ringBuffer = disruptor.getRingBuffer(); LongEventProducerWithTranslator longEventProducerWithTranslator = new LongEventProducerWithTranslator(); ByteBuffer bb = ByteBuffer.allocate(8); for (long l = 0; l &lt; 100; l++) &#123; bb.putLong(0, l); ringBuffer.publishEvent(longEventProducerWithTranslator, bb); Thread.sleep(10); &#125;&#125; java8版: 123456789101112131415161718192021@SuppressWarnings(&quot;unchecked&quot;)@Testpublic void singleProducerLongEventJava8Test() &#123; int bufferSize = 1 &lt;&lt; 3; Disruptor&lt;LongEvent&gt; disruptor = new Disruptor&lt;&gt;(LongEvent::new, bufferSize, (ThreadFactory) Thread::new, ProducerType.SINGLE, new BlockingWaitStrategy()); disruptor.handleEventsWith((event, sequence, endOfBatch) -&gt; log.info(&quot;handle event: &quot; + event)); disruptor.start(); RingBuffer&lt;LongEvent&gt; ringBuffer = disruptor.getRingBuffer(); ByteBuffer bb = ByteBuffer.allocate(8); LongStream.range(0, 100) .forEach(tryLongConsumer(l -&gt; &#123; bb.putLong(0, l); ringBuffer.publishEvent((event, sequence, buffer) -&gt; event.setValue(buffer.getLong(0)), bb); Thread.sleep(10); &#125;));&#125; 多生产者, 单消费者123456789101112131415161718192021222324252627282930313233343536373839@SuppressWarnings(&quot;unchecked&quot;)@Testpublic void multiProducerOneCustomerTest() throws InterruptedException &#123; CountDownLatch countDownLatch = new CountDownLatch(30); int bufferSize = 1 &lt;&lt; 6; Disruptor&lt;LongEvent&gt; disruptor = new Disruptor&lt;&gt;(LongEvent::new, bufferSize, Executors.defaultThreadFactory(), ProducerType.MULTI, new SleepingWaitStrategy()); disruptor.handleEventsWith((event, sequence, endOfBatch) -&gt; &#123; log.info(&quot;handle event: &#123;&#125;, sequence: &#123;&#125;, endOfBatch: &#123;&#125;&quot;, event, sequence, endOfBatch); countDownLatch.countDown(); &#125;); LongEventProducerWithTranslator longEventProducerWithTranslator = new LongEventProducerWithTranslator(); disruptor.start(); new Thread(() -&gt; produce(disruptor, longEventProducerWithTranslator, 0, 10)).start(); new Thread(() -&gt; produce(disruptor, longEventProducerWithTranslator, 10, 20)).start(); new Thread(() -&gt; produce(disruptor, longEventProducerWithTranslator, 20, 30)).start(); countDownLatch.await();&#125;private void produce(Disruptor&lt;LongEvent&gt; disruptor, LongEventProducerWithTranslator longEventProducerWithTranslator, int i, int i2) &#123; try &#123; RingBuffer&lt;LongEvent&gt; ringBuffer = disruptor.getRingBuffer(); ByteBuffer bb = ByteBuffer.allocate(8); for (long l = i; l &lt; i2; l++) &#123; bb.putLong(0, l); ringBuffer.publishEvent(longEventProducerWithTranslator, bb); TimeUnit.MILLISECONDS.sleep(20); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;&#125; 一个及以上生产者, 多个消费者 先处理完c1和c2才处理c3: 1234567891011121314151617181920@Testpublic void multiCustomerOneProducerTest() throws InterruptedException &#123; int bufferSize = 1 &lt;&lt; 8; Disruptor&lt;LongEvent&gt; disruptor = new Disruptor&lt;&gt;(LongEvent::new, bufferSize, Executors.defaultThreadFactory(), ProducerType.MULTI, new YieldingWaitStrategy()); LongEventHandler c1 = new LongEventHandler(); LongEventHandler2 c2 = new LongEventHandler2(); LongEventHandler3 c3 = new LongEventHandler3(); disruptor.handleEventsWith(c1, c2).then(c3); LongEventProducerWithTranslator longEventProducerWithTranslator = new LongEventProducerWithTranslator(); disruptor.start(); new Thread(() -&gt; produce(disruptor, longEventProducerWithTranslator, 0, 100)).start(); TimeUnit.SECONDS.sleep(1);&#125; 从上图结果可以看出来c1和c2的顺序是不确定的, c3总是在最后. 如图, 消费者1b消费时, 必须保证消费者1a已经完成对该消息的消费；消费者2b消费时, 必须保证消费者2a已经完成对该消息的消费；消费者c3消费时, 必须保证消费者1b和2b已经完成对该消息的消费. 12345678910111213141516171819202122232425@SuppressWarnings(&quot;unchecked&quot;)@Testpublic void multiCustomerOneProducerTest2() throws InterruptedException &#123; int bufferSize = 1 &lt;&lt; 8; Disruptor&lt;LongEvent&gt; disruptor = new Disruptor&lt;&gt;(LongEvent::new, bufferSize, Executors.defaultThreadFactory(), ProducerType.SINGLE, new LiteBlockingWaitStrategy()); LongEventHandler c1a = new LongEventHandler(); LongEventHandler2 c2a = new LongEventHandler2(); LongEventHandler3 c1b = new LongEventHandler3(); LongEventHandler4 c2b = new LongEventHandler4(); disruptor.handleEventsWith(c1a, c2a); disruptor.after(c1a).then(c1b); disruptor.after(c2a).then(c2b); disruptor.after(c1b, c2b).then((EventHandler&lt;LongEvent&gt;) (event, sequence, endOfBatch) -&gt; System.out.println(&quot;last costumer \n&quot;)); LongEventProducerWithTranslator longEventProducerWithTranslator = new LongEventProducerWithTranslator(); disruptor.start(); new Thread(() -&gt; produce(disruptor, longEventProducerWithTranslator, 0, 30)).start(); TimeUnit.SECONDS.sleep(1);&#125; 再来一个复杂点的: 12345678910111213141516171819202122232425262728@SuppressWarnings(&quot;unchecked&quot;)@Testpublic void multiCustomerOneProducerTest3() throws InterruptedException &#123; int bufferSize = 1 &lt;&lt; 8; Disruptor&lt;LongEvent&gt; disruptor = new Disruptor&lt;&gt;(LongEvent::new, bufferSize, Executors.defaultThreadFactory(), ProducerType.SINGLE, new LiteBlockingWaitStrategy()); EventHandler a = (EventHandler&lt;LongEvent&gt;) (event, sequence, endOfBatch) -&gt; System.out.println(&quot;process a... event: &quot; + event); EventHandler b = (EventHandler&lt;LongEvent&gt;) (event, sequence, endOfBatch) -&gt; System.out.println(&quot;process b... event: &quot; + event); EventHandler c = (EventHandler&lt;LongEvent&gt;) (event, sequence, endOfBatch) -&gt; System.out.println(&quot;process c... event: &quot; + event); EventHandler d = (EventHandler&lt;LongEvent&gt;) (event, sequence, endOfBatch) -&gt; System.out.println(&quot;process d... event: &quot; + event); EventHandler e = (EventHandler&lt;LongEvent&gt;) (event, sequence, endOfBatch) -&gt; System.out.println(&quot;process e... a,b,c has completed, event: &quot; + event + &quot;\n&quot;); EventHandler f = (EventHandler&lt;LongEvent&gt;) (event, sequence, endOfBatch) -&gt; System.out.println(&quot;process f... d has completed, event: &quot; + event + &quot;\n&quot;); EventHandler g = (EventHandler&lt;LongEvent&gt;) (event, sequence, endOfBatch) -&gt; System.out.println(&quot;process g... e,f has completed, event: &quot; + event + &quot;\n\n&quot;); disruptor.handleEventsWith(a, b, c, d); disruptor.after(a, b, c).then(e); disruptor.after(d).then(f); disruptor.after(e, f).then(g); LongEventProducerWithTranslator longEventProducerWithTranslator = new LongEventProducerWithTranslator(); disruptor.start(); new Thread(() -&gt; produce(disruptor, longEventProducerWithTranslator, 0, 2)).start(); TimeUnit.SECONDS.sleep(1);&#125; 异常处理Disruptor默认会把异常包装成RuntimeException并抛出去, 导致线程挂掉或阻塞, 我们需要自定义异常处理器: 1234567891011121314151617disruptor.setDefaultExceptionHandler(new ExceptionHandler&lt;LongEvent&gt;() &#123; @Override public void handleEventException(Throwable ex, long sequence, LongEvent event) &#123; System.out.println(&quot;捕捉异常: &quot; + ex.getMessage()); System.out.println(&quot;处理异常逻辑...&quot;); &#125; @Override public void handleOnStartException(Throwable ex) &#123; System.out.println(&quot;handleOnStartException&quot;); &#125; @Override public void handleOnShutdownException(Throwable ex) &#123; System.out.println(&quot;handleOnShutdownException&quot;); &#125; &#125;); 从RingBuffer中移除对象 来自官方翻译: 当通过Disruptor传递数据时, 对象可能比预期寿命更长. 为避免发生这种情况, 可能需要在处理事件后清除事件. 如果你有一个单一的事件处理程序清除在同一个处理程序中的值是足够的. 如果你有一连串的事件处理程序, 那么你可能需要一个特定的处理程序放置在链的末尾来处理对象. 12345678910111213141516171819202122232425262728293031class ObjectEvent&lt;T&gt;&#123; T val; void clear() &#123; val = null; &#125;&#125;public class ClearingEventHandler&lt;T&gt; implements EventHandler&lt;ObjectEvent&lt;T&gt;&gt;&#123; public void onEvent(ObjectEvent&lt;T&gt; event, long sequence, boolean endOfBatch) &#123; // Failing to call clear here will result in the // object associated with the event to live until // it is overwritten once the ring buffer has wrapped // around to the beginning. event.clear(); &#125;&#125;public static void main(String[] args)&#123; Disruptor&lt;ObjectEvent&lt;String&gt;&gt; disruptor = new Disruptor&lt;&gt;( () -&gt; ObjectEvent&lt;String&gt;(), bufferSize, executor); disruptor .handleEventsWith(new ProcessingEventHandler()) .then(new ClearingObjectHandler());&#125; 消费者分片12345678910111213141516171819public final class MyHandler implements EventHandler&lt;ValueEvent&gt;&#123; private final long ordinal; private final long numberOfConsumers; public MyHandler(final long ordinal, final long numberOfConsumers) &#123; this.ordinal = ordinal; this.numberOfConsumers = numberOfConsumers; &#125; public void onEvent(final ValueEvent entry, final long sequence, final boolean onEndOfBatch) &#123; if ((sequence % numberOfConsumers) == ordinal) &#123; // Process the event &#125; &#125;&#125; 使用disruptor.handleEventsWithWorkerPool(...)也可以实现这种类似消费者组的功能. 总结 代码: https://github.com/masteranthoneyd/spring-boot-learning/tree/master/spring-boot-disruptor 来自某大神的点评:“当对性能的追求达到这样的程度, 以致对现代硬件构成的理解变得越来越重要. ”这句话恰当地形容了Disruptor/LMAX在对性能方面的追求和失败. 咦, 失败？为什么会这么说呢？Disruptor当然是一个优秀的框架, 我说的失败指的是在开发它的过程中, LMAX曽试图提高并发程序效率, 优化、使用锁或借助其他模型, 但是这些尝试最终失败了——然后他们构建了Disruptor. 再提问: 一个Java程序员在尝试提高他的程序性能的时候, 需要了解很多硬件知识吗？我想很多人都会回答“不需要”, 构建Disruptor的过程中, 最初开发人员对这个问题的回答可能也是“不需要”, 但是尝试失败后他们决定另辟蹊径. 总的看下Disruptor的设计: 锁到CAS、缓冲行填充、避免GC等, 我感觉这些设计都在刻意“迁就”或者“依赖”硬件设计, 这些设计更像是一种“(ugly)hack”（毫无疑问, Disruptor还是目前最优秀的方案之一）. Disruptor可以说是工程级别的项目, 通过各种高级的优化达到了性能的极致: 可选锁无关lock-free, 没有竞争所以非常快 所有访问者都记录自己的序号的实现方式, 允许多个生产者与多个消费者共享相同的数据结构 在每个对象中都能跟踪序列号, 没有为伪共享和非预期的竞争 增加缓存行补齐, 提升cache缓存命中率 环形数组中的元素不会被删除]]></content>
      <categories>
        <category>Programming</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Disruptor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于微服务的一些调研零散笔记]]></title>
    <url>%2F2018%2Fmicro-service-ddd-notice%2F</url>
    <content type="text"><![CDATA[Preface 微服务架构:微服务 (Microservices) 是一种软件架构风格 (Software Architecture Style), 它是以专注于单一责任与功能的小型功能区块 (Small Building Blocks) 为基础, 利用模组化的方式组合出复杂的大型应用程序, 各功能区块使用与语言无关 (Language-Independent/Language agnostic) 的 API 集相互通讯. 不拆分存储的微服务是伪服务: 在实践中, 我们常常见到一种架构, 后端存储是全部和在一个数据库中, 仅仅把前端的业务逻辑拆分到不同的服务进程中, 本质上和一个Monolithic一样, 只是把模块之间的进程内调用改为进程间调用, 这种切分不可取, 违反了分布式第一原则, 模块耦合没有解决, 性能却受到了影响. ConceptDDD: Domain-Driver Design 领域驱动设计 CQRS: Command Query Responsibility Segregation 命令查询职责分离 Event Sourcing: 事件溯源 Event-driven Architecture: 事件驱动架构, 使用事件来实现跨多个服务的业务逻辑 Saga: 长时间活动的事务(Long Lived Transaction, 简称为LLT)SEC(Saga Execution Coordinator): 一个基于事件驱动的状态机的协调器Saga模式和事件驱动 贫血模型: 对象只用于在各层之间传输数据用, 只有数据字段和Get/Set方法, 没有逻辑在对象中充血模型: 将数据和行为封装在一起, 并与现实世界的业务对象相映射. 各类具备明确的职责划分, 使得逻辑分散到合适对象中. (领域模型) Problem微服务架构必须解决这三个问题拆分领域模型、事务、查询 拆分领域模型遵循Single Responsibility(单一职责)Aggregate(聚合): 聚合通过id（例如主键）来引用而不是通过对象引用 聚合必须遵循一个事务只能对一个聚合进行创建或更新 聚合应该尽量细 事务由于采用了微服务拥有各自的私人数据库, 只能通过API访问, 不可避免出现了分布式跨数据库事务问题. ACID vs BASE传统事务 ACID: Atomicity（原子性）: 一个事务中的操作是原子的, 其中任何一步失败, 系统都能够完全回到事务前的状态 Consistency（一致性）: 数据库的状态始终保持一致 Isolation（隔离性）: 多个并发执行的事务不会互相影响 Durability（持久性）: 事务处理结束后, 对数据的修改是永久的 微服务下依靠分布式事务（如2PC）保证实时一致性（强一致性）, 性能底下, 牺牲了可用性, 已不适用于现代的微服务架构. BASE模型: Basically Available（基本可用）: 系统在出现不可预知的故障的时候, 允许损失部分可用性, 但不等于系统不可用 Soft State（软状态）: 允许系统中的数据存在中间状态, 并认为该中间状态的存在不会影响系统的整体可用性 Eventually Consistent（最终一致性）: 系统保证最终数据能够达到一致 微服务倡导每个微服务拥有私有的数据库, 且其他服务不能直接与访问该数据库, 只能通过该服务暴露的API进行交互. TCC业务层面的2PC, 需要实现Try、Comfirm、CancelGitHub中TCC实现框架 基于可靠消息达到最终一致性缺点是应用程序不能够立即读取到自己刚刚的写入（滞后性）. 使用本地事务对资源的操作与发布时间捆绑在同一事务中.优点: 使用了本地数据库的事务, 如果Event没有插入或发布成功, 那么订单也不会被创建.缺点: 需要单独处理Event发布在业务逻辑中, 繁琐容易忘记；Event发送有些滞后. 使用数据库特有的MySQL Binlog跟踪订阅binlog发送event优点: 提高了性能缺点: 不同的数据库, 日志格式不一样, 而且同一数据库, 不同版本格式也可能不一样, 决策的时候请慎重. Event Sourcing颠覆传统存储概念, 不持久化对象数据, 而是持久化对象变更的Event, 通过溯源, 遍历事件拿到对象的最新状态. 在我看来, 类似文件系统的概念, 一个操作是一层, 删除并不是减掉一层, 而是添加一层删除操作（类似Git中的版本, 可回滚, 有记录追踪）. 阿里云GTS全局事务GTS（Global Transaction Service）官方文档（需要捆绑Ali全家桶. . . ） 查询实践微服务之后, 除了事务之外, 查询是又是另外一个挑战. 在传统架构中, 我们可以JOIN多个表进行查询, 但在微服务当中, 数据库已经分开, 如果是通过Event Sourcing实现的架构就更加困难了（因为存储的是事件）. 解决之道: CQRS ExtendEvent-drivenSync（请求/响应）: 串行架构 优点: 个人认为, 只有一个优点, 可以偷懒缺点: 中心控制点承担了太多的职责, 入侵式强耦合代码, 如果此时多加一个业务例如创建用户团队, 那就必须在原来代码基础上继续入侵代码, 而且修改一行代码有可能影响到下文. Async（基于事件）: 并行/异步架构 优点: 客户端发起的不是一个请求, 而是发布一个事件, 然后其他协作者接收到该事件, 并知道该怎么做. 我们从来不会告知任何人去做任何事, 基于事件的系统天生就是异步的. 整个系统都很聪明, 业务逻辑并非存在某个核心大脑, 而是分布在不同的协作者中. 基于事件的协作方式耦合性很低, 这意味着你可以在不改变客户端代码的情况下, 对该事件添加新的订阅者来完成新增的功能需求. Spring Cloud FrameworkSpring Cloud Netflix这可是个大boss, 地位仅次于老大, 老大各项服务依赖与它, 与各种Netflix OSS组件集成, 组成微服务的核心, 它的小弟主要有Eureka, Hystrix, Zuul, Archaius… 太多了 Netflix Eureka 服务中心, 云端服务发现, 一个基于 REST 的服务, 用于定位服务, 以实现云端中间层服务发现和故障转移. 这个可是springcloud最牛鼻的小弟, 服务中心, 任何小弟需要其它小弟支持什么都需要从这里来拿, 同样的你有什么独门武功的都赶紧过报道, 方便以后其它小弟来调用；它的好处是你不需要直接找各种什么小弟支持, 只需要到服务中心来领取, 也不需要知道提供支持的其它小弟在哪里, 还是几个小弟来支持的, 反正拿来用就行, 服务中心来保证稳定性和质量. Netflix Hystrix 熔断器, 容错管理工具, 旨在通过熔断机制控制服务和第三方库的节点,从而对延迟和故障提供更强大的容错能力. 比如突然某个小弟生病了, 但是你还需要它的支持, 然后调用之后它半天没有响应, 你却不知道, 一直在等等这个响应；有可能别的小弟也正在调用你的武功绝技, 那么当请求多之后, 就会发生严重的阻塞影响老大的整体计划. 这个时候Hystrix就派上用场了, 当Hystrix发现某个小弟不在状态不稳定立马马上让它下线, 让其它小弟来顶上来, 或者给你说不用等了这个小弟今天肯定不行, 该干嘛赶紧干嘛去别在这排队了. Netflix Zuul Zuul 是在云平台上提供动态路由,监控,弹性,安全等边缘服务的框架. Zuul 相当于是设备和 Netflix 流应用的 Web 网站后端所有请求的前门. 当其它门派来找大哥办事的时候一定要先经过zuul,看下有没有带刀子什么的给拦截回去, 或者是需要找那个小弟的直接给带过去. Netflix Archaius 配置管理API, 包含一系列配置管理API, 提供动态类型化属性、线程安全配置操作、轮询框架、回调机制等功能. 可以实现动态获取配置, 原理是每隔60s（默认, 可配置）从配置源读取一次内容, 这样修改了配置文件后不需要重启服务就可以使修改后的内容生效, 前提使用archaius的API来读取. Spring Cloud Config俗称的配置中心, 配置管理工具包, 让你可以把配置放到远程服务器, 集中化管理集群配置, 目前支持本地存储、Git以及Subversion. 就是以后大家武器、枪火什么的东西都集中放到一起, 别随便自己带, 方便以后统一管理、升级装备. Spring Cloud Bus事件、消息总线, 用于在集群（例如, 配置变化事件）中传播状态变化, 可与Spring Cloud Config联合实现热部署. 相当于水浒传中日行八百里的神行太保戴宗, 确保各个小弟之间消息保持畅通. Spring Cloud for Cloud FoundryCloud Foundry是VMware推出的业界第一个开源PaaS云平台, 它支持多种框架、语言、运行时环境、云平台及应用服务, 使开发人员能够在几秒钟内进行应用程序的部署和扩展, 无需担心任何基础架构的问题 其实就是与CloudFoundry进行集成的一套解决方案, 抱了Cloud Foundry的大腿. Spring Cloud ClusterSpring Cloud Cluster将取代Spring Integration. 提供在分布式系统中的集群所需要的基础功能支持, 如: 选举、集群的状态一致性、全局锁、tokens等常见状态模式的抽象和实现. 如果把不同的帮派组织成统一的整体, Spring Cloud Cluster已经帮你提供了很多方便组织成统一的工具. Spring Cloud ConsulConsul 是一个支持多数据中心分布式高可用的服务发现和配置共享的服务软件,由 HashiCorp 公司用 Go 语言开发, 基于 Mozilla Public License 2.0 的协议进行开源. Consul 支持健康检查,并允许 HTTP 和 DNS 协议调用 API 存储键值对. Spring Cloud Consul 封装了Consul操作, consul是一个服务发现与配置工具, 与Docker容器可以无缝集成. 其它小弟Spring Cloud Security 基于spring security的安全工具包, 为你的应用程序添加安全控制. 这个小弟很牛鼻专门负责整个帮派的安全问题, 设置不同的门派访问特定的资源, 不能把秘籍葵花宝典泄漏了. Spring Cloud Sleuth 日志收集工具包, 封装了Dapper和log-based追踪以及Zipkin和HTrace操作, 为SpringCloud应用实现了一种分布式追踪解决方案. Spring Cloud Data Flow Data flow 是一个用于开发和执行大范围数据处理其模式包括ETL, 批量运算和持续运算的统一编程模型和托管服务. 对于在现代运行环境中可组合的微服务程序来说, Spring Cloud data flow是一个原生云可编配的服务. 使用Spring Cloud data flow, 开发者可以为像数据抽取, 实时分析, 和数据导入/导出这种常见用例创建和编配数据通道 （data pipelines）. Spring Cloud data flow 是基于原生云对 spring XD的重新设计, 该项目目标是简化大数据应用的开发. Spring XD 的流处理和批处理模块的重构分别是基于 Spring Boot的stream 和 task/batch 的微服务程序. 这些程序现在都是自动部署单元而且他们原生的支持像 Cloud Foundry、Apache YARN、Apache Mesos和Kubernetes 等现代运行环境. Spring Cloud data flow 为基于微服务的分布式流处理和批处理数据通道提供了一系列模型和最佳实践. Spring Cloud Stream Spring Cloud Stream是创建消息驱动微服务应用的框架. Spring Cloud Stream是基于Spring Boot创建, 用来建立单独的／工业级spring应用, 使用spring integration提供与消息代理之间的连接. 数据流操作开发包, 封装了与Redis,Rabbit、Kafka等发送接收消息. 一个业务会牵扯到多个任务, 任务之间是通过事件触发的, 这就是Spring Cloud stream要干的事了 Spring Cloud Task Spring Cloud Task 主要解决短命微服务的任务管理, 任务调度的工作, 比如说某些定时任务晚上就跑一次, 或者某项数据分析临时就跑几次. Spring Cloud Zookeeper ZooKeeper是一个分布式的, 开放源码的分布式应用程序协调服务, 是Google的Chubby一个开源的实现, 是Hadoop和Hbase的重要组件. 它是一个为分布式应用提供一致性服务的软件, 提供的功能包括: 配置维护、域名服务、分布式同步、组服务等. ZooKeeper的目标就是封装好复杂易出错的关键服务, 将简单易用的接口和性能高效、功能稳定的系统提供给用户. 操作Zookeeper的工具包, 用于使用zookeeper方式的服务发现和配置管理, 抱了Zookeeper的大腿. Spring Cloud Connectors Spring Cloud Connectors 简化了连接到服务的过程和从云平台获取操作的过程, 有很强的扩展性, 可以利用Spring Cloud Connectors来构建你自己的云平台. 便于云端应用程序在各种PaaS平台连接到后端, 如: 数据库和消息代理服务. Spring Cloud Starters Spring Boot式的启动项目, 为Spring Cloud提供开箱即用的依赖管理. Spring Cloud CLI 基于 Spring Boot CLI, 可以让你以命令行方式快速建立云组件. Demo基于事件驱动+事件溯源+Saga的微服务示例 一个微服务架构的在线购物网站（CQRS+Event Sourcing） spring-cloud-event-sourcing-example CQRS实现框架AxonFramework 溯源实现框架Eventuate Local]]></content>
      <categories>
        <category>Programming</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker可视化与管理工具]]></title>
    <url>%2F2018%2Fdocker-visual-management-and-orchestrate-tools%2F</url>
    <content type="text"><![CDATA[Preface 在学习了Docker的基本操作之后, 接下来就是Docker的管理部分了, 这包括Docker的可视化管理以及集群管理. 此篇主要记录Docker私有库的搭建, Docker编排工具的介绍以及使用, 可视化管理工具的介绍以及搭建… Docker Registry &amp; MirrorHarbor Harbor是一个用于存储和分发Docker镜像的企业级Registry服务器, 通过添加一些企业必需的功能特性, 例如安全、标识和管理等, 扩展了开源Docker Distribution. 作为一个企业级私有Registry服务器, Harbor提供了更好的性能和安全. 提升用户使用Registry构建和运行环境传输镜像的效率. Harbor支持安装在多个Registry节点的镜像资源复制, 镜像全部保存在私有Registry中, 确保数据和知识产权在公司内部网络中管控. 另外, Harbor也提供了高级的安全特性, 诸如用户管理, 访问控制和活动审计等. 基于角色的访问控制 - 用户与Docker镜像仓库通过“项目”进行组织管理, 一个用户可以对多个镜像仓库在同一命名空间（project）里有不同的权限. 镜像复制 - 镜像可以在多个Registry实例中复制（同步）. 尤其适合于负载均衡, 高可用, 混合云和多云的场景. 图形化用户界面 - 用户可以通过浏览器来浏览, 检索当前Docker镜像仓库, 管理项目和命名空间. AD/LDAP 支持 - Harbor可以集成企业内部已有的AD/LDAP, 用于鉴权认证管理. 审计管理 - 所有针对镜像仓库的操作都可以被记录追溯, 用于审计管理. 国际化 - 已拥有英文、中文、德文、日文和俄文的本地化版本. 更多的语言将会添加进来. RESTful API - RESTful API 提供给管理员对于Harbor更多的操控, 使得与其它管理软件集成变得更容易. 部署简单 - 提供在线和离线两种安装工具, 也可以安装到vSphere平台(OVA方式)虚拟设备. 集成clair进行镜像安全漏洞扫描 Harbor共由七个容器组成: a.harbor-adminserver:harbor系统管理服务 b.harbor-db: 由官方mysql镜像构成的数据库容器 c.harbor-jobservice:harbor的任务管理服务 d.harbor-log:harbor的日志收集、管理服务 e.harbor-ui:harbor的web页面服务 f.nginx:负责流量转发和安全验证 g.registry:官方的Docker registry, 负责保存镜像 Condition前置条件: 1.需要Python2.7或以上 2.Docker版本要在1.10或以上 3.Docker compose版本要在1.6.0或以上 DownloadRelease页面下载离线安装包（或在线也可以, 不过安装的时候很慢） Config解压缩之后, 目录下会生成harbor.conf文件, 该文件就是Harbor的配置文件. 123456789101112131415161718192021222324252627282930313233# 1. hostname设置访问地址, 可以使用ip、域名, 不可以设置为127.0.0.1或localhost# 2. 默认情况下, harbor使用的端口是80, 若使用自定义的端口, 除了要改docker-compose.yml文件中的配置外, # 这里的hostname也要加上自定义的端口, 在docker login、push时会报错# hostname = $&#123;IP_ADDR&#125;:$&#123;PORT&#125;hostname = 192.168.1.102:8888# 访问协议, 默认是http, 也可以设置https, 如果设置https, 则nginx ssl需要设置onui_url_protocol = http# mysql数据库root用户默认密码root123, 实际使用时修改下db_password = root123#Maximum number of job workers in job service max_job_workers = 3 #The path of secretkey storagesecretkey_path = /data# 启动Harbor后, 管理员UI登录的密码, 默认是Harbor12345# 若修改了此处的admin登录密码. 则登录后台时使用修改后的密码harbor_admin_password = Harbor12345# 认证方式, 这里支持多种认证方式, 如LADP、本次存储、数据库认证. 默认是db_auth, mysql数据库认证auth_mode = db_auth# 是否开启自注册self_registration = on# Token有效时间, 默认30分钟token_expiration = 30# 用户创建项目权限控制, 默认是everyone（所有人）, 也可以设置为adminonly（只能管理员）project_creation_restriction = everyone harbor默认监听80端口, 我们修改为8888端口, 同时docker-compose.yml也需要修改proxy的端口 还可以修改仓库的存储位置: Install运行安装脚本: 1./install.sh 集成clair漏洞扫描: 1./install.sh --with-clair 脚本会自动解压镜像文件并运行docker-compose 或者运行prepare文件再手动运行docker-compose 启动之后浏览器打开刚才修改的hostname 帐号密码默认是 admin/Harbor12345, 可在配置文件harbor.conf中修改 修改配置文件之后需要重新生成一些内置配置: 12./preparedocker-compose up -d 登录被refuse多次docker login被refuse 这是因为 Docker 默认不允许非 HTTPS 方式推送镜像. 我们可以通过 Docker 配置来取消这个限制, 或者配置能够通过 HTTPS 访问的私有仓库. 如果是systemd 的系统例如Ubuntu16.04+、Debian 8+、centos 7, 可以在/etc/docker/daemon.json 中写入如下内容: 1234&#123; &quot;registry-mirrors&quot;: [&quot;https://xxxxx.mirror.aliyuncs.com&quot;], &quot;insecure-registries&quot;: [&quot;192.168.1.102:8888&quot;]&#125; 然后重新加载Docker: 1sudo systemctl reload docker Login and Push1234docker login 192.168.1.102:8888 -u admin -p Harbor12345docker tag ubuntu:latest 192.168.1.102/library/ubuntu:latestdocker push 192.168.1.102/library/ubuntu:latest 注意: 使用docker stack deploy时, 如果是私有镜像, 需要终端登录后加上--with-registry-auth选项. 删除Harbor删除harbor, 但保留数据 1docker-compose down -v 删除harbor数据（对应docker-compose.yml里面的数据卷） 12rm -r /data/databaserm -r /data/registry 删除镜像 UI界面操作删除镜像, 只是删除元数据, 并未删除真实数据, 还需要调用registry的garbage-collect进行清理 1234567docker-compose stopdocker run -it --name gc --rm --volumes-from registry vmware/registry:2.6.2-photon garbage-collect --dry-run /etc/registry/config.yml #只是打印过程, 并不删除docker run -it --name gc --rm --volumes-from registry vmware/registry:2.6.2-photon garbage-collect /etc/registry/config.ymldocker-compose start 注意: 配置文件config.yml挂载在/etc/registry/下. 踩坑python版本在Ubuntu18.04中的python是3+版本的, 需要装回2.7版本, 不然会有不明异常. . . : 1sudo apt install python2.7 python-minimal -y Fail to generate key file这个貌似是openssl的问题, 解决方案是将prepare中的empty_subj = &quot;/C=/ST=/L=/O=/CN=/&quot;改为empty_subj = &quot;/&quot; Registry Mirrorregistry mirror原理 Docker Hub的镜像数据分为两部分: index数据和registry数据. 前者保存了镜像的一些元数据信息, 数据量很小；后者保存了镜像的实际数据, 数据量比较大. 平时我们使用docker pull命令拉取一个镜像时的过程是: 先去index获取镜像的一些元数据, 然后再去registry获取镜像数据. 所谓registry mirror就是搭建一个registry, 然后将docker hub的registry数据缓存到自己本地的registry. 整个过程是: 当我们使用docker pull去拉镜像的时候, 会先从我们本地的registry mirror去获取镜像数据, 如果不存在, registry mirror会先从docker hub的registry拉取数据进行缓存, 再传给我们. 而且整个过程是流式的, registry mirror并不会等全部缓存完再给我们传, 而且边缓存边给客户端传. 对于缓存, 我们都知道一致性非常重要. registry mirror与docker官方保持一致的方法是: registry mirror只是缓存了docker hub的registry数据, 并不缓存index数据. 所以我们pull镜像的时候会先连docker hub的index获取镜像的元数据, 如果我们registry mirror里面有该镜像的缓存, 且数据与从index处获取到的元数据一致, 则从registry mirror拉取；如果我们的registry mirror有该镜像的缓存, 但数据与index处获取的元数据不一致, 或者根本就没有该镜像的缓存, 则先从docker hub的registry缓存或者更新数据. 1、拉取镜像 1docker pull registry:latest 2、获取registry的默认配置 1docker run -it --rm --entrypoint cat registry:latest /etc/docker/registry/config.yml &gt; config.yml 内容可能如下: 123456789101112131415161718version: 0.1log: fields: service: registrystorage: cache: blobdescriptor: inmemory filesystem: rootdirectory: /var/lib/registryhttp: addr: :5000 headers: X-Content-Type-Options: [nosniff]health: storagedriver: enabled: true interval: 10s threshold: 3 我们在最后面加上如下配置: 1234proxy: remoteurl: https://registry-1.docker.io username: [username] password: [password] username和password是可选的, 如果配置了的话, 那registry mirror除了可以缓存所有的公共镜像外, 也可以访问这个用户所有的私有镜像. 启动registry容器: Bash 1docker run --restart=always -p 5000:5000 --name v2-mirror -v /data:/var/lib/registry -v $PWD/config.yml:/etc/registry/config.yml registry:latest /etc/registry/config.yml 当然我们也可以使用docker-compose启动: 12345678910111213version: &apos;3&apos;services: registry: image: library/registry:latest container_name: registry-mirror restart: always volumes: - /data:/var/lib/registry - ./config.yml:/etc/registry/config.yml ports: - 5000:5000 command: [&quot;serve&quot;, &quot;/etc/registry/config.yml&quot;] curl验证一下服务是否启动OK: 123456# ybd @ ybd-PC in ~ [17:30:14] $ curl -I http://192.168.6.113:5000HTTP/1.1 200 OKCache-Control: no-cacheDate: Fri, 05 Jan 2018 09:30:27 GMTContent-Type: text/plain; charset=utf-8 最后修改/etc/docker/daemon.json或/etc/default/docker中的registry-mirrors即可 Cluster and Orchestrate ToolsDocker Compose 官方文档: https://docs.docker.com/compose/ release: https://github.com/docker/compose/releases Compose是定义和运行多容器Docker应用程序的工具, 使用Compose, 您可以使用YAML文件来配置应用程序的服务, 然后, 使用单个命令创建并启动配置中的所有服务. Dockerfile 可以让用户管理一个单独的应用容器. 使用Docker Compose, 不再需要使用shell脚本来启动容器. 在配置文件中, 所有的容器通过services来定义, 然后使用docker-compose脚本来启动, 停止和重启应用, 和应用中的服务以及所有依赖服务的容器 Install最新安装请看官方文档: https://docs.docker.com/compose/install/#install-compose 1sudo curl -L https://github.com/docker/compose/releases/download/1.21.2/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose 变为可执行命令: 1sudo chmod +x /usr/local/bin/docker-compose 检查安装成功: 1docker-compose --version 卸载: 1sudo rm /usr/local/bin/docker-compose Command基本命令: -p 指定项目名称 build 构建项目中的服务容器 –force-rm 删除构建过程中的临时容器 --no-cache 构建过程中不使用 cache --pull 始终通过 pull 来获取更新版本的镜像 docker-compose kill 强制停止服务容器 docker-compose logs 查看容器的输出 调试必备 docker-compose pause 暂停一个服务容器 docker-compose unpause 恢复暂停 docker-compose port 打印某个容器端口所映射的公共端口 docker-compose ps 列出项目中目前的所有容器 -q 只打印容器 id docker-compose pull 拉取服务依赖的镜像 docker-compose restart -t 指定重启前停止容器的超时默认10秒 docker-compose rm 删除所有停止状态的容器先执行 stop docker-compose run 指定服务上执行一个命令 docker-compose start 启动已经存在的服务容器 docker-compose stop 停止已经存在的服务容器 docker-compose up 自动构建、创建服务、启动服务, 关联一系列, 运行在前台, ctrl c 就都停止运行. 如果容器已经存在, 将会尝试停止容器, 重新创建. 如果不希望重新创建, 可以 --no-recreate 就只启动处于停止状态的容器, 如果只想重新部署某个服务, 可以使用 docker-compose up --no-deps -d , 不影响其所依赖的服务 docker-compose up -d 后台启动运行, 生产环境必备 docker-compose down 停止并删除容器 Zsh命令补全12mkdir -p ~/.zsh/completioncurl -L https://raw.githubusercontent.com/docker/compose/$(docker-compose version --short)/contrib/completion/zsh/_docker-compose &gt; ~/.zsh/completion/_docker-compose 在.zshrc添加: 注意: (如果是oh-my-zsh, 在$ZSH/oh-my-zsh.sh中添加) 1fpath=(~/.zsh/completion $fpath) 执行: 1autoload -Uz compinit &amp;&amp; compinit -i 重载: 1exec $SHELL -l Compose 文件指令 最新参看文档: https://docs.docker.com/compose/compose-file/ 默认的模板文件名称为 docker-compose.yml, 格式为 YAML 格式. 12345678version: &quot;3&quot;services: webapp: image: examples/web ports: - &quot;80:80&quot; volumes: - &quot;/data&quot; 注意每个服务都必须通过 image 指令指定镜像或 build 指令（需要 Dockerfile）等来自动构建生成镜像. 如果使用 build 指令, 在 Dockerfile 中设置的选项(例如: CMD, EXPOSE, VOLUME, ENV 等) 将会自动被获取, 无需在 docker-compose.yml 中再次设置. 下面分别介绍各个指令的用法. build指定 Dockerfile 所在文件夹的路径（可以是绝对路径, 或者相对 docker-compose.yml 文件的路径）. Compose 将会利用它自动构建这个镜像, 然后使用这个镜像. 12345version: &apos;3&apos;services: webapp: build: ./dir 你也可以使用 context 指令指定 Dockerfile 所在文件夹的路径. 使用 dockerfile 指令指定 Dockerfile 文件名. 使用 arg 指令指定构建镜像时的变量. 123456789version: &apos;3&apos;services: webapp: build: context: ./dir dockerfile: Dockerfile-alternate args: buildno: 1 使用 cache_from 指定构建镜像的缓存 12345build: context: . cache_from: - alpine:latest - corp/web_app:3.14 cap_add, cap_drop指定容器的内核能力（capacity）分配. 例如, 让容器拥有所有能力可以指定为: 12cap_add: - ALL 去掉 NET_ADMIN 能力可以指定为: 12cap_drop: - NET_ADMIN command覆盖容器启动后默认执行的命令. 1command: echo &quot;hello world&quot; configs仅用于 Swarm mode, 详细内容请查看下面Swarm模式介绍 cgroup_parent指定父 cgroup 组, 意味着将继承该组的资源限制. 例如, 创建了一个 cgroup 组名称为 cgroups_1. 1cgroup_parent: cgroups_1 container_name指定容器名称. 默认将会使用 项目名称_服务名称_序号 这样的格式. 1container_name: docker-web-container 注意: 指定容器名称后, 该服务将无法进行扩展（scale）, 因为 Docker 不允许多个容器具有相同的名称. deploy仅用于 Swarm mode, 这是 V3 才能使用的语法, 通过docker-compose up方式启动会忽略这部分. 语法规则: 1234567deploy: replicas: 6 update_config: parallelism: 2 delay: 10s restart_policy: condition: on-failure mode首先 deploy 提供了一个模式选项, 它的值有 global 和 replicated 两个, 默认是 replicated 模式. 这两个模式的区别是: global: 每个集群每个服务实例启动一个容器, 就像以前启动 Service 时一样. replicated: 用户可以指定集群中实例的副本数量. 以前这个功能是无法在 Compose 中直接实现的, 以前需要用户先使用 docker-compose bundle 命令将 docker-compose.yml 转换为 .dab 文件, 然后才能拿到集群部署, 而且很多功能用不了. 但是随着这次更新把 stack 加进来了, deploy 也就水到渠成加进了 Compose 功能中. replicas上面说到可以指定副本数量, 其中 replicas 就是用于指定副本数量的选项. 12deploy: replicas: 6 部署服务栈: 1docker stack deploy --compose-file docker-compose.yml placement这是 Docker 1.12 版本时就引入的概念, 允许用户限制服务容器, 下面是官方的说明: node attribute matches example node.id Node ID node.id==2ivku8v2gvtg4 node.hostname Node hostname node.hostname!=node-2 node.role Node role node.role==manager node.labels user defined node labels node.labels.security==high engine.labels Docker Engine’s labels engine.labels.operatingsystem==ubuntu 14.04 1234567891011version: &apos;3&apos;services: db: image: postgres deploy: placement: constraints: - node.role == manager - engine.labels.operatingsystem == ubuntu 14.04 preferences: - spread: node.labels.zone update_config早在上一个版本中, Swarm 就提供了一个升级回滚的功能. 当服务升级出现故障时, 超过重试次数则停止升级的功能, 这也很方便, 避免让错误的应用替代现有正常服务. 这个选项用于告诉 Compose 使用怎样的方式升级, 以及升级失败后怎样回滚原来的服务. parallelism: 服务中多个容器同时更新. delay: 设置每组容器更新之间的延迟时间. failure_action: 设置更新失败时的动作, 可选值有 continue 与 pause (默认是: pause). monitor: 每次任务更新失败后监视故障的持续时间 (ns|us|ms|s|m|h) (默认: 0s). max_failure_ratio: 更新期间容忍的故障率. resources看例子: 1234567resources: limits: cpus: &apos;0.001&apos; memory: 50M reservations: cpus: &apos;0.0001&apos; memory: 20M 知道干啥用了吧, 这是一个新的语法选项, 替代了之前的类似 cpu_shares, cpu_quota, cpuset, mem_limit, memswap_limit 这种选项. 统一起来好看点. restart_policy设置如何重启容器, 毕竟有时候容器会意外退出. condition: 设置重启策略的条件, 可选值有 none, on-failure 和 any (默认: any). delay: 在重新启动尝试之间等待多长时间, 指定为持续时间（默认值: 0）. max_attempts: 设置最大的重启尝试次数, 默认是永不放弃, 哈哈, 感受到一股运维的绝望. window: 在决定重新启动是否成功之前要等待多长时间, 默认是立刻判断, 有些容器启动时间比较长, 指定一个“窗口期”非常重要. devices指定设备映射关系. 12devices: - &quot;/dev/ttyUSB1:/dev/ttyUSB0&quot; depends_on解决容器的依赖、启动先后的问题. 以下例子中会先启动 redis db 再启动 web 1234567891011121314version: &apos;3&apos;services: web: build: . depends_on: - db - redis redis: image: redis db: image: postgres 注意: web 服务不会等待 redis db 「完全启动」之后才启动. dns自定义 DNS 服务器. 可以是一个值, 也可以是一个列表. 12345dns: 8.8.8.8dns: - 8.8.8.8 - 114.114.114.114 dns_search配置 DNS 搜索域. 可以是一个值, 也可以是一个列表. 12345dns_search: example.comdns_search: - domain1.example.com - domain2.example.com tmpfs挂载一个 tmpfs 文件系统到容器. 1234tmpfs: /runtmpfs: - /run - /tmp env_file从文件中获取环境变量, 可以为单独的文件路径或列表, 默认读当前目录.env. 如果通过 docker-compose -f FILE 方式来指定 Compose 模板文件, 则 env_file 中变量的路径会基于模板文件路径. 如果有变量名称与 environment 指令冲突, 则按照惯例, 以后者为准. 123456env_file: .envenv_file: - ./common.env - ./apps/web.env - /opt/secrets.env 环境变量文件中每一行必须符合格式, 支持 # 开头的注释行. 12# common.env: Set development environmentPROG_ENV=development environment设置环境变量. 你可以使用数组或字典两种格式. 只给定名称的变量会自动获取运行 Compose 主机上对应变量的值, 可以用来防止泄露不必要的数据. 1234567environment: RACK_ENV: development SESSION_SECRET:environment: - RACK_ENV=development - SESSION_SECRET 如果变量名称或者值中用到 true|false, yes|no 等表达 布尔 含义的词汇, 最好放到引号里, 避免 YAML 自动解析某些内容为对应的布尔语义. 这些特定词汇, 包括 1y|Y|yes|Yes|YES|n|N|no|No|NO|true|True|TRUE|false|False|FALSE|on|On|ON|off|Off|OFF expose暴露端口, 但不映射到宿主机, 只被连接的服务访问. 仅可以指定内部端口为参数 123expose: - &quot;3000&quot; - &quot;8000&quot; external_links 注意: 不建议使用该指令. 链接到 docker-compose.yml 外部的容器, 甚至并非 Compose 管理的外部容器. 1234external_links: - redis_1 - project_db_1:mysql - project_db_1:postgresql extra_hosts类似 Docker 中的 --add-host 参数, 指定额外的 host 名称映射信息. 123extra_hosts: - &quot;googledns:8.8.8.8&quot; - &quot;dockerhub:52.1.157.61&quot; 会在启动后的服务容器中 /etc/hosts 文件中添加如下两条条目. 128.8.8.8 googledns52.1.157.61 dockerhub healthcheck通过命令检查容器是否健康运行. 12345healthcheck: test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;-f&quot;, &quot;http://localhost&quot;] interval: 1m30s timeout: 10s retries: 3 image指定为镜像名称或镜像 ID. 如果镜像在本地不存在, Compose 将会尝试拉去这个镜像. 123image: ubuntuimage: orchardup/postgresqlimage: a4bc65fd labels为容器添加 Docker 元数据（metadata）信息. 例如可以为容器添加辅助说明信息. 1234labels: com.startupteam.description: &quot;webapp for a startup team&quot; com.startupteam.department: &quot;devops department&quot; com.startupteam.release: &quot;rc3 for v1.0&quot; links 注意: 不推荐使用该指令. logging配置日志选项. 1234logging: driver: syslog options: syslog-address: &quot;tcp://192.168.0.42:123&quot; 目前支持三种日志驱动类型. 123driver: &quot;json-file&quot;driver: &quot;syslog&quot;driver: &quot;none&quot; options 配置日志驱动的相关参数. 123options: max-size: &quot;200k&quot; max-file: &quot;10&quot; 更多详情: https://docs.docker.com/engine/admin/logging/overview/ network_mode设置网络模式. 使用和 docker run 的 --network 参数一样的值. 12345network_mode: &quot;bridge&quot;network_mode: &quot;host&quot;network_mode: &quot;none&quot;network_mode: &quot;service:[service name]&quot;network_mode: &quot;container:[container name/id]&quot; networks配置容器连接的网络. 1234567891011version: &quot;3&quot;services: some-service: networks: - some-network - other-networknetworks: some-network: other-network: Docker 网络类型, 有 bridge overlay, 默认为bridge. 其中 overlay 网络类型用于 Swarm mode pid跟主机系统共享进程命名空间. 打开该选项的容器之间, 以及容器和宿主机系统之间可以通过进程 ID 来相互访问和操作. 1pid: &quot;host&quot; ports暴露端口信息. 使用宿主端口: 容器端口 (HOST:CONTAINER) 格式, 或者仅仅指定容器的端口（宿主将会随机选择端口）都可以. 12345ports: - &quot;3000&quot; - &quot;8000:8000&quot; - &quot;49100:22&quot; - &quot;127.0.0.1:8001:8001&quot; 注意: 当使用 HOST:CONTAINER 格式来映射端口时, 如果你使用的容器端口小于 60 并且没放到引号里, 可能会得到错误结果, 因为 YAML 会自动解析 xx:yy 这种数字格式为 60 进制. 为避免出现这种问题, 建议数字串都采用引号包括起来的字符串格式. secrets存储敏感数据, 例如 mysql 服务密码. 12345678910111213141516version: &quot;3&quot;services:mysql: image: mysql environment: MYSQL_ROOT_PASSWORD_FILE: /run/secrets/db_root_password secrets: - db_root_password - my_other_secretsecrets: my_secret: file: ./my_secret.txt my_other_secret: external: true security_opt指定容器模板标签（label）机制的默认属性（用户、角色、类型、级别等）. 例如配置标签的用户名和角色名. 123security_opt: - label:user:USER - label:role:ROLE stop_signal设置另一个信号来停止容器. 在默认情况下使用的是 SIGTERM 停止容器. 1stop_signal: SIGUSR1 sysctls配置容器内核参数. 1234567sysctls: net.core.somaxconn: 1024 net.ipv4.tcp_syncookies: 0sysctls: - net.core.somaxconn=1024 - net.ipv4.tcp_syncookies=0 ulimits指定容器的 ulimits 限制值. 例如, 指定最大进程数为 65535, 指定文件句柄数为 20000（软限制, 应用可以随时修改, 不能超过硬限制） 和 40000（系统硬限制, 只能 root 用户提高）. 12345ulimits: nproc: 65535 nofile: soft: 20000 hard: 40000 volumes数据卷所挂载路径设置. 可以设置宿主机路径 （HOST:CONTAINER） 或加上访问模式 （HOST:CONTAINER:ro）. 该指令中路径支持相对路径. 1234volumes: - /var/lib/mysql - cache/:/tmp/cache - ~/configs:/etc/configs/:ro 其它指令此外, 还有包括 domainname, entrypoint, hostname, ipc, mac_address, privileged, read_only, shm_size, restart, stdin_open, tty, user, working_dir 等指令, 基本跟 docker run 中对应参数的功能一致. 指定服务容器启动后执行的入口文件. 1entrypoint: /code/entrypoint.sh 指定容器中运行应用的用户名. 1user: nginx 指定容器中工作目录. 1working_dir: /code 指定容器中搜索域名、主机名、mac 地址等. 123domainname: your_website.comhostname: testmac_address: 08-00-27-00-0C-0A 允许容器中运行一些特权命令. 1privileged: true 指定容器退出后的重启策略为始终重启. 该命令对保持服务始终运行十分有效, 在生产环境中推荐配置为 always 或者 unless-stopped. 1restart: always 以只读模式挂载容器的 root 文件系统, 意味着不能对容器内容进行修改. 1read_only: true 打开标准输入, 可以接受外部输入. 1stdin_open: true 模拟一个伪终端. 1tty: true 读取变量Compose 模板文件支持动态读取主机的系统环境变量和当前目录下的 .env 文件中的变量. 例如, 下面的 Compose 文件将从运行它的环境中读取变量 ${MONGO_VERSION} 的值, 并写入执行的指令中. 12345version: &quot;3&quot;services:db: image: &quot;mongo:$&#123;MONGO_VERSION&#125;&quot; 如果执行 MONGO_VERSION=3.2 docker-compose up 则会启动一个 mongo:3.2 镜像的容器；如果执行 MONGO_VERSION=2.8 docker-compose up 则会启动一个 mongo:2.8 镜像的容器. 若当前目录存在 .env 文件, 执行 docker-compose 命令时将从该文件中读取变量. 在当前目录新建 .env 文件并写入以下内容. 12# 支持 # 号注释MONGO_VERSION=3.6 执行 docker-compose up 则会启动一个 mongo:3.6 镜像的容器. 官方例子: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889version: &quot;3&quot;services: redis: image: redis:alpine ports: - &quot;6379&quot; networks: - frontend deploy: replicas: 2 update_config: parallelism: 2 delay: 10s restart_policy: condition: on-failure db: image: postgres:9.4 volumes: - db-data:/var/lib/postgresql/data networks: - backend deploy: placement: constraints: [node.role == manager] vote: image: dockersamples/examplevotingapp_vote:before ports: - 5000:80 networks: - frontend depends_on: - redis deploy: replicas: 2 update_config: parallelism: 2 restart_policy: condition: on-failure result: image: dockersamples/examplevotingapp_result:before ports: - 5001:80 networks: - backend depends_on: - db deploy: replicas: 1 update_config: parallelism: 2 delay: 10s restart_policy: condition: on-failure worker: image: dockersamples/examplevotingapp_worker networks: - frontend - backend deploy: mode: replicated replicas: 1 labels: [APP=VOTING] restart_policy: condition: on-failure delay: 10s max_attempts: 3 window: 120s placement: constraints: [node.role == manager] visualizer: image: dockersamples/visualizer:stable ports: - &quot;8080:8080&quot; stop_grace_period: 1m30s volumes: - &quot;/var/run/docker.sock:/var/run/docker.sock&quot; deploy: placement: constraints: [node.role == manager]networks: frontend: backend:volumes: db-data: 理解多compose文件组合默认, compose会读取两个文件, 一个docker-compose.yml和一个可选的docker-compose.override.yml文件. 通常, docker-compose.yml文件包含你的基本配置, 而docker-compose.override.yml, 顾名思义, 就是包含的现有服务配置的覆盖内容, 或完全新的配置. 如果一个服务在这两个文件中都有定义, 那么compose将使用添加和覆盖配置中所描述的规则来合并服务 要使用多个override文件或不同名称的override文件, 可以使用-f选项来指定文件列表. compose根据在命令行指定的顺序来合并它们. 当使用多个配置文件时, 必须确保文件中所有的路径都是相对于base compose文件的(-f 指定的第一个compose文件). 这样要求是因为override文件不需要一个有效的compose文件. override文件可以只包含配置中的一小片段. 跟踪一个服务的片段是相对于那个路径的, 这是很困难的事, 所以一定要保持路径容易理解, 所以路径必须定义为相对于base文件的路径. 例如, 定义两个配置文件: docker-compose.yml 1234567891011web: image: example/my_web_app:latest links: - db - cachedb: image: postgres:latestcache: image: redis:latest docker-compose.prod.yml 123456789web: ports: - 80:80 environment: PRODUCTION: &apos;true&apos;cache: environment: TTL: &apos;500&apos; 要使用这个生产compose文件部署, 运行如下命令: 1docker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d 这将会使用docker-compose.yml和docker-compose.prod.yml来部署这三个服务 Docker Machine Docker Machine 是供给和管理 docker 化主机的工具. 有自己的命令行客户端 docker-machine. 提供多种环境的 docker 主机, 可以用 Docker Machine 在一个或者多个虚拟系统（本地或者远程）上安装 Docker Engine. Install最新安装请看官方文档: https://docs.docker.com/machine/install-machine/ 123base=https://github.com/docker/machine/releases/download/v0.14.0 &amp;&amp; \curl -L $base/docker-machine-$(uname -s)-$(uname -m) &gt;/tmp/docker-machine &amp;&amp; \sudo install /tmp/docker-machine /usr/local/bin/docker-machine uninstall: 1sudo rm $(which docker-machine) Zsh命令补全12mkdir -p ~/.zsh/completioncurl -L https://raw.githubusercontent.com/docker/machine/master/contrib/completion/zsh/_docker-machine &gt; ~/.zsh/completion/_docker-machine 在~/.zshrc添加: 注意: (如果是oh-my-zsh, 在$ZSH/oh-my-zsh.sh中添加) 1fpath=(~/.zsh/completion $fpath) 执行: 123autoload -Uz compinit &amp;&amp; \compinit -i &amp;&amp; \exec $SHELL -l Usage确保已经安装了virtualbox: 1sudo apt install virtualbox 创建本地实例: 使用 virtualbox 类型的驱动, 创建一台 Docker 主机, 命名为 test. 1docker-machine create -d virtualbox test 你也可以在创建时加上如下参数, 来配置主机或者主机上的 Docker. --engine-opt dns=114.114.114.114 配置 Docker 的默认 DNS --engine-registry-mirror https://registry.docker-cn.com 配置 Docker 的仓库镜像 --engine-insecure-registry 可以使用http的仓库 --virtualbox-memory 2048 配置主机内存 --virtualbox-cpu-count 2 配置主机 CPU 更多参数请使用 docker-machine create --driver virtualbox --help 命令查看. 12345678910111213141516171819202122232425262728293031323334353637$ docker-machine create --driver virtualbox --helpUsage: docker-machine create [OPTIONS] [arg...]Create a machine.Run &apos;docker-machine create --driver name&apos; to include the create flags for that driver in the help text.Options: --driver, -d &quot;none&quot; Driver to create machine with. --engine-env [--engine-env option --engine-env option] Specify environment variables to set in the engine --engine-insecure-registry [--engine-insecure-registry option --engine-insecure-registry option] Specify insecure registries to allow with the created engine --engine-install-url &quot;https://get.docker.com&quot; Custom URL to use for engine installation [$MACHINE_DOCKER_INSTALL_URL] --engine-label [--engine-label option --engine-label option] Specify labels for the created engine --engine-opt [--engine-opt option --engine-opt option] Specify arbitrary flags to include with the created engine in the form flag=value --engine-registry-mirror [--engine-registry-mirror option --engine-registry-mirror option] Specify registry mirrors to use [$ENGINE_REGISTRY_MIRROR] --engine-storage-driver Specify a storage driver to use with the engine --swarm Configure Machine with Swarm --swarm-addr addr to advertise for Swarm (default: detect and use the machine IP) --swarm-discovery Discovery service to use with Swarm --swarm-experimental Enable Swarm experimental features --swarm-host &quot;tcp://0.0.0.0:3376&quot; ip/socket to listen on for Swarm master --swarm-image &quot;swarm:latest&quot; Specify Docker image to use for Swarm [$MACHINE_SWARM_IMAGE] --swarm-master Configure Machine to be a Swarm master --swarm-opt [--swarm-opt option --swarm-opt option] Define arbitrary flags for swarm --swarm-strategy &quot;spread&quot; Define a default scheduling strategy for Swarm --virtualbox-boot2docker-url The URL of the boot2docker image. Defaults to the latest available version [$VIRTUALBOX_BOOT2DOCKER_URL] --virtualbox-cpu-count &quot;1&quot; number of CPUs for the machine (-1 to use the number of CPUs available) [$VIRTUALBOX_CPU_COUNT] --virtualbox-disk-size &quot;20000&quot; Size of disk for host in MB [$VIRTUALBOX_DISK_SIZE] --virtualbox-host-dns-resolver Use the host DNS resolver [$VIRTUALBOX_HOST_DNS_RESOLVER] --virtualbox-dns-proxy Proxy all DNS requests to the host [$VIRTUALBOX_DNS_PROXY] --virtualbox-hostonly-cidr &quot;192.168.99.1/24&quot; Specify the Host Only CIDR [$VIRTUALBOX_HOSTONLY_CIDR] --virtualbox-hostonly-nicpromisc &quot;deny&quot; Specify the Host Only Network Adapter Promiscuous Mode [$VIRTUALBOX_HOSTONLY_NIC_PROMISC] --virtualbox-hostonly-nictype &quot;82540EM&quot; Specify the Host Only Network Adapter Type [$VIRTUALBOX_HOSTONLY_NIC_TYPE] --virtualbox-import-boot2docker-vm The name of a Boot2Docker VM to import --virtualbox-memory &quot;1024&quot; Size of memory for host in MB [$VIRTUALBOX_MEMORY_SIZE] --virtualbox-no-share Disable the mount of your home directory 创建好主机之后, 查看主机 1234docker-machine lsNAME ACTIVE DRIVER STATE URL SWARM DOCKER ERRORStest - virtualbox Running tcp://192.168.99.187:2376 v17.10.0-ce 创建主机成功后, 可以通过 env 命令来让后续操作对象都是目标主机. 1docker-machine env test 后续根据提示在命令行输入命令之后就可以操作 test 主机. 通过以下命令恢复当前环境: 1docker-machine env -u 也可以通过 SSH 登录到主机. 1docker-machine ssh test 连接到主机之后你就可以在其上使用 Docker 了. 操作命令 active 查看活跃的 Docker 主机 config 输出连接的配置信息 create 创建一个 Docker 主机 env 显示连接到某个主机需要的环境变量 inspect 输出主机更多信息 ip 获取主机地址 kill 停止某个主机 ls 列出所有管理的主机 provision 重新设置一个已存在的主机 regenerate-certs 为某个主机重新生成 TLS 认证信息 restart 重启主机 rm 删除某台主机 ssh SSH 到主机上执行命令 scp 在主机之间复制文件 mount 挂载主机目录到本地 start 启动一个主机 status 查看主机状态 stop 停止一个主机 upgrade 更新主机 Docker 版本为最新 url 获取主机的 URL version 输出 docker-machine 版本信息 help 输出帮助信息 每个命令, 又带有不同的参数, 可以通过 1$ docker-machine COMMAND --help 来查看具体的用法. 注意: docker-machine 安装的 Docker 在 /etc/systemd/system 目录下多出了一个 Docker 相关的目录: docker.service.d. 这个目录中只有一个文件 10-machine.conf, 这个配置文件至关重要, 因为它会覆盖 Docker 默认安装时的配置文件, 从而以 Docker Machine 指定的方式启动 Docker daemon. 至此我们有了一个可以被远程访问的 Docker daemon. 使用KVM引擎启动https://github.com/dhiltgen/docker-machine-kvm 首先确保安装了KVM: 1sudo apt install libvirt-bin qemu-kvm 到 Release 页面下载相关驱动. Ubuntu 16.04: 1sudo curl -L https://github.com/dhiltgen/docker-machine-kvm/releases/download/v0.10.0/docker-machine-driver-kvm-ubuntu16.04 &gt; /usr/local/bin/docker-machine-driver-kvm &amp;&amp; sudo chmod +x /usr/local/bin/docker-machine-driver-kvm 最后启动: 1docker-machine create -d kvm --engine-registry-mirror=https://vioqnt8w.mirror.aliyuncs.com --engine-insecure-registry=192.168.122.213 test01 Swarm Mode Docker 1.12 Swarm mode 已经内嵌入 Docker 引擎, 成为了 docker 子命令 docker swarm. 请注意与旧的 Docker Swarm 区分开来. Swarm mode 内置 kv 存储功能, 提供了众多的新特性, 比如: 具有容错能力的去中心化设计、内置服务发现、负载均衡、路由网格、动态伸缩、滚动更新、安全传输等. 使得 Docker 原生的 Swarm 集群具备与 Mesos、Kubernetes 竞争的实力. 功能特点与Docker Engine集成的集群管理使用Docker Engine CLI创建一组Docker引擎, 您可以在其中部署应用程序服务. 您不需要其他编排软件来创建或管理群集. 节点分散式设计Docker Engine不是在部署时处理节点角色之间的差异, 而是在运行时处理角色变化. 您可以使用Docker Engine部署两种类型的节点, 管理节点和工作节点. 这意味着您可以从单个服务器构建整个群集. 声明性服务模型Docker Engine使用声明性方法来定义应用程序堆栈中各种服务的所需状态. 例如, 您可以描述由具有消息队列服务和数据库后端的Web前端服务组成的应用程序. 可扩容与缩放容器对于每个服务, 您可以声明要运行的任务数. 当您向上或向下缩放时, swarm管理器通过添加或删除任务来自动适应, 以保持所需的任务数量来保证集群的可靠状态. 容器容错状态协调群集管理器节点不断监视群集状态, 并协调您表示的期望状态的实际状态之间的任何差异. 例如, 如果设置一个服务以运行容器的10个副本, 并且托管其中两个副本的工作程序计算机崩溃, 则管理器将创建两个新副本以替换崩溃的副本. swarm管理器将新副本分配给正在运行和可用的worker节点上. 多主机网络您可以为服务指定覆盖网络. 当swarm管理器初始化或更新应用程序时, 它会自动为覆盖网络上的容器分配地址. 服务发现Swarm管理器节点为swarm中的每个服务分配唯一的DNS名称, 并负载平衡运行的容器. 您可以通过嵌入在swarm中的DNS服务器查询在群中运行的每个容器. 负载平衡您可以将服务的端口公开给外部负载平衡器. 在内部, swarm允许您指定如何在节点之间分发服务容器. 缺省安全群中的每个节点强制执行TLS相互验证和加密, 以保护其自身与所有其他节点之间的通信. 您可以选择使用自签名根证书或来自自定义根CA的证书. 滚动更新在已经运行期间, 您可以增量地应用服务更新到节点. swarm管理器允许您控制将服务部署到不同节点集之间的延迟. 如果出现任何问题, 您可以将任务回滚到服务的先前版本. 概念节点运行 Docker 的主机可以主动初始化一个 Swarm 集群或者加入一个已存在的 Swarm 集群, 这样这个运行 Docker 的主机就成为一个 Swarm 集群的节点 (node) . 节点分为管理 (manager) 节点和工作 (worker) 节点. 管理节点用于 Swarm 集群的管理, docker swarm 命令基本只能在管理节点执行（节点退出集群命令 docker swarm leave 可以在工作节点执行）. 一个 Swarm 集群可以有多个管理节点, 但只有一个管理节点可以成为 leader, leader 通过 raft 协议实现. 工作节点是任务执行节点, 管理节点将服务 (service) 下发至工作节点执行. 管理节点默认也作为工作节点. 你也可以通过配置让服务只运行在管理节点. 服务和任务任务 （Task）是 Swarm 中的最小的调度单位, 目前来说就是一个单一的容器. 服务 （Services） 是指一组任务的集合, 服务定义了任务的属性. 服务有两种模式: replicated services 按照一定规则在各个工作节点上运行指定个数的任务. global services 每个工作节点上运行一个任务 两种模式通过 docker service create 的 --mode 参数指定. 下图解释服务、任务、容器: 服务的任务及调试说明: 服务部署的复制模式和全局模式说明: 创建集群在创建集群前, 如果开启了防火墙, 请确认三台主机的防火墙能让swarm需求的端口开放, 需要打开主机之间的端口, 以下端口必须可用. 在某些系统上, 这些端口默认为打开.2377: TCP端口2377用于集群管理通信7946: TCP和UDP端口7946用于节点之间的通信4789: TCP和UDP端口4789用于覆盖网络流量如果您计划使用加密（–opt加密）创建覆盖网络, 则还需要确保协议50（ESP）已打开. docker swarm命令: 1234567891011121314151617181920212223242526272829303132docker swarm init --advertise-addr 172.18.60.133#恢复docker swarm init --advertise-addr 172.18.60.133 --force-new-cluster#其它节点加入docker swarm join --token \ SWMTKN-1-44gjumnutrh4k9lls54f5hp43kiioxf16iuh7qarjfqjsu7jio-2326b8ikb1xiysm3i7neh9nho 172.18.60.133:2377 #输出可以用来以worker角色加入的tokendocker swarm join-token worker#输出可以用来以manager角色加入的tokendocker swarm join-token manager#manager节点强制脱离docker swarm leave --force#worker节点脱离docker swarm leave#节点从swarm中移除docker node rm XXXXX#worker节点提升为managerdocker node promote ilog2#恢复为workerdocker node demote &lt;NODE&gt;#创建服务docker service create --replicas 3 --name helloworld alpine ping docker.com 节点管理查看集群中的docker信息1docker -H 10.0.11.150:2376 info 列出节点1docker node ls 说明:AVAILABILITY列:显示调度程序是否可以将任务分配给节点: Active 意味着调度程序可以将任务分配给节点. Pause 意味着调度程序不会将新任务分配给节点, 但现有任务仍在运行. Drain 意味着调度程序不会向节点分配新任务. 调度程序关闭所有现有任务并在可用节点上调度它们. MANAGER STATUS列显示节点是属于manager或者worker 没有值 表示不参与群管理的工作节点. Leader 意味着该节点是使得群的所有群管理和编排决策的主要管理器节点. Reachable 意味着节点是管理者节点正在参与Raft共识. 如果领导节点不可用, 则该节点有资格被选为新领导者. Unavailable 意味着节点是不能与其他管理器通信的管理器. 如果管理器节点不可用, 您应该将新的管理器节点加入群集, 或者将工作器节点升级为管理器. 查看节点的详细信息您可以在管理器节点上运行docker node inspect来查看单个节点的详细信息. 输出默认为JSON格式, 但您可以传递–pretty标志以以可读的yml格式打印结果 12345678910111213141516171819202122232425262728293031323334353637# ybd @ ybd-PC in ~ [9:37:23] $ docker node inspect --pretty ybd-machine1 ID: f917bibevklfp3xjsjoyx2g2tHostname: ybd-machine1Joined at: 2018-01-03 10:00:28.499769713 +0000 utcStatus: State: Ready Availability: Active Address: 192.168.6.113Platform: Operating System: linux Architecture: x86_64Resources: CPUs: 1 Memory: 995.9MiBPlugins: Log: awslogs, fluentd, gcplogs, gelf, journald, json-file, logentries, splunk, syslog Network: bridge, host, macvlan, null, overlay Volume: localEngine Version: 17.12.0-ceEngine Labels: - provider=virtualboxTLS Info: TrustRoot:-----BEGIN CERTIFICATE-----MIIBajCCARCgAwIBAgIUTdhfszkLcL0IC92X4TaOWbQlbZAwCgYIKoZIzj0EAwIwEzERMA8GA1UEAxMIc3dhcm0tY2EwHhcNMTcxMjIyMDg0NzAwWhcNMzcxMjE3MDg0NzAwWjATMREwDwYDVQQDEwhzd2FybS1jYTBZMBMGByqGSM49AgEGCCqGSM49AwEHA0IABEWabJlpAGjNi6x8QWGXnMUFwPe27anM5nHwLX8y05TbgamYvV7Is4CZ1BbUypJ/a9FpSp4FbV/6iYveIwwaHLSjQjBAMA4GA1UdDwEB/wQEAwIBBjAPBgNVHRMBAf8EBTADAQH/MB0GA1UdDgQWBBR1K7f/HuhGDD2gzDeejaH2r8ZxIzAKBggqhkjOPQQDAgNIADBFAiEApL0o/FwwzLrhalYddR+buFHg0Hg3jKh37t00TmMU7SICIAOzYZNcngOkQiY2K2poQqRw+dFU9xOk543G+zDHqX4h-----END CERTIFICATE----- Issuer Subject: MBMxETAPBgNVBAMTCHN3YXJtLWNh Issuer Public Key: MFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAERZpsmWkAaM2LrHxBYZecxQXA97btqczmcfAtfzLTlNuBqZi9XsizgJnUFtTKkn9r0WlKngVtX/qJi94jDBoctA== 更新节点Usage: docker node update [OPTIONS] NODE Options: –availability string Availability of the node (“active”|”pause”|”drain”) –label-add list Add or update a node label (key=value) –label-rm list Remove a node label if exists –role string Role of the node (“worker”|”manager”) 升级或降级节点您可以将工作程序节点提升为manager角色. 这在管理器节点不可用或者您希望使管理器脱机以进行维护时很有用. 类似地, 您可以将管理器节点降级为worker角色.无论您升级或降级节点, 您应该始终在群中维护奇数个管理器节点.要升级一个节点或一组节点, 请从管理器节点运行: 12docker node promote [NODE]docker node domote [NODE] 退出docker swarm集群work节点: 1docker swarm leave manager节点: 1docker swarm leave -f 可视化visualizer服务123456docker service create \--name=viz \--publish=8088:8080/tcp \--constraint=node.role==manager \--mount=type=bind,src=/var/run/docker.sock,dst=/var/run/docker.sock \dockersamples/visualizer Service用法12345678910111213141516171819202122232425262728创建服务docker service create \--image nginx \--replicas 2 \nginx 更新服务docker service update \--image nginx:alpine \nginx 删除服务docker service rm nginx 减少服务实例(这比直接删除服务要好)docker service scale nginx=0 增加服务实例docker service scale nginx=5 查看所有服务docker service ls 查看服务的容器状态docker service ps nginx 查看服务的详细信息. docker service inspect nginx 实现零宕机部署也非常简单. 这样也可以方便地实现持续部署: 12345678构建新镜像docker build -t hub.docker.com/image . 将新镜像上传到Docker仓库docker push hub.docker.com/image 更新服务的镜像docker service update --image hub.docker.com/image service 更新服务要慎重. 你的容器同时运行在多个主机上. 更新服务时, 只需要更新Docker镜像. 合理的测试和部署流程是保证成功的关键. Swarm非常容易入门. 分布式系统通常是非常复杂的. 与其他容器集群系统(Mesos, Kubernetes)相比, Swarm的学习曲线最低. Docker Visual ManagementRancher官方网站 如果是对集群管理并且管理员只限制Docker命令权限的话, 建议用这个工具, 商店用起来都比较方便, 优点: 界面中文化, 操作简单易懂,功能强大,容灾机制. 缺点: 不能团队分配权限, 容器操作权限太大没法满足需求, 部署时相应的Docker 服务也很多, 需要逐一去了解容器作用. Shipyard官方网站 Shipyard是在Docker Swarm的基础上, 管理Docker资源, 包括容器, 镜像, 注册表等. 优点: 支持镜像管理、容器管理. 支持控制台命令 容器资源消耗监控 支持集群swarm, 可以随意增加节点 支持控制用户管理权限, 可以设置某个容器对某个用户只读、管理权限. 有汉化版 缺点 : 启动容器较多, 占用每个节点的一部分资源 部署: 1curl -sSL https://shipyard-project.com/deploy | bash -s 注意: 这将在端口2375上暴露Docker Engine. 如果此节点可以在安全网络之外访问, 建议使用TLS. 支持集群, 所以可以添加节点: 1curl -sSL https://shipyard-project.com/deploy | ACTION=node DISCOVERY=etcd://10.0.0.10:4001 bash -s 它会下载并启动7个镜像: 界面: 容器信息: 初体验来说, 感觉跟下面的Portainer功能差不多, 但是Registry总是添加失败 Portainer官方网站 Portainer是Docker的图形化管理工具, 提供状态显示面板、应用模板快速部署、容器镜像网络数据卷的基本操作（包括上传下载镜像, 创建容器等操作）、事件日志显示、容器控制台操作、Swarm集群和服务等集中管理和操作、登录用户管理和控制等功能. 功能十分全面, 基本能满足中小型单位对容器管理的全部需求. 优点 支持容器管理、镜像管理 轻量级, 消耗资源少 基于docker api, 安全性高, 可指定docker api端口, 支持TLS证书认证. 支持权限分配 支持集群 缺点 功能不够强大. 容器创建后, 无法通过后台增加端口. 没有容灾机制 单机启动: 12345docker run -d -p 9000:9000 \--name portainer \--restart=always \-v /var/run/docker.sock:/var/run/docker.sock \portainer/portainer swarm模式启动: 12345678docker service create \--name portainer \--publish 9000:9000 \--constraint &apos;node.role == manager&apos; \--mount type=bind,src=/var/run/docker.sock,dst=/var/run/docker.sock \--mount type=bind,src=/path/on/host/data,dst=/data \portainer/portainer \-H unix:///var/run/docker.sock 容器管理: 镜像管理: 镜像仓库: Endpoints: 注意: 添加Endpoints先要暴露节点的2375端口. Finally 参考: Docker — 从入门到实践 在生产环境中使用Docker Swarm的一些建议 使用Docker Harbor搭建私有镜像服务器和Mirror服务器 远程连接docker daemon, Docker Remote API]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>Swarm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用 Reactor 进行反应式编程]]></title>
    <url>%2F2017%2Fwith-reactor-response-encode%2F</url>
    <content type="text"><![CDATA[Preface 反应式编程（Reactive Programming）这种新的编程范式越来越受到开发人员的欢迎. 在 Java 社区中比较流行的是 RxJava 和 RxJava 2. 本篇要介绍的是另外一个新的反应式编程库 Reactor.Reactor 框架是 Pivotal 公司（开发 Spring 等技术的公司）开发的, 实现了 Reactive Programming 思想, 符合 Reactive Streams 规范（Reactive Streams 是由 Netflix、TypeSafe、Pivotal 等公司发起的）的一项技术. 其名字有反应堆之意, 反映了其背后的强大的性能. 反应式编程介绍反应式编程来源于数据流和变化的传播, 意味着由底层的执行模型负责通过数据流来自动传播变化. 比如求值一个简单的表达式 c=a+b, 当 a 或者 b 的值发生变化时, 传统的编程范式需要对 a+b 进行重新计算来得到 c 的值. 如果使用反应式编程, 当 a 或者 b 的值发生变化时, c 的值会自动更新. 反应式编程最早由 .NET 平台上的 Reactive Extensions (Rx) 库来实现. 后来迁移到 Java 平台之后就产生了著名的 RxJava 库, 并产生了很多其他编程语言上的对应实现. 在这些实现的基础上产生了后来的反应式流（Reactive Streams）规范. 该规范定义了反应式流的相关接口, 并将集成到 Java 9 中. 在传统的编程范式中, 我们一般通过迭代器（Iterator）模式来遍历一个序列. 这种遍历方式是由调用者来控制节奏的, 采用的是拉的方式. 每次由调用者通过 next()方法来获取序列中的下一个值. 使用反应式流时采用的则是推的方式, 即常见的发布者-订阅者模式. 当发布者有新的数据产生时, 这些数据会被推送到订阅者来进行处理. 在反应式流上可以添加各种不同的操作来对数据进行处理, 形成数据处理链. 这个以声明式的方式添加的处理链只在订阅者进行订阅操作时才会真正执行. 反应式流中第一个重要概念是负压（backpressure）. 在基本的消息推送模式中, 当消息发布者产生数据的速度过快时, 会使得消息订阅者的处理速度无法跟上产生的速度, 从而给订阅者造成很大的压力. 当压力过大时, 有可能造成订阅者本身的奔溃, 所产生的级联效应甚至可能造成整个系统的瘫痪. 负压的作用在于提供一种从订阅者到生产者的反馈渠道. 订阅者可以通过 request()方法来声明其一次所能处理的消息数量, 而生产者就只会产生相应数量的消息, 直到下一次 request()方法调用. 这实际上变成了推拉结合的模式. Reactor 简介前面提到的 RxJava 库是 JVM 上反应式编程的先驱, 也是反应式流规范的基础. RxJava 2 在 RxJava 的基础上做了很多的更新. 不过 RxJava 库也有其不足的地方. RxJava 产生于反应式流规范之前, 虽然可以和反应式流的接口进行转换, 但是由于底层实现的原因, 使用起来并不是很直观. RxJava 2 在设计和实现时考虑到了与规范的整合, 不过为了保持与 RxJava 的兼容性, 很多地方在使用时也并不直观. Reactor 则是完全基于反应式流规范设计和实现的库, 没有 RxJava 那样的历史包袱, 在使用上更加的直观易懂. Reactor 也是 Spring 5 中反应式编程的基础. 学习和掌握 Reactor 可以更好地理解 Spring 5 中的相关概念. 在 Java 程序中使用 Reactor 库非常的简单, 只需要通过 Maven 或 Gradle 来添加对 io.projectreactor:reactor-core 的依赖即可, 目前的版本是 3.1.2.RELEASE: 1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;io.projectreactor&lt;/groupId&gt; &lt;artifactId&gt;reactor-core&lt;/artifactId&gt; &lt;version&gt;3.1.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; Flux 和 MonoFlux 和 Mono 是 Reactor 中的两个基本概念. Flux 表示的是包含 0 到 N 个元素的异步序列. 在该序列中可以包含三种不同类型的消息通知: 正常的包含元素的消息、序列结束的消息和序列出错的消息. 当消息通知产生时, 订阅者中对应的方法 onNext(), onComplete()和 onError()会被调用. Mono 表示的是包含 0 或者 1 个元素的异步序列. 该序列中同样可以包含与 Flux 相同的三种类型的消息通知. Flux 和 Mono 之间可以进行转换. 对一个 Flux 序列进行计数操作, 得到的结果是一个 Mono&lt;Long&gt;对象. 把两个 Mono 序列合并在一起, 得到的是一个 Flux 对象. 创建 Flux有多种不同的方式可以创建 Flux 序列. Flux 类的静态方法第一种方式是通过 Flux 类中的静态方法. just(): 可以指定序列中包含的全部元素. 创建出来的 Flux 序列在发布这些元素之后会自动结束. fromArray(), fromIterable()和 fromStream(): 可以从一个数组、Iterable 对象或 Stream 对象中创建 Flux 对象. empty(): 创建一个不包含任何元素, 只发布结束消息的序列. error(Throwable error): 创建一个只包含错误消息的序列. never(): 创建一个不包含任何消息通知的序列. range(int start, int count): 创建包含从 start 起始的 count 个数量的 Integer 对象的序列. interval(Duration period)和 interval(Duration delay, Duration period): 创建一个包含了从 0 开始递增的 Long 对象的序列. 其中包含的元素按照指定的间隔来发布. 除了间隔时间之外, 还可以指定起始元素发布之前的延迟时间. 代码清单 1 中给出了上述这些方法的使用示例. 清单 1. 通过 Flux 类的静态方法创建 Flux 序列 12345678910111213141516public static void main(String[] args) throws InterruptedException &#123; generateSimpleFlux();&#125;private static void generateSimpleFlux() throws InterruptedException &#123; Flux.just(&quot;Hello&quot;, &quot;World&quot;).subscribe(System.out::println); Integer[] array = &#123;1, 2, 3&#125;; Flux.fromArray(array).subscribe(System.out::println); Flux.fromStream(Stream.of(array)).subscribe(System.out::println); Flux.fromIterable(Arrays.asList(array)).subscribe(System.out::println); Flux.empty().subscribe(System.out::println); Flux.range(1, 10).subscribe(System.out::println); Flux.interval(Duration.ofSeconds(1)).subscribe(System.out::println); // Flux.interval(Duration.of(1, ChronoUnit.SECONDS)).subscribe(System.out::println); TimeUnit.SECONDS.sleep(5);&#125; 上面的这些静态方法适合于简单的序列生成, 当序列的生成需要复杂的逻辑时, 则应该使用 generate() 或 create() 方法. generate()方法generate()方法通过同步和逐一的方式来产生 Flux 序列. 序列的产生是通过调用所提供的 SynchronousSink 对象的 next(), complete()和 error(Throwable)方法来完成的. 逐一生成的含义是在具体的生成逻辑中, next()方法只能最多被调用一次. 在有些情况下, 序列的生成可能是有状态的, 需要用到某些状态对象. 此时可以使用 generate()方法的另外一种形式 generate(Callable&lt;S&gt; stateSupplier, BiFunction&lt;S,SynchronousSink&lt;T&gt;,S&gt; generator), 其中 stateSupplier 用来提供初始的状态对象. 在进行序列生成时, 状态对象会作为 generator 使用的第一个参数传入, 可以在对应的逻辑中对该状态对象进行修改以供下一次生成时使用. 在代码清单 2中, 第一个序列的生成逻辑中通过 next()方法产生一个简单的值, 然后通过 complete()方法来结束该序列. 如果不调用 complete()方法, 所产生的是一个无限序列. 第二个序列的生成逻辑中的状态对象是一个 ArrayList 对象. 实际产生的值是一个随机数. 产生的随机数被添加到 ArrayList 中. 当产生了 10 个数时, 通过 complete()方法来结束序列. 清单 2. 使用 generate()方法生成 Flux 序列 123456789101112131415161718private static void fluxGenerate() &#123; Flux.generate(sink -&gt; &#123; sink.next(&quot;Hello&quot;); sink.complete(); &#125;).subscribe(System.out::println); Random random = new Random(); Flux.generate(ArrayList::new, (list, sink) -&gt; &#123; int value = random.nextInt(100); list.add(value); sink.next(value); if (list.size() == 10) &#123; sink.complete(); &#125; return list; &#125;).subscribe(System.out::println); &#125; create()方法create()方法与 generate()方法的不同之处在于所使用的是 FluxSink 对象. FluxSink 支持同步和异步的消息产生, 并且可以在一次调用中产生多个元素. 在代码清单 3 中, 在一次调用中就产生了全部的 10 个元素. 清单 3. 使用 create()方法生成 Flux 序列 123456Flux.create(sink -&gt; &#123; for (int i = 0; i &lt; 10; i++) &#123; sink.next(i); &#125; sink.complete();&#125;).subscribe(System.out::println); 创建 MonoMono 的创建方式与之前介绍的 Flux 比较相似. Mono 类中也包含了一些与 Flux 类中相同的静态方法. 这些方法包括 just(), empty(), error()和 never()等. 除了这些方法之外, Mono 还有一些独有的静态方法. fromCallable()、fromCompletionStage()、fromFuture()、fromRunnable()和 fromSupplier(): 分别从 Callable、CompletionStage、CompletableFuture、Runnable 和 Supplier 中创建 Mono. delay(Duration duration): 创建一个 Mono 序列, 在指定的延迟时间之后, 产生数字 0 作为唯一值. ignoreElements(Publisher&lt;T&gt; source): 创建一个 Mono 序列, 忽略作为源的 Publisher 中的所有元素, 只产生结束消息. justOrEmpty(Optional&lt;? extends T&gt; data)和 justOrEmpty(T data): 从一个 Optional 对象或可能为 null 的对象中创建 Mono. 只有 Optional 对象中包含值或对象不为 null 时, Mono 序列才产生对应的元素. 还可以通过 create()方法来使用 MonoSink 来创建 Mono. 代码清单 4 中给出了创建 Mono 序列的示例. 清单 4. 创建 Mono 序列 12345678910private static final String HELLO = &quot;Hello&quot;;private static void buildMono() throws InterruptedException &#123; Mono.just(HELLO).subscribe(System.out::println); Mono.empty().subscribe(System.out::println); Mono.fromSupplier(() -&gt; HELLO).subscribe(System.out::println); Mono.justOrEmpty(Optional.of(HELLO)).subscribe(System.out::println); Mono.create(sink -&gt; sink.success(HELLO)).subscribe(System.out::println); Mono.delay(Duration.ofSeconds(1)).subscribe(System.out::println); TimeUnit.SECONDS.sleep(2); &#125; 操作符和 RxJava 一样, Reactor 的强大之处在于可以在反应式流上通过声明式的方式添加多种不同的操作符. 下面对其中重要的操作符进行分类介绍. buffer 和 bufferTimeout这两个操作符的作用是把当前流中的元素收集到集合中, 并把集合对象作为流中的新元素. 在进行收集时可以指定不同的条件: 所包含的元素的最大数量或收集的时间间隔. 方法 buffer()仅使用一个条件, 而 bufferTimeout()可以同时指定两个条件. 指定时间间隔时可以使用 Duration 对象或毫秒数. 除了元素数量和时间间隔之外, 还可以通过 bufferUntil 和 bufferWhile 操作符来进行收集. 这两个操作符的参数是表示每个集合中的元素所要满足的条件的 Predicate 对象. bufferUntil 会一直收集直到 Predicate 返回为 true. 使得 Predicate 返回 true 的那个元素可以选择添加到当前集合或下一个集合中；bufferWhile 则只有当 Predicate 返回 true 时才会收集. 一旦值为 false, 会立即开始下一次收集. 代码清单 5 给出了 buffer 相关操作符的使用示例. 第一行语句输出的是 5 个包含 20 个元素的数组；第二行语句输出的是 2 个包含了 10 个元素的数组；第三行语句输出的是 5 个包含 2 个元素的数组. 每当遇到一个偶数就会结束当前的收集；第四行语句输出的是 5 个包含 1 个元素的数组, 数组里面包含的只有偶数. 需要注意的是, 在代码清单 5 中, 首先通过 toStream()方法把 Flux 序列转换成 Java 8 中的 Stream 对象, 再通过 forEach()方法来进行输出. 这是因为序列的生成是异步的, 而转换成 Stream 对象可以保证主线程在序列生成完成之前不会退出, 从而可以正确地输出序列中的所有元素. 清单 5. buffer 相关操作符的使用示例 1234Flux.range(1, 100).buffer(20).subscribe(System.out::println);Flux.interval(Duration.ofMillis(100)).buffer(10).take(2).toStream().forEach(System.out::println);Flux.range(1, 10).bufferUntil(i -&gt; i % 2 == 0).subscribe(System.out::println);Flux.range(1, 10).bufferWhile(i -&gt; i % 2 == 0).subscribe(System.out::println); filter对流中包含的元素进行过滤, 只留下满足 Predicate 指定条件的元素. 代码清单 6 中的语句输出的是 1 到 10 中的所有偶数. 清单 6. filter 操作符使用示例 1Flux.range(1, 10).filter(i -&gt; i % 2 == 0).subscribe(System.out::println); windowwindow 操作符的作用类似于 buffer, 所不同的是 window 操作符是把当前流中的元素收集到另外的 Flux 序列中, 因此返回值类型是 Flux&lt;Flux&lt;T&gt;&gt;. 在代码清单 7 中, 两行语句的输出结果分别是 5 个和 2 个 UnicastProcessor 字符. 这是因为 window 操作符所产生的流中包含的是 UnicastProcessor 类的对象, 而 UnicastProcessor 类的 toString 方法输出的就是 UnicastProcessor 字符. 清单 7. window 操作符使用示例 12Flux.range(1, 100).window(20).subscribe(System.out::println);Flux.intervalMillis(100).windowMillis(1001).take(2).toStream().forEach(System.out::println); zipWithzipWith 操作符把当前流中的元素与另外一个流中的元素按照一对一的方式进行合并. 在合并时可以不做任何处理, 由此得到的是一个元素类型为 Tuple2 的流；也可以通过一个 BiFunction 函数对合并的元素进行处理, 所得到的流的元素类型为该函数的返回值. 在代码清单 8 中, 两个流中包含的元素分别是 a, b 和 c, d. 第一个 zipWith 操作符没有使用合并函数, 因此结果流中的元素类型为 Tuple2；第二个 zipWith 操作通过合并函数把元素类型变为 String. 清单 8. zipWith 操作符使用示例 123456Flux.just(&quot;a&quot;, &quot;b&quot;) .zipWith(Flux.just(&quot;c&quot;, &quot;d&quot;)) .subscribe(System.out::println);Flux.just(&quot;a&quot;, &quot;b&quot;) .zipWith(Flux.just(&quot;c&quot;, &quot;d&quot;), (s1, s2) -&gt; String.format(&quot;%s-%s&quot;, s1, s2)) .subscribe(System.out::println); taketake 系列操作符用来从当前流中提取元素. 提取的方式可以有很多种. take(long n), take(Duration timespan)和 takeMillis(long timespan): 按照指定的数量或时间间隔来提取. takeLast(long n): 提取流中的最后 N 个元素. takeUntil(Predicate&lt;? super T&gt; predicate): 提取元素直到 Predicate 返回 true. takeWhile(Predicate&lt;? super T&gt; continuePredicate): 当 Predicate 返回 true 时才进行提取. takeUntilOther(Publisher&lt;?&gt; other): 提取元素直到另外一个流开始产生元素. 在代码清单 9 中, 第一行语句输出的是数字 1 到 10；第二行语句输出的是数字 991 到 1000；第三行语句输出的是数字 1 到 9；第四行语句输出的是数字 1 到 10, 使得 Predicate 返回 true 的元素也是包含在内的. 清单 9. take 系列操作符使用示例 1234Flux.range(1, 1000).take(10).subscribe(System.out::println);Flux.range(1, 1000).takeLast(10).subscribe(System.out::println);Flux.range(1, 1000).takeWhile(i -&gt; i &lt; 10).subscribe(System.out::println);Flux.range(1, 1000).takeUntil(i -&gt; i == 10).subscribe(System.out::println); reduce 和 reduceWithreduce 和 reduceWith 操作符对流中包含的所有元素进行累积操作, 得到一个包含计算结果的 Mono 序列. 累积操作是通过一个 BiFunction 来表示的. 在操作时可以指定一个初始值. 如果没有初始值, 则序列的第一个元素作为初始值. 在代码清单 10 中, 第一行语句对流中的元素进行相加操作, 结果为 5050；第二行语句同样也是进行相加操作, 不过通过一个 Supplier 给出了初始值为 100, 所以结果为 5150. 清单 10. reduce 和 reduceWith 操作符使用示例 12Flux.range(1, 100).reduce((x, y) -&gt; x + y).subscribe(System.out::println);Flux.range(1, 100).reduceWith(() -&gt; 100, (x, y) -&gt; x + y).subscribe(System.out::println); merge 和 mergeSequentialmerge 和 mergeSequential 操作符用来把多个流合并成一个 Flux 序列. 不同之处在于 merge 按照所有流中元素的实际产生顺序来合并, 而 mergeSequential 则按照所有流被订阅的顺序, 以流为单位进行合并. 代码清单 11 中分别使用了 merge 和 mergeSequential 操作符. 进行合并的流都是每隔 100 毫秒产生一个元素, 不过第二个流中的每个元素的产生都比第一个流要延迟 50 毫秒. 在使用 merge 的结果流中, 来自两个流的元素是按照时间顺序交织在一起；而使用 mergeSequential 的结果流则是首先产生第一个流中的全部元素, 再产生第二个流中的全部元素. 清单 11. merge 和 mergeSequential 操作符使用示例 123456Flux.merge(Flux.interval(Duration.ofMillis(100)).take(5), Flux.interval(Duration.ofMillis(50), Duration.ofMillis(100)).take(5)).subscribe(System.out::println);TimeUnit.SECONDS.sleep(2);System.out.println();Flux.mergeSequential(Flux.interval(Duration.ofMillis(100)).take(5), Flux.interval(Duration.ofMillis(50), Duration.ofMillis(100)).take(5)) .toStream() .forEach(System.out::println); flatMap 和 flatMapSequentialflatMap 和 flatMapSequential 操作符把流中的每个元素转换成一个流, 再把所有流中的元素进行合并. flatMapSequential 和 flatMap 之间的区别与 mergeSequential 和 merge 之间的区别是一样的. 在代码清单 12 中, 流中的元素被转换成每隔 100 毫秒产生的数量不同的流, 再进行合并. 由于第一个流中包含的元素数量较少, 所以在结果流中一开始是两个流的元素交织在一起, 然后就只有第二个流中的元素. 清单 12. flatMap 操作符使用示例 1234Flux.just(5, 10) .flatMap(x -&gt; Flux.intervalMillis(x * 10, 100).take(x)) .toStream() .forEach(System.out::println); concatMapconcatMap 操作符的作用也是把流中的每个元素转换成一个流, 再把所有流进行合并. 与 flatMap 不同的是, concatMap 会根据原始流中的元素顺序依次把转换之后的流进行合并；与 flatMapSequential 不同的是, concatMap 对转换之后的流的订阅是动态进行的, 而 flatMapSequential 在合并之前就已经订阅了所有的流. 代码清单 13 与代码清单 12 类似, 只不过把 flatMap 换成了 concatMap, 结果流中依次包含了第一个流和第二个流中的全部元素. 清单 13. concatMap 操作符使用示例 1234Flux.just(5, 10) .concatMap(x -&gt; Flux.intervalMillis(x * 10, 100).take(x)) .toStream() .forEach(System.out::println); combineLatestcombineLatest 操作符把所有流中的最新产生的元素合并成一个新的元素, 作为返回结果流中的元素. 只要其中任何一个流中产生了新的元素, 合并操作就会被执行一次, 结果流中就会产生新的元素. 在 代码清单 14 中, 流中最新产生的元素会被收集到一个数组中, 通过 Arrays.toString 方法来把数组转换成 String. 清单 14. combineLatest 操作符使用示例 12345Flux.combineLatest( Arrays::toString, Flux.intervalMillis(100).take(5), Flux.intervalMillis(50, 100).take(5)).toStream().forEach(System.out::println); 消息处理当需要处理 Flux 或 Mono 中的消息时, 如之前的代码清单所示, 可以通过 subscribe 方法来添加相应的订阅逻辑. 在调用 subscribe 方法时可以指定需要处理的消息类型. 可以只处理其中包含的正常消息, 也可以同时处理错误消息和完成消息. 代码清单 15 中通过 subscribe()方法同时处理了正常消息和错误消息. 清单 15. 通过 subscribe()方法处理正常和错误消息 123Flux.just(1, 2) .concatWith(Mono.error(new IllegalStateException())) .subscribe(System.out::println, System.err::println); 正常的消息处理相对简单. 当出现错误时, 有多种不同的处理策略. 第一种策略是通过 onErrorReturn()方法返回一个默认值. 在代码清单 16 中, 当出现错误时, 流会产生默认值 0. 清单 16. 出现错误时返回默认值 1234Flux.just(1, 2) .concatWith(Mono.error(new IllegalStateException())) .onErrorReturn(0) .subscribe(System.out::println); 第二种策略是通过 onErrorResume()方法来根据不同的异常类型来选择要使用的产生元素的流. 在代码清单 18 中, 根据异常类型来返回不同的流作为出现错误时的数据来源. 因为异常的类型为 IllegalArgumentException, 所产生的元素为-1. 清单 18. 出现错误时根据异常类型来选择流 1234567891011Flux.just(1, 2) .concatWith(Mono.error(new IllegalArgumentException())) .onErrorResume(e -&gt; &#123; if (e instanceof IllegalStateException) &#123; return Mono.just(0); &#125; else if (e instanceof IllegalArgumentException) &#123; return Mono.just(-1); &#125; return Mono.empty(); &#125;) .subscribe(System.out::println); 当出现错误时, 还可以通过 retry 操作符来进行重试. 重试的动作是通过重新订阅序列来实现的. 在使用 retry 操作符时可以指定重试的次数. 代码清单 19 中指定了重试次数为 1, 所输出的结果是 1, 2, 1, 2 和错误信息. 清单 19. 使用 retry 操作符进行重试 1234Flux.just(1, 2) .concatWith(Mono.error(new IllegalStateException())) .retry(1) .subscribe(System.out::println); 调度器前面介绍了反应式流和在其上可以进行的各种操作, 通过调度器（Scheduler）可以指定这些操作执行的方式和所在的线程. 有下面几种不同的调度器实现. 当前线程, 通过 Schedulers.immediate()方法来创建. 单一的可复用的线程, 通过 Schedulers.single()方法来创建. 使用弹性的线程池, 通过 Schedulers.elastic()方法来创建. 线程池中的线程是可以复用的. 当所需要时, 新的线程会被创建. 如果一个线程闲置太长时间, 则会被销毁. 该调度器适用于 I/O 操作相关的流的处理. 使用对并行操作优化的线程池, 通过 Schedulers.parallel()方法来创建. 其中的线程数量取决于 CPU 的核的数量. 该调度器适用于计算密集型的流的处理. 使用支持任务调度的调度器, 通过 Schedulers.timer()方法来创建. 从已有的 ExecutorService 对象中创建调度器, 通过 Schedulers.fromExecutorService()方法来创建. 某些操作符默认就已经使用了特定类型的调度器. 比如 interval()方法创建的流就使用了由 Schedulers.parallel()创建的调度器. 通过 publishOn()和 subscribeOn()方法可以切换执行操作的调度器. 其中 publishOn()方法切换的是操作符的执行方式, 而 subscribeOn()方法切换的是产生流中元素时的执行方式. 在代码清单 20 中, 使用 create()方法创建一个新的 Flux 对象, 其中包含唯一的元素是当前线程的名称. 接着是两对 publishOn()和 map()方法, 其作用是先切换执行时的调度器, 再把当前的线程名称作为前缀添加. 最后通过 subscribeOn()方法来改变流产生时的执行方式. 运行之后的结果是[elastic-2][single-1] parallel-1. 最内层的线程名字 parallel-1 来自产生流中元素时使用的 Schedulers.parallel()调度器, 中间的线程名称 single-1 来自第一个 map 操作之前的 Schedulers.single()调度器, 最外层的线程名字 elastic-2 来自第二个 map 操作之前的 Schedulers.elastic()调度器. 清单 20. 使用调度器切换操作符执行方式 1234567891011Flux.create(sink -&gt; &#123; sink.next(Thread.currentThread().getName()); sink.complete();&#125;).publishOn(Schedulers.single()).map(x -&gt; String.format(&quot;[%s] %s&quot;, Thread.currentThread().getName(), x)).publishOn(Schedulers.elastic()).map(x -&gt; String.format(&quot;[%s] %s&quot;, Thread.currentThread().getName(), x)).subscribeOn(Schedulers.parallel()).toStream().forEach(System.out::println); 测试在对使用 Reactor 的代码进行测试时, 需要用到 io.projectreactor.addons:reactor-test 库. 使用 StepVerifier进行测试时的一个典型的场景是对于一个序列, 验证其中所包含的元素是否符合预期. StepVerifier 的作用是可以对序列中包含的元素进行逐一验证. 在代码清单 21 中, 需要验证的流中包含 a 和 b 两个元素. 通过 StepVerifier.create()方法对一个流进行包装之后再进行验证. expectNext()方法用来声明测试时所期待的流中的下一个元素的值, 而 verifyComplete()方法则验证流是否正常结束. 类似的方法还有 verifyError()来验证流由于错误而终止. 清单 21. 使用 StepVerifier 验证流中的元素 1234StepVerifier.create(Flux.just(&quot;a&quot;, &quot;b&quot;)) .expectNext(&quot;a&quot;) .expectNext(&quot;b&quot;) .verifyComplete(); 操作测试时间有些序列的生成是有时间要求的, 比如每隔 1 分钟才产生一个新的元素. 在进行测试中, 不可能花费实际的时间来等待每个元素的生成. 此时需要用到 StepVerifier 提供的虚拟时间功能. 通过 StepVerifier.withVirtualTime()方法可以创建出使用虚拟时钟的 StepVerifier. 通过 thenAwait(Duration)方法可以让虚拟时钟前进. 在代码清单 22 中, 需要验证的流中包含两个产生间隔为一天的元素, 并且第一个元素的产生延迟是 4 个小时. 在通过 StepVerifier.withVirtualTime()方法包装流之后, expectNoEvent()方法用来验证在 4 个小时之内没有任何消息产生, 然后验证第一个元素 0 产生；接着 thenAwait()方法来让虚拟时钟前进一天, 然后验证第二个元素 1 产生；最后验证流正常结束. 清单 22. 操作测试时间 1234567StepVerifier.withVirtualTime(() -&gt; Flux.interval(Duration.ofHours(4), Duration.ofDays(1)).take(2)) .expectSubscription() .expectNoEvent(Duration.ofHours(4)) .expectNext(0L) .thenAwait(Duration.ofDays(1)) .expectNext(1L) .verifyComplete(); 使用 TestPublisherTestPublisher 的作用在于可以控制流中元素的产生, 甚至是违反反应流规范的情况. 在代码清单 23 中, 通过 create()方法创建一个新的 TestPublisher 对象, 然后使用 next()方法来产生元素, 使用 complete()方法来结束流. TestPublisher 主要用来测试开发人员自己创建的操作符. 清单 23. 使用 TestPublisher 创建测试所用的流 123456789final TestPublisher&lt;String&gt; testPublisher = TestPublisher.create();testPublisher.next(&quot;a&quot;);testPublisher.next(&quot;b&quot;);testPublisher.complete(); StepVerifier.create(testPublisher) .expectNext(&quot;a&quot;) .expectNext(&quot;b&quot;) .expectComplete(); 启用调试模式当需要获取更多与流相关的执行信息时, 可以在程序开始的地方添加代码清单 24 中的代码来启用调试模式. 在调试模式启用之后, 所有的操作符在执行时都会保存额外的与执行链相关的信息. 当出现错误时, 这些信息会被作为异常堆栈信息的一部分输出. 通过这些信息可以分析出具体是在哪个操作符的执行中出现了问题. 清单 24. 启用调试模式 1Hooks.onOperatorDebug(); 不过当调试模式启用之后, 记录这些额外的信息是有代价的. 一般只有在出现了错误之后, 再考虑启用调试模式. 但是当为了找到问题而启用了调试模式之后, 之前的错误不一定能很容易重现出来. 为了减少可能的开销, 可以限制只对特定类型的操作符启用调试模式. 使用检查点另外一种做法是通过 checkpoint 操作符来对特定的流处理链来启用调试模式. 代码清单 25 中, 在 map 操作符之后添加了一个名为 test 的检查点. 当出现错误时, 检查点名称会出现在异常堆栈信息中. 对于程序中重要或者复杂的流处理链, 可以在关键的位置上启用检查点来帮助定位可能存在的问题. 清单 25. 使用 checkpoint 操作符 1Flux.just(1, 0).map(x -&gt; 1 / x).checkpoint(&quot;test&quot;).subscribe(System.out::println); 日志记录在开发和调试中的另外一项实用功能是把流相关的事件记录在日志中. 这可以通过添加 log 操作符来实现. 在代码清单 26 中, 添加了 log 操作符并指定了日志分类的名称. 清单 26. 使用 log 操作符记录事件 1Flux.range(1, 2).log(&quot;YBD&quot;).subscribe(System.out::println); 在实际的运行时, 所产生的输出如代码清单 27 所示. 清单 27. log 操作符所产生的日志 1234567816:18:06.381 [main] DEBUG reactor.util.Loggers$LoggerFactory - Using Slf4j logging framework16:18:06.391 [main] INFO YBD - | onSubscribe([Synchronous Fuseable] FluxRange.RangeSubscription)16:18:06.393 [main] INFO YBD - | request(unbounded)16:18:06.393 [main] INFO YBD - | onNext(1)116:18:06.394 [main] INFO YBD - | onNext(2)216:18:06.394 [main] INFO YBD - | onComplete() “冷”与“热”序列之前的代码清单中所创建的都是冷序列. 冷序列的含义是不论订阅者在何时订阅该序列, 总是能收到序列中产生的全部消息. 而与之对应的热序列, 则是在持续不断地产生消息, 订阅者只能获取到在其订阅之后产生的消息. 在代码清单 28 中, 原始的序列中包含 10 个间隔为 1 秒的元素. 通过 publish()方法把一个 Flux 对象转换成 ConnectableFlux 对象. 方法 autoConnect()的作用是当 ConnectableFlux 对象有一个订阅者时就开始产生消息. 代码 source.subscribe()的作用是订阅该 ConnectableFlux 对象, 让其开始产生数据. 接着当前线程睡眠 5 秒钟, 第二个订阅者此时只能获得到该序列中的后 5 个元素, 因此所输出的是数字 5 到 9. 清单 28. 热序列 12345678final Flux&lt;Long&gt; source = Flux.interval(Duration.ofSeconds(1)) .take(10) .publish() .autoConnect();source.subscribe();Thread.sleep(5000);source.toStream() .forEach(System.out::println); End反应式编程范式对于习惯了传统编程范式的开发人员来说, 既是一个需要进行思维方式转变的挑战, 也是一个充满了更多可能的机会. Reactor 作为一个基于反应式流规范的新的 Java 库, 可以作为反应式应用的基础. 本文对 Reactor 库做了详细的介绍, 包括 Flux 和 Mono 序列的创建、常用操作符的使用、调度器、错误处理以及测试和调试技巧等. 参考: https://www.ibm.com/developerworks/cn/java/j-cn-with-reactor-response-encode/index.html Demo: https://github.com/masteranthoneyd/reactor-simple-demo]]></content>
      <categories>
        <category>Programming</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Reactor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring5新特征与WebFlux反应式编程]]></title>
    <url>%2F2017%2Fnew-in-spring-framework-5%2F</url>
    <content type="text"><![CDATA[Preface Spring 5 于 2017 年 9 月发布了通用版本 (GA), 它标志着自 2013 年 12 月以来第一个主要 Spring Framework 版本. 它提供了一些人们期待已久的改进, 还采用了一种全新的编程范例, 以反应式宣言中陈述的反应式原则为基础. 这个版本是很长时间以来最令人兴奋的 Spring Framework 版本. Spring 5 兼容 Java™8 和 JDK 9, 它集成了反应式流, 以便提供一种颠覆性方法来实现端点和 Web 应用程序开发. 诚然, 反应式编程不仅是此版本的主题, 还是令许多开发人员激动不已的重大特性. 人们对能够针对负载波动进行无缝扩展的灾备和响应式服务的需求在不断增加, Spring 5 很好地满足了这一需求. 本文将全面介绍 Spring 5. 我将介绍 Java SE 8 和 Java EE 7 API 的基准升级、Spring 5 的新反应式编程模型、HTTP/2 支持, 以及 Spring 通过 Kotlin 对函数式编程的全面支持. 我还会简要介绍测试和性能增强, 最后介绍对 Spring 核心和容器的一般性修订. Spring Framework 5 中的新特性升级到 Java SE 8 和 Java EE 7直到现在, Spring Framework 仍支持一些弃用的 Java 版本, 但 Spring 5 已从旧包袱中解放出来. 为了充分利用 Java 8 特性, 它的代码库已进行了改进, 而且该框架要求将 Java 8 作为最低的 JDK 版本. Spring 5 在类路径（和模块路径）上完全兼容 Java 9, 而且它通过了 JDK 9 测试套件的测试. 对 Java 9 爱好者而言, 这是一条好消息, 因为在 Java 9 发布后, Spring 能立即使用它. 在 API 级别上, Spring 5 兼容 Java EE 8 技术, 满足对 Servlet 4.0、Bean Validation 2.0 和全新的 JSON Binding API 的需求. 对 Java EE API 的最低要求为 V7, 该版本引入了针对 Servlet、JPA 和 Bean Validation API 的次要版本. 反应式编程模型Spring 5 最令人兴奋的新特性是它的反应式编程模型. Spring 5 Framework 基于一种反应式基础而构建, 而且是完全异步和非阻塞的. 只需少量的线程, 新的事件循环执行模型就可以垂直扩展. 该框架采用反应式流来提供在反应式组件中传播负压的机制. 负压是一个确保来自多个生产者的数据不会让使用者不堪重负的概念. Spring WebFlux 是 Spring 5 的反应式核心, 它为开发人员提供了两种为 Spring Web 编程而设计的编程模型: 一种基于注解的模型和 Functional Web Framework (WebFlux.fn). 基于注解的模型是 Spring WebMVC 的现代替代方案, 该模型基于反应式基础而构建, 而 Functional Web Framework 是基于@Controller 注解的编程模型的替代方案. 这些模型都通过同一种反应式基础来运行, 后者调整非阻塞 HTTP 来适应反应式流 API. 使用注解进行编程WebMVC 程序员应该对 Spring 5 的基于注解的编程模型非常熟悉. Spring 5 调整了 WebMVC 的 @Controller 编程模型, 采用了相同的注解. 在清单 1 中, BookController 类提供了两个方法, 分别响应针对某个图书列表的 HTTP 请求, 以及针对具有给定 id 的图书的 HTTP 请求. 请注意 resource 方法返回的对象（Mono 和 Flux）. 这些对象是实现反应式流规范中的 Publisher 接口的反应式类型. 它们的职责是处理数据流. Mono 对象处理一个仅含 1 个元素的流, 而 Flux 表示一个包含 N 个元素的流. 清单 1. 反应式控制器123456789101112131415@RestControllerpublic class BookController &#123; @GetMapping(&quot;/book&quot;) Flux&lt;Book&gt; list() &#123; return this.repository.findAll(); &#125; @GetMapping(&quot;/book/&#123;id&#125;&quot;) Mono&lt;Book&gt; findById(@PathVariable String id) &#123; return this.repository.findOne(id); &#125; // Plumbing code omitted for brevity&#125; 这是针对 Spring Web 编程的注解. 现在我们使用函数式 Web 框架来解决同一个问题. 函数式编程Spring 5 的新函数式方法将请求委托给处理函数, 这些函数接受一个服务器请求实例并返回一种反应式类型. 清单 2 演示了这一过程, 其中 listBook 和 getBook 方法类似于清单 1 中的功能. 清单 2. 清单 2.BookHandler 函数类1234567891011121314151617public class BookHandler &#123; public Mono&lt;ServerResponse&gt; listBooks(ServerRequest request) &#123; return ServerResponse.ok() .contentType(APPLICATION_JSON) .body(repository.allPeople(), Book.class); &#125; public Mono&lt;ServerResponse&gt; getBook(ServerRequest request) &#123; return repository.getBook(request.pathVariable(&quot;id&quot;)) .then(book -&gt; ServerResponse.ok() .contentType(APPLICATION_JSON) .body(fromObject(book))) .otherwiseIfEmpty(ServerResponse.notFound().build()); &#125; // Plumbing code omitted for brevity&#125; 通过路由函数来匹配 HTTP 请求谓词与媒体类型, 将客户端请求路由到处理函数. 清单 3 展示了图书资源端点 URI 将调用委托给合适的处理函数: 清单 3. Router 函数123456789BookHandler handler = new BookHandler(); RouterFunction&lt;ServerResponse&gt; personRoute = route( GET(&quot;/books/&#123;id&#125;&quot;) .and(accept(APPLICATION_JSON)), handler::getBook) .andRoute( GET(&quot;/books&quot;) .and(accept(APPLICATION_JSON)), handler::listBooks); 这些示例背后的数据存储库也支持完整的反应式体验, 该体验是通过 Spring Data 对反应式 Couchbase、Reactive MongoDB 和 Cassandra 的支持来实现的. 使用 REST 端点执行反应式编程新的编程模型脱离了传统的 Spring WebMVC 模型, 引入了一些很不错的新特性. 举例来说, WebFlux 模块为 RestTemplate 提供了一种完全非阻塞、反应式的替代方案, 名为 WebClient. 清单 4 创建了一个 WebClient, 并调用 books 端点来请求一本给定 id 为 1234 的图书. 清单 4. 通过 WebClient 调用 REST 端点123456Mono&lt;Book&gt; book = WebClient.create(&quot;http://localhost:8080&quot;) .get() .url(&quot;/books/&#123;id&#125;&quot;, 1234) .accept(APPLICATION_JSON) .exchange(request) .then(response -&gt; response.bodyToMono(Book.class)); HTTP/2 支持HTTP/2 幕后原理: 要了解 HTTP/2 如何提高传输性能, 减少延迟, 并帮助提高应用程序吞吐量, 从而提供经过改进的丰富 Web 体验, 请查阅https://www.ibm.com/developerworks/cn/web/wa-http2-under-the-hood/index.html. Spring Framework 5.0 将提供专门的 HTTP/2 特性 支持, 还支持人们期望出现在 JDK 9 中的新 HTTP 客户端. 尽管 HTTP/2 的服务器推送功能已通过 Jetty servlet 引擎的 ServerPushFilter 类向 Spring 开发人员公开了很长一段时间, 但如果发现 Spring 5 中开箱即用地提供了 HTTP/2 性能增强, Web 优化者们一定会为此欢呼雀跃. Java EE Servlet 规范预计将于 2017 年第 4 季度发布, Servlet 4.0 支持将在 Spring 5.1 中提供. 到那时, HTTP/2 特性 将由 Tomcat 9.0、Jetty 9.3 和 Undertow 1.4 原生提供. Kotlin 和 Spring WebFlux Kotlin 是一种来自 JetBrains 的面向对象的语言, 它支持函数式编程. 它的主要优势之一是与 Java 有非常高的互操作性. 通过引入对 Kotlin 的专门支持, Spring 在 V5 中全面吸纳了这一优势. 它的函数式编程风格与 Spring WebFlux 模块完美匹配, 它的新路由 DSL 利用了函数式 Web 框架以及干净且符合语言习惯的代码. 可以像清单 5 中这样简单地表达端点路由: 清单 5. Kotlin 的用于定义端点的路由 DSL 12345678910111213@Beanfun apiRouter() = router &#123; (accept(APPLICATION_JSON) and &quot;/api&quot;).nest &#123; &quot;/book&quot;.nest &#123; GET(&quot;/&quot;, bookHandler::findAll) GET(&quot;/&#123;id&#125;&quot;, bookHandler::findOne) &#125; &quot;/video&quot;.nest &#123; GET(&quot;/&quot;, videoHandler::findAll) GET(&quot;/&#123;genre&#125;&quot;, videoHandler::findByGenre) &#125; &#125;&#125; 使用 Kotlin 1.1.4+ 时, 还添加了对 Kotlin 的不可变类的支持（通过带默认值的可选参数）, 以及对完全支持 null 的 API 的支持. 使用 Lambda 表达式注册 bean作为传统 XML 和 JavaConfig 的替代方案, 现在可以使用 lambda 表达式注册 Spring bean, 使 bean 可以实际注册为提供者. 清单 6 使用 lambda 表达式注册了一个 Book bean. 清单 6. 将 Bean 注册为提供者1234GenericApplicationContext context = new GenericApplicationContext();context.registerBean(Book.class, () -&gt; new Book(context.getBean(Author.class)) ); Spring WebMVC 支持最新的 API全新的 WebFlux 模块提供了许多新的、令人兴奋的功能, 但 Spring 5 也迎合了愿意继续使用 Spring MVC 的开发人员的需求. Spring 5 中更新了模型-视图-控制器框架, 以兼容 WebFlux 和最新版的 Jackson 2.9 和 Protobuf 3.0, 甚至包括对新的 Java EE 8 JSON-Binding API 的支持. 除了 HTTP/2 特性 的基础服务器实现之外, Spring WebMVC 还通过 MVC 控制器方法的一个参数来支持 Servlet 4.0 的 PushBuilder. 最后, WebMVC 全面支持 Reactor 3.1 的 Flux 和 Mono 对象, 以及 RxJava 1.3 和 2.1, 它们被视为来自 MVC 控制器方法的返回值. 这项支持的最终目的是支持 Spring Data 中的新的反应式 WebClient 和反应式存储库. 使用 JUnit 5 执行条件和并发测试JUnit 和 Spring 5: Spring 5 全面接纳了函数式范例, 并支持 JUnit 5 及其新的函数式测试风格. 还提供了对 JUnit 4 的向后兼容性, 以确保不会破坏旧代码. Spring 5 的测试套件通过多种方式得到了增强, 但最明显的是它对 JUnit 5 的支持. 现在可以在您的单元测试中利用 Java 8 中提供的函数式编程特性. 清单 7 演示了这一支持: 清单 7.JUnit 5 全面接纳了 Java 8 流和 lambda 表达式1234567@Testvoid givenStreamOfInts_SumShouldBeMoreThanFive() &#123; assertTrue(Stream.of(20, 40, 50) .stream() .mapToInt(i -&gt; i) .sum() &gt; 110, () -&gt; &quot;Total should be more than 100&quot;);&#125; 迁移到 JUnit 5: 如果您对升级到 JUnit 5 持观望态度, Steve Perry 的分两部分的深入剖析教程 将说服您冒险尝试. Spring 5 继承了 JUnit 5 在 Spring TestContext Framework 内实现多个扩展 API 的灵活性. 举例而言, 开发人员可以使用 JUnit 5 的条件测试执行注解 @EnabledIf 和 @DisabledIf 来自动计算一个 SpEL (Spring Expression Language) 表达式, 并适当地启用或禁用测试. 借助这些注解, Spring 5 支持以前很难实现的复杂的条件测试方案. Spring TextContext Framework 现在能够并发执行测试. 使用 Spring WebFlux 执行集成测试Spring Test 现在包含一个 WebTestClient, 后者支持对 Spring WebFlux 服务器端点执行集成测试. WebTestClient 使用模拟请求和响应来避免耗尽服务器资源, 并能直接绑定到 WebFlux 服务器基础架构. WebTestClient 可绑定到真实的服务器, 或者使用控制器或函数. 在清单 8 中, WebTestClient 被绑定到 localhost: 清单 8. 绑定到 localhost 的 WebTestClient 1234WebTestClient testClient = WebTestClient .bindToServer() .baseUrl(&quot;http://localhost:8080&quot;) .build(); 清单 9. 将 WebTestClient 绑定到 RouterFunction 1234567891011RouterFunction bookRouter = RouterFunctions.route( RequestPredicates.GET(&quot;/books&quot;), request -&gt; ServerResponse.ok().build()); WebTestClient .bindToRouterFunction(bookRouter) .build().get().uri(&quot;/books&quot;) .exchange() .expectStatus().isOk() .expectBody().isEmpty(); 包清理和弃用Spring 5 中止了对一些过时 API 的支持. 遭此厄运的还有 Hibernate 3 和 4, 为了支持 Hibernate 5, 它们遭到了弃用. 另外, 对 Portlet、Velocity、JasperReports、XMLBeans、JDO 和 Guava 的支持也已中止. 包级别上的清理工作仍在继续: Spring 5 不再支持 beans.factory.access、jdbc.support.nativejdbc、mock.staticmock（来自 spring-aspects 模块）或 web.view.tiles2M. Tiles 3 现在是 Spring 的最低要求. 对 Spring 核心和容器的一般更新Spring Framework 5 改进了扫描和识别组件的方法, 使大型项目的性能得到提升. 目前, 扫描是在编译时执行的, 而且向 META-INF/spring.components 文件中的索引文件添加了组件坐标. 该索引是通过一个为项目定义的特定于平台的应用程序构建任务来生成的. 标有来自 javax 包 的注解的组件会添加到索引中, 任何带 @Index 注解的类或接口都会添加到索引中. Spring 的传统类路径扫描方式没有删除, 而是保留为一种后备选择. 有许多针对大型代码库的明显性能优势, 而托管许多 Spring 项目的服务器也会缩短启动时间. Spring 5 还添加了对 @Nullable 的支持, 后者可用于指示可选的注入点. 使用者现在必须准备接受 null 值. 此外, 还可以使用此注解来标记可以为 null 的参数、字段和返回值. @Nullable 主要用于 IntelliJ IDEA 等 IDE, 但也可用于 Eclipse 和 FindBugs, 它使得在编译时处理 null 值变得更方便, 而无需在运行时发送 NullPointerExceptions. Spring Logging 还提升了性能, 自带开箱即用的 Commons Logging 桥接器. 现在已通过资源抽象支持防御性编程, 为 getFile访问提供了 isFile 指示器. 小结Spring 5 的首要特性是新的反应式编程模型, 这代表着对提供可无缝扩展、基于 Spring 的响应式服务的重大保障. 随着人们对 Spring 5 的采用, 开发人员有望看到反应式编程将会成为使用 Java 语言的 Web 和企业应用程序开发的未来发展道路. 未来的 Spring Framework 版本将继续反映这一承诺, 因为 Spring Security、Spring Data 和 Spring Integration 有望采用反应式编程的特征和优势. 总之, Spring 5 代表着一次大受 Spring 开发人员欢迎的范例转变, 同时也为其他框架指出了一条发展之路. 使用 Spring 5 的 WebFlux 开发反应式 Web 应用 WebFlux 简介WebFlux 模块的名称是 spring-webflux, 名称中的 Flux 来源于 Reactor 中的类 Flux. 该模块中包含了对反应式 HTTP、服务器推送事件和 WebSocket 的客户端和服务器端的支持. 对于开发人员来说, 比较重要的是服务器端的开发, 这也是本文的重点. 在服务器端, WebFlux 支持两种不同的编程模型: 第一种是 Spring MVC 中使用的基于 Java 注解的方式；第二种是基于 Java 8 的 lambda 表达式的函数式编程模型. 这两种编程模型只是在代码编写方式上存在不同. 它们运行在同样的反应式底层架构之上, 因此在运行时是相同的. WebFlux 需要底层提供运行时的支持, WebFlux 可以运行在支持 Servlet 3.1 非阻塞 IO API 的 Servlet 容器上, 或是其他异步运行时环境, 如 Netty 和 Undertow. 最方便的创建 WebFlux 应用的方式是使用 Spring Boot 提供的应用模板. 直接访问 Spring Initializ 网站（http://start.spring.io/ ）, 选择创建一个 Maven 或 Gradle 项目. Spring Boot 的版本选择 2.0.0 M2（或更高）. 在添加的依赖中, 选择 Reactive Web. 最后输入应用所在的分组和名称, 点击进行下载即可. 需要注意的是, 只有在选择了 Spring Boot 2.0.0 M2 之后, 依赖中才可以选择 Reactive Web. 下载完成之后可以导入到 IDE 中进行编辑. 本文从三个方面对 WebFlux 进行介绍. 首先是使用经典的基于 Java 注解的编程模型来进行开发, 其次是使用 WebFlux 新增的函数式编程模型来进行开发, 最后介绍 WebFlux 应用的测试. 通过这样循序渐进的方式让读者了解 WebFlux 应用开发的细节. Java 注解编程模型基于 Java 注解的编程模型, 对于使用过 Spring MVC 的开发人员来说是再熟悉不过的. 在 WebFlux 应用中使用同样的模式, 容易理解和上手. 我们先从最经典的 Hello World 的示例开始说明. 代码清单 1 中的 BasicController 是 REST API 的控制器, 通过@RestController 注解来声明. 在 BasicController 中声明了一个 URI 为/hello_world 的映射. 其对应的方法 sayHelloWorld()的返回值是 Mono&lt;String&gt;类型, 其中包含的字符串&quot;Hello World&quot;会作为 HTTP 的响应内容. 清单 1. Hello World 示例1234567@RestControllerpublic class BasicController &#123; @GetMapping(&quot;/hello_world&quot;) public Mono&lt;String&gt; sayHelloWorld() &#123; return Mono.just(&quot;Hello World&quot;); &#125;&#125; 从代码清单 1 中可以看到, 使用 WebFlux 与 Spring MVC 的不同在于, WebFlux 所使用的类型是与反应式编程相关的 Flux 和 Mono 等, 而不是简单的对象. 对于简单的 Hello World 示例来说, 这两者之间并没有什么太大的差别. 对于复杂的应用来说, 反应式编程和负压的优势会体现出来, 可以带来整体的性能的提升. REST API简单的 Hello World 示例并不足以说明 WebFlux 的用法. 在下面的小节中, 本文将介绍其他具体的实例. 先从 REST API 开始说起. REST API 在 Web 服务器端应用中占据了很大的一部分. 我们通过一个具体的实例来说明如何使用 WebFlux 来开发 REST API. 该 REST API 用来对用户数据进行基本的 CRUD 操作. 作为领域对象的 User 类中包含了 id、name 和 email 等三个基本的属性. 为了对 User 类进行操作, 我们需要提供服务类 UserService, 如代码清单 2 所示. 类 UserService 使用一个 Map 来保存所有用户的信息, 并不是一个持久化的实现. 这对于示例应用来说已经足够了. 类 UserService 中的方法都以 Flux 或 Mono 对象作为返回值, 这也是 WebFlux 应用的特征. 在方法 getById()中, 如果找不到 ID 对应的 User 对象, 会返回一个包含了 ResourceNotFoundException 异常通知的 Mono 对象. 方法 getById()和 createOrUpdate()都可以接受 String 或 Flux 类型的参数. Flux 类型的参数表示的是有多个对象需要处理. 这里使用 doOnNext()来对其中的每个对象进行处理. 清单 2. UserService 123456789101112131415161718192021222324252627282930@Serviceclass UserService &#123; private final Map&lt;String, User&gt; data = new ConcurrentHashMap&lt;&gt;(); Flux&lt;User&gt; list() &#123; return Flux.fromIterable(this.data.values()); &#125; Flux&lt;User&gt; getById(final Flux&lt;String&gt; ids) &#123; return ids.flatMap(id -&gt; Mono.justOrEmpty(this.data.get(id))); &#125; Mono&lt;User&gt; getById(final String id) &#123; return Mono.justOrEmpty(this.data.get(id)) .switchIfEmpty(Mono.error(new ResourceNotFoundException())); &#125; Flux&lt;User&gt; createOrUpdate(final Flux&lt;User&gt; users) &#123; return users.doOnNext(user -&gt; this.data.put(user.getId(), user)); &#125; Mono&lt;User&gt; createOrUpdate(final User user) &#123; this.data.put(user.getId(), user); return Mono.just(user); &#125; Mono&lt;User&gt; delete(final String id) &#123; return Mono.justOrEmpty(this.data.remove(id)); &#125;&#125; 代码清单 3 中的类 UserController 是具体的 Spring MVC 控制器类. 它使用类 UserService 来完成具体的功能. 类 UserController 中使用了注解@ExceptionHandler 来添加了 ResourceNotFoundException 异常的处理方法, 并返回 404 错误. 类 UserController 中的方法都很简单, 只是简单地代理给 UserService 中的对应方法. 清单 3. UserController 123456789101112131415161718192021222324252627282930313233343536373839404142@RestController@RequestMapping(&quot;/user&quot;)public class UserController &#123; private final UserService userService; @Autowired public UserController(final UserService userService) &#123; this.userService = userService; &#125; @ResponseStatus(value = HttpStatus.NOT_FOUND, reason = &quot;Resource not found&quot;) @ExceptionHandler(ResourceNotFoundException.class) public void notFound() &#123; &#125; @GetMapping(&quot;&quot;) public Flux&lt;User&gt; list() &#123; return this.userService.list(); &#125; @GetMapping(&quot;/&#123;id&#125;&quot;) public Mono&lt;User&gt;getById(@PathVariable(&quot;id&quot;) final String id) &#123; return this.userService.getById(id); &#125; @PostMapping(&quot;&quot;) public Flux&lt;User&gt; create(@RequestBody final Flux&lt;User&gt; users) &#123; return this.userService.createOrUpdate(users); &#125; @PutMapping(&quot;/&#123;id&#125;&quot;) public Mono&lt;User&gt; update(@PathVariable(&quot;id&quot;) final String id, @RequestBody final User user) &#123; Objects.requireNonNull(user); user.setId(id); return this.userService.createOrUpdate(user); &#125; @DeleteMapping(&quot;/&#123;id&#125;&quot;) public Mono&lt;User&gt; delete(@PathVariable(&quot;id&quot;) final String id) &#123; return this.userService.delete(id); &#125;&#125; 服务器推送事件服务器推送事件（Server-Sent Events, SSE）允许服务器端不断地推送数据到客户端. 相对于 WebSocket 而言, 服务器推送事件只支持服务器端到客户端的单向数据传递. 虽然功能较弱, 但优势在于 SSE 在已有的 HTTP 协议上使用简单易懂的文本格式来表示传输的数据. 作为 W3C 的推荐规范, SSE 在浏览器端的支持也比较广泛, 除了 IE 之外的其他浏览器都提供了支持. 在 IE 上也可以使用 polyfill 库来提供支持. 在服务器端来说, SSE 是一个不断产生新数据的流, 非常适合于用反应式流来表示. 在 WebFlux 中创建 SSE 的服务器端是非常简单的. 只需要返回的对象的类型是 Flux&lt;ServerSentEvent&gt;, 就会被自动按照 SSE 规范要求的格式来发送响应. 代码清单 4 中的 SseController 是一个使用 SSE 的控制器的示例. 其中的方法 randomNumbers()表示的是每隔一秒产生一个随机数的 SSE 端点. 我们可以使用类 ServerSentEvent.Builder 来创建 ServerSentEvent 对象. 这里我们指定了事件名称 random, 以及每个事件的标识符和数据. 事件的标识符是一个递增的整数, 而数据则是产生的随机数. 清单 4. 服务器推送事件示例 1234567891011121314@RestController@RequestMapping(&quot;/sse&quot;)public class SseController &#123; @GetMapping(&quot;/randomNumbers&quot;) public Flux&lt;ServerSentEvent&lt;Integer&gt;&gt; randomNumbers() &#123; return Flux.interval(Duration.ofSeconds(1)) .map(seq -&gt; Tuples.of(seq, ThreadLocalRandom.current().nextInt())) .map(data -&gt; ServerSentEvent.&lt;Integer&gt;builder() .event(&quot;random&quot;) .id(Long.toString(data.getT1())) .data(data.getT2()) .build()); &#125;&#125; 在测试 SSE 时, 我们只需要使用 curl 来访问即可. 代码清单 5 给出了调用 curl http://localhost:8080/sse/randomNumbers 的结果. 清单 5. SSE 服务器端发送的响应 1234567891011id:0event:randomdata:751025203 id:1event:randomdata:-1591883873 id:2event:randomdata:-1899224227 WebSocketWebSocket 支持客户端与服务器端的双向通讯. 当客户端与服务器端之间的交互方式比较复杂时, 可以使用 WebSocket. WebSocket 在主流的浏览器上都得到了支持. WebFlux 也对创建 WebSocket 服务器端提供了支持. 在服务器端, 我们需要实现接口 org.springframework.web.reactive.socket.WebSocketHandler 来处理 WebSocket 通讯. 接口 WebSocketHandler 的方法 handle 的参数是接口 WebSocketSession 的对象, 可以用来获取客户端信息、接送消息和发送消息. 代码清单 6 中的 EchoHandler 对于每个接收的消息, 会发送一个添加了”ECHO -&gt; “前缀的响应消息. WebSocketSession 的 receive 方法的返回值是一个 Flux&lt;WebSocketMessage&gt;对象, 表示的是接收到的消息流. 而 send 方法的参数是一个 Publisher&lt;WebSocketMessage&gt;对象, 表示要发送的消息流. 在 handle 方法, 使用 map 操作对 receive 方法得到的 Flux&lt;WebSocketMessage&gt;中包含的消息继续处理, 然后直接由 send 方法来发送. 清单 6. WebSocket 的 EchoHandler 示例123456789@Componentpublic class EchoHandler implements WebSocketHandler &#123; @Override public Mono&lt;Void&gt; handle(final WebSocketSession session) &#123; return session.send( session.receive() .map(msg -&gt; session.textMessage(&quot;ECHO -&gt; &quot; + msg.getPayloadAsText()))); &#125;&#125; 在创建了 WebSocket 的处理器 EchoHandler 之后, 下一步需要把它注册到 WebFlux 中. 我们首先需要创建一个类 WebSocketHandlerAdapter 的对象, 该对象负责把 WebSocketHandler 关联到 WebFlux 中. 代码清单 7 中给出了相应的 Spring 配置. 其中的 HandlerMapping 类型的 bean 把 EchoHandler 映射到路径 /echo. 清单 7. 注册 EchoHandler 1234567891011121314151617181920@Configurationpublic class WebSocketConfiguration &#123; @Autowired @Bean public HandlerMapping webSocketMapping(final EchoHandler echoHandler) &#123; final Map&lt;String, WebSocketHandler&gt; map = new HashMap&lt;&gt;(1); map.put(&quot;/echo&quot;, echoHandler); final SimpleUrlHandlerMapping mapping = new SimpleUrlHandlerMapping(); mapping.setOrder(Ordered.HIGHEST_PRECEDENCE); mapping.setUrlMap(map); return mapping; &#125; @Bean public WebSocketHandlerAdapter handlerAdapter() &#123; return new WebSocketHandlerAdapter(); &#125;&#125; 运行应用之后, 可以使用工具来测试该 WebSocket 服务. 打开工具页面 https://www.websocket.org/echo.html, 然后连接到 ws://localhost:8080/echo, 可以发送消息并查看服务器端返回的结果. 函数式编程模型在上节中介绍了基于 Java 注解的编程模型, WebFlux 还支持基于 lambda 表达式的函数式编程模型. 与基于 Java 注解的编程模型相比, 函数式编程模型的抽象层次更低, 代码编写更灵活, 可以满足一些对动态性要求更高的场景. 不过在编写时的代码复杂度也较高, 学习曲线也较陡. 开发人员可以根据实际的需要来选择合适的编程模型. 目前 Spring Boot 不支持在一个应用中同时使用两种不同的编程模式. 为了说明函数式编程模型的用法, 我们使用 Spring Initializ 来创建一个新的 WebFlux 项目. 在函数式编程模型中, 每个请求是由一个函数来处理的, 通过接口 org.springframework.web.reactive.function.server.HandlerFunction 来表示. HandlerFunction 是一个函数式接口, 其中只有一个方法 Mono&lt;T extends ServerResponse&gt; handle(ServerRequest request), 因此可以用 labmda 表达式来实现该接口. 接口 ServerRequest 表示的是一个 HTTP 请求. 通过该接口可以获取到请求的相关信息, 如请求路径、HTTP 头、查询参数和请求内容等. 方法 handle 的返回值是一个 Mono&lt;T extends ServerResponse&gt;对象. 接口 ServerResponse 用来表示 HTTP 响应. ServerResponse 中包含了很多静态方法来创建不同 HTTP 状态码的响应对象. 本节中通过一个简单的计算器来展示函数式编程模型的用法. 代码清单 8 中给出了处理不同请求的类 CalculatorHandler, 其中包含的方法 add、subtract、multiply 和 divide 都是接口 HandlerFunction 的实现. 这些方法分别对应加、减、乘、除四种运算. 每种运算都是从 HTTP 请求中获取到两个作为操作数的整数, 再把运算的结果返回. 清单 8. 处理请求的类 CalculatorHandler 123456789101112131415161718192021222324252627282930313233343536373839@Componentpublic class CalculatorHandler &#123; public Mono&lt;ServerResponse&gt; add(final ServerRequest request) &#123; return calculate(request, (v1, v2) -&gt; v1 + v2); &#125; public Mono&lt;ServerResponse&gt; subtract(final ServerRequest request) &#123; return calculate(request, (v1, v2) -&gt; v1 - v2); &#125; public Mono&lt;ServerResponse&gt; multiply(final ServerRequest request) &#123; return calculate(request, (v1, v2) -&gt; v1 * v2); &#125; public Mono&lt;ServerResponse&gt; divide(final ServerRequest request) &#123; return calculate(request, (v1, v2) -&gt; v1 / v2); &#125; private Mono&lt;ServerResponse&gt; calculate(final ServerRequest request, final BiFunction&lt;Integer, Integer, Integer&gt; calculateFunc) &#123; final Tuple2&lt;Integer, Integer&gt; operands = extractOperands(request); return ServerResponse .ok() .body(Mono.just(calculateFunc.apply(operands.getT1(), operands.getT2())), Integer.class); &#125; private Tuple2&lt;Integer, Integer&gt; extractOperands(final ServerRequest request) &#123; return Tuples.of(parseOperand(request, &quot;v1&quot;), parseOperand(request, &quot;v2&quot;)); &#125; private int parseOperand(final ServerRequest request, final String param) &#123; try &#123; return Integer.parseInt(request.queryParam(param).orElse(&quot;0&quot;)); &#125; catch (final NumberFormatException e) &#123; return 0; &#125; &#125;&#125; 在创建了处理请求的 HandlerFunction 之后, 下一步是为这些 HandlerFunction 提供路由信息, 也就是这些 HandlerFunction 被调用的条件. 这是通过函数式接口 org.springframework.web.reactive.function.server.RouterFunction 来完成的. 接口 RouterFunction 的方法 Mono&lt;HandlerFunction&lt;T extends ServerResponse&gt;&gt; route(ServerRequest request)对每个 ServerRequest, 都返回对应的 0 个或 1 个 HandlerFunction 对象, 以 Mono&lt;HandlerFunction&gt;来表示. 当找到对应的 HandlerFunction 时, 该 HandlerFunction 被调用来处理该 ServerRequest, 并把得到的 ServerResponse 返回. 在使用 WebFlux 的 Spring Boot 应用中, 只需要创建 RouterFunction 类型的 bean, 就会被自动注册来处理请求并调用相应的 HandlerFunction. 代码清单 9 给了示例相关的配置类 Config. 方法 RouterFunctions.route 用来根据 Predicate 是否匹配来确定 HandlerFunction 是否被应用. RequestPredicates 中包含了很多静态方法来创建常用的基于不同匹配规则的 Predicate. 如 RequestPredicates.path 用来根据 HTTP 请求的路径来进行匹配. 此处我们检查请求的路径是/calculator. 在清单 9 中, 我们首先使用 ServerRequest 的 queryParam 方法来获取到查询参数 operator 的值, 然后通过反射 API 在类 CalculatorHandler 中找到与查询参数 operator 的值名称相同的方法来确定要调用的 HandlerFunction 的实现, 最后调用查找到的方法来处理该请求. 如果找不到查询参数 operator 或是 operator 的值不在识别的列表中, 服务器端返回 400 错误；如果反射 API 的方法调用中出现错误, 服务器端返回 500 错误. 清单 9. 注册 RouterFunction 123456789101112131415@Configurationpublic class Config &#123; @Bean @Autowired public RouterFunction&lt;ServerResponse&gt;routerFunction(final CalculatorHandler calculatorHandler) &#123; return RouterFunctions.route(RequestPredicates.path(&quot;/calculator&quot;), request -&gt; request.queryParam(&quot;operator&quot;).map(operator -&gt; Mono.justOrEmpty(ReflectionUtils.findMethod(CalculatorHandler.class, operator, ServerRequest.class)) .flatMap(method -&gt; (Mono&lt;ServerResponse&gt;) ReflectionUtils.invokeMethod(method, calculatorHandler, request)) .switchIfEmpty(ServerResponse.badRequest().build()) .onErrorResume(ex -&gt; ServerResponse.status(HttpStatus.INTERNAL_SERVER_ERROR).build())) .orElse(ServerResponse.badRequest().build())); &#125;&#125; 客户端除了服务器端实现之外, WebFlux 也提供了反应式客户端, 可以访问 HTTP、SSE 和 WebSocket 服务器端. HTTP对于 HTTP 和 SSE, 可以使用 WebFlux 模块中的类 org.springframework.web.reactive.function.client.WebClient. 代码清单 10 中的 RESTClient 用来访问前面小节中创建的 REST API. 首先使用 WebClient.create 方法来创建一个新的 WebClient 对象, 然后使用方法 post 来创建一个 POST 请求, 并使用方法 body 来设置 POST 请求的内容. 方法 exchange 的作用是发送请求并得到以 Mono&lt;ServerResponse&gt;表示的 HTTP 响应. 最后对得到的响应进行处理并输出结果. ServerResponse 的 bodyToMono 方法把响应内容转换成类 User 的对象, 最终得到的结果是 Mono&lt;User&gt;对象. 调用 createdUser.block 方法的作用是等待请求完成并得到所产生的类 User 的对象. 清单 10. 使用 WebClient 访问 REST API 123456789101112131415public class RESTClient &#123; public static void main(final String[] args) &#123; final User user = new User(); user.setName(&quot;Test&quot;); user.setEmail(&quot;test@example.org&quot;); final WebClient client = WebClient.create(&quot;http://localhost:8080/user&quot;); final Monol&lt;User&gt; createdUser = client.post() .uri(&quot;&quot;) .accept(MediaType.APPLICATION_JSON) .body(Mono.just(user), User.class) .exchange() .flatMap(response -&gt; response.bodyToMono(User.class)); System.out.println(createdUser.block()); &#125;&#125; SSEWebClient 还可以用同样的方式来访问 SSE 服务, 如代码清单 11 所示. 这里我们访问的是在之前的小节中创建的生成随机数的 SSE 服务. 使用 WebClient 访问 SSE 在发送请求部分与访问 REST API 是相同的, 所不同的地方在于对 HTTP 响应的处理. 由于 SSE 服务的响应是一个消息流, 我们需要使用 flatMapMany 把 Mono&lt;ServerResponse&gt;转换成一个 Flux&lt;ServerSentEvent&gt;对象, 这是通过方法 BodyExtractors.toFlux 来完成的, 其中的参数 new ParameterizedTypeReference&lt;ServerSentEvent&lt;String&gt;&gt;() {}表明了响应消息流中的内容是 ServerSentEvent 对象. 由于 SSE 服务器会不断地发送消息, 这里我们只是通过 buffer 方法来获取前 10 条消息并输出. 清单 11. 使用 WebClient 访问 SSE 服务 12345678910111213141516public class SSEClient &#123; public static void main(final String[] args) &#123; final WebClient client = WebClient.create(); client.get() .uri(&quot;http://localhost:8080/sse/randomNumbers&quot;) .accept(MediaType.TEXT_EVENT_STREAM) .exchange() .flatMapMany(response -&gt; response.body(BodyExtractors.toFlux(new ParameterizedTypeReference&lt;ServerSentEvent&lt;String&gt;&gt;() &#123; &#125;))) .filter(sse -&gt; Objects.nonNull(sse.data())) .map(ServerSentEvent::data) .buffer(10) .doOnNext(System.out::println) .blockFirst(); &#125;&#125; WebSocket访问 WebSocket 不能使用 WebClient, 而应该使用专门的 WebSocketClient 客户端. Spring Boot 的 WebFlux 模板中默认使用的是 Reactor Netty 库. Reactor Netty 库提供了 WebSocketClient 的实现. 在代码清单 12 中, 我们访问的是上面小节中创建的 WebSocket 服务. WebSocketClient 的 execute 方法与 WebSocket 服务器建立连接, 并执行给定的 WebSocketHandler 对象. 该 WebSocketHandler 对象与代码清单 6 中的作用是一样的, 只不过它是工作于客户端, 而不是服务器端. 在 WebSocketHandler 的实现中, 首先通过 WebSocketSession 的 send 方法来发送字符串 Hello 到服务器端, 然后通过 receive 方法来等待服务器端的响应并输出. 方法 take(1)的作用是表明客户端只获取服务器端发送的第一条消息. 清单 12. 使用 WebSocketClient 访问 WebSocket 1234567891011public class WSClient &#123; public static void main(final String[] args) &#123; final WebSocketClient client = new ReactorNettyWebSocketClient(); client.execute(URI.create(&quot;ws://localhost:8080/echo&quot;), session -&gt; session.send(Flux.just(session.textMessage(&quot;Hello&quot;))) .thenMany(session.receive().take(1).map(WebSocketMessage::getPayloadAsText)) .doOnNext(System.out::println) .then()) .block(Duration.ofMillis(5000)); &#125;&#125; 测试在 spring-test 模块中也添加了对 WebFlux 的支持. 通过类 org.springframework.test.web.reactive.server.WebTestClient 可以测试 WebFlux 服务器. 进行测试时既可以通过 mock 的方式来进行, 也可以对实际运行的服务器进行集成测试. 代码清单 13 通过一个集成测试来测试 UserController 中的创建用户的功能. 方法 WebTestClient.bindToServer 绑定到一个运行的服务器并设置了基础 URL. 发送 HTTP 请求的方式与代码清单 10 相同, 不同的是 exchange 方法的返回值是 ResponseSpec 对象, 其中包含了 expectStatus 和 expectBody 等方法来验证 HTTP 响应的状态码和内容. 方法 jsonPath 可以根据 JSON 对象中的路径来进行验证. 清单 13. 测试 UserController 12345678910111213141516public class UserControllerTest &#123; private final WebTestClient client = WebTestClient.bindToServer().baseUrl(&quot;http://localhost:8080&quot;).build(); @Test public void testCreateUser() throws Exception &#123; final User user = new User(); user.setName(&quot;Test&quot;); user.setEmail(&quot;test@example.org&quot;); client.post().uri(&quot;/user&quot;) .contentType(MediaType.APPLICATION_JSON) .body(Mono.just(user), User.class) .exchange() .expectStatus().isOk() .expectBody().jsonPath(&quot;name&quot;).isEqualTo(&quot;Test&quot;); &#125;&#125; 小结反应式编程范式为开发高性能 Web 应用带来了新的机会和挑战. Spring 5 中的 WebFlux 模块可以作为开发反应式 Web 应用的基础. 由于 Spring 框架的流行, WebFlux 会成为开发 Web 应用的重要趋势之一. 本文对 Spring 5 中的 WebFlux 模块进行了详细的介绍, 包括如何用 WebFlux 开发 HTTP、SSE 和 WebSocket 服务器端应用, 以及作为客户端来访问 HTTP、SSE 和 WebSocket 服务. 对于 WebFlux 的基于 Java 注解和函数式编程等两种模型都进行了介绍. 最后介绍了如何测试 WebFlux 应用. End 原文链接: https://www.ibm.com/developerworks/cn/java/spring5-webflux-reactive/index.html https://www.ibm.com/developerworks/cn/java/j-whats-new-in-spring-framework-5-theedom/index.html]]></content>
      <categories>
        <category>Programming</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring5</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式原则与UML类图]]></title>
    <url>%2F2017%2Fdesign-pattern-uml-and-six-principle%2F</url>
    <content type="text"><![CDATA[Preface 设计模式, 总的来说, 就是前人踩过无数的坑总结出来的软件设计经验. 在学习设计模式之前, 有必要了解它的一些规则以及建模.UML(Unified Modeling Language)又称统一建模语言或标准建模语言, 是始于1997年一个OMG(Object Management Group)标准, 它是一个支持模型化和软件系统开发的图形化语言, 为软件开发的所有阶段提供模型化和可视化支持, 包括由需求分析到规格, 到构造和配置. Design Pattern在软件工程中, 设计模式（design pattern）是对软件设计中普遍存在（反复出现）的各种问题, 所提出的解决方案. 这个术语是由埃里希·伽玛（Erich Gamma）等人在1990年代从建筑设计领域引入到计算机科学的. 设计模式并不直接用来完成代码的编写, 而是描述在各种不同情况下, 要怎么解决问题的一种方案. 面向对象设计模式通常以类别或对象)来描述其中的关系和相互作用, 但不涉及用来完成应用程序的特定类别或对象. 设计模式能使不稳定依赖于相对稳定、具体依赖于相对抽象, 避免会引起麻烦的紧耦合, 以增强软件设计面对并适应变化的能力. ——来自维基百科 六大原则.单一职责原则单一职责原则（Single Responsibility Principle,SRP）: 就一个类而言, 应该仅有一个引起它变化的原因. 即一个类应该只负责一个功能领域中的相应职责. 单一职责原则是实现高内聚、低耦合的指导方针, 它是最简单但又最难运用的原则, 需要设计人员发现类的不同职责并将其分离, 而发现类的多重职责需要设计人员具有较强的分析设计能力和相关实践经验. 开闭原则开闭原则（Open-Closed Principle,OCP）: 是指软件实体（类、模块、函数等等）应该可以扩展, 但是不可修改. 即软件实体应该尽量在不修改原有代码的情况下进行扩展. 为了满足开闭原则, 需要对系统进行抽象化设计, 抽象化是开闭原则的关键. 里氏替换原则里氏替换原则（Liskov Substitution Principle,LSP）: 所有引用父类的地方必须能够透明的使用子类的对象. 即子类型必须能够替换掉它们的父类型. 里氏替换原则告诉我们, 在软件中将一个基类对象替换成它的子类对象, 程序将不会产生任何错误和异常, 反过来则不成立, 如果一个软件实体使用的是一个子类对象的话, 那么它不一定能够使用基类对象. 因此在程序中尽量使用基类类型来对对象进行定义, 而在运行时再确定其子类类型, 用子类对象来替换父类对象. 同时, 里氏代换原则是实现开闭原则的重要方式之一. 依赖倒置原则依赖倒置原则（Dependency Inversion Principle,DIP）: 抽象不应该依赖细节, 细节应该依赖于抽象. 即应该针对接口编程, 而不是针对实现编程. 在大多数情况下, 我们会同时使用开闭原则、里氏代换原则和依赖倒转原则, 开闭原则是目标, 里氏代换原则是基础, 依赖倒转原则是手段. 接口隔离原则接口隔离原则（Interface Segregation Principle,ISP）: 使用专门的接口, 而不使用单一的总接口, 即客户端不应该依赖那些它不需要的接口. 根据接口隔离原则, 当一个接口太大时, 我们需要将它分割成一些更细小的接口, 使用该接口的客户端仅需知道与之相关的方法即可. 每一个接口应该承担一种相对独立的角色, 不干不该干的事, 该干的事都要干. 迪米特法则迪米特法则（Law of Demeter,LoD）: 一个软件实体应当尽可能少地与其它实体发生相互作用. 迪米特法则又称为最少知识原则（LeastKnowledge Principle,LIP）.如果一个系统符合迪米特法则, 那么当其中某一个模块发生修改时, 就会尽量少地影响其他模块, 扩展会相对容易, 这是对软件实体之间通信的限制, 迪米特法则要求限制软件实体之间通信的宽度和深度. 迪米特法则可降低系统的耦合度, 使类与类之间保持松散的耦合关系. 三大类型创建型(Creational) 单例模式(Singleton): 保证一个类仅有一个实例, 并提供一个访问它的全局访问点. 工厂方法(Factory Method): 定义一个创建对象的接口, 让其子类自己决定实例化哪一个工厂类, 工厂模式使其创建过程延迟到子类进行. 抽象工厂(Abstract Factory): 提供一个创建一系列相关或相互依赖对象的接口, 而无需指定它们具体的类. 建造者模式(Builder): 将一个复杂对象的构建与它的表示分离, 使得同样的构建过程可以创建不同的表示. 原型模式(Prototype): 用原型实例指定创建对象的种类, 并且通过拷贝这些原型来创建新的对象. 结构型(Structural) 适配器模式(Adapter): 适配器模式把一个类的接口变换成客户端所期待的另一种接口, 从而使原本因接口不匹配而无法在一起工作的两个类能够在一起工作. 装饰模式(Decrator): 装饰模式是在不必改变原类文件和使用继承的情况下, 动态的扩展一个对象的功能. 它是通过创建一个包装对象, 也就是装饰来包裹真实的对象. 代理模式(Proxy): 为其他对象提供一种代理以控制对这个对象的访问 ； 外观模式(Facade): 为子系统中的一组接口提供一个一致的界面, 外观模式定义了一个高层接口, 这个接口使得这一子系统更加容易使用. 桥接模式(Bridge): 将抽象部分与实现部分分离, 使它们都可以独立的变化. 组合模式(Composite): 允许你将对象组合成树形结构来表现”整体-部分”层次结构. 组合能让客户以一致的方法处理个别对象以及组合对象. 享元模式(Flyweight): 运用共享技术有效地支持大量细粒度的对象. 行为型(Behavioral) 策略模式(Strategy): 定义一组算法, 将每个算法都封装起来, 并且使他们之间可以互换. 模板方法(Template Method): 一个操作中算法的框架, 而将一些步骤延迟到子类中, 使得子类可以不改变算法的结构即可重定义该算法中的某些特定步骤. 观察者模式(Observer): 定义对象间的一种一对多的依赖关系, 当一个对象的状态发生改变时, 所有依赖于它的对象都得到通知并被自动更新. 迭代器模式(Iterator): 提供一种方法顺序访问一个聚合对象中各个元素, 而又无须暴露该对象的内部表示； 职责链模式(Chain of Responsibility): 避免请求发送者与接收者耦合在一起, 让多个对象都有可能接收请求, 将这些对象连接成一条链, 并且沿着这条链传递请求, 直到有对象处理它为止. 命令模式(Command): 将一个请求封装为一个对象, 从而使你可以用不同的请求对客户进行参数化, 对请求排队和记录请求日志, 以及支持可撤销的操作； 备忘录模式(Memento): 在不破坏封装性的前提下, 捕获一个对象的内部状态, 并在该对象之外保存这个状态. 这样就可以将该对象恢复到原先保存的状态. 状态模式(State): 允许对象在内部状态改变时改变它的行为, 对象看起来好像修改了它的类. 访问者模式(Visitor): 表示一个作用于其对象结构中的各元素的操作, 它使你可以在不改变各元素类的前提下定义作用于这些元素的新操作. 中介者模式(Mediator): 用一个中介对象来封装一系列的对象交互, 中介者使各对象不需要显示地相互引用. 从而使其耦合松散, 而且可以独立地改变它们之间的交互. 解释器模式(Interpreter): 给定一个语言, 定义它的文法表示, 并定义一个解释器, 这个解释器使用该标识来解释语言中的句子. 四大阶段 1、没学之前, 什么是设计模式, 老听别人说设计模式, 感觉好高大上, 那它到底是什么鬼. 这时我们设计的代码复用性很差、难以维护. 2、学了几个模式后, 感觉很简单, 于是到处想着要用自己学过的模式, 这样就会造成滥用. 最后感觉还不如不用. 3、学完全部模式时, 感觉很多模式太相似了, 无法很清晰的知道各模式之间的区别、联系, 这时一脸懵逼, 脑子一团乱麻. 在使用时, 分不清要使用那种模式. 4、模式已熟记于心, 已忘其形, 深知其意, 达到无剑胜有剑的境界, 恭喜你, 万剑归宗已练成！！！ UMLUML中有九种建模的图标, 即:用例图、类图、对象图、顺序图、协作图、状态图、活动图、组件图、配置图 Class Diagram在这主要学习一下类图 Class diagram .通过显示出系统的类以及这些类之间的关系来表示系统. 类图是静态的———它们显示出什么可以产生影响但不会告诉你什么时候产生影响. UML类的符号是一个被划分成三块的方框: 类名, 属性, 和操作. 抽象类的名字, 是斜体的. 类之间的关系是连接线. 类与类的关系 泛化: 可以简单的理解为继承关系； 实现: 一般是接口和实现类之间的关系； 关联: 一种拥有关系, 比如老师类中有学生列表, 那么老师类和学生类就是拥有关系； 聚合: 整体与部分的关系, 但是整体和部分是可以分离而独立存在的, 如汽车类和轮胎类； 组合: 整体与部分的关系, 但是二者不可分离, 分离了就没有意义了, 例如, 公司类和部门类, 没有公司就没有部门； 依赖: 一种使用关系, 例如创建 A 类必须要有 B 类. StarUMLStarUML…就是一个画UML的很炫酷的工具=.= 显示interface在staruml中, interface默认是以一个圆圈显示的(尴尬了)…, 但好在可以设置成想要的样子. 添加一个圆圈（interface）之后, 右键或选择菜单栏中的Format 选择Stereotype Display -&gt; Label, 这样矩形就显示出来了 同样是Format, 然后把Suppress Operations取消掉, 这样操作就可以显示出来了 GliffyGliffy是一个在线绘图工具, 支持Chrome插件, 非常强大.]]></content>
      <categories>
        <category>Programming</category>
        <category>Java</category>
        <category>Design Pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Design Pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu 常用命令]]></title>
    <url>%2F2017%2Fnote-of-linux-command%2F</url>
    <content type="text"><![CDATA[Preface =.= 这里只记录一些个人比较常用到的Ubuntu命令 SSH相关安装SSH12sudo apt install sshsudo apt install openssh-server 查看启动成功: ps -e|grep ssh, 如果看到sshd那代表成功了, 如果没有, 执行: 1sudo/etc/init.d/ssh start ssh的配置文件位于/etc/ssh/sshd_config, 修改后需要重启ssh: 1sudo /etc/init.d/sshresart 保持长连接只需要在ssh命令后加上发送心跳即可:1ssh -o ServerAliveInterval=30 root@123.456.88 -p 2333 生成SSH密钥和公钥打开终端, 使用下面的ssh-keygen来生成RSA密钥和公钥. -t表示type, 就是说要生成RSA加密的钥匙:1ssh-keygen -t rsa -C "your_email@youremail.com" RSA也是默认的加密类型, 所以你也可以只输入ssh-keygen, 默认的RSA长度是2048位, 如果你非常注重安全, 那么可以指定4096位的长度:1ssh-keygen -b 4096 -t rsa -C "your_email@youremail.com" 生成SSH Key的过程中会要求你指定一个文件来保存密钥, 按Enter键使用默认的文件就行了, 然后需要输入一个密码来加密你的SSH Key, 密码至少要20位长度, SSH密钥会保存在home目录下的.ssh/id_rsa文件中, SSH公钥保存在.ssh/id_rsa.pub文件中.1234567891011121314151617181920Generating public/private rsa key pair.Enter file in which to save the key (/home/matrix/.ssh/id_rsa): #按Enter键Enter passphrase (empty for no passphrase): #输入一个密码Enter same passphrase again: #再次输入密码Your identification has been saved in /home/matrix/.ssh/id_rsa.Your public key has been saved in /home/matrix/.ssh/id_rsa.pub.The key fingerprint is:e1:dc:ab:ae:b6:19:b0:19:74:d5:fe:57:3f:32:b4:d0 matrix@vividThe key&apos;s randomart image is:+---[RSA 4096]----+| .. || . . || . . .. . || . . o o.. E .|| o S ..o ...|| = ..+...|| o . . .o .|| .o . || .++o |+-----------------+ 文件传输姿势:12345# 传输单个文件scp -P &lt;端口&gt; &lt;源文件&gt; &lt;目标文件&gt;# 传输文件夹scp -P &lt;端口&gt; -r &lt;源文件夹&gt; &lt;目标文件夹&gt; 注意-P要在前面例如把本地的file复制到远程服务器:1scp -P 2333 /home/ybd/file root@123.456.78:/root/file 免密码登录远程服务器姿势一使用上述scp把公钥上传到服务器, 然后:1cat id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys 姿势二可以使用ssh-copy-id命令来完成:1ssh-copy-id &lt;用户名&gt;@&lt;服务器ip&gt; -p &lt;端口&gt; 输入远程用户的密码后, SSH公钥就会自动上传了, SSH公钥保存在远程Linux服务器的.ssh/authorized_keys文件中. 别名alias简化命令只需要在当前用户目录加上别名命令, 但博主用的是zsh, 所有配置在.zshrc而不是.bashrc12echo "alias vps='ssh -o ServerAliveInterval=30 root@172.104.65.190 -p 2333'" &gt;&gt; ~/.zshrcsource ~/.zshrc 然后直接输入vps就可以登陆远程服务器了. 切换用户使用su命令切换用户, ex:1su - ybd 这样就切换到了ybd用户su -就是su -l(l为login的意思), l可以省略, 所以一般写成su -…..(坑爹)如果不加用户名, 默认是 su root切换root用户.注意: su 和 su -的区别 前者是直接切换, 还保留了当前位置以及变量 而后者不单单切换了用户, 而且还切换到了用户目录, 并且之前用户的环境变量没有了！ 因为这个原因, 写Dockerfile困扰了好一段时间…囧 还有su也可以使用某个用户的身份执行一些命令, ex:1234# 执行单个命令su - $&#123;USER_NAME&#125; -c &quot;npm install -g hexo-cli&quot;# 执行shell脚本su - $&#123;USER_NAME&#125; -s /bin/bash shell.sh 执行完之后还是保持当前用户.可以通过exit退出当前用户. ufw防火墙安装Ubuntu自带ufw, 没有可以直接安装: 1sudo get install ufw 查看端口是否开启1telnet 192.168.1.103 80 设置默认规则大多数系统只需要打开少量的端口接受传入连接, 并且关闭所有剩余的端口. 从一个简单的规则基础开始, ufw default命令可以用于设置对传入和传出连接的默认响应动作. 要拒绝所有传入并允许所有传出连接, 那么运行: 12sudo ufw default allow outgoingsudo ufw default deny incoming 查看本地的端口开启情况1sudo ufw status 打开80端口1sudo ufw allow 80 允许从一个 IP 地址连接1sudo ufw allow from 123.45.67.89 允许特定子网的连接1sudo ufw allow from 123.45.67.89/24 允许特定 IP/ 端口的组合1sudo ufw allow from 123.45.67.89 to any port 22 proto tcp 防火墙开启/禁用1234# 开启sudo ufw enable# 禁用sudo ufw disable 防火墙重启:1sudo ufw reload 用户与用户组相关添加用户useradd ex:创建ybd用户并且加入ybd用户组并且创建用户目录: 123useradd -g ybd -m ybd# 或者user add -m -U ybd 修改密码1passwd ybd 修改用户usermod 添加用户组groupadd 修改用户组 ex:将test组的名子改成test21groupmod -n test2 test 删除组test21groupdel test2 查看组查看当前登录用户所在的组:1groups 查看用户test所在组:1groups test 查看所有组:1cat /etc/group 修改用户名 usermod不允许你改变正在线上的使用者帐号名称. 当usermod用来改变userID, 必须确认这名user没在电脑上执行任何程序, 否则会报“usermod: user xxx is currently logged in”错误. 因此必须root用户登录或者其他用户登录然后切换到root身份, 而不能在当前用户下切换至root进行修改. 1、以root身份登录 2、usermod -l hadoop seed该命令相当于做了两件事: 将/etc/passwd下的用户名栏从seed修改为hadoop, 其他部分不变 将/etc/shadow下的用户名栏从seed修改为hadoop, 其他部分不变 3、usermod -c hadoop hadoop 相当于将/etc/passwd下的注解栏修改为hadoop, 其他部分不变 4、groupmod -n hadoop seed 将原来的用户组seed修改为hadoop, 只修改组名, 组标识号不变, 相当于修改了文件/etc/group和/etc/gshadow 5、usermod -md /home/hadoop hadoop相当于做了两件事: 将~下的登入目录栏修改为/home/hadoop, 其他部分不变 将原来的用户目录/home/seed修改为新的用户目录/home/hadoop 网络相关curl 来自: https://itbilu.com/linux/man/4yZ9qH_7X.html curl是一个开源的用于数据传输的命令行工具与库，它使用URL语法格式，支持众多传输协议，包括：HTTP、HTTPS、FTP、FTPS、GOPHER、TFTP、SCP、SFTP、SMB、TELNET、DICT、LDAP、LDAPS、FILE、IMAP、SMTP、POP3、RTSP和RTMP。curl库提供了很多强大的功能，你可以利用它来进行HTTP/HTTPS请求、上传/下载文件等，且支持Cookie、认证、代理、限速等。 直接访问: 1curlyangbingdong.com 重定向跟踪 页面使用了重定向，这时我们可以添加-L参数来跟踪URL重定向： 1curl -L https://git.io/vokNn 页面保存 1curl -o [文件名] https://git.io/vokNn 查看头信息 如果需要查看访问页面的可以添加-i或--include参数： 1curl -i yangbingdong.com 添加-i参数后，页面响应头会和页面源码（响应体）一块返回。如果只想查看响应头，可以使用-I或--head参数. POST数据提交 curl使用POST提交表单数据时，除了-X参数指定请求方法外，还要使用--data参数添加提交数据： 1curl -X POST --data &apos;keyword=linux&apos; itbilu.com 添加请求头 有时在进行HTTP请求时，需要自定义请求头。在curl中，可以通过-H或--header参数来指定请求头。多次使用-H或--header参数可指定多个请求头。 如，指定Content-Type及Authorization请求头： 1curl -H &apos;Content-Type:application/json&apos; -H &apos;Authorization: bearer eyJhbGciOiJIUzI1NiJ9&apos; itbilu.com Cookie支持 Cookie是一种常用的保持服务端会话信息的方法，crul也支持使用Cookie。 可以通过--cookie参数指定发送请求时的Cookie值，也可以通过-b [文件名]来指定一个存储了Cookie值的本地文件： 1curl -b stored_cookies_in_file itbilu.com Cookie值可能会被服务器所返回的值所修改，并应用于下次HTTP请求。这时，可以能过-c参数指定存储服务器返回Cookie值的存储文件： 1curl -b cookies.txt -c newcookies.txt itbilu.com 递归下载抓取整个网站内容1wget -r -p -k -np &lt;URL&gt; 参数说明:-r: 递归下载-p: 下载所有用于显示 HTML 页面的图片之类的元素-k: 在转换文件 X 前先将它备份为 X.orig-np: 不追溯至父目录 跟踪日志输出1234tail -f &lt;log&gt;# 输出最后1000行tail -1000 &lt;log&gt; 统计文件夹大小1du -hs `ls -al |awk &apos;&#123;print $9&#125;&apos;` 上面命令可以统计文件夹中所有的文件夹和文件的大小, 并且包括隐藏目录. 缺点是连上级目录也会统计. 如果不需要列出上级目录, 则把ls命令的-a换成-A, 就不会列出点文件了.1du -hs `ls -Al |awk &apos;&#123;print $9&#125;&apos;` 如果不需要列出文件, 只需文件夹, 则在ls中增加-d参数即可123du -hs `ls -Adl |awk &apos;&#123;print $9&#125;&apos;`或du -hs `ls -Al |grep ^d|awk &apos;&#123;print $9&#125;&apos;` 压缩和解压缩打包但是不压缩(tar): tar -cf &lt;压缩包文件名&gt; &lt;要打包的目录&gt;打包并压缩(tar.gz): tar -zcf &lt;压缩包文件名&gt; &lt;要打包的目录&gt; 解压缩tar文件: tar -xvf &lt;压缩包文件&gt;解压缩tar.gz文件: tar -zxvf &lt;压缩包文件&gt; 目录与文件 以下转载于http://blog.csdn.net/wzzfeitian/article/details/40985549 find命令find &lt; path &gt; &lt; expression &gt; &lt; cmd &gt; path: 所要搜索的目录及其所有子目录. 默认为当前目录. expression: 所要搜索的文件的特征. cmd: 对搜索结果进行特定的处理. 如果什么参数也不加, find默认搜索当前目录及其子目录, 并且不过滤任何结果（也就是返回所有文件）, 将它们全都显示在屏幕上. find命令常用选项及实例-name 按照文件名查找文件.12find /dir -name filename 在/dir目录及其子目录下面查找名字为filename的文件find . -name &quot;*.c&quot; 在当前目录及其子目录（用“.”表示）中查找任何扩展名为“c”的文件 -perm 按照文件权限来查找文件.1find . -perm 755 –print 在当前目录下查找文件权限位为755的文件, 即文件属主可以读、写、执行, 其他用户可以读、执行的文件 -prune 使用这一选项可以使find命令不在当前指定的目录中查找, 如果同时使用-depth选项, 那么-prune将被find命令忽略. 12find /apps -path &quot;/apps/bin&quot; -prune -o –print 在/apps目录下查找文件, 但不希望在/apps/bin目录下查找find /usr/sam -path &quot;/usr/sam/dir1&quot; -prune -o –print 在/usr/sam目录下查找不在dir1子目录之内的所有文件 -depth: 在查找文件时, 首先查找当前目录中的文件, 然后再在其子目录中查找. 1find / -name &quot;CON.FILE&quot; -depth –print 它将首先匹配所有的文件然后再进入子目录中查找 -user 按照文件属主来查找文件. 1find ~ -user sam –print 在$HOME目录中查找文件属主为sam的文件 -group 按照文件所属的组来查找文件. 1find /apps -group gem –print 在/apps目录下查找属于gem用户组的文件 -mtime -n +n 按照文件的更改时间来查找文件, -n表示文件更改时间距现在n天以内, +n表示文件更改时间距现在n天以前. 12find / -mtime -5 –print 在系统根目录下查找更改时间在5日以内的文件find /var/adm -mtime +3 –print 在/var/adm目录下查找更改时间在3日以前的文件 -nogroup 查找无有效所属组的文件, 即该文件所属的组在/etc/groups中不存在. 1find / –nogroup -print -nouser 查找无有效属主的文件, 即该文件的属主在/etc/passwd中不存在. 1find /home -nouser –print -newer file1 ! file2 查找更改时间比文件file1新但比文件file2旧的文件. -type 查找某一类型的文件, 诸如: b - 块设备文件. d - 目录. c - 字符设备文件. p - 管道文件. l - 符号链接文件. f - 普通文件. 123find /etc -type d –print 在/etc目录下查找所有的目录find . ! -type d –print 在当前目录下查找除目录以外的所有类型的文件find /etc -type l –print 在/etc目录下查找所有的符号链接文件 -size n[c] 查找文件长度为n块的文件, 带有c时表示文件长度以字节计.123find . -size +1000000c –print 在当前目录下查找文件长度大于1 M字节的文件find /home/apache -size 100c –print 在/home/apache目录下查找文件长度恰好为100字节的文件find . -size +10 –print 在当前目录下查找长度超过10块的文件（一块等于512字节） -mount 在查找文件时不跨越文件系统mount点. find . -name “*.XC” -mount –print 从当前目录开始查找位于本文件系统中文件名以XC结尾的文件（不进入其他文件系统） -follow 如果find命令遇到符号链接文件, 就跟踪至链接所指向的文件 -exec find命令对匹配的文件执行该参数所给出的shell命令. 相应命令的形式为command {} \, 注意{}和\;之间的空格 12345678$ find ./ -size 0 -exec rm &#123;&#125; \; 删除文件大小为零的文件$ rm -i `find ./ -size 0` $ find ./ -size 0 | xargs rm -f &amp;为了用ls -l命令列出所匹配到的文件, 可以把ls -l命令放在find命令的-exec选项中: $ find . -type f -exec ls -l &#123;&#125; \;在/logs目录中查找更改时间在5日以前的文件并删除它们: find /logs -type f -mtime +5 -exec rm &#123;&#125; \; -ok, 和-exec的作用相同, 只不过以一种更为安全的模式来执行该参数所给出的shell命令, 在执行每一个命令之前, 都会给出提示, 让用户来确定是否执行. 1find . -name &quot;*.conf&quot; -mtime +5 -ok rm &#123;&#125; \; 在当前目录中查找所有文件名以.LOG结尾、更改时间在5日以上的文件, 并删除它们, 只不过在删除之前先给出提示 说明: 如果你要寻找一个档案的话, 那么使用 find 会是一个不错的主意. 不过, 由于 find 在寻找数据的时候相当的耗硬盘, 所以没事情不要使用 find 啦！有更棒的指令可以取代呦, 那就是 whereis 与 locate 咯~ 一些常用命令123456789101112131415161718192021221. find . -type f -exec ls -l &#123;&#125; \;查找当前路径下的所有普通文件, 并把它们列出来. 2. find logs -type f -mtime +5 -exec rm &#123;&#125; \;删除logs目录下更新时间为5日以上的文件. 3.find . -name &quot;*.log&quot; -mtime +5 -ok rm &#123;&#125; \;删除当前路径下以. log结尾的五日以上的文件, 删除之前要确认. 4. find ~ -type f -perm 4755 -print查找$HOME目录下suid位被设置, 文件属性为755的文件打印出来. 说明: find在有点系统中会一次性得到将匹配到的文件都传给exec, 但是有的系统对exec的命令长度做限制, 就会报: ”参数列太长“, 这就需要使用xargs. xargs是部分取传来的文件. 5. find / -type f -print |xargs filexargs测试文件分类6. find . -name &quot;core*&quot; -print|xargs echo &quot; &quot;&gt;/tmp/core.log将core文件信息查询结果报存到core. log日志. 7. find / -type f -print | xargs chmod o -w8. find . -name * -print |xargs grep &quot;DBO&quot; grep命令1grep [选项] pattern [文件名] 命令中的选项为: -? 同时显示匹配行上下的？行, 如: grep -2 pattern filename 同时显示匹配行的上下2行. -b, —byte-offset 打印匹配行前面打印该行所在的块号码. -c,—count 只打印匹配的行数, 不显示匹配的内容. -f File, —file=File 从文件中提取模板. 空文件中包含0个模板, 所以什么都不匹配. -h, —no-filename 当搜索多个文件时, 不显示匹配文件名前缀. -i, —ignore-case 忽略大小写差别. -q, —quiet 取消显示, 只返回退出状态. 0则表示找到了匹配的行. -l, —files-with-matches 打印匹配模板的文件清单. -L, —files-without-match 打印不匹配模板的文件清单. -n, —line-number 在匹配的行前面打印行号. -s, —silent 不显示关于不存在或者无法读取文件的错误信息. -v, —revert-match 反检索, 只显示不匹配的行. -w, —word-regexp 如果被\&lt;和&gt;引用, 就把表达式做为一个单词搜索. -V, —version 显示软件版本信息. 123456789101112ls -l | grep &apos;^a&apos; 通过管道过滤ls -l输出的内容, 只显示以a开头的行. grep &apos;test&apos; d* 显示所有以d开头的文件中包含test的行. grep &apos;test&apos; aa bb cc 显示在aa, bb, cc文件中匹配test的行. grep &apos;[a-z]&apos; aa 显示所有包含每个字符串至少有5个连续小写字符的字符串的行. grep &apos;w(es)t.*&apos; aa 如果west被匹配, 则es就被存储到内存中, 并标记为1, 然后搜索任意个字符(.*), 这些字符后面紧跟着另外一个es(), 找到就显示该行. 如果用egrep或grep -E, 就不用&quot;&quot;号进行转义, 直接写成&apos;w(es)t.*&apos;就可以了. grep -i pattern files : 不区分大小写地搜索. 默认情况区分大小写grep -l pattern files : 只列出匹配的文件名, grep -L pattern files : 列出不匹配的文件名, grep -w pattern files : 只匹配整个单词, 而不是字符串的一部分(如匹配‘magic’, 而不是‘magical’), grep -C number pattern files : 匹配的上下文分别显示[number]行, grep pattern1 | pattern2 files : 显示匹配 pattern1 或 pattern2 的行, grep pattern1 files | grep pattern2 : 显示既匹配 pattern1 又匹配 pattern2 的行. pattern为所要匹配的字符串, 可使用下列模式1234567. 匹配任意一个字符* 匹配0 个或多个*前的字符^ 匹配行开头$ 匹配行结尾[] 匹配[ ]中的任意一个字符, []中可用 - 表示范围, 例如[a-z]表示字母a 至z 中的任意一个\ 转意字符 xargs命令【xargs定位参数位置 | xargs控制参数位置 | 如何定位控制xargs参数位置】背景:管道 + xargs用于把上游输出转换为下游参数输入.例如 ls *.bak | xargs rm -f 问题:xargs默认把输入作为参数放到命令的最后, 但是很多命令需要自己定位参数的位置, 比如拷贝命令cp {上游结果} destFolder 解决方法:xargs 使用大写字母i 定义参数指示符 -I &lt;指示符&gt;, 然后用这个参数指示符定位参数插入的位置, 例如: 1ls *.bak | xargs -I % cp % /tmp/test 注释: 这里使用%作为指示符, 第一个%可以理解为声明, 第二个%可以理解为调用. 你也可以用其他字符, 比如 ls *.bak | xargs -I {} cp {} /tmp/test 简介之所以能用到xargs这个命令, 关键是由于很多命令不支持|管道来传递参数, 而日常工作中有有这个必要, 所以就有了xargs命令, 例如: 12find /sbin -perm +700 | ls -l 这个命令是错误的find /sbin -perm +700 | xargs ls -l 这样才是正确的 xargs 可以读入 stdin 的资料, 并且以空白字元或断行字元作为分辨, 将 stdin 的资料分隔成为 arguments . 因为是以空白字元作为分隔, 所以, 如果有一些档名或者是其他意义的名词内含有空白字元的时候, xargs 可能就会误判了～选项解释-0 当sdtin含有特殊字元时候, 将其当成一般字符, 像/ ‘ 空格等 123root@localhost:~/test#echo &quot;//&quot;|xargs echoroot@localhost:~/test#echo &quot;//&quot;|xargs -0 echo/ -a file 从文件中读入作为sdtin 123root@localhost:~/test#cat test#!/bin/shecho &quot;hello world/n&quot;root@localhost:~/test#xargs -a test echo#!/bin/sh echo hello world/nroot@localhost:~/test# -e flag , 注意有的时候可能会是-E, flag必须是一个以空格分隔的标志, 当xargs分析到含有flag这个标志的时候就停止. 1234root@localhost:~/test#cat txt/bin tao shou kunroot@localhost:~/test#cat txt|xargs -E &apos;shou&apos; echo/bin tao -p 当每次执行一个argument的时候询问一次用户. 12root@localhost:~/test#cat txt|xargs -p echoecho /bin tao shou kun ff ?...y/bin tao shou kun ff -n num 后面加次数, 表示命令在执行的时候一次用的argument的个数, 默认是用所有的 1234567root@localhost:~/test#cat txt|xargs -n1 echo/bintaoshoukunroot@localhost:~/test3#cat txt|xargs echo/bin tao shou ku -t 表示先打印命令, 然后再执行. 12root@localhost:~/test#cat txt|xargs -t echoecho /bin tao shou kun/bin tao shou kun -i 或者是-I, 这得看linux支持了, 将xargs的每项名称, 一般是一行一行赋值给{}, 可以用{}代替. 1$ ls | xargs -t -i mv &#123;&#125; &#123;&#125;.bak -r no-run-if-empty 当xargs的输入为空的时候则停止xargs, 不用再去执行了. 12root@localhost:~/test#echo &quot;&quot;|xargs -t -r mvroot@localhost:~/test# -s num 命令行的最大字符数, 指的是xargs后面那个命令的最大命令行字符数 1234567root@localhost:~/test#cat test |xargs -i -x -s 14 echo &quot;&#123;&#125;&quot;exp1exp5filexargs: argument line too longlinux-2root@localhost:~/test# -L num Use at most max-lines nonblank input lines per command line.-s是含有空格的. -l 同-L -d delim 分隔符, 默认的xargs分隔符是回车, argument的分隔符是空格, 这里修改的是xargs的分隔符 123456789101112131415161718192021root@localhost:~/test#cat txt |xargs -i -p echo &#123;&#125;echo /bin tao shou kun ?...yroot@localhost:~/test#cat txt |xargs -i -p -d &quot; &quot; echo &#123;&#125;echo /bin ?...yecho tao ?.../binyecho shou ?...tao再如: root@localhost:~/test#cat test |xargs -i -p -d &quot; &quot; echo &#123;&#125;echo exp1exp5filelinux-2ngis_posttaotesttxtxen-3?...yroot@localhost:~/test#cat test |xargs -i -p echo &#123;&#125;echo exp1 ?...yecho exp5 ?...exp1yecho file ?...exp5y -x exit的意思, 主要是配合-s使用. -P 修改最大的进程数, 默认是1, 为0时候为as many as it can 其他查找命令1. locate命令locate命令其实是“find -name”的另一种写法, 但是要比后者快得多, 原因在于它不搜索具体目录, 而是搜索一个数据库（/var/lib/locatedb）, 这个数据库中含有本地所有文件信息. Linux系统自动创建这个数据库, 并且每天自动更新一次, 所以使用locate命令查不到最新变动过的文件. 为了避免这种情况, 可以在使用locate之前, 先使用updatedb命令, 手动更新数据库. locate命令的使用实例: 1234$ locate /etc/sh搜索etc目录下所有以sh开头的文件. $ locate -i ~/m搜索用户主目录下, 所有以m开头的文件, 并且忽略大小写. 2. whereis命令whereis命令只能用于程序名的搜索, 而且只搜索二进制文件（参数-b）、man说明文件（参数-m）和源代码文件（参数-s）. 如果省略参数, 则返回所有信息. whereis命令的使用实例: 12$ whereis grepgrep: /bin/grep /usr/share/man/man1p/grep.1p.gz /usr/share/man/man1/grep.1.gz 3. which命令which命令的作用是, 在PATH变量指定的路径中, 搜索某个系统命令的位置, 并且返回第一个搜索结果. 也就是说, 使用which命令, 就可以看到某个系统命令是否存在, 以及执行的到底是哪一个位置的命令. which命令的使用实例: 12$ which grep/bin/grep sed命令 sed是stream editor的简称，也就是流编辑器。它一次处理一行内容，处理时，把当前处理的行存储在临时缓冲区中，称为“模式空间”（pattern space），接着用sed命令处理缓冲区中的内容，处理完成后，把缓冲区的内容送往屏幕。接着处理下一行，这样不断重复，直到文件末尾。文件内容并没有 改变，除非你使用重定向存储输出。 sed命令常用的使用方法为： 1sed [option] &apos;command&apos; input_file 常见的option选项： -n 使用安静(silent)模式（想不通为什么不是-s）。在一般sed的用法中，所有来自stdin的内容一般都会被列出到屏幕上。但如果加上-n参数后，则只有经过sed特殊处理的那一行(或者动作)才会被列出来；-e 直接在指令列模式上进行 sed 的动作编辑；-f 直接将 sed 的动作写在一个文件内， -f filename 则可以执行filename内的sed命令；-r 让sed命令支持扩展的正则表达式(默认是基础正则表达式)；-i 直接修改读取的文件内容，而不是由屏幕输出。 常用的命令： a\： append即追加字符串， a \的后面跟上字符串s(多行字符串可以用\n分隔)，则会在当前选择的行的后面都加上字符串s； c\： 取代/替换字符串，c \后面跟上字符串s(多行字符串可以用\n分隔)，则会将当前选中的行替换成字符串s； d： delete即删除，该命令会将当前选中的行删除； i\： insert即插入字符串，i \后面跟上字符串s(多行字符串可以用\n分隔)，则会在当前选中的行的前面都插入字符串s； p： print即打印，该命令会打印当前选择的行到屏幕上； s： 替换，通常s命令的用法是这样的：1，2s/old/new/g，将old字符串替换成new字符串；其中的g 表示global全局替换，如果没有global的话，只会替换每一行中的第一个匹配的内容； =： 显示文件行号 在sed 命令中的定位问题： 定址用于决定对哪些行进行编辑。地址的形式可以是数字、正则表达式、或二者的结合。如果没有指定地址，sed将处理输入文件的所有行。 如： 3，表示第3行， 1,5 表示第1-5行， $ 表示最后一行； /sb/ 表示包含sb的行， /sb/, /2b/ 表示包含 sb至包含 2b的行； /^ha.*day$/ 表示以ha开头，以day结尾的行 s/\(.*\)line$/\1/g 表示：\(\)包裹的内容表示正则表达式的第n部分，序号从1开始计算。本例中只有一个\(\)所以\(.*\)表示正则表达式的第一部分，这部分匹配任意字符串，所以\(.*\)line$匹配的就是以line结尾的任何行。用\1表示匹配到的第一部分，同样\2表示第二部分，\3表示第三部分，可以依次这样引用。 所以，它的意思是把每一行的line删除掉。 系统监控查看磁盘空间1df -hl 显示格式为: 123文件系统 容量 已用 可用 已用% 挂载点 Filesystem Size Used Avail Use% Mounted on df -hl 查看磁盘剩余空间 df -h 查看每个根路径的分区大小 du -sh [目录名] 返回该目录的大小 du -sm [文件夹] 返回该文件夹总M数 查看内存使用情况free: 1234root@localhost:~# free -h total used free shared buff/cache availableMem: 989M 121M 87M 7.0M 781M 662MSwap: 255M 14M 241M letsencrypt 自动脚本https://github.com/Neilpang/acme.sh Extend使用systemd设置开机启动 ubuntu从16.04开始不再使用initd管理系统, 改用systemd 为了像以前一样, 在/etc/rc.local中设置开机启动程序, 需要以下几步: 1、systemd默认读取/etc/systemd/system下的配置文件, 该目录下的文件会链接/lib/systemd/system/下的文件. 一般系统安装完/lib/systemd/system/下会有rc-local.service文件, 即我们需要的配置文件. 链接过来: 1ln -fs /lib/systemd/system/rc-local.service /etc/systemd/system/rc-local.service 12cd /etc/systemd/system/vim rc-local.service rc-local.service内容: 123456789101112131415161718192021222324# This file is part of systemd.## systemd is free software; you can redistribute it and/or modify it# under the terms of the GNU Lesser General Public License as published by# the Free Software Foundation; either version 2.1 of the License, or# (at your option) any later version.# This unit gets pulled automatically into multi-user.target by# systemd-rc-local-generator if /etc/rc.local is executable.[Unit]Description=/etc/rc.local CompatibilityConditionFileIsExecutable=/etc/rc.localAfter=network.target[Service]Type=forkingExecStart=/etc/rc.local startTimeoutSec=0RemainAfterExit=yesGuessMainPID=no[Install]WantedBy=multi-user.targetAlias=rc-local.service 2、创建/etc/rc.local文件 1touch /etc/rc.local 3、赋可执行权限 1chmod 755 /etc/rc.local 4、编辑rc.local, 添加需要开机启动的任务 123#!/bin/bashecho &quot;test test &quot; &gt; /var/test_boot_up.log 5、执行reboot重启系统验证OK. 最后, 说一下/etc/systemd/system/下的配置文件（XXXX.service）,其中有三个配置项, [Unit] / [Service] / [Install] [Unit] 区块: 启动顺序与依赖关系. [Service] 区块: 启动行为,如何启动, 启动类型. [Install] 区块, 定义如何安装这个配置文件, 即怎样做到开机启动. apt-get update无法下载 出现类似情况, 可以找到/etc/apt/sources.list.d目录, 删除对应的.list文件即可. printf进制转换 二进制:binanry number 八进制:otcal number 十进制:decimal number 十六进制: hexadecimal number 一般使用jstack查找线程时候用到 十进制转16进制: 1printf &quot;%x\n&quot; 666 输出的是29a, 一般16进制前面会加个0x表示, 所以可以这样: 1printf &quot;0x%x\n&quot; 666 16进制转十进制: 1printf &quot;%d\n&quot; 0x29a Shell自动交互输入重定向Here Document12345678910#!/bin/bashftp -i -n 192.168.167.187 &lt;&lt; EOFuser hzc 123456pwdcd testpwdclosebyeEOF 管道，echo + sleep + |1234567#!/bin/bash(echo &quot;curpassword&quot;sleep 1echo &quot;newpassword&quot;sleep 1echo &quot;newpassword&quot;)|passwd expect1sudo apt-get install expect]]></content>
      <categories>
        <category>OperatingSystem</category>
        <category>Ubuntu</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker入坑笔记]]></title>
    <url>%2F2017%2Fdocker-learning%2F</url>
    <content type="text"><![CDATA[Preface Docker是什么？下面是官方的一段说明:Docker is the world’s leading software containerization platform.恩, 很niubility, 引领世界软件容器化的平台…本篇主要记录Docker的基础学习（安装、简单使用） Containerization VS Virtualization了解Docker之前, 我们有必要了解一下容器化 容器相当于轻量级的虚拟机, 但隔离性不如虚拟机. Story Long long ago… Dev: “帮我构建几台跟生产环境一样的测试服务器” Ops: “给我一个星期时间” Dev: “明天用…” Ops: “开发的这群傻叉新给的发布包又把系统CPU搞到100%了, 应用又夯住了, 都是些什么水平的人啊…” Dev: “运维的这帮傻鸟技术太差, 维护的是些什么稀烂的系统, 在我这跑得好好的, 上他们那应用就挂…” Ops: “这是开发的锅…” Dev: “这是运维的盘…” Q: 线上线下环境不一致, 线上JDK1.8.01,线下JDK1.8.02, 数据库版本不统一等环境问题 单机安装和配置MySQL、Memcatched、MongoDB、Hadoop、GlusterFS、RabbitMQ、Node.js、Nginx已经够复杂, 集群更不用说 最终引发的问题就是, 我们的服务方是用户, 受害方也是用户… 各司其职的同时也在两者之间形成了一面无形的墙, 阻碍了开发和运维之间的沟通和协作, 而Docker、DevOps的出现就是为了击碎这堵无形之墙. Docker核心理念: Build, Ship, and Run Any App, Anywhere (Java的核心理念: Write once, run anywhere) Docker是GO语言编写的容器化的一种实现, 是一个分布式应用构建、迁移和运行的开放平台, 它允许开发或运维人员将应用和运行应用所依赖的文件打包到一个标准化的单元（容器）中运行. 其他的容器实现有OpenVZ, Pouch(Ali出品)等. 服务器好比运输码头: 拥有场地和各种设备（服务器硬件资源） 服务器容器化好比作码头上的仓库: 拥有独立的空间堆放各种货物或集装箱 (仓库之间完全独立, 独立的应用系统和操作系统） 实现的核心技术: lcx、cgroup、namespaces…（Linux内核级别隔离技术） 注意点: 不能乱玩…遵循单一职责, 无状态. Docker实现DevOps的优势优势一: 开发、测试和生产环境的统一化和标准化. 镜像作为标准的交付件, 可在开发、测试和生产环境上以容器来运行, 最终实现三套环境上的应用以及运行所依赖内容的完全一致. 优势二: 解决底层基础环境的异构问题. 基础环境的多元化造成了从Dev到Ops过程中的阻力, 而使用Docker Engine可无视基础环境的类型. 不同的物理设备, 不同的虚拟化类型, 不同云计算平台, 只要是运行了Docker Engine的环境, 最终的应用都会以容器为基础来提供服务. 优势三: 易于构建、迁移和部署. Dockerfile实现镜像构建的标准化和可复用, 镜像本身的分层机制也提高了镜像构建的效率. 使用Registry可以将构建好的镜像迁移到任意环境, 而且环境的部署仅需要将静态只读的镜像转换为动态可运行的容器即可. 优势四: 轻量和高效. 和需要封装操作系统的虚拟机相比, 容器仅需要封装应用和应用需要的依赖文件, 实现轻量的应用运行环境, 且拥有比虚拟机更高的硬件资源利用率. 优势五: 工具链的标准化和快速部署. 将实现DevOps所需的多种工具或软件进行Docker化后, 可在任意环境实现一条或多条工具链的快速部署. 适合敏捷开发、持续交付 核心概念以下是Docker的三个基本概念. Image(镜像)官方而言, Docker 镜像是一个特殊的文件系统, 除了提供容器运行时所需的程序、库、资源、配置等文件外, 还包含了一些为运行时准备的一些配置参数（如匿名卷、环境变量、用户等）. 镜像不包含任何动态数据, 其内容在构建之后也不会被改变.对博主而言, 它相当于就是个Java Class(类)=.= 但它的存储结构类似Git, 一层一层地网上盖, 删除一个文件并不会真的删除, 只是在那个文件上面做了一个标记为已删除. 在最终容器运行的时候, 虽然不会看到这个文件, 但是实际上该文件会一直跟随镜像. 因此, 在构建镜像的时候, 需要额外小心, 每一层尽量只包含该层需要添加的东西, 任何额外的东西应该在该层构建结束前清理掉. Container(容器) 通俗来说, 如果镜像是类, 那么容器就是这个类的实例了, 镜像是静态的定义, 容器是镜像运行时的实体. 容器可以被创建、启动、停止、删除、暂停等. 容器也有其特性, 例如存储, 不指定数据卷(Volume)的话, 容器消亡数据也就跟着没了…跟多特性请自行百度~ Repository(仓库)仓库没啥好说的了, 以 Ubuntu 镜像 为例, ubuntu 是仓库的名字, 其内包含有不同的版本标签, 如, 14.04, 16.04. 我们可以通过 ubuntu:14.04, 或者 ubuntu:16.04 来具体指定所需哪个版本的镜像. 如果忽略了标签, 比如 ubuntu, 那将视为 ubuntu:latest 安装这里以Ubuntu为例（当然是因为博主用的是Ubuntu= =）, 版本的话Docker目前支持的Ubuntu版本最低为12.04LTS,但从稳定性上考虑,推荐使用14.04LTS或更高的版本. 使用脚本自动安装在测试或开发环境中 Docker 官方为了简化安装流程, 提供了一套便捷的安装脚本, Ubuntu 系统上可以使用这套脚本安装:12curl -fsSL get.docker.com -o get-docker.shsudo sh get-docker.sh --mirror Aliyun 执行这个命令后, 脚本就会自动的将一切准备工作做好, 并且把 Docker 安装在系统中 使用 APT 镜像源 安装123456sudo apt-get updatesudo apt-get install \ apt-transport-https \ ca-certificates \ curl \ software-properties-common 鉴于国内网络问题, 强烈建议使用国内源 国内源12345curl -fsSL https://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add -sudo add-apt-repository \ &quot;deb [arch=amd64] https://mirrors.aliyun.com/docker-ce/linux/ubuntu \ $(lsb_release -cs) \ stable&quot; 以上命令会添加 稳定 版本的 Docker CE APT 镜像源, 如果需要最新版本的 Docker CE 请将 stable 改为 edge 或者 test . 从 Docker 17.06 开始, edge test 版本的 APT 镜像源也会包含稳定版本的 Docker 官方源12345curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -sudo add-apt-repository \ &quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu \ $(lsb_release -cs) \ stable&quot; 安装 Docker CE12sudo apt-get updatesudo apt-get install docker-ce 启动 Docker CE12sudo systemctl enable dockersudo systemctl start docker 建立 docker 用户组默认情况下, docker 命令会使用 Unix socket 与 Docker 引擎通讯. 而只有 root 用户和 docker 组的用户才可以访问 Docker 引擎的 Unix socket. 出于安全考虑, 一般 Linux 系统上不会直接使用 root 用户. 因此, 更好地做法是将需要使用 docker 的用户加入 docker 用户组.建立 docker 组(貌似执行了自动安装脚本会自动建一个docker的用户组):1sudo groupadd docker 将当前用户加入 docker 组:1sudo usermod -aG docker $USER 加入docker 组之后要重启才能生效哦… Mirror Acceleration没有代理的话国内访问Docker Hub的速度实在感人, 但Docker官方和国内很多云服务商都提供了加速器服务: Docker 官方提供的中国registry mirror 阿里云加速器 DaoCloud 加速器 灵雀云加速器 如阿里, 注册并申请后会得到加速域名如https://vioqnt8w.mirror.aliyuncs.com, 然后正如官方说的一样, 通过修改daemon配置文件/etc/docker/daemon.json来使用加速器:12345678sudo mkdir -p /etc/dockersudo tee /etc/docker/daemon.json &lt;&lt;-&apos;EOF&apos;&#123; &quot;registry-mirrors&quot;: [&quot;https://vioqnt8w.mirror.aliyuncs.com&quot;]&#125;EOFsudo systemctl daemon-reloadsudo systemctl restart docker 查看生效: 1sudo docker info|grep &quot;Registry Mirrors&quot; -A 1 输出如下: 12Registry Mirrors: https://vioqnt8w.mirror.aliyuncs.com/ 镜像的相关操作获取Docker Hub 上有大量的高质量的镜像可以用, 我们可以通过以下的方式获取镜像:1docker pull [选项] [Docker Registry地址]&lt;仓库名&gt;:&lt;标签&gt; 选项可以通过docker pull --help查看.eg, 从Docker Hub下载REPOSITORY为java的所有镜像:1docker pull -a java 列出使用docker images [OPTIONS] [REPOSITORY[:TAG]]列出已下载的镜像列表包含了仓库名、标签、镜像 ID、创建时间以及所占用的空间 OPTIONS说明:123456-a :列出本地所有的镜像（含中间映像层, 默认情况下, 过滤掉中间映像层）；--digests :显示镜像的摘要信息；-f :显示满足条件的镜像；--format :指定返回值的模板文件；--no-trunc :显示完整的镜像信息；-q :只显示镜像ID. eg:12# 看到在 mongo:3.2 之后建立的镜像,想查看某个位置之前的镜像也可以, 只需要把 since 换成 before 即可docker images -f since=mongo:3.2 虚悬镜像(dangling image)举个例子: 原来为 mongo:3.2, 随着官方镜像维护, 发布了新版本后, 重新 docker pull mongo:3.2 时, mongo:3.2 这个镜像名被转移到了新下载的镜像身上, 而旧的镜像上的这个名称则被取消, 从而成为了 &lt;none&gt;. 除了 docker pull 可能导致这种情况, docker build 也同样可以导致这种现象. 由于新旧镜像同名, 旧镜像名称被取消, 从而出现仓库名、标签均为 &lt;none&gt; 的镜像. 这类无标签镜像也被称为 虚悬镜像(dangling image) , 可以用下面的命令专门显示这类镜像:1docker images -f dangling=true 一般来说, 虚悬镜像已经失去了存在的价值, 是可以随意删除的, 可以用下面的命令删除:1docker rmi $(docker images -q -f dangling=true) Commit从容器创建一个新的镜像:1docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]] OPTIONS说明:1234-a :提交的镜像作者；-c :使用Dockerfile指令来创建镜像；-m :提交时的说明文字；-p :在commit时, 将容器暂停. eg:1docker commit -a &quot;ybd&quot; -m &quot;my apache&quot; a404c6c174a2 mymysql:v1 当我们修改了镜像文件提交时候, 可以使用docker diff [OPTIONS] CONTAINER查看修改了什么东西.一般地, 不推荐使用commit来构建镜像, 之前也提过, 镜像是特殊的文件系统, 改了东西之后原来的基础之上叠加, 使之变得越来越臃肿. 此外, 使用 docker commit 意味着所有对镜像的操作都是黑箱操作, 生成的镜像也被称为黑箱镜像, 换句话说, 就是除了制作镜像的人知道执行过什么命令、怎么生成的镜像, 别人根本无从得知. 一般我们会使用Dockerfile定制镜像. 删除删除镜像可以使用:1docker rmi [OPTIONS] IMAGE [IMAGE...] OPTIONS说明:12-f :强制删除；--no-prune :不移除该镜像的过程镜像, 默认移除； 一般会组合使用: 12345docker rmi $(docker images -q -f dangling=true)docker rmi $(docker images -q redis)docker rmi $(docker images -q -f before=mongo:3.2) 查看元数据docker inspect : 获取容器/镜像的元数据. 1docker inspect [OPTIONS] CONTAINER|IMAGE [CONTAINER|IMAGE...] OPTIONS说明: 123-f :指定返回值的模板文件. -s :显示总的文件大小. --type :为指定类型返回JSON. 实例 获取镜像mysql:5.6的元信息. 1234567891011121314151617181920212223~: docker inspect mysql:5.6[ &#123; &quot;Id&quot;: &quot;sha256:2c0964ec182ae9a045f866bbc2553087f6e42bfc16074a74fb820af235f070ec&quot;, &quot;RepoTags&quot;: [ &quot;mysql:5.6&quot; ], &quot;RepoDigests&quot;: [], &quot;Parent&quot;: &quot;&quot;, &quot;Comment&quot;: &quot;&quot;, &quot;Created&quot;: &quot;2016-05-24T04:01:41.168371815Z&quot;, &quot;Container&quot;: &quot;e0924bc460ff97787f34610115e9363e6363b30b8efa406e28eb495ab199ca54&quot;, &quot;ContainerConfig&quot;: &#123; &quot;Hostname&quot;: &quot;b0cf605c7757&quot;, &quot;Domainname&quot;: &quot;&quot;, &quot;User&quot;: &quot;&quot;, &quot;AttachStdin&quot;: false, &quot;AttachStdout&quot;: false, &quot;AttachStderr&quot;: false, &quot;ExposedPorts&quot;: &#123; &quot;3306/tcp&quot;: &#123;&#125; &#125;,... 获取正在运行的容器mymysql的 IP. 12~: docker inspect -f &apos;&apos; mymysql172.17.0.3 查看容器内部IP: 12docker inspect --format=&apos;&#123;\&#123;.NetworkSettings.IPAddress&#125;&#125;&apos; CONTAINER（注: 由于代码块解析的问题, 上面NetworkSettings前面的 \ 去掉） 标签docker tag: 1docker tag IMAGE/CONTAINER TAG ex: 1234将同一IMAGE_ID的所有tag, 合并为一个新的# docker tag 195eb2565349 ybd/ubuntu:rm_test新建一个tag, 保留旧的那条记录# docker tag Registry/Repos:Tag New_Registry/New_Repos:New_Tag 保存镜像到归档文件docker save : 将指定镜像保存成 tar 归档文件. 1docker save [OPTIONS] IMAGE [IMAGE...] OPTIONS说明: 1-o :输出到的文件. 实例 将镜像runoob/ubuntu:v3 生成my_ubuntu_v3.tar文档 runoob@runoob:~$ docker save -o my_ubuntu_v3.tar runoob/ubuntu:v3 导入镜像Importdocker import : 从归档文件中创建镜像. 1docker import [OPTIONS] file|URL|- [REPOSITORY[:TAG]] OPTIONS说明: 123-c :应用docker 指令创建镜像；-m :提交时的说明文字； 例如: 1docker import ubuntu.tar ybd/ubuntu:v1 LoadUsage: docker load [OPTIONS] Load an image from a tar archive or STDIN Options: 123-i, --input string Read from tar archive file, instead of STDIN-q, --quiet Suppress the load output 区别 首先, docker import可以重新指定镜像的名字, docker load不可以 其次, 我们发现导出后的版本会比原来的版本稍微小一些. 那是因为导出后, 会丢失历史和元数据. 执行下面的命令就知道了:显示镜像的所有层(layer)docker images --tree执行命令, 显示下面的内容. 正你看到的, 导出后再导入(exported-imported)的镜像会丢失所有的历史, 而保存后再加载（saveed-loaded）的镜像没有丢失历史和层(layer). 这意味着使用导出后再导入的方式, 你将无法回滚到之前的层(layer), 同时, 使用保存后再加载的方式持久化整个镜像, 就可以做到层回滚（可以执行docker tag 来回滚之前的层）. 容器的相关操作开启docker run : 创建一个新的容器并运行一个命令 docker create : 创建一个新的容器但不启动它12docker run [OPTIONS] IMAGE [COMMAND] [ARG...]docker create [OPTIONS] IMAGE [COMMAND] [ARG...] docker run OPTIONS说明:123456789101112131415161718192021222324252627282930313233-a stdin: 指定标准输入输出内容类型, 可选 STDIN/STDOUT/STDERR 三项；-d: 后台运行容器, 并返回容器ID；-i: 以交互模式运行容器, 通常与 -t 同时使用；-t: 为容器重新分配一个伪输入终端, 通常与 -i 同时使用；-v: 挂载数据卷--name=&quot;nginx-lb&quot;: 为容器指定一个名称；--restart=always: docker启动容器也跟着启动--dns 8.8.8.8: 指定容器使用的DNS服务器, 默认和宿主一致；--dns-search example.com: 指定容器DNS搜索域名, 默认和宿主一致；-h &quot;mars&quot;: 指定容器的hostname；-e username=&quot;ritchie&quot;: 设置环境变量；--env-file=[]: 从指定文件读入环境变量；--cpuset=&quot;0-2&quot; or --cpuset=&quot;0,1,2&quot;: 绑定容器到指定CPU运行；-m :设置容器使用内存最大值；--net=&quot;bridge&quot;: 指定容器的网络连接类型, 支持 bridge/host/none/container: 四种类型；--link=[]: 添加链接到另一个容器；--expose=[]: 开放一个端口或一组端口； &lt;b&gt;实例&lt;/b&gt; 例如, 启动一个 bash 终端, 允许用户进行交互:1docker run -t -i ubuntu:14.04 /bin/bash 当利用 docker run 来创建容器时, Docker 在后台运行的标准操作包括: 检查本地是否存在指定的镜像, 不存在就从公有仓库下载 利用镜像创建并启动一个容器 分配一个文件系统, 并在只读的镜像层外面挂载一层可读写层 从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去 从地址池配置一个 ip 地址给容器 执行用户指定的应用程序 执行完毕后容器被终止 启动一个es并指明healthcheck相关策略: 1234567docker run --rm -d \ --name=elasticsearch \ --health-cmd=&quot;curl --silent --fail localhost:9200/_cluster/health || exit 1&quot; \ --health-interval=5s \ --health-retries=12 \ --health-timeout=2s \ elasticsearch:5.5 暂停docker pause :暂停容器中所有的进程. docker unpause :恢复容器中所有的进程. 123docker pause [OPTIONS] CONTAINER [CONTAINER...]docker unpause [OPTIONS] CONTAINER [CONTAINER...] 实例 暂停数据库容器db01提供服务. 1docker pause db01 恢复数据库容器db01提供服务. 1docker unpause db01 停止docker stop :停止一个运行中的容器:1docker stop [OPTIONS] CONTAINER [CONTAINER...] 杀掉容器docker kill :杀掉一个运行中的容器. 1docker kill [OPTIONS] CONTAINER [CONTAINER...] OPTIONS说明: 1-s :向容器发送一个信号 实例 杀掉运行中的容器mynginx 1docker kill -s KILL mynginx 进入容器使用docker exec :1docker exec [OPTIONS] CONTAINER COMMAND [ARG...] OPTIONS说明:12345-d :分离模式: 在后台运行-i :即使没有附加也保持STDIN 打开-t :分配一个伪终端 例如进入ubuntu容器交互式模式:1docker exec -it ubuntu /bin/sh 或者使用docker attach: 1docker attach --sig-proxy=false CONTAINER attach是可以带上--sig-proxy=false来确保CTRL-D或CTRL-C不会关闭容器. 导出容器导出容器快照1docker export [OPTIONS] CONTAINER 例如:1docker export 7691a814370e &gt; ubuntu.tar 删除1docker rm [OPTIONS] CONTAINER [CONTAINER...] OPTIONS说明:12345-f :通过SIGKILL信号强制删除一个运行中的容器-l :移除容器间的网络连接, 而非容器本身-v :-v 删除与容器关联的卷 删除所有容器:1docker rm $(docker ps -a -q) 但这并不会删除运行中的容器 列出容器1docker ps [OPTIONS] OPTIONS说明:123456789101112131415-a :显示所有的容器, 包括未运行的. -f, --filter :根据条件过滤显示的内容. --format :指定返回值的模板文件. -l :显示最近创建的容器. -n :列出最近创建的n个容器. --no-trunc :不截断输出. -q :静默模式, 只显示容器编号. -s :显示总的文件大小. 例如列出最近创建的5个容器信息:1docker ps -n 5 列出所有创建的容器ID:1docker ps -a -q 下面是docker官方的filter参数: Filter Description id Container’s ID name Container’s name label An arbitrary string representing either a key or a key-value pair. Expressed as &lt;key&gt; or &lt;key&gt;=&lt;value&gt; exited An integer representing the container’s exit code. Only useful with --all. status One of created, restarting, running, removing, paused, exited, or dead ancestor Filters containers which share a given image as an ancestor. Expressed as &lt;image-name&gt;[:&lt;tag&gt;], &lt;image id&gt;, or &lt;image@digest&gt; before or since Filters containers created before or after a given container ID or name volume Filters running containers which have mounted a given volume or bind mount. network Filters running containers connected to a given network. publish or expose Filters containers which publish or expose a given port. Expressed as &lt;port&gt;[/&lt;proto&gt;] or &lt;startport-endport&gt;/[&lt;proto&gt;] health Filters containers based on their healthcheck status. One of starting, healthy, unhealthy or none. isolation Windows daemon only. One of default, process, or hyperv. is-task Filters containers that are a “task” for a service. Boolean option (true or false) ex 列出所有状态为退出的容器: 1docker ps -q --filter status=exited 查看日志1docker logs [OPTIONS] CONTAINER OPTIONS说明: 1234567-f : 跟踪日志输出--since :显示某个开始时间的所有日志-t : 显示时间戳--tail :仅列出最新N条容器日志 数据拷贝docker cp :用于容器与主机之间的数据拷贝. 123docker cp [OPTIONS] CONTAINER:SRC_PATH DEST_PATH|-docker cp [OPTIONS] SRC_PATH|- CONTAINER:DEST_PATH OPTIONS说明: 1-L :保持源目标中的链接 实例 将主机/www/runoob目录拷贝到容器96f7f14e99ab的/www目录下. 1docker cp /www/runoob 96f7f14e99ab:/www/ 将主机/www/runoob目录拷贝到容器96f7f14e99ab中, 目录重命名为www. 1docker cp /www/runoob 96f7f14e99ab:/www 将容器96f7f14e99ab的/www目录拷贝到主机的/tmp目录中. 1docker cp 96f7f14e99ab:/www /tmp/ Volume的相关操作Usage: docker volume COMMAND Command Description docker volume create Create a volume docker volume inspect Display detailed information on one or more volumes docker volume ls List volumes docker volume prune Remove all unused volumes docker volume rm Remove one or more volumes ex 删除所有悬浮的volume: 1docker volume rm $(docker volume ls -q -f dangling=true) 选择 -v 还是 -–mount 参数Docker 新用户应该选择 --mount 参数, 经验丰富的 Docker 使用者对 -v 或者 --volume 已经很熟悉了, 但是推荐使用 --mount 参数. 使用 --mount 标记可以指定挂载一个本地主机的目录到容器中去. 12345$ docker run -d -P \--name web \--mount type=bind,source=/src/webapp,target=/opt/webapp \training/webapp \python app.py 上面的命令加载主机的 /src/webapp 目录到容器的 /opt/webapp目录. 这个功能在进行测试的时候十分方便, 比如用户可以放置一些程序到本地目录中, 来查看容器是否正常工作. 本地目录的路径必须是绝对路径, 以前使用 -v 参数时如果本地目录不存在 Docker 会自动为你创建一个文件夹, 现在使用 --mount 参数时如果本地目录不存在, Docker 会报错. Docker 挂载主机目录的默认权限是 读写, 用户也可以通过增加 readonly 指定为 只读. 12345docker run -d -P \--name web \--mount type=bind,source=/src/webapp,target=/opt/webapp,readonly \training/webapp \python app.py Network的相关操作基本命令: 123456docker network createdocker network connectdocker network lsdocker network rmdocker network disconnectdocker network inspect 下面先创建一个新的 Docker 网络. 1docker network create -d bridge my-net -d 参数指定 Docker 网络类型, 有 bridge overlay. 其中 overlay 网络类型用于 Swarm mode 容器链接网络: 1docker run -it --rm --name busybox1 --network my-net busybox sh 创建一个Swarm mode网络: 1234567docker network create \--driver overlay \--opt encrypted \--attachable \--subnet 10.0.9.0/24 \--gateway 10.0.9.99 \my-network Dockerfile 详解 制作一个镜像可以使用docker commit和定制Dockerfile, 但推荐的是写Dockerfile. 因为docker commit是一个暗箱操作, 除了制作镜像的人知道执行过什么命令、怎么生成的镜像, 别人根本无从得知, 而且会加入一些没用的操作导致镜像臃肿. Build Images首先在当前空目录创建一个Dockerfile:123456789101112131415161718192021222324FROM ubuntu:latestENV BLOG_PATH /root/blogENV NODE_VERSION 6MAINTAINER yangbingdong &lt;yangbingdong1994@gmail.com&gt;RUN \ apt-get update -y &amp;&amp; \ apt-get install -y git curl libpng-dev &amp;&amp; \ curl -sL https://deb.nodesource.com/setup_$NODE_VERSION.x | bash - &amp;&amp; \ apt-get install -y nodejs &amp;&amp; \ apt-get clean &amp;&amp; \ apt-get autoclean &amp;&amp; \ rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/* &amp;&amp; \ npm install -g hexo-cliWORKDIR $BLOG_PATHVOLUME [&quot;$BLOG_PATH&quot;, &quot;/root/.ssh&quot;]EXPOSE 4000CMD [&apos;/bin/bash&apos;] 然后在当前目录打开终端:1docker build -t &lt;repo-name&gt;/&lt;image-name&gt;:&lt;tag&gt; . 其中&lt;repo-name&gt;表示仓库名, 与远程仓库（如docker hub）名字要一致, &lt;tag&gt;表示标签, 不给默认latest, 都是可选项, 例如可以写成这样:1docker build -t &lt;image-name&gt; . 看到Successfully built就表示构建成功了 注意docker build 命令最后有一个 .表示构建的上下文, 镜像构建需要把上下文的东西上传到Docker引擎去构建. Dockerfile 指令From 指定基础镜像所谓定制镜像, 那一定是以一个镜像为基础, 在其上进行定制. 而 FROM 就是指定基础镜像, 因此一个 Dockerfile 中 FROM 是必备的指令, 并且必须是第一条指令. 在 Docker Hub上有非常多的高质量的官方镜像, 有可以直接拿来使用的服务类的镜像, 如 nginx、redis、mongo、mysql、httpd、php、tomcat 等； 也有一些方便开发、构建、运行各种语言应用的镜像, 如 node、openjdk、python、ruby、golang 等. 可以在其中寻找一个最符合我们最终目标的镜像为基础镜像进行定制. 如果没有找到对应服务的镜像, 官方镜像中还提供了一些更为基础的操作系统镜像, 如 ubuntu、debian、centos、fedora、alpine 等, 这些操作系统的软件库为我们提供了更广阔的扩展空间. 除了选择现有镜像为基础镜像外, Docker 还存在一个特殊的镜像, 名为 scratch. 这个镜像是虚拟的概念, 并不实际存在, 它表示一个空白的镜像. RUN 执行命令RUN 指令是用来执行命令行命令的. 由于命令行的强大能力, RUN 指令在定制镜像时是最常用的指令之一. 其格式有两种: shell 格式: RUN &lt;命令&gt;, 就像直接在命令行中输入的命令一样. 刚才写的 Dockrfile 中的 RUN 指令就是这种格式. 1RUN echo &apos;&lt;h1&gt;Hello, Docker!&lt;/h1&gt;&apos; &gt; /usr/share/nginx/html/index.html exec 格式: RUN [&quot;可执行文件&quot;, &quot;参数1&quot;, &quot;参数2&quot;], 这更像是函数调用中的格式. 注意: RUN命令尽量精简, 也就是像上面一样一个RUN（使用$$ \）, 如果分开写很多个RUN会导致镜像铺了很多层从而臃肿. RUN最后记住清理掉没用的垃圾, 很多人初学 Docker 制作出了很臃肿的镜像的原因之一, 就是忘记了每一层构建的最后一定要清理掉无关文件. COPY 复制文件格式: COPY &lt;源路径&gt;... &lt;目标路径&gt; COPY [&quot;&lt;源路径1&gt;&quot;,... &quot;&lt;目标路径&gt;&quot;] 和 RUN 指令一样, 也有两种格式, 一种类似于命令行, 一种类似于函数调用. COPY 指令将从构建上下文目录中 &lt;源路径&gt; 的文件/目录复制到新的一层的镜像内的 &lt;目标路径&gt; 位置. 比如:1COPY package.json /usr/src/app/ ADD 更高级的复制文件ADD 指令和 COPY 的格式和性质基本一致. 但是在 COPY 基础上增加了一些功能. 比如 &lt;源路径&gt; 可以是一个 URL, 这种情况下, Docker 引擎会试图去下载这个链接的文件放到 &lt;目标路径&gt; 去. 下载后的文件权限自动设置为 600, 如果这并不是想要的权限, 那么还需要增加额外的一层 RUN进行权限调整, 另外, 如果下载的是个压缩包, 需要解压缩, 也一样还需要额外的一层 RUN 指令进行解压缩. 所以不如直接使用 RUN 指令, 然后使用 wget 或者 curl 工具下载, 处理权限、解压缩、然后清理无用文件更合理. 因此, 这个功能其实并不实用, 而且不推荐使用. 如果 &lt;源路径&gt; 为一个 tar 压缩文件的话, 压缩格式为 gzip, bzip2 以及 xz 的情况下, ADD 指令将会自动解压缩这个压缩文件到 &lt;目标路径&gt; 去. 在某些情况下, 这个自动解压缩的功能非常有用, 比如官方镜像 ubuntu 中: 123FROM scratchADD ubuntu-xenial-core-cloudimg-amd64-root.tar.gz /... 但在某些情况下, 如果我们真的是希望复制个压缩文件进去, 而不解压缩, 这时就不可以使用 ADD 命令了. 在 Docker 官方的最佳实践文档中要求, 尽可能的使用 COPY, 因为 COPY 的语义很明确, 就是复制文件而已, 而 ADD 则包含了更复杂的功能, 其行为也不一定很清晰. 最适合使用 ADD 的场合, 就是所提及的需要自动解压缩的场合. 另外需要注意的是, ADD 指令会令镜像构建缓存失效, 从而可能会令镜像构建变得比较缓慢. 因此在 COPY 和 ADD 指令中选择的时候, 可以遵循这样的原则, 所有的文件复制均使用 COPY 指令, 仅在需要自动解压缩的场合使用 ADD. CMD 容器启动命令CMD 指令就是用于指定默认的容器主进程的启动命令的. CMD 指令的格式和 RUN 相似, 也是两种格式: shell 格式: CMD &lt;命令&gt; exec 格式: CMD [&quot;可执行文件&quot;, &quot;参数1&quot;, &quot;参数2&quot;...] 参数列表格式: CMD [&quot;参数1&quot;, &quot;参数2&quot;...]. 在指定了 ENTRYPOINT 指令后, 用 CMD 指定具体的参数. 在运行时可以指定新的命令来替代镜像设置中的这个默认命令, 比如, ubuntu 镜像默认的 CMD 是 /bin/bash, 如果我们直接 docker run -it ubuntu 的话, 会直接进入 bash. 我们也可以在运行时指定运行别的命令, 如 docker run -it ubuntu cat /etc/os-release. 这就是用 cat /etc/os-release 命令替换了默认的 /bin/bash 命令了, 输出了系统版本信息. 在指令格式上, 一般推荐使用 exec 格式, 这类格式在解析时会被解析为 JSON 数组, 因此一定要使用双引号 &quot;, 而不要使用单引号. 如果使用 shell 格式的话, 实际的命令会被包装为 sh -c 的参数的形式进行执行. 比如:1CMD echo $HOME 在实际执行中, 会将其变更为:1CMD [ &quot;sh&quot;, &quot;-c&quot;, &quot;echo $HOME&quot; ] 所以如果使用shell格式会导致容器莫名退出, 因为实际上执行的事sh命令, 而sh命令执行完时候容器也就没有存在的意义. ENTRYPOINT 入口点ENTRYPOINT 的格式和 RUN 指令格式一样, 分为 exec 格式和 shell 格式. ENTRYPOINT 的目的和 CMD 一样, 都是在指定容器启动程序及参数. ENTRYPOINT 在运行时也可以替代, 不过比 CMD 要略显繁琐, 需要通过 docker run 的参数 --entrypoint 来指定. 当指定了 ENTRYPOINT 后, CMD 的含义就发生了改变, 不再是直接的运行其命令, 而是将 CMD 的内容作为参数传给 ENTRYPOINT 指令, 换句话说实际执行时, 将变为: 1&lt;ENTRYPOINT&gt; &quot;&lt;CMD&gt;&quot; 这个指令非常有用, 例如可以把命令后面的参数传进来或启动容器前准备一些环境然后执行启动命令（通过脚本exec &quot;$@&quot;）. ENV 设置环境变量格式有两种: ENV &lt;key&gt; &lt;value&gt; ENV &lt;key1&gt;=&lt;value1&gt; &lt;key2&gt;=&lt;value2&gt;... 这个指令很简单, 就是设置环境变量而已, 无论是后面的其它指令, 如 RUN, 还是运行时的应用, 都可以直接使用这里定义的环境变量. ex: 1234ENV NODE_VERSION 6...RUN curl -sL https://deb.nodesource.com/setup_$NODE_VERSION.x | bash - &amp;&amp; \... ARG 构建参数格式: ARG &lt;参数名&gt;[=&lt;默认值&gt;] 构建参数和 ENV 的效果一样, 都是设置环境变量. 所不同的是, ARG 所设置的构建环境的环境变量, 在将来容器运行时是不会存在这些环境变量的. 但是不要因此就使用 ARG 保存密码之类的信息, 因为 docker history 还是可以看到所有值的. Dockerfile 中的 ARG 指令是定义参数名称, 以及定义其默认值. 该默认值可以在构建命令 docker build 中用 --build-arg &lt;参数名&gt;=&lt;值&gt; 来覆盖. 在 1.13 之前的版本, 要求 --build-arg 中的参数名, 必须在 Dockerfile 中用 ARG 定义过了, 换句话说, 就是 --build-arg 指定的参数, 必须在 Dockerfile 中使用了. 如果对应参数没有被使用, 则会报错退出构建. 从 1.13 开始, 这种严格的限制被放开, 不再报错退出, 而是显示警告信息, 并继续构建. 这对于使用 CI 系统, 用同样的构建流程构建不同的 Dockerfile 的时候比较有帮助, 避免构建命令必须根据每个 Dockerfile 的内容修改. VOLUME 定义匿名卷格式为: VOLUME [&quot;&lt;路径1&gt;&quot;, &quot;&lt;路径2&gt;&quot;...] VOLUME &lt;路径&gt; 之前我们说过, 容器运行时应该尽量保持容器存储层不发生写操作, 对于数据库类需要保存动态数据的应用, 其数据库文件应该保存于卷(volume)中, 后面的章节我们会进一步介绍 Docker 卷的概念. 为了防止运行时用户忘记将动态文件所保存目录挂载为卷, 在 Dockerfile 中, 我们可以事先指定某些目录挂载为匿名卷, 这样在运行时如果用户不指定挂载, 其应用也可以正常运行, 不会向容器存储层写入大量数据.1VOLUME /data 这里的 /data 目录就会在运行时自动挂载为匿名卷, 任何向 /data 中写入的信息都不会记录进容器存储层, 从而保证了容器存储层的无状态化. 当然, 运行时可以覆盖这个挂载设置. 比如:1docker run -d -v mydata:/data xxxx 在这行命令中, 就使用了 mydata 这个命名卷挂载到了 /data 这个位置, 替代了 Dockerfile 中定义的匿名卷的挂载配置. EXPOSE 声明端口格式为 EXPOSE &lt;端口1&gt; [&lt;端口2&gt;...].EXPOSE 指令是声明运行时容器提供服务端口, 这只是一个声明, 在运行时并不会因为这个声明应用就会开启这个端口的服务. 在 Dockerfile 中写入这样的声明有两个好处, 一个是帮助镜像使用者理解这个镜像服务的守护端口, 以方便配置映射；另一个用处则是在运行时使用随机端口映射时, 也就是 docker run -P时, 会自动随机映射 EXPOSE 的端口. 此外, 在早期 Docker 版本中还有一个特殊的用处. 以前所有容器都运行于默认桥接网络中, 因此所有容器互相之间都可以直接访问, 这样存在一定的安全性问题. 于是有了一个 Docker 引擎参数 --icc=false, 当指定该参数后, 容器间将默认无法互访, 除非互相间使用了 --links 参数的容器才可以互通, 并且只有镜像中 EXPOSE 所声明的端口才可以被访问. 这个 --icc=false 的用法, 在引入了 docker network后已经基本不用了, 通过自定义网络可以很轻松的实现容器间的互联与隔离. 要将 EXPOSE 和在运行时使用 -p &lt;宿主端口&gt;:&lt;容器端口&gt; 区分开来. -p, 是映射宿主端口和容器端口, 换句话说, 就是将容器的对应端口服务公开给外界访问, 而 EXPOSE 仅仅是声明容器打算使用什么端口而已, 并不会自动在宿主进行端口映射. WORKDIR 指定工作目录格式为 WORKDIR &lt;工作目录路径&gt;.使用 WORKDIR 指令可以来指定工作目录（或者称为当前目录）, 以后各层的当前目录就被改为指定的目录, 如该目录不存在, WORKDIR 会帮你建立目录. 之前提到一些初学者常犯的错误是把 Dockerfile 等同于 Shell 脚本来书写, 这种错误的理解还可能会导致出现下面这样的错误:12RUN cd /appRUN echo &quot;hello&quot; &gt; world.txt 如果将这个 Dockerfile 进行构建镜像运行后, 会发现找不到 /app/world.txt 文件, 或者其内容不是 hello. 原因其实很简单, 在 Shell 中, 连续两行是同一个进程执行环境, 因此前一个命令修改的内存状态, 会直接影响后一个命令；而在 Dockerfile 中, 这两行 RUN 命令的执行环境根本不同, 是两个完全不同的容器. 这就是对 Dokerfile 构建分层存储的概念不了解所导致的错误. 之前说过每一个 RUN 都是启动一个容器、执行命令、然后提交存储层文件变更. 第一层 RUN cd /app 的执行仅仅是当前进程的工作目录变更, 一个内存上的变化而已, 其结果不会造成任何文件变更. 而到第二层的时候, 启动的是一个全新的容器, 跟第一层的容器更完全没关系, 自然不可能继承前一层构建过程中的内存变化. 因此如果需要改变以后各层的工作目录的位置, 那么应该使用 WORKDIR 指令. USER 指定当前用户格式: USER &lt;用户名&gt; USER 指令和 WORKDIR 相似, 都是改变环境状态并影响以后的层. WORKDIR 是改变工作目录, USER则是改变之后层的执行 RUN, CMD 以及 ENTRYPOINT 这类命令的身份. 当然, 和 WORKDIR 一样, USER 只是帮助你切换到指定用户而已, 这个用户必须是事先建立好的, 否则无法切换. 123RUN groupadd -r redis &amp;&amp; useradd -r -g redis redisUSER redisRUN [ &quot;redis-server&quot; ] HEALTHCHECK 健康检查格式: HEALTHCHECK [选项] CMD &lt;命令&gt;: 设置检查容器健康状况的命令 HEALTHCHECK NONE: 如果基础镜像有健康检查指令, 使用这行可以屏蔽掉其健康检查指令 HEALTHCHECK 支持下列选项: --interval=&lt;间隔&gt;: 两次健康检查的间隔, 默认为 30 秒； --timeout=&lt;间隔&gt;: 健康检查命令运行超时时间, 如果超过这个时间, 本次健康检查就被视为失败, 默认 30 秒； --retries=&lt;次数&gt;: 当连续失败指定次数后, 则将容器状态视为 unhealthy, 默认 3 次. --start-period=&lt;间隔&gt;: 应用的启动的初始化时间, 在启动过程中的健康检查失效不会计入, 默认 0 秒； (从17.05)引入 在 HEALTHCHECK [选项] CMD 后面的命令, 格式和 ENTRYPOINT 一样, 分为 shell 格式, 和 exec 格式. 命令的返回值决定了该次健康检查的成功与否: 0: 成功； 1: 失败； 2: 保留值, 不要使用 容器启动之后, 初始状态会为 starting (启动中). Docker Engine会等待 interval 时间, 开始执行健康检查命令, 并周期性执行. 如果单次检查返回值非0或者运行需要比指定 timeout 时间还长, 则本次检查被认为失败. 如果健康检查连续失败超过了 retries 重试次数, 状态就会变为 unhealthy (不健康). 注: 一旦有一次健康检查成功, Docker会将容器置回 healthy (健康)状态 当容器的健康状态发生变化时, Docker Engine会发出一个 health_status 事件. 假设我们有个镜像是个最简单的 Web 服务, 我们希望增加健康检查来判断其 Web 服务是否在正常工作, 我们可以用 curl来帮助判断, 其 Dockerfile 的 HEALTHCHECK 可以这么写: 1234FROM elasticsearch:5.5HEALTHCHECK --interval=5s --timeout=2s --retries=12 \ CMD curl --silent --fail localhost:9200/_cluster/health || exit 1 ENTRYPOINT与CMD使用区别 No ENTRYPOINT ENTRYPOINT entry arg0 ENTRYPOINT [“entry”, “arg0”] No CMD error, not allowed /bin/sh -c entry arg0 entry arg0 CMD [“cmd”, “arg1”] cmd arg1 /bin/sh -c entry arg0 entry arg0 cmd arg1 CMD cmd arg1 /bin/sh -c cmd arg1 /bin/sh -c entry arg0 entry arg0 /bin/sh -c cmd arg1 上表源于官方文档中的Understand how CMD and ENTRYPOINT interact, 有所简化. ENTRYPOINT和CMD至少要有一个. 使用ENTRYPOINT entry arg0形式, 与CMD将没有任何配合. 因此, 除非特定需求, 否则不推荐这种使用方式. 右下角entry arg0 /bin/sh -c cmd arg1这种形式, 几乎没有什么使用场景, 反而是常见错误, 应该尽量避免. 本质上, 其实可以理解为ENTRYPOINT是真正的Docker可执行入口, 而CMD则是可选参数. 之所以在很多情况下直接写CMD也能生效, 是因为ENTRYPOINT就相当于是指定Shell, 而CMD则是指定Shell中执行的命令. 注意, 只是『相当于』. 注意PID原则上, 一个Docker容器里应该只有一个进程, 其PID为1. Docker外部的操作, 比如docker stop, 就是向这个进程发送信号. 如果那个唯一的前台进程PID不为1, 那么就会收不到信号, 只能在超时（默认约10秒）后被kill. 在Dockerfile中使用ENTRYPOINT entry arg0这种形式时, entry的位置总是应该使用exec, 后面再接其它内容. 比如, ENTRYPOINT exec top, 这可以确保top命令是PID为1的进程. 否则, ENTRYPOINT top的形式, PID为1的进程就是/bin/sh -c top, 而top则被挤到了另外一个进程. 踩坑 Dockerfile里也需要注意权限问题（nodejs7版本以上不能正常安装hexo, 需要创建用户并制定权限去安装） 在docker容器里如果是root用户对挂载的文件进行了操作, 那么实际上挂载文件的权限也变成了root的 使用attach进入容器, 退出的时候容器也跟着退出了. . . 囧 每一个RUN是一个新的shell su -之前在启动脚本加了-, 导致环境变量以及工作目录都变了 Hexo Dockerfile12345678910111213141516171819202122232425262728293031323334353637FROM ubuntu:16.04MAINTAINER yangbingdong &lt;yangbingdong1994@gmail.com&gt;USER rootENV NODE_VERSION 8.9.4ENV NODE_DIR /opt/nodejsENV HOXO_DIR /root/hexoRUN apt-get update &amp;&amp; \ apt-get install -y git curl &amp;&amp; \ mkdir $&#123;NODE_DIR&#125; &amp;&amp; \ curl -L https://nodejs.org/dist/v$&#123;NODE_VERSION&#125;/node-v$&#123;NODE_VERSION&#125;-linux-x64.tar.gz | tar xvzf - -C $&#123;NODE_DIR&#125; --strip-components=1 ENV PATH $PATH:$&#123;NODE_DIR&#125;/binRUN npm install -g hexo-cliENV PATH $PATH:$&#123;NODE_DIR&#125;/binRUN cd /root &amp;&amp; \ hexo init hexo &amp;&amp; \ cd hexo &amp;&amp; \ git clone https://github.com/iissnan/hexo-theme-next themes/next &amp;&amp; \ npm install &amp;&amp; \ apt-get clean &amp;&amp; \ apt-get autoremove -y &amp;&amp; \ rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/*VOLUME [&quot;/root/hexo/source/_posts&quot;] WORKDIR /root/hexoCOPY docker-entrypoint.sh /docker-entrypoint.shENTRYPOINT [&quot;/docker-entrypoint.sh&quot;] docker-entrypoint.sh: 1234#!/bin/shset -ehexo clean &amp;&amp; hexo serverexec &quot;$@&quot; 修改Docker默认镜像, 容器存放位置方法一、软链接默认情况下Docker的存放位置为: /var/lib/docker可以通过下面命令查看具体位置: 1sudo docker info | grep &quot;Docker Root Dir&quot; 解决这个问题, 最直接的方法当然是挂载分区到这个目录, 但是我的数据盘还有其他东西, 这肯定不好管理, 所以采用修改镜像和容器的存放路径的方式达到目的. 这个方法里将通过软连接来实现. 首先停掉Docker服务: 123systemctl restart docker或者service docker stop 然后移动整个/var/lib/docker目录到目的路径: 12mv /var/lib/docker /root/data/dockerln -s /root/data/docker /var/lib/docker 这时候启动Docker时发现存储目录依旧是/var/lib/docker, 但是实际上是存储在数据盘的, 你可以在数据盘上看到容量变化. 方法二、修改镜像和容器的存放路径指定镜像和容器存放路径的参数是--graph=/var/lib/docker, 我们只需要修改配置文件指定启动参数即可. Docker 的配置文件可以设置大部分的后台进程参数, 在各个操作系统中的存放位置不一致, 在 Ubuntu 中的位置是: /etc/default/docker, 在 CentOS 中的位置是: /etc/sysconfig/docker. 如果是 CentOS 则添加下面这行: 1OPTIONS=--graph=&quot;/root/data/docker&quot; --selinux-enabled -H fd:// 如果是 Ubuntu 则添加下面这行（因为 Ubuntu 默认没开启 selinux）: 123OPTIONS=--graph=&quot;/root/data/docker&quot; -H fd://# 或者DOCKER_OPTS=&quot;-g /root/data/docker&quot; 最后重新启动, Docker 的路径就改成 /root/data/docker 了. 定期清理容器日志 参考: https://zhuanlan.zhihu.com/p/29051214 通过logrotate服务实现日志定期清理和回卷logrotate是个十分有用的工具, 它可以自动对日志进行截断（或轮循）、压缩以及删除旧的日志文件. 例如, 你可以设置logrotate, 让/var/log/foo日志文件每30天轮循, 并删除超过6个月的日志. 配置完后, logrotate的运作完全自动化, 不必进行任何进一步的人为干预. https://github.com/blacklabelops/logrotate 12345678docker run -d \ --restart=always \ --name=logrotate \ -v /var/lib/docker/containers:/var/lib/docker/containers \ -v /var/log/docker:/var/log/docker \ -e &quot;LOGS_DIRECTORIES=/var/lib/docker/containers /var/log/docker&quot; \ -e &quot;LOGROTATE_INTERVAL=daily&quot; \ blacklabelops/logrotate 通过修改dockerd参数进行回卷和清理在/etc/docker/daemon.json中添加log-driver以及log-opts参数: 12345678&#123; &quot;registry-mirrors&quot;: [&quot;https://vioqnt8w.mirror.aliyuncs.com&quot;], &quot;insecure-registries&quot;: [&quot;192.168.6.113:8888&quot;], &quot;log-driver&quot;:&quot;json-file&quot;, &quot;log-opts&quot;:&#123; &quot;max-size&quot; :&quot;10m&quot;,&quot;max-file&quot;:&quot;3&quot; &#125;&#125; 参数说明: 设置单个容器日志超过10M则进行回卷, 回卷的副本数超过3个就进行清理. 重启docker 1sudo systemctl daemon-reload &amp;&amp; sudo systemctl restart docker 数据卷备份与恢复数据卷备份12345docker run --rm \ --volumes-from &lt;ContainerName&gt; \ -v $(pwd):/backup \ busybox \ tar cvf /backup/backup.tar /data --rm: 执行完命令之后移除容器 --volumes-from &lt;Container&gt;: 连接要备份数据的容器 -v $(pwd):/backup: 挂载当前路径到容器 busybox 容器, 数据将会备份到此路径 busybox: 非常小的镜像 tar cvf /backup/backup.tar /data: 将 /data 路径下的文件打包到 backup.tar 数据卷恢复1、新建容器 1docker run -v /data --name &lt;ContainerName&gt; &lt;Image&gt; 2、恢复数据 12345docker run --rm \ --volumes-from &lt;ContainerName&gt; \ -v $(pwd):/backup \ busybox \ tar xvf /backup/backup.tar 注意: 其中的路径 /data 仅为示例, 具体需要备份的文件路径请结合自身需求. 使用Github自动构建Docker 一开始玩Docker总是用别人的镜像确实很爽歪歪…But, 如果要定制个性化的Image那就必须要自己写Dockerfile了, 但是每一次修改完Dockerfile, 都要经过几个步骤:Built -&gt; Push -&gt; Delete invalid images对于程序猿而言做重复的事情是很恐怖的, 所以博主选择Github自动构建Docker Image~ 创建用于自动构建的仓库在Github上面创建一个项目并把Dockerfile以及上下文需要用到的文件放到里面. 链接仓库服务首先需要绑定一个仓库服务（Github）: 1、登录Docker Hub；2、选择 Profile &gt; Settings &gt; Linked Accounts &amp; Services；3、选择需要连接的仓库服务（目前只支持Github和BitBucket）；4、这时候需要授权, 点击授权就可以了. 创建一个自动构建自动构建需要创建对应的仓库类型自动构建仓库也可以使用docker push把已有的镜像上传上去1、选择Create &gt; Create Automated Build；2、选择Github；3、接下来会列出User/Organizations的所有项目, 从中选择你需要的构建的项目（包含Dockerfile）；4、可以选择Click here to customize自定义路径；5、最后点击创建就可以了. 集成到Github用过Github自动构建当然需要Github的支持啦, 这里只需要在Github里面点两下就配置完成, 很方便:在Add Service里面找到Docker并添加 构建设置勾选自动构建系统会默认帮我们勾上自动构建选项:这时候, 当我们的Dockerfile有变动会自动触发构建:还在构建过程中我们可以点击Cancel取消构建过程. 添加新的构建Docker hub默认选择master分支作为latest版本, 我们可以根据自己的标签或分支构建不同的版本: （点击箭头位置会出现例子）这样, 当我们创建一个标签如1.0.2并push上去的时候会自动触发构建～ Git标签相关请看: Git标签管理 远程触发构建当然我们也可以远程触发构建, 同样在Build Setting页面:然后例子已经说的很清楚了 参考: https://docs.docker.com/docker-hub/builds/ 使用代理构建镜像有时候, 我们构建镜像需要在镜像内安装一些软件, 因为构建时采用的是bridge模式, 对于一些资源比较稀缺或需要科学上网才能安装的软件慢得简直无法忍受. 对此, 我们可以在构建时设置构建参数（--build-arg）从而达到代理安装的目的. 或者也可以用官方的Docker Hub自动构建, 或者将Dockerfile上传到VPS进行构建=.=…但感觉没必要. 例如像下面Dockerfile: 123456789FROM XXXXXXMAINTAINER ybd &lt;yangbingdong1994@gmail.com&gt; ARG HTTP_PROXYENV http_proxy=$&#123;HTTP_PROXY&#125; https_proxy=$&#123;HTTP_PROXY&#125;RUN apk update &amp;&amp; \ apk add --no-cache &amp;&amp; \ apk add curl bash tree tzdata .....ENV http_proxy=ENV https_proxy= 然后构建: 1docker build --build-arg HTTP_PROXY=192.168.6.113:8118 -t yangbingdong/oraclejdk8 . 192.168.6.113:8118是从Sock5转换过来的http代理 注意: 镜像内软件安装完成时候需要将代理置空, 所以上面示例最后两行后面的值是空的, 否则接下来容器内发生的网络访问都会走代理… 开启远程API注意: 这是一个危险动作, 仅测试使用, 生产慎用！ 某些应用可能需要使用Docker的远程API调用, 例如Portainer. 方式一, 修改配置文件打开/lib/systemd/system/docker.service, 将ExecStart=/usr/bin/docker daemon -H fd://修改为ExecStart=/usr/bin/docker daemon -H fd:// -H tcp://0.0.0.0:2375. 其中2375是就是远程调用端口. 然后重启Dcoker: 1sudo systemctl daemon-reload &amp;&amp; sudo service docker restart 方式二, 添加代理这种方式比较优雅点, 不需要重启Docker或更改配置文件: 1234567docker run -ti -d -p 2375:2375 \--restart=always \--hostname=$HOSTNAME \--name shipyard-proxy \-v /var/run/docker.sock:/var/run/docker.sock \-e PORT=2375 \shipyard/docker-proxy Self Usage Docker Or Compose以下是个人使用的一些容器运行命令或者docker-compose.yml, 不定时更新 Mysql运行实例: 1234567891011121314MYSQL_DATA=$&#123;HOME&#125;/data/docker/mysql/data &amp;&amp; \MYSQL_PORT=3306 &amp;&amp; \MYSQL_VERSION=latest &amp;&amp; \docker run --name=mysql \--restart=always \-p $&#123;MYSQL_PORT&#125;:3306 \-v $&#123;MYSQL_DATA&#125;:/var/lib/mysql \-e MYSQL_ROOT_PASSWORD=root \-d \mysql:$&#123;MYSQL_VERSION:-latest&#125; \--character-set-server=utf8mb4 \--collation-server=utf8mb4_unicode_ci \--sql-mode=STRICT_TRANS_TABLES,NO_ENGINE_SUBSTITUTION \--lower-case-table-names=1 链接Mysql服务端需要安装终端客户端: 1sudo apt install mysql-client 链接: 12mysql -h 127.0.0.1 -P 3306 -u root -p// 然后需要输入密码 Redis运行实例: 123456789101112REDIS_DATA=$&#123;HOME&#125;/data/docker/redis/data &amp;&amp; \REDIS_CONF=$&#123;HOME&#125;/data/docker/redis/redis.conf &amp;&amp; \REDIS_PORT=6379 &amp;&amp; \REDIS_VERSION=latest &amp;&amp; \docker run -p $&#123;REDIS_PORT&#125;:6379 \--restart=always \-v $&#123;REDIS_DATA&#125;:/usr/local/etc/redis/redis.conf \-v $&#123;REDIS_DATA&#125;:/data \--name redis \-d \redis:$&#123;REDIS_VERSION:-latest&#125; \redis-server /usr/local/etc/redis/redis.conf --appendonly yes 链接Redis服务端需要安装终端客户端: 1sudo apt install redis-tools 链接: 1redis-cli Portainer功能: 管理容器与swarm集群 单机版: 12345docker run -d -p 9000:9000 \--name portainer \--restart=always \-v /var/run/docker.sock:/var/run/docker.sock \portainer/portainer:&#123;PORTAINER_VERSION:-latest&#125; 集群版: 123456789PORTAINER_DATA=$&#123;HOME&#125;/data/docker/portainer/datadocker service create \--name portainer \--publish 9000:9000 \--constraint &apos;node.role == manager&apos; \--mount type=bind,src=/var/run/docker.sock,dst=/var/run/docker.sock \--mount type=bind,src=$&#123;PORTAINER_DATA&#125;,dst=/data \portainer/portainer:&#123;PORTAINER_VERSION:-latest&#125; \-H unix:///var/run/docker.sock Visualizer123456docker service create \--name=viz \--publish=8088:8080/tcp \--constraint=node.role==manager \--mount=type=bind,src=/var/run/docker.sock,dst=/var/run/docker.sock \dockersamples/visualizer Nexus3创建Volume : 1docker volume create --name nexus-data 运行实例: 12345678NEXUS_PORT=8090 &amp;&amp; \NEXUS_VERSION=3.6.2 &amp;&amp; \docker run --restart=always \-d \-p $&#123;NEXUS_PORT&#125;:8081 \--name nexus \-v nexus-data:/nexus-data \sonatype/nexus3:$&#123;NEXUS_VERSION&#125; 查看启动日志: 1docker logs nexus 备份: 123456789BAK_CONTAINER=ubuntu:latest &amp;&amp; \VOLUME=nexus-data &amp;&amp; \BAK_PATH=$&#123;PWD&#125; &amp;&amp; \BAK_ARCHIVE_NAME=nexus-data &amp;&amp; \docker run --rm \-v $&#123;BAK_PATH&#125;:/backup \-v $&#123;VOLUME&#125;:/backup-data \$&#123;BAK_CONTAINER&#125; \tar zcvf /backup/$&#123;BAK_ARCHIVE_NAME&#125;.tar.gz /backup-data 还原: 先要创建还原的Volume: 1docker volume create --name nexus-data1 然后: 12345678910BAK_CONTAINER=ubuntu:latest &amp;&amp; \RESTORE_VOLUME=nexus-data1 &amp;&amp; \BAK_PATH=$&#123;PWD&#125; &amp;&amp; \BAK_ARCHIVE_NAME=nexus-data &amp;&amp; \docker volume create --name $&#123;RESTORE_VOLUME&#125; &amp;&amp; \docker run --rm \-v $&#123;RESTORE_VOLUME&#125;:/restore \-v $&#123;BAK_PATH&#125;:/backup \ubuntu:latest \tar zxvf /backup/$&#123;BAK_ARCHIVE_NAME&#125;.tar.gz -C /restore --strip-components=1 Shadowsocks服务端: 12345678SS_PASSWORD=123456 &amp;&amp; \SS_PORT=22 &amp;&amp; \docker run -dt \--name ssserver \--restart=always \-p $&#123;SS_PORT&#125;:6443 \mritd/shadowsocks:latest \-m &quot;ss-server&quot; -s &quot;-s 0.0.0.0 -p 6443 -m aes-256-cfb -k $&#123;PASSWORD&#125; --fast-open&quot; 客户端: 123456789SS_IP=127.0.0.1 &amp;&amp; \SS_PORT=22 &amp;&amp; \SS_PASSWORD=123456 &amp;&amp; \docker run -d \--name ssclient \--restart=always \-p 1080:1080 \mritd/shadowsocks:latest \-m &quot;ss-local&quot; -s &quot;-s $&#123;SS_IP&#125; -p $&#123;SS_PORT&#125; -b 0.0.0.0 -l 1080 -m aes-256-cfb -k $&#123;SS_PASSWORD&#125; --fast-open&quot; 加速需要开启BBR Ngrok（服务端）运行实例: 123456NGROK_DATA=/root/docker/ngrok/data &amp;&amp; \NGROK_PORT=9000 &amp;&amp; \docker run -idt --name ngrok-server \-p $&#123;NGROK_PORT&#125;:80 -p 4432:443 -p 4443:4443 \-v $&#123;NGROK_DATA&#125;:/myfiles \-e DOMAIN=&apos;ngrok.yangbingdong.com&apos; hteen/ngrok /bin/sh /server.sh 详情: Docker搭建Ngrok Zookeeper集群docker-compose.yml: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576version: &apos;3.4&apos;services: zoo1: image: zookeeper:latest hostname: zoo1 environment: ZOO_MY_ID: 1 ZOO_SERVERS: server.1=0.0.0.0:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888 ports: - &quot;2181:2181&quot; deploy: mode: replicated replicas: 1 restart_policy: condition: on-failure delay: 5s max_attempts: 3 placement: constraints: - node.hostname == ybd-PC networks: zoo-net: aliases: - zookeeper1 zoo2: image: zookeeper:latest hostname: zoo2 environment: ZOO_MY_ID: 2 ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=0.0.0.0:2888:3888 server.3=zoo3:2888:3888 ports: - &quot;2182:2181&quot; deploy: mode: replicated replicas: 1 restart_policy: condition: on-failure delay: 5s max_attempts: 3 placement: constraints: - node.hostname == qww-PC networks: zoo-net: aliases: - zookeeper2 zoo3: image: zookeeper:latest hostname: zoo3 environment: ZOO_MY_ID: 3 ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=0.0.0.0:2888:3888 ports: - &quot;2183:2181&quot; deploy: mode: replicated replicas: 1 restart_policy: condition: on-failure delay: 5s max_attempts: 3 placement: constraints: - node.hostname == qww-PC networks: zoo-net: aliases: - zookeeper3# docker network create -d=overlay --attachable zoo-netnetworks: zoo-net: external: name: zoo-net Kafka集群docker-compose.yml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677version: &apos;3.4&apos;services: kafka1: image: wurstmeister/kafka:1.0.0 ports: - &quot;9092:9092&quot; environment: KAFKA_BROKER_ID: 1 KAFKA_ADVERTISED_PORT: 9092 KAFKA_ZOOKEEPER_CONNECT: zookeeper1:2181,zookeeper2:2181,zookeeper3:2181 deploy: mode: replicated replicas: 1 restart_policy: condition: on-failure delay: 5s max_attempts: 3 placement: constraints: - node.hostname == ybd-PC networks: zoo-net: aliases: - kafka1 kafka2: image: wurstmeister/kafka:1.0.0 ports: - &quot;9093:9092&quot; environment: KAFKA_BROKER_ID: 2 KAFKA_ADVERTISED_PORT: 9093 KAFKA_ZOOKEEPER_CONNECT: zookeeper1:2181,zookeeper2:2181,zookeeper3:2181 deploy: mode: replicated replicas: 1 restart_policy: condition: on-failure delay: 5s max_attempts: 3 placement: constraints: - node.hostname == qww-PC networks: zoo-net: aliases: - kafka2 kafka3: image: wurstmeister/kafka:1.0.0 ports: - &quot;9094:9092&quot; environment: KAFKA_BROKER_ID: 3 KAFKA_ADVERTISED_PORT: 9094 KAFKA_ZOOKEEPER_CONNECT: zookeeper1:2181,zookeeper2:2181,zookeeper3:2181 deploy: mode: replicated replicas: 1 restart_policy: condition: on-failure delay: 5s max_attempts: 3 placement: constraints: - node.hostname == qww-PC networks: zoo-net: aliases: - kafka3# docker network create -d=overlay --attachable zoo-netnetworks: zoo-net: external: name: zoo-net 参考: http://www.blockchain4u.info/docker/2017/07/28/kafka-cluster-with-docker Kafka Managerdocker-compose.yml: 1234567891011121314151617181920212223242526272829version: &apos;3.4&apos;services: kafka-manager: image: sheepkiller/kafka-manager environment: ZK_HOSTS: zookeeper1:2181,zookeeper2:2181,zookeeper3:2181 APPLICATION_SECRET: letmein ports: - &quot;9100:9000&quot; deploy: mode: replicated replicas: 1 restart_policy: condition: on-failure delay: 5s max_attempts: 3 placement: constraints: - node.hostname == ybd-PC networks: zoo-net: aliases: - kafka-manager# docker network create -d=overlay --attachable zoo-netnetworks: zoo-net: external: name: zoo-net Logrotate功能: 日志清理 单机运行: 123456789docker run -d \--name logrotate \--restart always \-v /var/lib/docker/containers:/var/lib/docker/containers \-v /var/log/docker:/var/log/docker \-e &quot;LOGS_DIRECTORIES=/var/lib/docker/containers /var/log/docker&quot; \-e &quot;LOGROTATE_SIZE=10M&quot; \-e &quot;LOGROTATE_INTERVAL=weekly&quot; \blacklabelops/logrotate:1.2 docker-compose.yml: 1234567891011121314151617version: &apos;3.4&apos;services: kafka-manager: image: blacklabelops/logrotate:1.2 volumes: - /var/lib/docker/containers:/var/lib/docker/containers environment: LOGS_DIRECTORIES: /var/lib/docker/containers LOGROTATE_INTERVAL: weekly LOGROTATE_SIZE: 20M TZ: Asia/Shanghai deploy: mode: global restart_policy: condition: on-failure delay: 5s max_attempts: 3 ShowDoc功能: API与数据字典管理 docker-compose.yml: 12345678910version: &apos;3.4&apos;services: showdoc: image: yangbingdong/showdoc:1.0 volumes: - /home/ybd/data/docker/showdoc/data:/var/www/html ports: - &quot;4999:80&quot; restart: always 其中要把 ShowDoc 整个项目根目录所有文件拷贝到 data 里面, 确保里面文件可执行 chmod -R 777 data 访问 localhost:4999/install 进行设置后把data里面的 install 目录删除防止再次安装. Last 参考:Docker — 从入门到实践Docker命令大全Docker命令官方文档]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java8 Noob Tutorial]]></title>
    <url>%2F2017%2Fjava-8-tutorial%2F</url>
    <content type="text"><![CDATA[Preface “Java is still not dead—and people are starting to figure that out.”Java 8是自Java 5（2004年）发布以来Java语言最大的一次版本升级, Java 8带来了很多的新特性, 包括Lambda 表达式、方法引用、流(Stream API)、默认方法、Optional、组合式异步编程、新的时间 API, 等等各个方面. 利用这些特征, 我们可以写出如同清泉般的简洁代码= =… Default Methods for InterfacesJava 8 允许我们使用default关键字, 为接口声明添加非抽象的方法实现. 这个特性又被称为扩展方法. 下面是我们的第一个例子:1234567interface Formula &#123; double calculate(int a); default double sqrt(int a) &#123; return Math.sqrt(a); &#125;&#125; 在接口Formula中, 除了抽象方法caculate以外, 还定义了一个默认方法sqrt.Formula的实现类只需要实现抽象方法caculate就可以了. 默认方法sqrt可以直接使用.123456789Formula formula = new Formula() &#123; @Override public double calculate(int a) &#123; return sqrt(a * 100); &#125;&#125;;formula.calculate(100); // 100.0formula.sqrt(16); // 4.0 那么这个新特征有啥用呢？我们往往会碰到这样一个情况我们定义的接口根据不同的场景定义了几个不同的实现类, 那么如果需要这几个实现类调用的方法都得到同一个结果或者只有一个实现类需要这个接口方法, 那么我们需要去重写每个实现了这个接口的类, 而这大大增加了我们的实现需求的负担. 正是为了解决Java接口中只能定义抽象方法的问题. Java8新增加了默认方法的特性. 默认方法可以被继承接口重写成抽象方法或者重新定义成默认方法. 除了默认方法, 接口里还可以声明静态方法, 并且可以实现. 例子如下: 123456private interface DefaulableFactory &#123; // Interfaces now allow static methods static Defaulable create( Supplier&lt; Defaulable &gt; supplier ) &#123; return supplier.get(); &#125;&#125; Conflict因为一个类可以实现多个接口, 所以当一个类实现了多个接口, 而这些接口中存在两个或两个以上方法签名相同的默认方法时就会产生冲突, java8定义如下三条原则来解决冲突: 类或父类中显式声明的方法, 其优先级高于所有的默认方法； 如果1规则失效, 则选择与当前类距离最近的具有具体实现的默认方法； 如果2规则也失效, 则需要显式指定接口. Lambda Expressions先来看一段代码: 123456789public interface ActionListener &#123; void actionPerformed(ActionEvent e);&#125;button.addActionListener(new ActionListener()) &#123; public void actionPerformed(ActionEvent e) &#123; ui.dazzle(e.getModifiers()); &#125;&#125; 匿名类型最大的问题就在于其冗余的语法. 有人戏称匿名类型导致了“高度问题”（height problem）: 比如前面ActionListener的例子里的五行代码中仅有一行在做实际工作.Lambda表达式（又被成为“闭包”或“匿名方法”）是简洁地表示可传递的匿名函数的一种方式, 它提供了轻量级的语法, 从而解决了匿名内部类带来的“高度问题”. 重点留意这四个关键词: 匿名、函数、传递、简洁Lambda的三个部分: 参数列表 箭头 Lambda 主体 Lambda的基本语法大概就是下面这样子的了: (parameters) -&gt; expression (parameters) -&gt; { statements; } 来看个例子:1234567List&lt;String&gt; names = Arrays.asList("D", "B", "C", "A");Collections.sort(names, new Comparator&lt;String&gt;() &#123; @Override public int compare(String a, String b) &#123; return b.compareTo(a); &#125;&#125;); 使用Lambda来表示:1234567Collections.sort(names, (String a, String b) -&gt; &#123; return b.compareTo(a);&#125;);或者是Collections.sort(names, (String a, String b) -&gt; b.compareTo(a));亦或是Collections.sort(names, (a, b) -&gt; b.compareTo(a)); 在IDEA里面, 对于可以写成Lambda表达式的, 按下Alt+Enter 它会智能地提示转换 Lexiacal Scope访问局部变量1、可以直接在Lambda表达式中访问外层的局部变量, 但是和匿名对象不同的是, Lambda表达式的局部变量可以不用声明为final, 不过局部变量必须不可被后面的代码修改（即隐性的具有final的语义）.eg: 下面代码无法编译 123int num = 1; Converter&lt;Integer, String&gt; s = (param) -&gt; String.valueOf(param + num); num = 5; 在Lambda表达式中试图修改局部变量是不允许的！ 2、在 Lambda 表达式当中被引用的变量的值不可以被更改. 3、在 Lambda 表达式当中不允许声明一个与局部变量同名的参数或者局部变量. 访问对象字段与静态变量和局部变量不同的是, Lambda内部对于实例的字段（即: 成员变量）以及静态变量是即可读又可写. 不能访问接口的默认方法Lambda表达式中是无法访问到默认方法的. 补充: Lambda表达式对值封闭, 对变量开放的原文是: lambda expressions close over values, not variables, 在这里增加一个例子以说明这个特性: 12345int sum = 0;list.forEach(e -&gt; &#123; sum += e.size(); &#125;); // Illegal, close over valuesList&lt;Integer&gt; aList = new List&lt;&gt;();list.forEach(e -&gt; &#123; aList.add(e); &#125;); // Legal, open over variables 匿名内部类的简写？Lambda表达式通过invokedynamic指令实现, 书写Lambda表达式不会产生新的类. 如果有如下代码, 编译之后只有一个class文件: 1234567public class MainLambda &#123; public static void main(String[] args) &#123; new Thread( () -&gt; System.out.println(&quot;Lambda Thread run()&quot;) ).start();; &#125;&#125; 编译之后的结果: 通过javap反编译命名, 我们更能看出Lambda表达式内部表示的不同: 12345678910111213141516171819// javap -c -p MainLambda.classpublic class MainLambda &#123; ... public static void main(java.lang.String[]); Code: 0: new #2 // class java/lang/Thread 3: dup 4: invokedynamic #3, 0 // InvokeDynamic #0:run:()Ljava/lang/Runnable; /*使用invokedynamic指令调用*/ 9: invokespecial #4 // Method java/lang/Thread.&quot;&lt;init&gt;&quot;:(Ljava/lang/Runnable;)V 12: invokevirtual #5 // Method java/lang/Thread.start:()V 15: return private static void lambda$main$0(); /*Lambda表达式被封装成主类的私有方法*/ Code: 0: getstatic #6 // Field java/lang/System.out:Ljava/io/PrintStream; 3: ldc #7 // String Lambda Thread run() 5: invokevirtual #8 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 8: return&#125; 反编译之后我们发现Lambda表达式被封装成了主类的一个私有方法, 并通过invokedynamic指令进行调用. Lambda表达式中的this既然Lambda表达式不是内部类的简写, 那么Lambda内部的this引用也就跟内部类对象没什么关系了. 在Lambda表达式中this的意义跟在表达式外部完全一样. eg: 12345678910111213141516public class Test2 &#123; public static void main(String[] args) &#123; Test2 test = new Test2(); test.method(); &#125; @Override public String toString() &#123; return "Lambda"; &#125; public void method() &#123; Runnable runnable = () -&gt; &#123; System.out.println(this.toString()); &#125;; new Thread(runnable).start(); &#125; &#125; 显示结果: Lambda Functional Interfaces任意只包含一个抽象方法的接口, 我们都可以用来做成Lambda表达式. 为了让你定义的接口满足要求, 你应当在接口前加上@FunctionalInterface 标注. 编译器会注意到这个标注, 如果你的接口中定义了第二个抽象方法的话, 编译器会抛出异常.eg:12345678@FunctionalInterfaceinterface Converter&lt;F, T&gt; &#123; T convert(F from);&#125; Converter&lt;String, Integer&gt; converter = (from) -&gt; Integer.valueOf(from);Integer converted = converter.convert("123");System.out.println(converted); // 123 注意, 如果你不写@FunctionalInterface 标注, 程序也是正确的.下面是Java SE 7中已经存在的函数式接口:· java.lang.Runnable· java.util.concurrent.Callable· java.security.PrivilegedAction· java.util.Comparator· java.io.FileFilter· java.beans.PropertyChangeListener 除此之外, Java SE 8中增加了一个新的包: java.util.function, 它里面包含了常用的函数式接口, 例如:· Predicate&lt;T&gt;——接收T对象并返回boolean· Consumer&lt;T&gt;——接收T对象, 不返回值· Function&lt;T, R&gt;——接收T对象, 返回R对象· Supplier&lt;T&gt;——提供T对象（例如工厂）, 不接收值· UnaryOperator&lt;T&gt;——接收T对象, 返回T对象· BinaryOperator&lt;T&gt;——接收两个T对象, 返回T对象 除了上面的这些基本的函数式接口, 我们还提供了一些针对原始类型（Primitive type）的特化（Specialization）函数式接口, 例如IntSupplier和LongBinaryOperator. （我们只为int、long和double提供了特化函数式接口, 如果需要使用其它原始类型则需要进行类型转换）同样的我们也提供了一些针对多个参数的函数式接口, 例如BiFunction&lt;T, U, R&gt;, 它接收T对象和U对象, 返回R对象. Method and Constructor ReferencesLambda表达式允许我们定义一个匿名方法, 并允许我们以函数式接口的方式使用它. 我们也希望能够在已有的方法上实现同样的特性.方法引用和Lambda表达式拥有相同的特性（例如, 它们都需要一个目标类型, 并需要被转化为函数式接口的实例）, 不过我们并不需要为方法引用提供方法体, 我们可以直接通过方法名称引用已有方法. 方法引用就是替代那些转发参数的 Lambda 表达式的语法糖.方法引用有很多种, 它们的语法如下:· 静态方法引用: ClassName::methodName· 实际上的实例方法引用: instanceReference::methodName· 超类上的实例方法引用: super::methodName· 类型上的实例方法引用: ClassName::methodName· 构造方法引用: Class::new· 数组构造方法引用: TypeName[]::new 对于静态方法引用, 我们需要在类名和方法名之间加入::分隔符, 例如Integer::sum.结合Lambda可以使我们的代码更加简洁:1234List&lt;String&gt; strings = Arrays.asList("a", "b");strings.stream().map(String::toUpperCase).forEach(System.out::println);List&lt;Character&gt; chars = Arrays.asList('a', 'b'); System.out.println(chars.stream().map(String::valueOf).collect(Collectors.joining(","))); OptionalNullPointException可以说是所有Java程序员都遇到过的一个异常, 虽然Java从设计之初就力图让程序员脱离指针的苦海, 但是指针确实是实际存在的, 而java设计者也只能是让指针在Java语言中变得更加简单、易用, 而不能完全的将其剔除, 所以才有了我们日常所见到的关键字null. 空指针异常是一个运行时异常, 对于这一类异常, 如果没有明确的处理策略, 那么最佳实践在于让程序早点挂掉, 但是很多场景下, 不是开发人员没有具体的处理策略, 而是根本没有意识到空指针异常的存在. 当异常真的发生的时候, 处理策略也很简单, 在存在异常的地方添加一个if语句判定即可, 但是这样的应对策略会让我们的程序出现越来越多的null判定, 我们知道一个良好的程序设计, 应该让代码中尽量少出现null关键字, 而Java8所提供的Optional类则在减少NullPointException的同时, 也提升了代码的美观度. 但首先我们需要明确的是, 它并 不是对null关键字的一种替代, 而是对于null判定提供了一种更加优雅的实现, 从而避免NullPointException. java.util.Optional&lt;T&gt; 对可能缺失的值建模,引入的目的并非是要消除每一个 null 引用, 而是帮助你更好地设计出普适的 API. 创建 Optional 对象,三个静态工厂方法: Optional.empty: 创建空的 Optional 对象 Optional.of: 依据非空值创建 Optional 对象, 若传空值会抛 NPE Optianal.ofNullable: 创建 Optional 对象, 允许传空值 Optional API: isPresent(): 变量存在返回true get(): 返回封装的变量值, 或者抛出 NoSuchElementException orElse(T other): 提供默认值 orElseGet(Supplier&lt;? extends T&gt; other): orElse 方法的延迟调用版 orElseThrow(Supplier&lt;&gt; extends X&gt; exceptionSupplier): 类似 get, 但可以定制希望抛出的异常类型 ifPresent(Consumer&lt;? super T&gt;): 变量存在时可以执行一个方法 filter(Predicate&lt;? super T&gt; predicate): 过滤 map(Function&lt;? super T, ? extends U&gt; mapper): 转换 flatMap(Function&lt;? super T, Optional&lt;U&gt;&gt; mapper): 转换成Optional 值得注意的是: Optional是一个final类, 未实现任何接口, 所以当我们在利用该类包装定义类的属性的时候, 如果我们定义的类有序列化的需求, 那么因为Optional没有实现Serializable接口, 这个时候执行序列化操作就会有问题:12345678public class User implements Serializable&#123; /** 用户编号 */ private long id; private String name; private int age; private Optional&lt;Long&gt; phone; // 不能序列化 private Optional&lt;String&gt; email; // 不能序列化 不过我们可以采用如下替换策略:12345private long phone;public Optional&lt;Long&gt; getPhone() &#123; return Optional.ofNullable(this.phone);&#125; Optional 类设计的初衷仅仅是要支持能返回 Optional 对象的方法, 没有考虑将它作为类的字段使用… 另外, 在Java9中对Optional添加了三个新的方法: public Optional&lt;T&gt; or(Supplier&lt;? extends Optional&lt;? extends T&gt;&gt; supplier)or 方法的作用是, 如果一个 Optional 包含值, 则返回自己；否则返回由参数 supplier 获得的 Optional public void ifPresentOrElse(Consumer&lt;? super T&gt; action, Runnable emptyAction)ifPresentOrElse 方法的用途是, 如果一个 Optional 包含值, 则对其包含的值调用函数 action, 即 action.accept(value), 这与 ifPresent 一致；与 ifPresent 方法的区别在于, ifPresentOrElse 还有第二个参数 emptyAction —— 如果 Optional 不包含值, 那么 ifPresentOrElse 便会调用 emptyAction, 即 emptyAction.run() public Stream&lt;T&gt; stream()stream 方法的作用就是将 Optional 转为一个 Stream, 如果该 Optional 中包含值, 那么就返回包含这个值的 Stream；否则返回一个空的 Stream（Stream.empty()）. 举个例子, 在 Java8, 我们会写下面的代码: 12345678// 此处 getUserById 返回的是 Optional&lt;User&gt;public List&lt;User&gt; getUsers(Collection&lt;Integer&gt; userIds) &#123; return userIds.stream() .map(this::getUserById) // 获得 Stream&lt;Optional&lt;User&gt;&gt; .filter(Optional::isPresent)// 去掉不包含值的 Optional .map(Optional::get) .collect(Collectors.toList());&#125; 而有了 Optional.stream(), 我们就可以将其简化为: 123456public List&lt;User&gt; getUsers(Collection&lt;Integer&gt; userIds) &#123; return userIds.stream() .map(this::getUserById) // 获得 Stream&lt;Optional&lt;User&gt;&gt; .flatMap(Optional::stream) // Stream 的 flatMap 方法将多个流合成一个流 .collect(Collectors.toList());&#125; Streams 流是什么先来一段代码: 12345Arrays.asList("a1", "a2", "b1", "c2", "c1").stream() .filter(s -&gt; s.startsWith("c")) .map(String::toUpperCase) .sorted() .forEach(System.out::println); 流是Java SE 8类库中新增的关键抽象, 它被定义于java.util.stream（这个包里有若干流类型: Stream&lt;T&gt;代表对象引用流, 此外还有一系列特化（specialization）流, 比如IntStream代表整形数字流）. 每个流代表一个值序列, 流提供一系列常用的聚集操作, 使得我们可以便捷的在它上面进行各种运算. 集合类库也提供了便捷的方式使我们可以以操作流的方式使用集合、数组以及其它数据结构. 流的操作可以被组合成流水线（Pipeline）. 引入的原因: 声明性方式处理数据集合 透明地并行处理, 提高性能 流 的定义: 从支持数据处理操作的源生成的元素序列两个重要特点: 流水线 内部迭代 流与集合: 集合与流的差异就在于什么时候进行计算 集合是内存中的数据结构, 包含数据结构中目前所有的值 流的元素则是按需计算/生成 另一个关键区别在于遍历数据的方式 集合使用 Collection 接口, 需要用户去做迭代, 称为外部迭代 流的 Streams 库使用内部迭代 流的使用: 一个数据源（如集合）来执行一个查询； 一个中间操作链, 形成一条流的流水线； 一个终端操作, 执行流水线, 并能生成结果. 流的流水线背后的理念类似于构建器模式. 常见的中间操作有filter,map,limit,sorted,distinct；常见的终端操作有 forEach,count,collect. 流的操作类型分为两种: Intermediate: 一个流可以后面跟随零个或多个 intermediate 操作. 其目的主要是打开流, 做出某种程度的数据映射/过滤, 然后返回一个新的流, 交给下一个操作使用. 这类操作都是惰性化的（lazy）, 就是说, 仅仅调用到这类方法, 并没有真正开始流的遍历. Terminal: 一个流只能有一个 terminal 操作, 当这个操作执行后, 流就被使用“光”了, 无法再被操作. 所以这必定是流的最后一个操作. Terminal 操作的执行, 才会真正开始流的遍历, 并且会生成一个结果, 或者一个 side effect. 流的使用构建流 由值创建流: Stream.of、Stream.empty、IntStream.range 由集合创建流: Collection.stream、Collection.parallelStream 由数组创建流: Arrays.stream(数组变量) 由文件生成流: Files.lines、Files.walk 由BufferedReader创建流: java.io.BufferedReader.lines 由函数生成流: 创建无限流, 迭代: Stream.iterate（接受一个种子值, 和一个UnaryOperator） 生成: Stream.generate（接收一个Supplier接口） 使用流Intermediate（中间操作）: 筛选: 谓词筛选: filter 筛选互异的元素: distinct 忽略头几个元素: skip 截短至指定长度: limit 排序: sorted 偷瞄（输出）: peek 平行化: parallel 串行化: sequential 映射: 对流中每个元素应用函数: map 流的扁平化: flatMap 转为原始流: mapToInt、mapToInt、mapToInt 从原始流转为普通流: boxed 数值范围: range:[起始值, 结束值) rangeClosed:[起始值, 结束值] Terminal（终结操作） 查找和匹配: 检查谓词是否至少匹配一个元素: anyMatch 检查谓词是否匹配所有元素: allMatch/noneMatch 查找元素: findAny 查找第一个元素: findFirst 归约（折叠）: reduce(初值, 结合操作) 元素求和: count、sum 最大值和最小值: min、 max 遍历: forEach、 forEachOrdered anyMatch,allMatch,noneMatch 都用到了短路；distinct,sorted是有状态且无界的, skip,limit,reduce是有状态且有界的.原始类型流特化: IntStream,DoubleStream,LongStream, 避免暗含的装箱成本. 映射到数值流: mapToInt,mapToDouble,mapToLong 转换回流对象: boxed 默认值: OptionalInt,OptionalDouble,OptionalLong 用流收集数据对流调用 collect 方法将对流中的元素触发归约操作（由 Collector 来参数化）.Collectors 实用类提供了许多静态工厂方法, 用来创建常见收集器的实例, 主要提供三大功能: 将流元素归约和汇总为一个值 元素分组 元素分区 归约和汇总(Collectors 类中的工厂方法): 统计个数: Collectors.counting 查找流中最大值和最小值: Collectors.maxBy,Collectors.minBy 汇总: Collectors.summingInt,Collectors.averagingInt,summarizingInt/IntSummaryStatistics. 还有对应的 long 和 double 类型的函数 连接字符串: joining 广义的归约汇总: Collectors.reducing(起始值, 映射方法, 二元结合)/Collectors.reducing(二元结合). Collectors.reducing 工厂方法是所有上述特殊情况的一般化. collect vs. reduce, 两者都是 Stream 接口的方法, 区别在于: 语意问题 reduce 方法旨在把两个值结合起来生成一个新值, 是不可变的归约； collect 方法设计就是要改变容器, 从而累积要输出的结果 实际问题 以错误的语义使用 reduce 会导致归约过程不能并行工作 分组和分区 分组: Collectors.groupingBy 多级分组 按子数组收集数据: maxBy 把收集器的结果转换为另一种结果 collectingAndThen 与 groupingBy 联合使用的其他收集器例子: summingInt,mapping 分区: Collectors.partitioningBy是分组的特殊情况, 由一个谓词作为分类函数(分区函数), 返回一个Map, 只有两个Boolean类型的key. Ex1:使用collect()生成Collection前面已经提到通过collect()方法将Stream转换成容器的方法, 这里再汇总一下. 将Stream转换成List或Set是比较常见的操作, 所以Collectors工具已经为我们提供了对应的收集器, 通过如下代码即可完成: 1234// 将Stream转换成List或SetStream&lt;String&gt; stream = Stream.of(&quot;I&quot;, &quot;love&quot;, &quot;you&quot;, &quot;too&quot;);List&lt;String&gt; list = stream.collect(Collectors.toList()); // (1)Set&lt;String&gt; set = stream.collect(Collectors.toSet()); // (2) 上述代码能够满足大部分需求, 但由于返回结果是接口类型, 我们并不知道类库实际选择的容器类型是什么, 有时候我们可能会想要人为指定容器的实际类型, 这个需求可通过Collectors.toCollection(Supplier&lt;C&gt; collectionFactory)方法完成. 123// 使用toCollection()指定规约容器的类型ArrayList&lt;String&gt; arrayList = stream.collect(Collectors.toCollection(ArrayList::new));// (3)HashSet&lt;String&gt; hashSet = stream.collect(Collectors.toCollection(HashSet::new));// (4) 上述代码(3)处指定规约结果是ArrayList, 而(4)处指定规约结果为HashSet. 一切如你所愿. Ex2:使用collect()生成Map前面已经说过Stream背后依赖于某种数据源, 数据源可以是数组、容器等, 但不能是Map. 反过来从Stream生成Map是可以的, 但我们要想清楚Map的key和value分别代表什么, 根本原因是我们要想清楚要干什么. 通常在三种情况下collect()的结果会是Map: 使用Collectors.toMap()生成的收集器, 用户需要指定如何生成Map的key和value. 使用Collectors.partitioningBy()生成的收集器, 对元素进行二分区操作时用到. 使用Collectors.groupingBy()生成的收集器, 对元素做group操作时用到. 情况1: 使用toMap()生成的收集器, 这种情况是最直接的, 前面例子中已提到, 这是和Collectors.toCollection()并列的方法. 如下代码展示将学生列表转换成由&lt;学生, GPA&gt;组成的Map. 非常直观, 无需多言. 1234// 使用toMap()统计学生GPAMap&lt;Student, Double&gt; studentToGPA = students.stream().collect(Collectors.toMap(Functions.identity(),// 如何生成key student -&gt; computeGPA(student)));// 如何生成value 情况2: 使用partitioningBy()生成的收集器, 这种情况适用于将Stream中的元素依据某个二值逻辑（满足条件, 或不满足）分成互补相交的两部分, 比如男女性别、成绩及格与否等. 下列代码展示将学生分成成绩及格或不及格的两部分. 123// Partition students into passing and failingMap&lt;Boolean, List&lt;Student&gt;&gt; passingFailing = students.stream() .collect(Collectors.partitioningBy(s -&gt; s.getGrade() &gt;= PASS_THRESHOLD)); 情况3: 使用groupingBy()生成的收集器, 这是比较灵活的一种情况. 跟SQL中的group by语句类似, 这里的groupingBy()也是按照某个属性对数据进行分组, 属性相同的元素会被对应到Map的同一个key上. 下列代码展示将员工按照部门进行分组: 123// Group employees by departmentMap&lt;Department, List&lt;Employee&gt;&gt; byDept = employees.stream() .collect(Collectors.groupingBy(Employee::getDepartment)); 以上只是分组的最基本用法, 有些时候仅仅分组是不够的. 在SQL中使用group by是为了协助其他查询, 比如1. 先将员工按照部门分组, 2. 然后统计每个部门员工的人数. Java类库设计者也考虑到了这种情况, 增强版的groupingBy()能够满足这种需求. 增强版的groupingBy()允许我们对元素分组之后再执行某种运算, 比如求和、计数、平均值、类型转换等. 这种先将元素分组的收集器叫做上游收集器, 之后执行其他运算的收集器叫做下游收集器(downstream Collector). 1234// 使用下游收集器统计每个部门的人数Map&lt;Department, Integer&gt; totalByDept = employees.stream() .collect(Collectors.groupingBy(Employee::getDepartment, Collectors.counting()));// 下游收集器 上面代码的逻辑是不是越看越像SQL？高度非结构化. 还有更狠的, 下游收集器还可以包含更下游的收集器, 这绝不是为了炫技而增加的把戏, 而是实际场景需要. 考虑将员工按照部门分组的场景, 如果我们想得到每个员工的名字（字符串）, 而不是一个个Employee对象, 可通过如下方式做到: 12345// 按照部门对员工分布组, 并只保留员工的名字Map&lt;Department, List&lt;String&gt;&gt; byDept = employees.stream() .collect(Collectors.groupingBy(Employee::getDepartment, Collectors.mapping(Employee::getName,// 下游收集器 Collectors.toList())));// 更下游的收集器 Notice And Optimization 流不可被复用 一般先filter、limit、skip操作后再进行sorted、peek、map等操作以达到short-circuiting 目的 Stream操作分类 中间操作(Intermediate operations) 无状态(Stateless) unordered() filter() map() mapToInt() mapToLong() mapToDouble() flatMap() flatMapToInt() flatMapToLong() flatMapToDouble() peek() 有状态(Stateful) distinct() sorted() sorted() limit() skip() 结束操作(Terminal operations) 非短路操作 forEach() forEachOrdered() toArray() reduce() collect() max() min() count() 短路操作(short-circuiting) anyMatch() allMatch() noneMatch() findFirst() findAny() Stream上的所有操作分为两类: 中间操作和结束操作, 中间操作只是一种标记, 只有结束操作才会触发实际计算. 中间操作又可以分为无状态的(Stateless)和有状态的(Stateful), 无状态中间操作是指元素的处理不受前面元素的影响, 而有状态的中间操作必须等到所有元素处理之后才知道最终结果, 比如排序是有状态操作, 在读取所有元素之前并不能确定排序结果；结束操作又可以分为短路操作和非短路操作, 短路操作是指不用处理全部元素就可以返回结果, 比如找到第一个满足条件的元素. 之所以要进行如此精细的划分, 是因为底层对每一种情况的处理方式不同. AnnotationsJava 8中的注解是可重复的.首先, 我们定义一个包装注解, 它包括了一个实际注解的数组:12345678@interface Hints &#123; Hint[] value();&#125;@Repeatable(Hints.class)@interface Hint &#123; String value();&#125; 只要在前面加上注解名: @Repeatable, Java 8 允许我们对同一类型使用多重注解变体1: 使用注解容器（老方法）12@Hints(&#123;@Hint(&quot;hint1&quot;), @Hint(&quot;hint2&quot;)&#125;)class Person &#123;&#125; 变体2: 使用可重复注解（新方法）123@Hint(&quot;hint1&quot;)@Hint(&quot;hint2&quot;)class Person &#123;&#125; 使用变体2, Java编译器能够在内部自动对@Hint进行设置. 这对于通过反射来读取注解信息来说, 是非常重要的.12345678Hint hint = Person.class.getAnnotation(Hint.class);System.out.println(hint); // nullHints hints1 = Person.class.getAnnotation(Hints.class);System.out.println(hints1.value().length); // 2Hint[] hints2 = Person.class.getAnnotationsByType(Hint.class);System.out.println(hints2.length); // 2 尽管我们绝对不会在Person类上声明@Hints注解, 但是它的信息仍然可以通过getAnnotation(Hints.class)来读取. 并且, getAnnotationsByType方法会更方便, 因为它赋予了所有@Hints注解标注的方法直接的访问权限.12@Target(&#123;ElementType.TYPE_PARAMETER, ElementType.TYPE_USE&#125;)@interface MyAnnotation &#123;&#125; Time API现有API存在的问题 线程安全: Date和Calendar不是线程安全的, 你需要编写额外的代码处理线程安全问题 API设计和易用性: 由于Date和Calendar的设计不当你无法完成日常的日期操作 ZonedDate和Time: 你必须编写额外的逻辑处理时区和那些旧的逻辑 好在JSR 310规范中为Java8添加了新的API在java.time包中, 新的API纠正了过去的缺陷 新的日期API ZoneId: 时区ID, 用来确定Instant和LocalDateTime互相转换的规则 Instant: 用来表示时间线上的一个点 LocalDate: 表示没有时区的日期, LocalDate是不可变并且线程安全的 LocalTime: 表示没有时区的时间, LocalTime是不可变并且线程安全的 LocalDateTime: 表示没有时区的日期时间, LocalDateTime是不可变并且线程安全的 Clock: 用于访问当前时刻、日期、时间, 用到时区 Duration: 用秒和纳秒表示时间的数量 最常用的就是LocalDate、LocalTime、LocalDateTime ClockClock提供了对当前时间和日期的访问功能. Clock是对当前时区敏感的, 并可用于替代System.currentTimeMillis()方法来获取当前的毫秒时间. 当前时间线上的时刻可以用Instance类来表示. Instance也能够用于创建原先的java.util.Date对象. 12345Clock clock = Clock.systemDefaultZone();long millis = clock.millis();Instant instant = clock.instant();Date legacyDate = Date.from(instant); // legacy java.util.Date Timezones时区类可以用一个ZoneId来表示. 时区类的对象可以通过静态工厂方法方便地获取. 时区类还定义了一个偏移量, 用来在当前时刻或某时间与目标时区时间之间进行转换. 12345678910System.out.println(ZoneId.getAvailableZoneIds());// prints all available timezone idsZoneId zone1 = ZoneId.of(&quot;Europe/Berlin&quot;);ZoneId zone2 = ZoneId.of(&quot;Brazil/East&quot;);System.out.println(zone1.getRules());System.out.println(zone2.getRules());// ZoneRules[currentStandardOffset=+01:00]// ZoneRules[currentStandardOffset=-03:00] LocalDateLocalDate代表一个IOS格式(yyyy-MM-dd)的日期, 它有多个构造方法: 1234LocalDate.now();LocalDate.of(2018, 8, 15);LocalDate.parse(&quot;2018-08-15&quot;);LocalDate.parse(&quot;2018.08.15&quot;, DateTimeFormatter.ofPattern(&quot;yyyy.MM.dd&quot;)) 其他API: 1234567891011121314// 获取明天LocalDate tomorrow = LocalDate.now().plusDays(1);// 上一个月的今天LocalDate prevMonth = LocalDate.now().minus(1, ChronoUnit.MONTHS);// 获取今天是星期几DayOfWeek thursday = LocalDate.parse(&quot;2018-09-27&quot;).getDayOfWeek();// 获取今天是几号int dayOfMonth = LocalDate.parse(&quot;2018-09-27&quot;).getDayOfMonth();// 今年是不是闰年boolean leapYear = LocalDate.now().isLeapYear(); 日期比较: 1234LocalDate now = LocalDate.now();LocalDate tomorrow = now.plusDays(1);System.out.println(now.isBefore(tomorrow));System.out.println(tomorrow.isAfter(now)); 获取这个月的第一天 1234LocalDate firstDayOfMonth = LocalDate.parse(&quot;2018-08-15&quot;).with(TemporalAdjusters.firstDayOfMonth());System.out.println(&quot;这个月的第一天: &quot; + firstDayOfMonth);firstDayOfMonth = firstDayOfMonth.withDayOfMonth(1);System.out.println(&quot;这个月的第一天: &quot; + firstDayOfMonth); 判断否是生日 1234LocalDate birthday = LocalDate.of(1994, 04, 15);MonthDay birthdayMd = MonthDay.of(birthday.getMonth(), birthday.getDayOfMonth());MonthDay today = MonthDay.from(LocalDate.now());System.out.println(&quot;否是生日: &quot; + today.equals(birthdayMd)); 固定的日期, 比如信用卡过期时间 1234YearMonth currentYearMonth = YearMonth.now();System.out.printf(&quot;Days in month year %s: %d%n&quot;, currentYearMonth,currentYearMonth.lengthOfMonth()); YearMonth creditCardExpiry = YearMonth.of(2018, Month.FEBRUARY); System.out.printf(&quot;Your credit card expires on %s %n&quot;, creditCardExpiry); LocalTime构造方法与LocalDate类似: 123LocalTime.now();LocalTime.parse(&quot;15:02&quot;);LocalTime.of(15, 02); 时间加减: 12LocalTime.parse(&quot;15:02&quot;).plus(1, ChronoUnit.HOURS);LocalTime.now().plusHours(1); 获取时间的小时、分钟: 12int hour = LocalTime.parse(&quot;15:02&quot;).getHour();int minute = LocalTime.parse(&quot;15:02&quot;).getMinute(); 时间比较: 12LocalTime.parse(&quot;15:02&quot;).isBefore(LocalTime.parse(&quot;16:02&quot;));LocalTime.parse(&quot;15:02&quot;).isAfter(LocalTime.parse(&quot;16:02&quot;)); 一天的开始与结束: 12System.out.println(LocalTime.MAX);System.out.println(LocalTime.MIN); 输出: 1223:59:59.99999999900:00 LocalDateTime这个应该是最常用的了, 构造方法与上面两个类似: 123LocalDateTime.now();LocalDateTime.of(2018, Month.AUGUST, 15, 15, 18);LocalDateTime.parse(&quot;2018-08-15T15:18:00&quot;); 时间加减操作与上面差不多: 12LocalDateTime tomorrow = now.plusDays(1);LocalDateTime minusTowHour = now.minusHours(2); 时间比较: 1tomorrow.isAfter(minusTowHour) 获取特定单位: 1Month month = now.getMonth(); 转换成LocalDate和LocalTime: 12now.toLocalDate();now.toLocalTime(); 获取某天的开始: 12LocalDateTime localDateTime = LocalDateTime.now();LocalDateTime startOfDay = now.toLocalDate().atStartOfDay(); 日期格式化123456LocalDateTime now = LocalDateTime.now();DateTimeFormatter dateTimeFormatter = DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd HH:mm:ss&quot;);System.out.println(&quot;默认格式化: &quot; + now);System.out.println(&quot;自定义格式化: &quot; + now.format(dateTimeFormatter));LocalDateTime localDateTime = LocalDateTime.parse(&quot;2018-08-15 15:27:44&quot;, dateTimeFormatter);System.out.println(&quot;字符串转LocalDateTime: &quot; + localDateTime); 也可以使用DateTimeFormatter的format方法将日期、时间格式化为字符串 123DateTimeFormatter dateTimeFormatter = DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd&quot;);String dateString = dateTimeFormatter.format(LocalDate.now());System.out.println(&quot;日期转字符串: &quot; + dateString); 日期周期Period类用于修改给定日期或获得的两个日期之间的区别. 给初始化的日期添加5天: 12LocalDate initialDate = LocalDate.parse(&quot;2018-08-15&quot;);LocalDate finalDate = initialDate.plus(Period.ofDays(5)); 周期API中提供给我们可以比较两个日期的差别, 像下面这样获取差距天数: 1long between = ChronoUnit.DAYS.between(initialDate, finalDate); 上面的代码会返回5, 当然你想获取两个日期相差多少小时也是简单的. 与Date转换Date和Instant互相转换 12Date date = Date.from(Instant.now());Instant instant = date.toInstant(); Date转换为LocalDateTime 1LocalDateTime now = LocalDateTime.ofInstant(new Date().toInstant(), ZoneId.systemDefault()); LocalDateTime转Date 1Date date = Date.from(LocalDateTime.now().atZone(ZoneId.systemDefault()).toInstant()); LocalDate转Date 1Date date = Date.from(LocalDate.now().atStartOfDay().atZone(ZoneId.systemDefault()).toInstant()); Other ExtendLambda表达式遇上检测型异常先来看一段代码: 12345678long count = Files.walk(Paths.get(&quot;/home/test&quot;)) // 获得项目目录下的所有目录及文件 .filter(file -&gt; !Files.isDirectory(file)) // 筛选出文件 .filter(file -&gt; file.toString().endsWith(&quot;.java&quot;)) // 筛选出 java 文件 .flatMap(file -&gt; Files.lines(file)) // 按行获得文件中的文本 .filter(line -&gt; !line.trim().isEmpty()) // 过滤掉空行 .count();System.out.println(&quot;代码行数: &quot; + count); Files.walk(Path) 在 JDK1.8 时添加, 深度优先遍历一个 Path （目录）, 返回这个目录下所有的 Path（目录和文件）, 通过 Stream&lt;Path&gt; 返回； Files.lines(Path) 也是在 JDK1.8 时添加, 功能是返回指定 Path （文件）中所有的行, 通过 Stream&lt;String&gt; 返回. 然后, 编译不过 —— 因为 Files.lines(Path) 会抛出 IOException, 如果要编译通过, 得这样写: 123456789101112131415long count = Files.walk(Paths.get(&quot;/home/test&quot;)) // 获得项目目录下的所有文件 .filter(file -&gt; !Files.isDirectory(file)) // 筛选出文件 .filter(file -&gt; file.toString().endsWith(&quot;.java&quot;)) // 筛选出 java 文件 .flatMap(file -&gt; &#123; try &#123; return Files.lines(file); &#125; catch (IOException ex) &#123; ex.printStackTrace(System.err); return Stream.empty(); // 抛出异常时返回一个空的 Stream &#125; &#125;) // 按行获得文件中的文本 .filter(line -&gt; !line.trim().isEmpty()) // 过滤掉空行 .count();System.out.println(&quot;代码行数: &quot; + count); 对于有强迫症的程序员来说这简直是噩梦, one-liner expression 的 Lambda需要绝对的简介明了. 这里有两种做法, 比较偷懒的就是每个会抛出异常的地方我们独自捕获处理, 这样带来的问题就是不够通用, 每个异常方法都要捕获一次: 12345678910111213141516171819public static void main(String[] args) throws Exception &#123; long count = Files.walk(Paths.get(&quot;/home/test&quot;)) // 获得项目目录下的所有文件 .filter(file -&gt; !Files.isDirectory(file)) // 筛选出文件 .filter(file -&gt; file.toString().endsWith(&quot;.java&quot;)) // 筛选出 java 文件 .flatMap(file -&gt; getLines(file)) // 按行获得文件中的文本 .filter(line -&gt; !line.trim().isEmpty()) // 过滤掉空行 .count(); System.out.println(&quot;代码行数: &quot; + count);&#125;private static Stream&lt;String&gt; getLines(Path file) &#123; try &#123; return Files.lines(file); &#125; catch (IOException ex) &#123; ex.printStackTrace(System.err); return Stream.empty(); &#125;&#125; 这种解决方法下, 我们需要处理受检异常 —— 即在程序抛出异常的时候, 我们需要告诉程序怎么去做（getLines 方法中抛出异常时我们输出了异常, 并返回一个空的 Stream） 上面方式当然是不可取的啦, 我们选择更偷懒的方式, 将会抛出异常的函数进行包装, 使其不抛出受检异常. 如果一个 FunctionInterface 的方法会抛出受检异常（比如 Exception）, 那么该 FunctionInterface 便可以作为会抛出受检异常的 Lambda 的目标类型.我们定义如下一个 FunctionInterface: 1234@FunctionalInterfacepublic interface UncheckedFunction&lt;T, R&gt; &#123; R apply(T t) throws Exception;&#125; 那么该 FunctionInterface 便可以作为类似于 file -&gt; File.lines(file) 这类会抛出受检异常的 Lambda 的目标类型, 此时 Lambda 中并不需要捕获异常（因为目标类型的 apply 方法已经将异常抛出了）—— 之所以原来的 Lambda 需要捕获异常, 就是因为在流式操作 flatMap 中使用的 java.util.function 包下的 Function&lt;T, R&gt; 没有抛出异常: 那我们如何使用 UncheckedFunction 到流式操作的 Lambda 中呢？首先我们定义一个 Trier 类, 它的 tryFunction 方法提供将 UncheckedFunction 包装为 Function 的功能: 1234567891011121314151617181920public class Trier &#123; private static final Logger LOGGER = LoggerFactory.getLogger(Trier.class); public static &lt;T, R&gt; Function&lt;T, R&gt; tryFunction(UncheckedFunction&lt;T, R&gt; function) &#123; requireNonNull(function); return t -&gt; &#123; try &#123; return function.apply(t); &#125; catch (Exception e) &#123; throw logAndThrow(e); &#125; &#125;; &#125; @FunctionalInterface public static interface UncheckedFunction&lt;T, R&gt; &#123; R apply(T t) throws Exception; &#125;&#125; 然后在原先的代码中, 我们使用 Trier.tryFunction 方法来对会抛出受检异常的 Lambda 进行包装: 12345678910long count = Files.walk(Paths.get(&quot;/home/test&quot;)) // 获得项目目录下的所有文件 .filter(file -&gt; !Files.isDirectory(file)) // 筛选出文件 .filter(file -&gt; file.toString().endsWith(&quot;.java&quot;)) // 筛选出 java 文件 .flatMap(Trier.tryFunction(file -&gt; Files.lines(file))) // 将 会抛出受检异常的 Lambda 包装为 抛出非受检异常的 Lambda .filter(line -&gt; !line.trim().isEmpty()) // 过滤掉空行 .count();System.out.println(&quot;代码行数: &quot; + count); 指定默认值的包装方法, 即如果抛出异常, 那么就返回默认值: 123456789101112131415public static &lt;T, R&gt; Function&lt;T, R&gt; tryFunction(UncheckedFunction&lt;T, R&gt; function, R defaultValue) &#123; requireNonNull(function); return t -&gt; &#123; try &#123; return function.apply(t); &#125; catch (Exception e) &#123; return logAndReturn(e, defaultValue); &#125; &#125;; &#125; private static &lt;R&gt; R logAndReturn(Exception e, R defaultValue) &#123; LOGGER.error(&quot;Trier catch an exception: &quot; + getFullStackTrace(e) + &quot;\n And return default value: &quot; + defaultValue); return defaultValue; &#125; 比如我们前面的例子, 如果 file -&gt; Files.lines(file) 抛出异常了, 说明在访问 file 类的时候出了问题, 我们可以就假设这个文件的行数为 0 , 那么默认值就是个空的 Stream&lt;String&gt;: 12345678910long count = Files.walk(Paths.get(&quot;/home/test&quot;)) // 获得项目目录下的所有文件 .filter(file -&gt; !Files.isDirectory(file)) // 筛选出文件 .filter(file -&gt; file.toString().endsWith(&quot;.java&quot;)) // 筛选出 java 文件 .flatMap(Trier.tryFunction(file -&gt; Files.lines(file), Stream.empty())) .filter(line -&gt; !line.trim().isEmpty()) // 过滤掉空行 .count();System.out.println(&quot;代码行数: &quot; + count); 如此类推, 我们可以创建UncheckedConsumer、UncheckedSupplier等: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115public class Trier &#123; private static final Logger LOGGER = LoggerFactory.getLogger(Trier.class); public static &lt;T, R&gt; Function&lt;T, R&gt; tryFunction(UncheckedFunction&lt;T, R&gt; function) &#123; requireNonNull(function); return t -&gt; &#123; try &#123; return function.apply(t); &#125; catch (Exception e) &#123; throw logAndThrow(e); &#125; &#125;; &#125; public static &lt;T, R&gt; Function&lt;T, R&gt; tryFunction(UncheckedFunction&lt;T, R&gt; function, R defaultValue) &#123; requireNonNull(function); return t -&gt; &#123; try &#123; return function.apply(t); &#125; catch (Exception e) &#123; return logAndReturn(e, defaultValue); &#125; &#125;; &#125; public static &lt;T&gt; Supplier&lt;T&gt; trySupplier(UncheckedSupplier&lt;T&gt; supplier) &#123; requireNonNull(supplier); return () -&gt; &#123; try &#123; return supplier.get(); &#125; catch (Exception e) &#123; throw logAndThrow(e); &#125; &#125;; &#125; public static &lt;T&gt; Supplier&lt;T&gt; trySupplier(UncheckedSupplier&lt;T&gt; supplier, T defaultValue) &#123; requireNonNull(supplier); return () -&gt; &#123; try &#123; return supplier.get(); &#125; catch (Exception e) &#123; return logAndReturn(e, defaultValue); &#125; &#125;; &#125; public static &lt;T&gt; Consumer&lt;T&gt; tryConsumer(UncheckedConsumer&lt;T&gt; consumer) &#123; requireNonNull(consumer); return t -&gt; &#123; try &#123; consumer.accept(t); &#125; catch (Exception e) &#123; throw logAndThrow(e); &#125; &#125;; &#125; public static &lt;T&gt; Predicate&lt;T&gt; tryPredicate(UncheckedPredicate&lt;T&gt; predicate) &#123; requireNonNull(predicate); return t -&gt; &#123; try &#123; return predicate.test(t); &#125; catch (Exception e) &#123; throw logAndThrow(e); &#125; &#125;; &#125; public static &lt;T&gt; Predicate&lt;T&gt; tryPredicate(UncheckedPredicate&lt;T&gt; predicate, boolean defaultValue) &#123; requireNonNull(predicate); return t -&gt; &#123; try &#123; return predicate.test(t); &#125; catch (Exception e) &#123; return logAndReturn(e, defaultValue); &#125; &#125;; &#125; private static void log(Exception e) &#123; LOGGER.error(&quot;Trier catch an exception: &quot; + getFullStackTrace(e)); &#125; private static &lt;R&gt; R logAndReturn(Exception e, R defaultValue) &#123; LOGGER.error(&quot;Trier catch an exception: &quot; + getFullStackTrace(e) + &quot;\n And return default value: &quot; + defaultValue); return defaultValue; &#125; private static RuntimeException logAndThrow(Exception e) &#123; log(e); throw new RuntimeException(e); &#125; @FunctionalInterface public interface UncheckedFunction&lt;T, R&gt; &#123; R apply(T t) throws Exception; &#125; @FunctionalInterface public interface UncheckedSupplier&lt;T&gt; &#123; T get() throws Exception; &#125; @FunctionalInterface public interface UncheckedConsumer&lt;T&gt; &#123; void accept(T t) throws Exception; &#125; @FunctionalInterface public interface UncheckedPredicate&lt;T&gt; &#123; boolean test(T t) throws Exception; &#125;&#125; Java8 对字符串连接的改进有时候, 我们会有一种需求就是将若干个字符串用某个链接符衔接起来, 例如有一个 List, 将其格式化为 元素1, 元素2, 元素3, … 元素N 的字符串形式. 以前我们的一般做法就是使用StringBuilder: 123456789101112131415161718public static String formatList(List&lt;String&gt; list, String delimiter) &#123; StringBuilder result = new StringBuilder(); for (String str : list) &#123; result.append(str).append(delimiter); &#125; // 删除末尾多余的 delimiter result.delete(result.length() - delimiter.length(), result.length()); return result.toString();&#125;public static void main(String[] args) throws Exception &#123; List&lt;String&gt; list = Arrays.asList(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;, &quot;e&quot;, &quot;f&quot;, &quot;g&quot;); System.out.println(&quot;使用 StringBuilder: &quot;); String format = formatList(list, &quot;,&quot;); System.out.println(format);&#125; 运行结果: 12使用 StringBuilder: a,b,c,d,e,f,g JDK1.8 时, 添加了一个新的用于字符串连接的类, 专门用于这种需要 分隔符 的场合, 它就是 StringJoiner. StringJoiner 在构造时可以指定一个分隔符（delimiter）, 然后每连接一个元素它便会加上一个 delimiter, 使用 StringJoiner 改写 formatList: 123456789101112131415public static String formatList(List&lt;String&gt; list, String delimiter) &#123; StringJoiner result = new StringJoiner(delimiter); for (String str : list) &#123; result.add(str); &#125; return result.toString();&#125;public static void main(String[] args) throws Exception &#123; List&lt;String&gt; list = Arrays.asList(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;, &quot;e&quot;, &quot;f&quot;, &quot;g&quot;); System.out.println(&quot;使用 StringJoiner: &quot;); String format = formatList(list, &quot;,&quot;); System.out.println(format);&#125; 结果与上面一样. 或者使用String.join: 123public static String formatList(List&lt;String&gt; list, String delimiter) &#123; return String.join(delimiter, list);&#125; 它的底层也是调用StringJoiner: 但是我们看到了 String.join 方法的不足 —— 它不能指定前缀和后缀 —— 比如我们如果想要直接将 List&lt;String&gt; 格式化为 { 元素1, 元素2, 元素3, … 元素N } 呢？（此时前缀为 &quot;{ &quot;, 后缀为 &quot; }&quot;） 查看 StringJoiner 的构造方法, 发现 StringJoiner 除了指定 分隔符 的构造方法, 还有一个可以指定 分隔符、前缀和后缀 的构造方法: 修改 formatList: 1234567891011121314151617public static String formatList( List&lt;String&gt; list, String delimiter, String prefix, String suffix) &#123; StringJoiner result = new StringJoiner(delimiter, prefix, suffix); for (String str : list) &#123; result.add(str); &#125; return result.toString();&#125;public static void main(String[] args) throws Exception &#123; List&lt;String&gt; list = Arrays.asList(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;, &quot;e&quot;, &quot;f&quot;, &quot;g&quot;); System.out.println(&quot;使用 StringJoiner, 带前缀和后缀: &quot;); String format = formatList(list, &quot;, &quot;, &quot;&#123; &quot;, &quot; &#125;&quot;); System.out.println(format);&#125; 运行结果: 12使用 StringJoiner, 带前缀和后缀: &#123; a, b, c, d, e, f, g &#125; 事实上, Java8 对于字符串集合的连接操作提供了一个专门的流式 API, 即 Collectors.joining 函数: 无参的 joining() 方法, 即不存在连接符（底层实现为 StringBuilder）； joining(CharSequence delimiter) 方法, 即分隔符为 delimiter（底层实现为 StringJoiner）； joining(CharSequence delimiter, CharSequence prefix, CharSequence suffix)方法, 即分隔符为 delimiter, 前缀为 prefix, 后缀为 suffix（底层实现为 StringJoiner）. 那怎么使用呢？ 我们直接使用三个参数的 Collectors.joining 方法改写 formatList: 12345678910111213public static String formatList( List&lt;String&gt; list, String delimiter, String prefix, String suffix) &#123; return list.stream().collect(Collectors.joining(delimiter, prefix, suffix));&#125;public static void main(String[] args) throws Exception &#123; List&lt;String&gt; list = Arrays.asList(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;, &quot;e&quot;, &quot;f&quot;, &quot;g&quot;); System.out.println(&quot;使用 Collectors.joining: &quot;); String format = formatList(list, &quot;, &quot;, &quot;&#123; &quot;, &quot; &#125;&quot;); System.out.println(format);&#125; 运行结果同上. Java8 中 Map 接口的新方法假如现在我们存在这样的需求: 给定一个 List&lt;String&gt;, 统计每个元素出现的所有位置. 比如, 给定 list: [&quot;a&quot;, &quot;b&quot;, &quot;b&quot;, &quot;c&quot;, &quot;c&quot;, &quot;c&quot;, &quot;d&quot;, &quot;d&quot;, &quot;d&quot;, &quot;f&quot;, &quot;f&quot;, &quot;g&quot;] , 那么应该返回: 123456a : [0]b : [1, 2]c : [3, 4, 5]d : [6, 7, 8]f : [9, 10]g : [11] 很明显, 我们很适合使用 Map 来完成这件事情: 12345678910111213141516171819202122232425public static Map&lt;String, List&lt;Integer&gt;&gt; getElementPositions(List&lt;String&gt; list) &#123; Map&lt;String, List&lt;Integer&gt;&gt; positionsMap = new HashMap&lt;&gt;(); for (int i = 0; i &lt; list.size(); i++) &#123; String str = list.get(i); List&lt;Integer&gt; positions = positionsMap.get(str); if (positions == null) &#123; // 如果 positionsMap 还不存在 str 这个键及其对应的 List&lt;Integer&gt; positions = new ArrayList&lt;&gt;(1); positionsMap.put(str, positions); // 将 str 及其对应的 positions 放入 positionsMap &#125; positions.add(i); // 将索引加入 str 相关联的 List&lt;Integer&gt; 中 &#125; return positionsMap;&#125;public static void main(String[] args) throws Exception &#123; List&lt;String&gt; list = Arrays.asList(&quot;a&quot;, &quot;b&quot;, &quot;b&quot;, &quot;c&quot;, &quot;c&quot;, &quot;c&quot;, &quot;d&quot;, &quot;d&quot;, &quot;d&quot;, &quot;f&quot;, &quot;f&quot;, &quot;g&quot;); System.out.println(&quot;使用 Java8 之前的 API: &quot;); Map&lt;String, List&lt;Integer&gt;&gt; elementPositions = getElementPositions(list); System.out.println(elementPositions);&#125; 运行结果: 12使用 Java8 之前的 API: &#123;a=[0], b=[1, 2], c=[3, 4, 5], d=[6, 7, 8], f=[9, 10], g=[11]&#125; 在Java8之后, Map添加了一下新的方法签名: 查看源码发现computeIfAbsent很符合上面需求: 我们可以改造成这样子: 1234567891011121314151617public static Map&lt;String, List&lt;Integer&gt;&gt; getElementPositions(List&lt;String&gt; list) &#123; Map&lt;String, List&lt;Integer&gt;&gt; positionsMap = new HashMap&lt;&gt;(); for (int i = 0; i &lt; list.size(); i++) &#123; positionsMap.computeIfAbsent(list.get(i), k -&gt; new ArrayList&lt;&gt;(1)).add(i); &#125; return positionsMap;&#125;public static void main(String[] args) throws Exception &#123; List&lt;String&gt; list = Arrays.asList(&quot;a&quot;, &quot;b&quot;, &quot;b&quot;, &quot;c&quot;, &quot;c&quot;, &quot;c&quot;, &quot;d&quot;, &quot;d&quot;, &quot;d&quot;, &quot;f&quot;, &quot;f&quot;, &quot;g&quot;); System.out.println(&quot;使用 computeIfAbsent: &quot;); Map&lt;String, List&lt;Integer&gt;&gt; elementPositions = getElementPositions(list); System.out.println(elementPositions);&#125; 效果一样, 但是代码优雅整洁了很多. 当 forEach 需要索引上面的例子通过Java8新增的Map方法可以很优雅地实现一些需求: 1234567public static Map&lt;String, List&lt;Integer&gt;&gt; getElementPositions(List&lt;String&gt; list) &#123; Map&lt;String, List&lt;Integer&gt;&gt; positionsMap = new HashMap&lt;&gt;(); for (int i = 0; i &lt; list.size(); i++) &#123; positionsMap.computeIfAbsent(list.get(i), k -&gt; new ArrayList&lt;&gt;(1)).add(i); &#125; return positionsMap;&#125; 但是方法里面的for循环似乎让这个方法不太优雅了, Java8中Iterable提供的foreach并不带索引的: 我们可以自己写一个: 1234567891011 public static &lt;E&gt; void forEach( Iterable&lt;? extends E&gt; elements, BiConsumer&lt;Integer, ? super E&gt; action) &#123; Objects.requireNonNull(elements); Objects.requireNonNull(action); int index = 0; for (E element : elements) &#123; action.accept(index++, element); &#125; &#125;&#125; 然后改造getElementPositions方法: 123456789public static Map&lt;String, List&lt;Integer&gt;&gt; getElementPositions(List&lt;String&gt; list) &#123; Map&lt;String, List&lt;Integer&gt;&gt; positionsMap = new HashMap&lt;&gt;(); Iterables.forEach(list, (index, str) -&gt; &#123; positionsMap.computeIfAbsent(str, k -&gt; new ArrayList&lt;&gt;(1)).add(index); &#125;); return positionsMap;&#125; 使用Lambda代替字符串定义接口: 1234@FunctionalInterfacepublic interface Fn&lt;T&gt; extends Serializable &#123; Object apply(T source);&#125; 编写Entity: 1234@Datapublic class Foo &#123; private Integer bar;&#125; 获取Fn的信息的工具类: 123456789101112131415161718192021import java.beans.Introspector;import java.lang.invoke.SerializedLambda;import java.lang.reflect.Method;public class Reflections &#123; private Reflections() &#123; &#125; public static String fnToFieldName(Fn fn) &#123; try &#123; Method method = fn.getClass().getDeclaredMethod("writeReplace"); method.setAccessible(Boolean.TRUE); SerializedLambda serializedLambda = (SerializedLambda) method.invoke(fn); String getter = serializedLambda.getImplMethodName(); String fieldName = Introspector.decapitalize(getter.replace("get", "")); return fieldName; &#125; catch (ReflectiveOperationException e) &#123; throw new RuntimeException(e); &#125; &#125;&#125; 运行: 1234567891011public class FnConverter&lt;T&gt; &#123; public String convertFnToString(Fn&lt;T&gt; fn)&#123; return Reflections.fnToFieldName(fn); &#125; public static void main(String[] args) &#123; FnConverter&lt;Foo&gt; fnConverter = new FnConverter&lt;&gt;(); String fieldName = fnConverter.convertFnToString(Foo::getBar); System.out.println("方法名："+fieldName); &#125;&#125; 结果: 1方法名：bar Summary关于java8的介绍与使用网上有太多太多了, 如java8最佳技巧等等… 更加深入理解函数式编程请参考Java Functional Programming Internals 参考Java8简明教程知乎专栏CarpenterLeehttp://winterbe.com/posts/2014/03/16/java-8-tutorial/http://brianway.github.io/2017/03/29/javase-java8/#%E6%B5%81stream-apihttps://segmentfault.com/a/1190000007832130]]></content>
      <categories>
        <category>Programming</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VPS自搭建Ngrok内网穿透服务]]></title>
    <url>%2F2017%2Fself-hosted-build-ngrok-server%2F</url>
    <content type="text"><![CDATA[前言 Ngrok可以干嘛？我们经常会有 “把本机开发中的 web 项目给朋友看一下” 或 “测试一下支付宝、微信的支付功能” 这种临时需求, 为此专门购买个域名然后在 VPS或云主机 上部署一遍就有点太浪费了. 那么这时候, Ngrok就是个很好的东西, 它可以实现我们的这种需求. 而且 Ngrok 官网本身还提供了公共服务, 只需要注册一个帐号, 运行它的客户端, 就可以快速把内网映射出去. 不过这么好的服务, 没多久就被墙了~幸好Ngrok是开源的, 那么我们可以自己搭建一个Ngrok！ 域名泛解析因为内网穿透需要用到多级域名, 这里, 博主的这个域名是在Namesilo购买的, 然后转到DNSPod解析:如图所示, 我搞买的域名是yangbingdong.com,将ngrok.yangbingdong.com通过A记录解析导VPS的ip地址, 再将*.ngrok.yangbingdong.com通过CNAME解析导ngrok.yangbingdong.com, 完成泛解析. 服务端安装安装GO环境 这里博主选择通过下载最新版解压安装. 123456789apt-get updateapt-get -y install build-essential mercurial gitwget https://storage.googleapis.com/golang/go1.8.1.linux-amd64.tar.gztar -C /usr/local -xzf go1.8.1.linux-amd64.tar.gzmkdir $HOME/goecho 'export GOROOT=/usr/local/go' &gt;&gt; /etc/profile.d/go.shecho 'export GOPATH=$HOME/go' &gt;&gt; /etc/profile.d/go.shecho 'export PATH=$PATH:$GOROOT/bin:$GOPATH/bin' &gt;&gt; /etc/profile.d/go.shsource /etc/profile.d/go.sh 安装Ngrok123cd /usr/local/src/git clone https://github.com/tutumcloud/ngrok.git ngrokexport GOPATH=/usr/local/src/ngrok/ 生成自签名SSL证书, ngrok为ssl加密连接:12345678910111213cd ngrokNGROK_DOMAIN="ngrok.yangbingdong.com"openssl genrsa -out rootCA.key 2048openssl req -x509 -new -nodes -key rootCA.key -subj "/CN=$NGROK_DOMAIN" -days 5000 -out rootCA.pemopenssl genrsa -out device.key 2048openssl req -new -key device.key -subj "/CN=$NGROK_DOMAIN" -out device.csropenssl x509 -req -in device.csr -CA rootCA.pem -CAkey rootCA.key -CAcreateserial -out device.crt -days 5000cp rootCA.pem assets/client/tls/ngrokroot.crtcp device.crt assets/server/tls/snakeoil.crt cp device.key assets/server/tls/snakeoil.keyGOOS=linux GOARCH=amd64make cleanmake release-server release-client 注意: 上面的ngrok.yangbingdong.com换成自己的域名. 如果是32位系统,GOARCH=386; 如果是64为系统, GOARCH=amd64 如果要编译linux,GOOS=linux;如果要编译window,GOOS=windows 启动server1cd /usr/local/src/ngrok/bin &amp;&amp; ./ngrokd -domain="ngrok.yangbingdong.com" -httpAddr=":8002" -httpsAddr=":8003" -tunnelAddr=":4000" ngrok.yangbingdong.com换成自己的域名. 其他端口可自己配置.顺利的话, 可以正常编译, 在bin下面可以看到「ngrokd」和「ngrok」, 其中「ngrokd」是服务端执行程序, 「ngrok」是客户端执行程序 后台运行:1cd /usr/local/src/ngrok/bin &amp;&amp; nohup ./ngrokd -domain="ngrok.yangbingdong.com" -httpAddr=":8002" -httpsAddr=":8003" -tunnelAddr=":4000" &gt; /dev/null 2&gt;&amp;1 &amp; 123456apt-get install screenscreen -S 任意名字（例如: keepngork）然后运行ngrok启动命令最后按快捷键ctrl+A+D既可以保持ngrok后台运行 设置开机启动12345vim /etc/init.d/ngrok_start:cd /usr/local/src/ngrok/bin./ngrokd -domain="ngrok.yangbingdong.com" -httpAddr=":8002" -httpsAddr=":8003" -tunnelAddr=":4000"chmod 755 /etc/init.d/ngrok_start 客户端使用下载客户端1scp -P 26850 root@12.34.56.78:/usr/local/src/ngrok/bin/ngrok ~/ 将12.34.56.78换成自己的VPS ip. 启动客户端写一个简单的配置文件, 随意命名如 ngrok.cfg:12server_addr: ngrok.yangbingdong.com:4000trust_host_root_certs: false 然后启动:1./ngrok -subdomain ybd -config=ngrok.cfg 8080 其中ybd是自定义的域名前缀, ngrok.cfg是上面创建的配置文件, 8080是本地需要映射到外网的端口.没有意外的话访问ybd.ngrok.yangbingdong.com:8002就会映射到本机的8080端口了. 控制台: 就是上图的Web Interface, 通过这个界面可以看到远端转发过来的 http 详情, 包括完整的 request/response 信息, 相当于附带了一个抓包工具. 另外, Ngrok支持多种协议, 启动的时候可以指定通过-proto指定协议, 例如: http协议: 1./ngrok -subdomain ybd -config=ngrok.cfg -proto=http 8080 tcp协议: 1./ngrok -subdomain ybd -config=ngrok.cfg -proto=tcp 8080 应该会看到: 12345678ngrok (Ctrl+C to quit)Tunnel Status onlineVersion 1.7/1.7Forwarding tcp://ybd.ngrok.yangbingdong.com:8002-&gt; 127.0.0.1:8080Web Interface 127.0.0.1:4040# Conn 0Avg Conn Time 0.00ms Nginx添加server虽然可以访问, 但是带着端口就让人不舒服, 80端口又被Nginx占用, 那么可以用过Nginx反向代理Ngrok.Nginx的配置一般在/etc/nginx/conf.d或者/usr/local/nginx/conf.d里面:12345678910111213141516171819202122#ngrok.yangbingdong.com.confupstream ngrok &#123; server 127.0.0.1:8002; keepalive 64;&#125;server &#123; listen 80; server_name *.ngrok.yangbingdong.com; access_log /var/log/nginx/ngrok_access.log; proxy_set_header &quot;Host&quot; $host:8002; location / &#123; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Host $host:8002; proxy_pass_header Server; proxy_redirect off; proxy_pass http://ngrok; &#125; access_log off; log_not_found off;&#125; 重启Nginx:1nginx -s reload 维护脚本在网上看到的某大神写的维护脚本: 1234567wget https://gist.githubusercontent.com/IvanChou/1be8b15b1b41bf0ce2e9d939866bbfec/raw/1a2445599fe7fd706505a6e103a9dc60b4d3a0ed/ngrokd -O ngrokd##修改 脚本中的配置vi ngrokdchomd +x ngrokdsudo mv ngrokd /etc/init.d/ngrokd 常见错误在ngrok目录下执行如下命令, 编译ngrokd12345678910111213$ make release-server出现如下错误: GOOS=&quot;&quot; GOARCH=&quot;&quot; go get github.com/jteeuwen/go-bindata/go-bindatabin/go-bindata -nomemcopy -pkg=assets -tags=release \ -debug=false \ -o=src/ngrok/client/assets/assets_release.go \ assets/client/…make: bin/go-bindata: Command not foundmake: *** [client-assets] Error 127go-bindata被安装到了$GOBIN下了, go编译器找不到了. 修正方法是将$GOBIN/go-bindata拷贝到当前ngrok/bin下. $cp /home/ubuntu/.bin/go14/bin/go-bindata ./bin 遇到的问题: source与./写了一个Ngrok的安装脚本, 然后chmod +x ngrok-installation.sh赋权, 再./ngrok-installation.sh执行.但是遇到了一个奇怪的问题: 在脚本里面设置了环境变量并source让其生效, 然而出现的结果是由于没有加载到环境变量导致找不到命令, 百思不得解, Google了一把, 发现了原因: source命令与shell scripts的区别是:我们在test.sh设置了AA环境变量, 它只在fork出来的这个子shell中生效, 子shell只能继承父shell的环境变量, 而不能修改父shell的环境变量, 所以test.sh结束后, 父进程的环境就覆盖回去.source在当前bash环境下执行命令, 而scripts是启动一个子shell来执行命令. 这样如果把设置环境变量（或alias等等）的命令写进scripts中, 就只会影响子shell,无法改变当前的BASH,所以通过文件（命令列）设置环境变量时, 要用source 命令. 然后直接source ngrok-installation.sh, 安装成功！ Docker搭建Ngrok 安装Docker请看这里 构建镜像123git clone https://github.com/hteen/docker-ngrok.gitcd docker-ngrokdocker build -t hteen/ngrok . 运行镜像1234docker run -idt --name ngrok-server \-p 8082:80 -p 4432:443 -p 4443:4443 \-v /root/docker/ngrok/data:/myfiles \-e DOMAIN=&apos;ngrok.yangbingdong.com&apos; hteen/ngrok /bin/sh /server.sh -p: 80端口为http端口, 433端口为https端口, 4443端口为tunnel端口 -v: 生成的各种配置文件和客户端都在里面 -e: 泛化的域名 稍等片刻, 会在挂在的目录（/root/docker/ngrok/data）下面生成对应的配置文件以及客户端 1234bin/ngrokd 服务端bin/ngrok linux客户端bin/darwin_amd64/ngrok osx客户端bin/windows_amd64/ngrok.exe windows客户端 Nginx Conf12345678910111213141516171819202122server &#123; listen 80; server_name *.ngrok.yangbingdong.com; location / &#123; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://172.17.0.1:8082; &#125; &#125; server &#123; listen 443; server_name *.ngrok.yangbingdong.com; location / &#123; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://172.17.0.1:4432; &#125; &#125; 172.17.0.1为内网ip 注意: 大概每个星期会产生100M的日志文件.查年docker日志文件位置docker inspect &lt;id&gt; | grep LogPath查看大小ls -lh /var/lib/docker/containers/&lt;id&gt;/&lt;id&gt;-json.log]]></content>
      <categories>
        <category>VPS</category>
      </categories>
      <tags>
        <tag>VPS</tag>
        <tag>Ngrok</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NGINX初学指南(安装与简单配置)]]></title>
    <url>%2F2017%2Fnginx-noob-guide%2F</url>
    <content type="text"><![CDATA[前言 走上了VPS这条不归路, 就意味着需要会维护以及运营自己的服务器. 那么这一章记录一下学习Nginx的一些东西…本文绝大部分内容来自NGINX 网站的官方手册:https://www.nginx.com/resources/admin-guide/installing-nginx-open-source/http://nginx.org/en/docs/beginners_guide.html 安装NGINX部分主干版本VS稳定版本NGINX 有两个有效版本: 主干版本. 这个版本中包含了最新的功能和 BUG 修复, 并且总是最新的版本. 这个版本很可靠, 但是也包含了一些实验性质的模块和一定数量的新 BUG. 稳定版本. 这个版本没有最新的功能, 但是包含了关键 BUG 的修复. 在生产服务器中推荐使用稳定版本. 预编译包VS源码编译NGINX 的主干版本和稳定版本都可以以下两种方式安装: 预编译包安装. 这是一种快捷的安装方式. 预编译包中含有几乎所有 NGINX 官方模块并且适用于大多数主流的操作系统. 通过源码编译安装. 这种方式更加灵活: 你可以添加包括第三方模块在内的特殊模块以及最新的安全补丁. 通过源码编译和安装 通过源码编译 NGINX 带给你更多的灵活性: 你可以添加包括第三方模块在内的特殊模块以及最新的安全补丁. 先安装一些编译依赖:1apt-get update &amp;&amp; apt-get install -y build-essential libtool 安装 NGINX 依赖1、PCRC 库: 被 NGINX Core 和 Rewrite 模块需求, 并且提供正则表达式支持:1cd /usr/local/src &amp;&amp; wget ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/pcre-8.40.tar.gz &amp;&amp; tar -zxf pcre-8.40.tar.gz &amp;&amp; cd pcre-8.40 &amp;&amp; ./configure &amp;&amp; make &amp;&amp; make install 2、zlib 库: 为了头部压缩被 NGINX Gzip 模块需求:1cd /usr/local/src &amp;&amp; wget http://zlib.net/zlib-1.2.11.tar.gz &amp;&amp; tar -zxf zlib-1.2.11.tar.gz &amp;&amp; cd zlib-1.2.11 &amp;&amp; ./configure &amp;&amp; make &amp;&amp; make install 3、OpenSSL 库: 被 NGINX SSL 模块需求用以支持 HTTPS 协议: 这里博主并不选择源码安装=.=, 而是通过apt安装: 12apt-get upgradeapt-get install -y libssl-dev openssl 下载源码NGINX 同时提供了稳定版本和主干版本的源码文件. 源码文件可以从 NGINX Open Source 下载页面下载:Redirect Download Page下载并解压最新的主干版本源码文件, 在命令行中输入下面的命令:1cd /usr/local/src &amp;&amp; wget http://nginx.org/download/nginx-1.12.0.tar.gz &amp;&amp; tar -zxvf nginx-1.12.0.tar.gz &amp;&amp; cd nginx-1.12.0 配置构建选项配置选项要使用 ./configure 脚本来设置各种 NGINX 的参数, 其中包括源码和配置文件路径、编译器选项, 连接处理方法以及模块列表. 脚本最终创建了用于编译代码和安装 NGINX 的 Makefile 文件.例如:1./configure --sbin-path=/usr/local/nginx/nginx --conf-path=/usr/local/nginx/nginx.conf --pid-path=/usr/local/nginx/nginx.pid --with-pcre=../pcre-8.40 --with-zlib=../zlib-1.2.11 --with-http_ssl_module --with-stream --with-http_stub_status_module 配置 NGINX 路径配置脚本允许你设置 NGINX 二进制文件和配置文件的路径以及依赖库 （PCRC 或 SSL）的路径, 以便静态链接到 NGINX 二进制文件中. –prefix=path:定义保存 NGINX 文件的目录. 目录也将被用于所有通过 ./configure 设置的相对路径和 nginx.conf 配置文件的路径. 默认这个路径被设置为 /usr/local/nginx. –sbin-path=path:设置 NGINX 可执行文件的名称. 这个名称仅在安装期间使用. 该文件默认的被命名为 prefix/sbin/nginx. –conf-path=path:设置 NGINX 配置文件名称. 该文件默认的被命名为 prefix/conf/nginx.conf. 注意: 无论这个选项是什么, 你都可以在命令行中通过 -c 选项来指定使用不同的配置文件启动 NGINX. –pid-path=path:设置存储主进程的进程 id 的 nginx.pid 文件名. 在安装以后, 文件名的路径总是可以在 nginx.conf 文件中被修改, 通过使用 pid 指令. 默认该文件被命名为 prefix/logs/nginx.pid –error-log-path=path:设置主要的错误, 警告和诊断文件的名字. 安装之后, 文件名总是可以在 nginx.conf 文件中使用 error_log 指令修改. 该文件默认被命名为 prefix/logs/access.log. –user=name:设置凭据将被用于 NGINX worker 进程的非特权用户的名称. 在安装后, 这个名称可以通过使用 user 指令在 nginx.conf 文件中修改. 默认的名字是 nobody. –group=name:设置凭据将被用于 NGINX worker 进程的用户组名. 在安装以后, 这个名称可以通过使用 user 指令在 nginx.conf 文件中修改. 默认地, 用户组名被设置为非特权用户的名字. –with-pcre=path:设置 PCRE 库的源码的路径. 这个库在 location 指令和 ngx_http_rewrite_module 模块中被用于支持正则表达式. –with-pcre-jit:使用 “just-in-time compilation” 支持（pcre_jit 指令）来构建 PCRE 库. –with-zlib=path:设置 zlib 库的源码的路径. 这个库被用于 ngx_http_gzip_module 模块中. 配置 NGINX GCC 选项在配置脚本中你也可以指定编译器关联选项:–with-cc-opt=parameters:设置添加到 CFLAGS 变量中的附加参数. 在 FreeBSD 系统下, 当使用系统 PCRE 库的时候, –with-cc-opt=-I/usr/local/include 必须被指定. 如果被select支持的文件数量需要增加, 那么也可以像这下面这样指定: –with-cc-opt=-D/FD_SETSIZE=2048. –with-ld-opt=parameters:设置将用于链接时的附加参数. 当在 FreeBSD 下使用系统 PCRE 库时, –with-cc-opt=-L/usr/local/lib 必须被指定. 指定 NGINX 连接处理方法在配置脚本中, 你可以重新定义基于事件的轮询方法. 查看 Connection Processing Methods 了解更多内容.–with-select_module,–without-select_module:启用或禁用构建允许 NGINX 使用 select 方法工作的模块. 如果平台没有明确支持想 kqueue,epoll,/dev/poll这样更加合适的方法, 该模块将被自动构建. –with-poll_module,–without-poll-module:启用或禁用构建允许 NGINX 使用 poll() 方法工作的模块. 如果该平台没有明确支持像 kqueue,epoll,/dev/poll 这样更加更是的方法, 该模块将被自动构建. NGINX 模块模块的 NGINX 常量. 模块的设置就如其他构建选项一样被配置在 ./configure 脚本中.有一些模块被自动构建——他们不需要在配置脚本中指定. 然而, 一些默认的模块可以被排除在 NGINX 二进制文件之外, 通过在配置脚本中使用 -without- 配置选项.模块默认不包含第三方模块, 必须在配置脚本中使用其他的构建选项明确指定才行. 这些模块可以被链接到 NGINX 二进制文件, 以静态的方式在每次启动 NGINX 被加载, 或者如果他们在配置文件中被指定则以动态的方式被加载. 默认的模块构建如果你不需要一个默认的构建模块, 你可以通过使用 –without- 前缀的模块名来禁用它:1./configure --sbin-path=/usr/local/nginx/nginx --conf-path=/usr/local/nginx/nginx.conf --pid-path=/usr/local/nginx/nginx.pid --with-http_ssl_module --with-stream --with-pcre=../pcre-8.40 --with-zlib=../zlib-1.2.11 --without-http_empty_gif_module 模块名称 描述 http_charset_module 向 Content-Type 响应 header 域添加指定的字符集, 能够覆盖数据从一种编码到另外一种. http_gzip_module 使用 gzip 方法压缩响应, 有助于将传输的数据减少至少一半. http_ssi_module 通过它在响应中处理 SSI (Server Side Includes) 命令. http_userid_module 为客户端鉴定设置 cookies 适配. http_access_module 限制对特定客户端地址的访问 http_auth_basic_module 通过使用 HTTP Basic Authentication 协议验证用户名和密码来限制访问资源. http_autoindex_module 处理以斜线（/）结束的请求并产生一个目录列表. http_geo_module 创建依赖客户端 IP 地址值的变量. http_map_module 创建依赖其他变量值的变量. http_split_clients_module 创建适配 AB 测试的变量, 也被称为分隔测试. http_referer_module 如果请求的 header 域中的 Referer 使用了无效值, 阻止其访问站点. http_rewrite_module 使用正则表达式改变请求的 URI 并重定向. 有条件的选择. 需要 PCRE 库支持. http_proxy_module 传递请求到其他服务器. http_fastcgi_module 传递请求到 FastCGI 服务器. http_uwsgi_module 传递请求到 uwsgi 服务器. http_scgi_module 传递请求到 SCGI 服务器. http_memcached_module 从 memcached 服务器中获取响应. http_limit_conn_module 限制每个定义的 key 的连接数量, 特别是来自单一 IP 地址的连接数量. http_limit_req_module 限制每个定义的 key 的请求处理率, 特别是来自单一 IP 地址的处理率. http_empty_gif_module 发出单像素透明 GIF. http_browser_module 创建依赖请求 header 域中的 “User-Agent” 值的变量. http_upstream_hash_module 开启 hash 负载均衡方法. http_upstream_ip_hash_module 开启 IP hash 负载均衡方法. http_upstream_least_conn_module 开启 least_conn 负载均衡方法. http_upstream_keepalive_module 开启持续连接. http_upstream_zone_module 开启共享内存区. 非默认构建的模块一些 NGINX 模块不是默认构建的. 你需要通过添加到 ./configure 命令去手动启用他们. mail,stream,geoip,image_filter,perl和xslt 模块可以被动态编译. 查看 Dynamic Modules 来了解更多内容. 例如, ./configure 命令包含了这些模块:1./configure --sbin-path=/usr/local/nginx/nginx --conf-path=/usr/local/nginx/nginx.conf --pid-path=/usr/local/nginx/nginx.pid --with-pcre=../pcre-8.40 --with-zlib=../zlib-1.2.11 --with-http_ssl_module --with-stream --with-mail 选项 说明 –with-threads 允许 NGINX 使用线程池. 查看详情: Thread Pools in NGINX Boost Performance 9x! –with-file-aio 启用异步 I/O. –with-ipv6 启用 IPv6 支持. –with-http_ssl_module 提供 HTTPS 支持. 需要 SSL 库, 如 OpenSSL. 配置参考: ngx_http_ssl_module –with-http_v2_module 提供 HTTP/2 支持. 配置参考: ngx_http_v2_module, 更多信息: HTTP/2 Module in NGINX –with-http_realip_module 修改客户端地址为在指定 header 域中的发送地址. 参考配置: ngx_http_realip_module –with-http_addition_module 在响应的前后添加文本. 配置参考: ngx_http_addition_module –with-http_xslt_module 或 –with-http_xslt_module=dynamic 使用一种或多种 XSLT 样式表来转换 XML 响应. 该模块需要 Libxml2 和 XSLT 库. 配置参考: ngx_http_xslt_module –with-http_image_filter_module 或 –with-http_image_filter_module=dynamic 将图片在 JPEG、GIF 和 PNG 中转换格式. 该模块需要 LibGD 库. 配置参考: ngx_http_image_filter_module –with-http_geoip_module 或 –with-http_geoip_module=dynamic 允许创建依赖客户端 IP 地址值的变量. 该模块使用了 MaxMind GeoIP 数据库. 配置参考: ngx_http_geoip_module –with-http_sub_module 通过使用其他的字符串替换指定字符串修改响应. 配置参考: ngx_http_sub_module –with-http_dav_module 用于通过 WebDAV 协议的文件管理自动化. 配置参考: ngx_http_dav_module –with-http_flv_module 为 Flash Video (FLV) 文件提供伪流服务器端支持. 配置参考: ngx http_flv_module –with-mp4_module 为 MP4 文件提供伪流服务器端支持. 配置参考: ngx_http_mp4_module –with-http_gunzip_module 使用 Content-Encoding 解压响应: gzip 用于不支持 zip 编码方法的客户端. 配置参考: ngx_http_gunzip_module –with-http_gzip_static_module 允许发送使用 *.gz 文件扩展名而不是常规的预压缩文件. 配置参考: ngx_http_gzip_static_module –with-http_auth_request_module 基于子请求实施客户端授权. 配置参考: http_auth_request_module –with-http_random_index_module 处理使用斜杠 (/) 结尾的请求, 并且从一个目录取出一个随机文件来作为首页. 配置参考: ngx_http_random_index_module –with-http_secure_link_module 用于插件被请求链接的授权, 保护资源不被未授权访问或者限制链接的生命周期. 配置参考: ngx_http_secure_link_module –with-http_slice_module 允许将请求分隔为子请求, 每个请求返回确定的响应范围. 提供更多大型文件的有效缓存. 查看 ngx_http_slice_module 相关的指令列表. 配置参考: ngx_http_slice_module –with-http_degradation_module 当内存超出默认值的时候, 允许返回错误信息 –with-http_stub_status_module 提供访问基本状态信息. 配置参考: ngx_http_stub__status_module. 注意 NGINX Plus 用户不需要这个模块, 因为已经为他们提供了扩展状态的面板. –with-http_perl_module 或 –with-http_perl_module=dynamic 用于在 Perl 中实现位置和变量句柄, 并且将 Perl 调用插入到 SSI 中. 需要 PERL 库. 配置参考: ngx_http_perl_module . 该模块也可以被动态编译. –with-mail 或 –with-mail=dynamic 启用邮件代理功能. 配置参考: ngx_mail_core_module . 该模块也可以被动态编译. –with-mail_ssl_module 为使用 SSL/TLS 协议工作的邮件代理服务器提供支持. 需要想 OpenSSL 这样的 SSL 库. 配置参考: ngx_mail_ssl_module –with-stream 或 –with-stream=dynamic 开启 TCP 代理功能. 配置参考: ngx_stream_code_module . 该模块可以被动态编译. –with-google_perftools_module 允许使用 Google Performance 工具库. –with-cpp_test_module 或 –with-debug 开启调试日志. 第三方模块你可以使用你自己的模块或者第三方模块扩展 NGINX 的功能通过编译 NGINX 源码. 一些第三方模块被列举在 https://nginx.com/resources/wiki/modules/ 页面中. 使用第三方模块的你将要承担稳定性无法保证的风险. 静态链接模块被构建在 NGINX 源码中的大多数模块是被静态链接的: 他们在编译的时候被构建在 NGINX 源码中, 然后被静态的了链接到 NGINX 二进制文件中. 这些模块只能在 NGINX 重新编译之后才能禁用.要使用静态链接的第三方模块去编译 NGINX 源码, 在配置脚本中要指定 –add-module=option 并且输入模块的路径:1$ ./configure ... --add-module=/usr/build/nginx-rtmp-module 动态链接模块NGINX 模块也可以被编译为一个共享对象（.so 文件）, 然后在运行时动态的加载到 NGINX 中. 这样提供了更多的灵活性, 作为模块可以在任何时候被加载或反加载通过在 NGINX 配置文件中使用 **load_module* 指令指定. 注意: 这种模块必须支持动态链接.要使用动态加载第三方模块编译 NGINX 源码, 在配置脚本中要指定 –add-dynamic-module=配置选项和模块的路径.1$ ./configure ... --add-dynamic-module=/path/to/module 动态模块的结果文件 .so 在编译结束后在 prefix/modules/ 目录中被找到, prefix 是保存服务器文件的目录, 如: /usr/local/nginx/modules. 要想加载动态模块, 在 NGINX 安装完成后使用 local_module 指令.查看 Introducing Dynamic Modules in NGINX 1.9.11 和 Extending NGINX 来了解更多内容. 完成安装12./configure --prefix=/usr/local/nginx --with-pcre=../pcre-8.40 --with-zlib=../zlib-1.2.11 --with-http_stub_status_module --with-http_ssl_modulemake &amp;&amp; make install 到此NGINX已经安装完成, 但是, 此时直接敲nginx可能会显示没有找到命令, 因为还没有配置环境变量:1234touch /etc/profile.d/nginx.shecho "PATH=$PATH:/usr/local/nginx/sbin" &gt;&gt; /etc/profile.d/nginx.shecho "export PATH" &gt;&gt; /etc/profile.d/nginx.shsource /etc/profile.d/nginx.sh 完成！查看NGINX:1nginx -v 预编译包安装 博主用的就是这种方式, 简单粗暴！当然上面的方式也是过, 但毕竟只是个业余的, 手动一个个模块配置上去的话, 小白表示搞不定. 添加源12echo "deb http://nginx.org/packages/ubuntu/ trusty nginx" &gt;&gt; /etc/apt/sources.listecho "deb-src http://nginx.org/packages/ubuntu/ trusty nginx" &gt;&gt; /etc/apt/sources.list 更新并导入升级Key完成安装1wget http://nginx.org/keys/nginx_signing.key &amp;&amp; apt-key add nginx_signing.key &amp;&amp; apt-get update &amp;&amp; apt-get upgrade &amp;&amp; apt-get install openssl nginx 查看1nginx -V NGINX初学校验, 启动, 停止和重新加载配置12345# 校验nginx -t # 停止、退出、重新加载配置、重启nginx -s stop|quit|reload|reopen 也可以是这样:1kill -s QUIT 1888 #1888是nginx的PID 要获取全部正在运行中的 nginx 进程列表, 可以使用 ps 工具, 就像下面这样:1ps -ax | grep nginx 如果要了解更多的有关信号发送的信息, 请查看控制nginx. 配置文件的结构nginx 由被配置文件指定的指令控制的模块组成. 指令被分为简单指令和块指令. 简单指令有名称和参数组成, 通过空格来分隔开, 以 ; 号来结束. 块指令拥有和简单指令一样的结构, 但是不用 ; 结束而是使用一组被 {} 环绕的额外指令. 如果一个块指令在其内部包含了其他指令, 则被称为上下文（context）, 比如: events,http,server 和location. 被放置在配置文件中却不在任何上下文中的指令被认为是在主上下文之内的. events 和 http 指令就属于主上下文, server 在 http 之内, location 在 server 之内. 单行之中在 # 号之后的剩余内容被认为是注释. 静态内容服务一个重要的 web 服务器任务就是提供文件（比如图片或者静态 HTML 页面）. 你将会实现一个例子, 依赖于 request 请求, 文件将被从不同的本地目录（/data/www 和 /data/images）中提供. 这需要编辑配置文件并在 http 块之内使用两个 location 块来设置一个 server 块. 首先, 创建 /data/www 目录并且将一个名为 index.html 文件放进去, 然后在创建一个 /data/images 目录并放置一些图片在里面. 接下来, 打开配置文件. 默认的配置文件已经包含了一些 server 块的例子, 通常都被注释掉了. 那么现在, 注释掉全部块并且编写一个新的 server块吧: 1234http &#123; server &#123; &#125;&#125; 通常地, 配置文件可能包含了一些 server 块, 通过监听端口和服务器名字来区分. 一旦 nginx 决定哪个服务处理请求, 将会试着添加以下 location 块到 server 块中: 123location / &#123; root /data/www;&#125; 这个 location 块说明了 / 前缀和请求中的 URI 进行比较. 对于匹配的请求, URI 将会被添加到被 root 指令说明的路径中去, 就是到 /data/www 中, 形成一个在本地文件系统中的请求文件路径. 如果有多个匹配了 location 的块, nginx 会选择前缀最长的那个. 上面的那个 location 块是最短的前缀, 长度只有 1, 所以只有其他 location 块匹配都失败了, 这个块才会被使用. 接下来, 添加第二个 location 块: 123location /images/ &#123; root /data;&#125; 这将匹配以 /images/ 开始的请求（location / 也会匹配这个请求, 但他的前缀最短）. 最终 server 块的配置看起来是像下面这样的: 123456789server &#123; location / &#123; root /data/www ; &#125; location /iamges/ &#123; root /data; &#125;&#125; 配置一个监听标准 80 端口并且可在本机访问的服务器的工作就是这样了. 在响应使用以 /images/ 为开头的 URI 的请求中, 服务器会从 /data/images 目录中中发送文件. 例如, 在响应 http://localhost/images/example.png 的请求中, nginx 会发送 /data/images/exmaple.png 文件. 如果这个文件不存在, nginx 会发送一个 404 错误的响应. URI 不以 /images/ 开头的请求将被映射到 /data/www 目录中. 例如, 在响应 http://localhost/some/example.html 的请求中, nginx 将发送 /data/www/some/example.html 文件. 要想应用新的配置, 请启动 nginx（如果还没启动的话）或者发送 reload 信号到 nginx 主进程, 通过执行如下命令: 1nginx -s reload 本例中, 有些不会像期望中的那样工作, 你可以在 access.log 和 error.log 文件中尝试找到原因, 这些文件的位置在 /usr/local/nginx/logs 或 /var/log/nginx 中. 设置一个简单的代理服务器nginx 的一个频繁的用法是被设置作为代理服务器, 这意味着接收请求的服务器, 通过他们到被代理的服务器, 再通过他们取回相应, 并且通过他们发送给客户端. 下面我们来配置一个基本的代理服务器, 来为本地图片请求提供服务并将其他请求转到被代理的服务器上. 本例中, 两个服务器将被定义在一个 nginx 实例中. 首先, 通过增加一个 server 块到 nginx 配置文件的方式定义被代理的服务, 配置内容如下: 1234567server &#123; listen 8080; root /data/up1; location / &#123; &#125;&#125; 这是一个监听 8080 端口并且映射全部请求到本地 /data/up1 目录的简单服务器. 创建这个目录并放一个 index.html 在里面. 注意, root 指令被放置在 server 上下文中, 这样的 root 指令被用在当 location 块被选中提供服务的时候. 接下来, 使用上一节的服务器配置并修改为一个代理服务器的配置. 在第一 location 块中, 放入使用由协议, 名字以及被代理服务器的端口描述的参数的 proxy_pass 指令（在我们的例子中, 就是 http://localhost:8080）: 12345678server &#123; localtion / &#123; proxy_pass http://localhost:8080; &#125; localtion /images/ &#123; root /data; &#125;&#125; 我们将修改第二个 location 块, 它当前使用 /images/ 前缀来映射请求到 /data/images/ 下的文件, 我们现在想要让他匹配一些典型的图片类型扩展名的请求. 修改后的 localtion 块看起来像这样的: 123localtion ~ \.(gif|jpg|png)$ &#123; root /data/images;&#125; 参数是匹配了全部以 .gif .jpg .png 结尾的 URI 的正则表达式. 一个正则表达式应被 ~ 开始. 这样, 相关的请求就会被映射到 /data/images/ 目录中了. 当 nginx 选取一个 localtion 块来为请求提供服务的时候, 首先要检查 location 指令说明的前缀, 记住最长前缀的 location, 然后再检查正则表达式. 如果匹配了一个正则表达式, nginx 挑出这个 localtion, 否则, 它就会挑选之前被记录的. 代理服务器的配置结果看起来将会是下面这样: 12345678server&#123; location / &#123; proxy_pass http://localhost:8080/; &#125; localtion ~ \.(gif|jpg|png)$ &#123; root /data/images; &#125;&#125; 这个服务器将过滤以 .gif .jpg .png 结尾的请求, 并映射他们到 /data/images 目录（通过添加 URI 到 root 指令的参数）, 还会传递其他请求到被之前配置的被代理服务器上. 要应用新配置, 要像前面章节提到的发送 reload 信号给 nginx. 这里有更多的可能更加有用的配置代理连接的指令. 快速查看配置文件的方法nginx的配置放在nginx.conf文件中, 一般我们可以使用以下命令查看服务器中存在的nginx.conf文件. 1234locate nginx.conf/usr/local/etc/nginx/nginx.conf/usr/local/etc/nginx/nginx.conf.default...1234 如果服务器中存在多个nginx.conf文件, 我们并不知道实际上调用的是哪个配置文件, 因此我们必须找到实际调用的配置文件才能进行修改. 查看NGINX实际调用的配置文件1.查看NGINX路径1234ps aux|grep nginxroot 352 0.0 0.0 2468624 924 ?? S 10:43上午 0:00.08 nginx: worker process root 232 0.0 0.0 2459408 532 ?? S 10:43上午 0:00.02 nginx: master process /usr/local/opt/nginx/bin/nginx -g daemon off; root 2345 0.0 0.0 2432772 640 s000 S+ 1:01下午 0:00.00 grep nginx1234 NGINX的路径为: /usr/local/opt/nginx/bin/nginx 2.查看NGINX配置文件路径使用NGINX的 -t 参数进行配置检查, 即可知道实际调用的配置文件路径及是否调用有效. 123/usr/local/opt/nginx/bin/nginx -tnginx: the configuration file /usr/local/etc/nginx/nginx.conf syntax is oknginx: configuration file /usr/local/etc/nginx/nginx.conf test is successful123 测试可知, NGINX的配置文件路径为: /usr/local/etc/nginx/nginx.conf 且调用有效. 拒绝或允许指定IPNGINX拒绝或允许指定IP,是使用模块HTTP访问控制模块（HTTP Access）.控制规则按照声明的顺序进行检查, 首条匹配IP的访问规则将被启用.如下例: 123456location / &#123; deny 192.168.1.1; allow 192.168.1.0/24; allow 10.1.1.0/16; deny all;&#125; 上面的例子中仅允许192.168.1.0/24和10.1.1.0/16网络段访问这个location字段, 但192.168.1.1是个例外.注意规则的匹配顺序, 如果你使用过Apache你可能会认为你可以随意控制规则的顺序并且他们能够正常的工作, 但实际上不行, 下面的这个例子将拒绝掉所有的连接: 12345678location / &#123; #这里将永远输出403错误. deny all; #这些指令不会被启用, 因为到达的连接在第一条已经被拒绝 deny 192.168.1.1; allow 192.168.1.0/24; allow 10.1.1.0/1&#125; 最后 参考:Installing NGINX Open SourceNginx 初学者指南 顺便写了个安装脚本:源码版预编译版 人生在于折腾, 这几天玩VPS有很大的收获, 学会了一些以前不会的命令、写脚本、穿墙、Nginx等等, 坚持折腾！PS: 链接换成加粗斜体, 一个一个地找好累, 于是又学会了正则表达式: \[[\w\s]*\]\(https?://[a-z\.\?/_=0-9\s#&amp;-]*\), 一键替换～]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>VPS</tag>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Access Blocked Sites(科学上网):VPS自搭建ShadowSocks与加速]]></title>
    <url>%2F2017%2Fuse-vps-cross-wall-by-shadowsocks-under-ubuntu%2F</url>
    <content type="text"><![CDATA[Preface 最近在玩VPS, 作为没有Google就活不下去的开发人员, 翻山越岭已是日常= =…使用别人的VPN或者Sock5代理显然是不安全的, 个人信息随时被截获, 那么拥有一台自己VPS也是必需的, 价格也可以很便宜（绝对不是在打广告） 如果是要使用Linode作为VPS的并且还没注册的朋友, 可以填上我的邀请码: 79e24952d46644605b071a55c4fda3b23e1d1a5a ShadowSocks介绍 What is ShadowSocksShadowSocks(影梭) 是由clowwindy所开发的一个开源 Socks5 代理. 如其官网所言 , 它是 “A secure socks5 proxy, designed to protect your Internet traffic” （一个安全的 Socks5 代理）. 其作用, 亦如该项目主页的 wiki（中文版） 中所说, “A fast tunnel proxy that helps you bypass firewalls” （一个可穿透防火墙的快速代理）.不过, 在中国, 由于 GFW 的存在, 更多的网友用它来进行科学上网. This is a story…long long ago…我们的互联网通讯是这样的: when evil comes然后有一天, GFW 就出现了, 他像一个收过路费的强盗一样夹在了在用户和服务之间, 每当用户需要获取信息, 都经过了 GFW, GFW将它不喜欢的内容统统过滤掉, 于是客户当触发 GFW 的过滤规则的时候, 就会收到 Connection Reset 这样的响应内容, 而无法接收到正常的内容: ssh tunnel聪明的人们想到了利用境外服务器代理的方法来绕过 GFW 的过滤, 其中包含了各种HTTP代理服务、Socks服务、VPN服务… 其中以 ssh tunnel 的方法比较有代表性:1) 首先用户和境外服务器基于 ssh 建立起一条加密的通道2-3) 用户通过建立起的隧道进行代理, 通过 ssh server 向真实的服务发起请求4-5) 服务通过 ssh server, 再通过创建好的隧道返回给用户由于 ssh 本身就是基于 RSA 加密技术, 所以 GFW 无法从数据传输的过程中的加密数据内容进行关键词分析, 避免了被重置链接的问题, 但由于创建隧道和数据传输的过程中, ssh 本身的特征是明显的, 所以 GFW 一度通过分析连接的特征进行干扰, 导致 ssh存在被定向进行干扰的问题. shadowsocks于是 clowwindy 同学分享并开源了他的解决方案.简单理解的话, shadowsocks 是将原来 ssh 创建的 Socks5 协议拆开成 server 端和 client 端, 所以下面这个原理图基本上和利用 ssh tunnel 大致类似.1、6) 客户端发出的请求基于 Socks5 协议跟 ss-local 端进行通讯, 由于这个 ss-local 一般是本机或路由器或局域网的其他机器, 不经过 GFW, 所以解决了上面被 GFW 通过特征分析进行干扰的问题2、5) ss-local 和 ss-server 两端通过多种可选的加密方法进行通讯, 经过 GFW 的时候是常规的TCP包, 没有明显的特征码而且 GFW 也无法对通讯数据进行解密3、4) ss-server 将收到的加密数据进行解密, 还原原来的请求, 再发送到用户需要访问的服务, 获取响应原路返回 VPS选择BandwagonHOSTBandwagonHOST俗称搬瓦工, 隶属于美国IT7旗下的VPS服务品牌, VPS采用OpenVZ架构, 主要针对低端VPS市场.具体节点的选择, 可以在浏览器中输入以下IP进行实际测试（测试地址由www.banwagong.com提供）:美国洛杉矶 US West Coast-Los Angeles: 104.224.162.217美国佛罗里达 US West Coast-Florida: 104.224.141.127欧洲 荷兰 EU-Netherlands: 104.224.145.203美国 凤凰城 US, Arizona : 45.62.112.117一般而言, 中国用户使用洛杉矶和凤凰城的机房会有较好的网络体验.注: 搬瓦工已被墙, 需要翻墙访问. 搬瓦工从15年6月26日起支持支付宝付款. Digital OceanDigitalOcean是一家位于美国的云主机服务商, 总部位于纽约, 成立于2012年, VPS 核心架构采用KVM架构. 由于价格低廉, 高性能配置、灵活布置的优势, 近些年来发展迅猛.该公司拥有多个数据中心, 分布在: New York( Equinix 和 Telx 机房), San Francisco ( Telx ), Singapore ( Equinix ), Amsterdam ( TelecityGroup ), Germany ( Frankfurt ). 其私有数据网络供应商是Level3, NTT, nLayer, Tinet, Cogent, 和Telia.一般而言, 建议非电信用户可以采用新加坡节点, 速度非常给力. 电信用户不建议采用此VPS, 速度比较一般, 更推荐 Vultr 和 Linode 的日本机房. VultrVultr 是一家成立于2014年的VPS提供商. 根据域名所有者资料, 母公司是2005年成立于新泽西州的 ClanServers Hosting LLC 公司, 他们家的游戏服务器托管在全球6个国家的14个数据中心, 选择非常多. Vultr 家的服务器采用的 E3 的 CPU , 清一色的 Intel 的 SSD 硬盘, VPS采用KVM架构. Vultr 的计费按照使用计费（自行选择配置、可以按月或按小时计费）, 用多少算多少, 可以随时取消, 另外可以自己上传镜像安装需要的操作系统也是一大亮点. 现在已经成为 Digital Ocean 的有力竞争对手.Vultr的服务器托管在全球14个数据中心, 即时开通使用. 大陆访问日本机房速度不错, 延迟低、带宽足. LinodeLinode 是VPS 服务商中的大哥, 高富帅般的存在. 价格相对较高, 但是性能, 稳定性等各方面也非常给力. VPS 采用 Xen 架构, 不过最近的周年庆开始升级到 KVM 架构, VPS 性能进一步提升. 推荐给对连接速度和网络延迟有极致追求的用户.Linode只能使用信用卡支付, 官方会随机手工抽查, 被抽查到的话需要上传信用卡正反面照片以及可能还需要身份证正反面照片, 只要材料真实齐全, 审核速度很快, 一般一个小时之内就可以全部搞定. 账户成功激活以后, 就可以安心使用了. 博主的邀请码: 79e24952d46644605b071a55c4fda3b23e1d1a5a 准备工作准备一台VPS博主选择Linode 博主的邀请码: 79e24952d46644605b071a55c4fda3b23e1d1a5a SSH无密码登录VPS参考 免密码登录远程服务器 ShadowSocks服务端安装基于Docker 安装方式各种各样. . . 推荐Docker安装 拉取镜像Showdowsocks镜像: https://hub.docker.com/r/mritd/shadowsocks/ 1docker pull mritd/shadowsocks:latest 运行With Kcptun 1docker run -dt --name ssserver --restart=always -p 6443:6443 -p 6500:6500/udp mritd/shadowsocks:latest -m &quot;ss-server&quot; -s &quot;-s 0.0.0.0 -p 6443 -m aes-256-cfb -k 123456 --fast-open&quot; -x -e &quot;kcpserver&quot; -k &quot;-t 127.0.0.1:6443 -l :6500 -mode fast2&quot; 说明: -m : 参数后指定一个 shadowsocks 命令, 如 ss-local, 不写默认为 ss-server；该参数用于 shadowsocks 在客户端和服务端工作模式间切换, 可选项如下: ss-local、ss-manager、ss-nat、ss-redir、ss-server、ss-tunnel -s : 参数后指定一个 shadowsocks-libev 的参数字符串, 所有参数将被拼接到 ss-server 后 -x : 指定该参数后才会开启 kcptun 支持, 否则将默认禁用 kcptun -e : 参数后指定一个 kcptun 命令, 如 kcpclient, 不写默认为 kcpserver；该参数用于 kcptun 在客户端和服务端工作模式间切换, 可选项如下: kcpserver、kcpclient -k : 参数后指定一个 kcptun 的参数字符串, 所有参数将被拼接到 kcptun 后 Without Kcptun 1docker run -dt --name ssserver --restart=always -p 6443:6443 mritd/shadowsocks:latest -m &quot;ss-server&quot; -s &quot;-s 0.0.0.0 -p 6443 -m aes-256-cfb -k 123456 --fast-open&quot; ss命令说明: -s : 监听服务ip, 为服务器本地 -p : 端口 -m : 加密算法 -k : 密码 --fast-open : 开启TCP fast-open kcptun命令自行度娘=.= 脚本一键安装 更多精彩被容请移步到 https://teddysun.com/ root用户执行: 123wget --no-check-certificate -O shadowsocks-all.sh https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks-all.shchmod +x shadowsocks-all.sh./shadowsocks-all.sh 2&gt;&amp;1 | tee shadowsocks-all.log 安装完成后, 脚本提示如下12345678910111213Congratulations, your_shadowsocks_version install completed!Your Server IP :your_server_ipYour Server Port :your_server_portYour Password :your_passwordYour Encryption Method:your_encryption_methodYour QR Code: (For Shadowsocks Windows, OSX, Android and iOS clients) ss://your_encryption_method:your_password@your_server_ip:your_server_portYour QR Code has been saved as a PNG file path: your_path.pngWelcome to visit:https://teddysun.com/486.htmlEnjoy it! 卸载方法若已安装多个版本, 则卸载时也需多次运行（每次卸载一种） 使用root用户登录, 运行以下命令: 1./shadowsocks-all.sh uninstall 启动脚本启动脚本后面的参数含义, 从左至右依次为: 启动, 停止, 重启, 查看状态. Shadowsocks-Python 版:/etc/init.d/shadowsocks-python start | stop | restart | status ShadowsocksR 版:/etc/init.d/shadowsocks-r start | stop | restart | status Shadowsocks-Go 版:/etc/init.d/shadowsocks-go start | stop | restart | status Shadowsocks-libev 版:/etc/init.d/shadowsocks-libev start | stop | restart | status 各版本默认配置文件Shadowsocks-Python 版:/etc/shadowsocks-python/config.json ShadowsocksR 版:/etc/shadowsocks-r/config.json Shadowsocks-Go 版:/etc/shadowsocks-go/config.json Shadowsocks-libev 版:/etc/shadowsocks-libev/config.json ShadowSocks客户端安装安装与启动DockerWith Kcptun 1docker run -dt --name ssclient --restart=always -p 1080:1080 -p 6500:6500/udp mritd/shadowsocks:latest -m &quot;ss-local&quot; -s &quot;-s 127.0.0.1 -p 6500 -b 0.0.0.0 -l 1080 -m aes-256-cfb -k 123456 --fast-open&quot; -x -e &quot;kcpclient&quot; -k &quot;-r server-ip:6500 -l :6500 -mode fast2&quot; Without Kcptun 1docker run -dt --name ssclient --restart=always -p 1080:1080 mritd/shadowsocks:latest -m &quot;ss-local&quot; -s &quot;-s server-ip -p 6443 -b 0.0.0.0 -l 1080 -m aes-256-cfb -k 123456 --fast-open&quot; 注意: 如果使用了With Kcptun, ss的监听ip填本地 127.0.0.1, server-ip填服务器ip. 测试了一下, 在开启了BBR情况下, without kcptun更快.对于一般情况（没有开启BBR或其他加速）, with kcptun速度有所提升. pip 安装安装用PIP安装很简单:123sudo apt-get updatesudo apt-get install python-pipsudo apt-get install python-setuptools m2crypto 接着安装ShadowSocks:1pip install shadowsocks 如果是ubuntu16.04 直接 (16.04 里可以直接用apt 而不用 apt-get 这是一项改进.sudo apt install shadowsocks当然你在安装时候肯定有提示需要安装一些依赖比如python-setuptools m2crypto , 依照提示安装然后再安装就好. 也可以网上搜索有很多教程的. 启动安装好后, 在本地我们要用到sslocal , 终端输入sslocal –help 可以查看帮助, 像这样通过帮助提示我们知道各个参数怎么配置, 比如 sslocal -c 后面加上我们的json配置文件, 或者像下面这样直接命令参数写上运行.比如1sslocal -s 11.22.33.44 -p 50003 -k &quot;123456&quot; -l 1080 -t 600 -m aes-256-cfb -s表示服务IP, -p指的是服务端的端口, -l是本地端口默认是1080, -k 是密码（要加””）, -t超时默认300,-m是加密方法默认aes-256-cfb. 为了方便我推荐直接用sslcoal -c 配置文件路径 这样的方式, 简单好用.我们可以在/home/ybd/ 下新建个文件shadowsocks.json (ybd是我在我电脑上的用户名, 这里路径你自己看你的). 内容是这样:12345678&#123;"server":"11.22.33.44","server_port":8388,"local_port":1080,"password":"123456","timeout":600,"method":"aes-256-cfb"&#125; server: 你服务端的IPservier_port: 你服务端的端口local_port: 本地端口, 一般默认1080passwd: ss服务端设置的密码timeout: 超时设置 和服务端一样method: 加密方法 和服务端一样确定上面的配置文件没有问题, 然后我们就可以在终端输入 sslocal -c /home/ybd/shadowsocks.json 回车运行. 如果没有问题的话, 下面会是这样… 如果你选择这一种请跳过第二种. 你可以去系统的代理设置按照说明设置代理, 但一般是全局的, 然而我们访问baidu,taobao等着些网站如果用代理就有点绕了, 而且还会浪费服务器流量. 我们最好配置我们的浏览器让它可以自动切换, 该用代理用代理该直接连接自动直接连接. 所以请看配置浏览器. Shadowsocks Qt5安装GUI 图形界面程序, 然后按照提示配置相对应的参数. 安装教程地址: ShadowSocks-qt5 安装指南 在ubuntu上可以这样, 通过PPA源安装, 仅支持Ubuntu 14.04或更高版本.123sudo add-apt-repository ppa:hzwhuang/ss-qt5sudo apt-get updatesudo apt-get install shadowsocks-qt5 由于是图形界面, 配置和windows基本没啥差别就不赘述了. 经过上面的配置, 你只是启动了sslocal 但是要上网你还需要配置下浏览器到指定到代理端口比如1080才可以正式上网. 使用ShadowSocks代理实现科学上网毕竟Shadowsocks是sock5代理, 不能接受http协议, 所以我们需要把sock5转化成http流量. 配置浏览器代理假如你上面任选一种方式已经开始运行sslocal了, 火狐那个代理插件老是订阅不了gfwlist所以配置自动模式的话不好使. 这里用的是chrome, 你可以在Ubuntu软件中心下载得到. 安装插件我们需要给chrome安装SwitchyOmega插件, 但是没有代理之前是不能从谷歌商店安装这个插件的, 但是我们可以从Github上直接下载最新版https://github.com/FelisCatus/SwitchyOmega/releases/（这个是chrome的）然后浏览器地址打开chrome://extensions/, 启用开发者模式,将下载的插件托进去安装. 设置代理地址安装好插件会自动跳到设置选项, 有提示你可以跳过. 左边新建情景模式-选择代理服务器-比如命名为shadowProxy（叫什么无所谓）其他默认之后创建, 之后在代理协议选择SOCKS5, 地址为127.0.0.1,端口默认1080 . 然后保存即应用选项. 设置自动切换接着点击自动切换 ( Auto switch）上面的不用管, 在按照规则列表匹配请求后面选择刚才新建的SS, 默认情景模式选择直接连接. 点击应用选项保存. 再往下规则列表设置选择AutoProxy 然后将这个地址填进去, 点击下面的立即更新情景模式, 会有提示更新成功！ 点击浏览器右上角的SwitchyOmega图标, 下面选择自动切换, 然后打开google.com试试, 其他的就不在这贴图了. GenPAC全局代理如果不想每个浏览器都要设置代理, 可以通过GenPAC实现全局代理. 安装pip:123sudo apt-get install python-pip python-dev build-essential sudo pip install --upgrade pip sudo pip install --upgrade virtualenv GenPAC:12sudo pip install genpacsudo pip install --upgrade genpac 设置全局代理1、进入终端, Ctrl+Alt+T, cd到你希望生成文件存放的位置.例如:1cd /home/ybd/Data/application/shadowsocks 2、执行下面的语句:1sudo genpac --proxy="SOCKS5 127.0.0.1:1080" --gfwlist-proxy="SOCKS5 127.0.0.1:1080" -o autoproxy.pac --gfwlist-url="https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt" 注意:上面语句中127.0.0.1:1080应按照自己的情况填写.如果出现下面这种报错:1fetch gfwlist fail. online: https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt local: None 那么换成执行下面的语句:1sudo genpac --proxy="SOCKS5 127.0.0.1:1080" -o autoproxy.pac --gfwlist-url="https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt" 如果出现base64 decoding fail ., 安装其他版本:123sudo pip install https://github.com/JinnLynn/genpac/archive/master.zipsudo pip install --upgrade https://github.com/JinnLynn/genpac/archive/master.zipsudo pip uninstall genpac 3、全局代理系统设置 –&gt; 网络 –&gt; 网络代理“方法”选择“自动”“配置URL”填写:file:///home/ybd/Data/application/shadowsocks/autoproxy.pac点击“应用到整个系统”, 接下来可以愉悦的跨过墙了～ Proxychains 代理 https://github.com/rofl0r/proxychains-ng 这个是最新版的proxychains, 下面通过apt安装的是3.1版本的. 安装proxychains:123sudo apt install proxychains# 最新版为 sudo apt install proxychains4, 配置文件在/etc/proxychains4.conf, 命令为proxychains4 配置proxychains:编辑/etc/proxychains.conf, 最下面有一行socks4 127.0.0.1 9050, 把这一行注释掉, 添加一行socks5 127.0.0.1 1080测试: 1proxychains curl www.google.com 使用:用命令行启动软件, 在前面加上proxychains, 如:1proxychains firefox 使用shadowsocks+proxychains代理打开新的Firefox实现浏览器翻墙.也可以通过输入proxychains bash建立一个新的shell, 基于这个shell运行的所有命令都将使用代理. 如果需要配置不输出代理信息, 编辑 /etc/proxychains.conf 将 #quiet_mode 改为 quiet_mode. PrivoxyPrivoxy是一款带过滤功能的代理服务器, 针对HTTP、HTTPS协议. 通过Privoxy的过滤功能, 用户可以保护隐私、对网页内容进行过滤、管理cookies, 以及拦阻各种广告等. Privoxy可以用作单机, 也可以应用到多用户的网络. 1sudo apt install privoxy 安装好后进行配置, Privoxy的配置文件在/etc/privoxy/config, 这个配置文件中注释很多. 找到4.1. listen-address这一节, 确认监听的端口号, 如果有内网地址可以监听 0.0.0.0:8118. 找到5.2. forward-socks4, forward-socks4a, forward-socks5 and forward-socks5t这一节, 加上如下配置, 注意最后的点号. 重启一下Privoxy 1sudo /etc/init.d/privoxy restart 终端体验: 12export http_proxy=&quot;127.0.0.1:8118&quot; &amp;&amp; export https_proxy=&quot;127.0.0.1:8118&quot;wget http://www.google.com 在/etc/profile的末尾添加如下两句. 12export http_proxy=&quot;127.0.0.1:8118&quot;export https_proxy=&quot;127.0.0.1:8118&quot; 多用户管理https://github.com/mmmwhy/ss-panel-and-ss-py-mu : ss-panel mod魔改版一键脚本 12yum install screen wget -y &amp;&amp;screen -S ss wget -N --no-check-certificate https://raw.githubusercontent.com/mmmwhy/ss-panel-and-ss-py-mu/master/ss-panel-v3-mod.sh &amp;&amp; chmod +x ss-panel-v3-mod.sh &amp;&amp; bash ss-panel-v3-mod.sh ss-panel v3一键脚本 12yum install screen wget -y &amp;&amp;screen -S sswget -N --no-check-certificate https://raw.githubusercontent.com/mmmwhy/ss-panel-and-ss-py-mu/master/ss-panel_node.sh &amp;&amp; chmod +x ss-panel_node.sh &amp;&amp; bash ss-panel_node.sh 选项都差不多,直接输入1安装即可 装完之后可以直接访问ip 默认账号: 91vps 默认密码: 91vps phymyadmin 访问 ip:888 安装时间可能稍长, 耐心等候. . . 下面是其他的开源多用户管理平台 https://github.com/Ehco1996/django-sspanel 搭建-sspanel-v3-魔改版记录 https://91vps.win/ Shadowsocks OptimizeGoogle BBR一键安装最新内核并开启 BBR 脚本 更换Linode内核谷歌开发的TCP加速“外挂”, 目前已集成到最新的Linux内核.博主用的Linode不能直接命令更换内核, 需要到管理后台设置: 安装123wget --no-check-certificate https://github.com/teddysun/across/raw/master/bbr.sh &amp;&amp; \chmod +x bbr.sh &amp;&amp; \./bbr.sh 安装完后, 会提示要重启 VPS, 选择 Y 回车重启即可. 重启后输入 1lsmod | grep bbr 出现 tcp_bbr 即说明 BBR 已经启动. 开启TCP Fast Open这个需要服务器和客户端都是Linux 3.7+的内核, 一般Linux的服务器发行版只有debian jessie有3.7+的, 客户端用Linux更是珍稀动物, 所以这个不多说, 如果你的服务器端和客户端都是Linux 3.7+的内核, 那就在服务端和客户端的vi /etc/sysctl.conf文件中再加上一行. 12# turn on TCP Fast Open on both client and server sidenet.ipv4.tcp_fastopen = 3 然后把vi /etc/shadowsocks.json配置文件中&quot;fast_open&quot;: false改为&quot;fast_open&quot;: true. 这样速度也将会有非常显著的提升. TCP优化1.修改文件句柄数限制如果是ubuntu/centos均可修改/etc/sysctl.conf找到fs.file-max这一行, 修改其值为1024000, 并保存退出. 然后执行sysctl -p使其生效修改vi /etc/security/limits.conf文件, 加入 12* soft nofile 512000* hard nofile 1024000 针对centos,还需要修改vi /etc/pam.d/common-session文件, 加入session required pam_limits.so 2.修改vi /etc/profile文件, 加入ulimit -SHn 1024000然后重启服务器执行ulimit -n, 查询返回1024000即可. 1234567sysctl.conf报错解决方法修复modprobe的: rm -f /sbin/modprobe ln -s /bin/true /sbin/modprobe修复sysctl的: rm -f /sbin/sysctl ln -s /bin/true /sbin/sysctl 使用特殊端口GFW会通过某些手段来减轻数据过滤的负荷, 例如特殊的端口如ssh, ssh默认端口给ss用了那么久必须修改我们登录服务器的端口.修改SSH配置文件: 1vi /etc/ssh/sshd_config 找到#port 22, 将前面的#去掉, 然后修改端口 port 2333（自己设定）.然后重启SSH: 1service ssh restart VPS Security 公司刚买了一个Linode VPS 2TB流量的, 不到几天就被DDOS攻击, 直到余额被扣完停机. . . 吓得我马上谷歌了一些防御措施 修改SSH登录端口Ubuntu1、用下面命令进入配置文件vi /etc/ssh/sshd_config2、找到#port 22, 将前面的#去掉, 然后修改端口 port 12345（自己设定）.3、然后重启ssh服务 12#Debian/ubuntu /etc/init.d/ssh restart or service ssh restart#CentOS service sshd restart CentOS1、临时关闭SELinux: 1setenforce 0 2、修改SSH端口 123456vi /etc/ssh/sshd_config#在Port 22下面加一行, 以端口2333为例, Port 2333#重启ssh服务: systemctl restart sshd.service 3、防火墙中放行新加入端口 1firewall-cmd --permanent --add-port=2333/tcp 4、用该命令查询 1firewall-cmd --permanent --query-port=2333/tcp 如果是yes就是添加成功, 如果是no就是没成功 5、成功后重载防火墙 1firewall-cmd --reload 6、关闭SELinux 查看SELinux状态SELINUX, 如果是enabled就是开启状态 vi /etc/selinux/config 修改SELINUX=disabled 最后重启vps试试用新的2333端口登录, 如果登录成功再vi /etc/ssh/sshd_config把Port 22端口删除, 再重启ssh服务就好了. 使用密钥登录SSH1、服务端生成密钥 1234567891011121314151617181920212223242526#生成SSH密钥对ssh-keygen -t rsaGenerating public/private rsa key pair.#建议直接回车使用默认路径Enter file in which to save the key (/root/.ssh/id_rsa): #输入密码短语（留空则直接回车）Enter passphrase (empty for no passphrase): #重复密码短语Enter same passphrase again: Your identification has been saved in /root/.ssh/id_rsa.Your public key has been saved in /root/.ssh/id_rsa.pub.The key fingerprint is:aa:8b:61:13:38:ad:b5:49:ca:51:45:b9:77:e1:97:e1 root@localhost.localdomainThe key&apos;s randomart image is:+--[ RSA 2048]----+| .o. || .. . . || . . . o o || o. . . o E ||o.= . S . ||.*.+ . ||o.* . || . + . || . o. |+-----------------+ 2、复制密钥对 也可以手动在客户端建立目录和authorized_keys, 注意修改权限 123#复制公钥到无密码登录的服务器上,22端口改变可以使用下面的命令#ssh-copy-id -i ~/.ssh/id_rsa.pub &quot;-p 10022 user@server&quot;ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.15.241 3、关闭密码登陆(编辑/etc/ssh/sshd_config) 123456789101112#禁用密码验证PasswordAuthentication no#启用密钥验证RSAAuthentication yesPubkeyAuthentication yes#指定公钥数据库文件AuthorizedKeysFile .ssh/authorized_keys#root 用户能否通过 SSH 登录PermitRootLogin yes 4、重启SSH 123456#RHEL/CentOS系统service sshd restart#ubuntu系统service ssh restart#debian系统/etc/init.d/ssh restart 防火墙Ubuntu防火墙UFW1234ufw enableufw allow sshufw allow [shadowsocks_port]ufw allow from [remote_ip] CentOS1234567891011121314151617181920212223# 显示状态firewall-cmd --state# 启用systemctl start firewalld.service# Postgresql端口设置. 允许192.168.142.166访问5432端口firewall-cmd --permanent --add-rich-rule=&quot;rule family=&quot;ipv4&quot; source address=&quot;192.168.142.166&quot; port protocol=&quot;tcp&quot; port=&quot;5432&quot; accept&quot;# redis端口设置. 允许192.168.142.166访问6379端口firewall-cmd --permanent --add-rich-rule=&quot;rule family=&quot;ipv4&quot; source address=&quot;192.168.142.166&quot; port protocol=&quot;tcp&quot; port=&quot;6379&quot; accept&quot;# 查看配置结果, 验证配置firewall-cmd --list-all# 删除规则firewall-cmd --permanent --remove-rich-rule=&quot;rule family=&quot;ipv4&quot; source address=&quot;192.168.142.166&quot; port protocol=&quot;tcp&quot; port=&quot;11300&quot; accept&quot;# 更新防火墙规则firewall-cmd --reload# 重启防火墙systemctl restart firewalld.service DDOS deflateDDOS deflate是一款免费的用来防御和减轻DDOS攻击的脚本. 它通过netstat监测跟踪创建大量网络连接的IP地址, 在检测到某个结点超过预设的限制时, 该程序会通过APF或IPTABLES禁止或阻挡这些IP. 安装: 123wget http://www.moerats.com/usr/down/DDOS/deflate.sh &amp;&amp; \chmod +x deflate.sh &amp;&amp; \./deflate.sh 配置文件/usr/local/ddos/ddos.conf 123456789101112131415161718192021222324252627282930313233343536##### Paths of the script and other filesPROGDIR=&quot;/usr/local/ddos&quot;PROG=&quot;/usr/local/ddos/ddos.sh&quot;IGNORE_IP_LIST=&quot;/usr/local/ddos/ignore.ip.list&quot;# 白名单.如有反向代理,注意添加本机地址和本机外网IP地址,防止提供反向代理的主机被判定为攻击.CRON=&quot;/etc/cron.d/ddos.cron&quot;APF=&quot;/etc/apf/apf&quot;IPT=&quot;/sbin/iptables&quot;##### frequency in minutes for running the script##### Caution: Every time this setting is changed, run the script with cron##### option so that the new frequency takes effectFREQ=1##### How many connections define a bad IP? Indicate that below. # 单IP发起连接数阀值,不建议设置太低.NO_OF_CONNECTIONS=150##### APF_BAN=1 (Make sure your APF version is atleast 0.96)##### APF_BAN=0 (Uses iptables for banning ips instead of APF) #一般情况下你是使用iptables来做防火墙,所以这里你需要将 APF_BAN的值改为0.APF_BAN=1##### KILL=0 (Bad IPs are’nt banned, good for interactive execution of script)##### KILL=1 (Recommended setting)KILL=1 #是否屏蔽IP, 默认即可##### An email is sent to the following address when an IP is banned. # 当单IP发起的连接数超过阀值后,将发邮件给指定的收件人.##### Blank would suppress sending of mailsEMAIL_TO=&quot;root&quot; # 这里是邮箱, 可以把root替换成你的邮箱##### Number of seconds the banned ip should remain in blacklist. # 设置被挡IP多少秒后移出黑名单.BAN_PERIOD=600 将上述配置文件修改完成后, 使用命令启动即可 1ddos -d Ubuntu中可能会报错: 1234root@localhost:~# ddos -d/usr/local/sbin/ddos: 13: [: /usr/local/ddos/ddos.conf: unexpected operatorDDoS-Deflate version 0.6Copyright (C) 2005, Zaf &lt;zaf@vsnl.com&gt; 因为启动大多数为 bash 脚本, 而 Ubuntu 的默认环境为 dash, 所以需要使用 dpkg-reconfigure dash, 选择 NO, 切换为 bash 运行脚本: 1dpkg-reconfigure dash Denyhosts防暴力攻击这个方法比较省时省力. denyhosts 是 Python 语言写的一个程序, 它会分析 sshd 的日志文件, 当发现重复的失败登录时就会记录 IP 到 /etc/hosts.deny 文件, 从而达到自动屏 IP 的功能:12345# Debian/Ubuntu: sudo apt install denyhosts # RedHat/CentOSyum install denyhosts 默认配置就能很好的工作, 如要个性化设置可以修改 /etc/denyhosts.conf 12345678910111213141516171819202122232425SECURE_LOG = /var/log/auth.log #ssh 日志文件, 它是根据这个文件来判断的. HOSTS_DENY = /etc/hosts.deny #控制用户登陆的文件PURGE_DENY = #过多久后清除已经禁止的, 空表示永远不解禁BLOCK_SERVICE = sshd #禁止的服务名, 如还要添加其他服务, 只需添加逗号跟上相应的服务即可DENY_THRESHOLD_INVALID = 5 #允许无效用户失败的次数DENY_THRESHOLD_VALID = 10 #允许普通用户登陆失败的次数DENY_THRESHOLD_ROOT = 1 #允许root登陆失败的次数DENY_THRESHOLD_RESTRICTED = 1WORK_DIR = /var/lib/denyhosts #运行目录SUSPICIOUS_LOGIN_REPORT_ALLOWED_HOSTS=YESHOSTNAME_LOOKUP=YES #是否进行域名反解析LOCK_FILE = /var/run/denyhosts.pid #程序的进程IDADMIN_EMAIL = root@localhost #管理员邮件地址,它会给管理员发邮件SMTP_HOST = localhostSMTP_PORT = 25SMTP_FROM = DenyHosts &lt;nobody@localhost&gt;SMTP_SUBJECT = DenyHosts ReportAGE_RESET_VALID=5d #用户的登录失败计数会在多久以后重置为0, (h表示小时, d表示天, m表示月, w表示周, y表示年)AGE_RESET_ROOT=25dAGE_RESET_RESTRICTED=25dAGE_RESET_INVALID=10dRESET_ON_SUCCESS = yes #如果一个ip登陆成功后, 失败的登陆计数是否重置为0DAEMON_LOG = /var/log/denyhosts #自己的日志文件DAEMON_SLEEP = 30s #当以后台方式运行时, 每读一次日志文件的时间间隔. DAEMON_PURGE = 1h #当以后台方式运行时, 清除机制在 HOSTS_DENY 中终止旧条目的时间间隔,这个会影响PURGE_DENY的间隔. 查看已拦截的IPcat /etc/hosts.deny查看拦截记录cat /etc/hosts.deny | wc -l重启服务service denyhosts restart写入自启echo &quot;service denyhosts restart&quot; &gt;&gt; /etc/rc.local vDDoS（只支持CentOS和CloudLinux）Github: https://github.com/duy13/vDDoS-Protection VPS Speed Testspeedtest下载: 12wget https://raw.githubusercontent.com/sivel/speedtest-cli/master/speedtest.py &amp;&amp; \chmod +x speedtest.py 运行: 1234./speedtest.py#或者python speedtest.py 结果: 12345678910[root@li1890-191 ~]# ./speedtest.pyRetrieving speedtest.net configuration...Testing from Linode (123.456.789.123)...Retrieving speedtest.net server list...Selecting best server based on ping...Hosted by IPA CyberLab (Bunkyo) [5.97 km]: 2.998 msTesting download speed................................................................................Download: 2036.69 Mbit/sTesting upload speed................................................................................................Upload: 208.17 Mbit/s speedtest-cli 地址: https://github.com/sivel/speedtest-cli pip方式安装 1pip install speedtest-cli 或github安装 12git clone https://github.com/sivel/speedtest-cli.gitpython speedtest-cli/setup.py install 用法: 1、list 根据距离显示所有的节点服务器列表. 2、列出所有北京节点服务器 12345[root@li1890-191 ~]# speedtest-cli --list | grep Beijing 4713) China Mobile Group Beijing Co.Ltd (Beijing, China) [2093.67 km] 5505) Beijing Broadband Network (Beijing, China) [2093.67 km] 5145) Beijing Unicom (Beijing, China) [2093.67 km]18462) Beijing Broadband Network (Beijing, China) [2093.67 km] 3、选择节点测试下载速度 1speedtest-cli --server=6611 Finally低调使用. . . SSR GUI客户端: erguotou520/electron-ssr 更多精彩内容请查看: https://teddysun.com v2ray: https://github.com/v2ray/v2ray-core]]></content>
      <categories>
        <category>VPS</category>
      </categories>
      <tags>
        <tag>VPS</tag>
        <tag>ShadowSocks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java基本数据类型传递与引用传递的那点事]]></title>
    <url>%2F2017%2Fjava-call-by-value%2F</url>
    <content type="text"><![CDATA[前言 今天在逛博客的时候看到了有意思的东西, 下面代码会输出什么？123456789public static void change(String s) &#123; s = "123"; &#125; public static void main(String args[]) &#123; String s = "abc"; change(s); System.out.println(s); &#125; 结果是abc.为什么？经过一番查找与理解, 又学习到了… 捋一捋术语Java的值传递和引用传递在面试中一般都会都被涉及到, 今天我们就来聊聊这个问题, 首先我们必须认识到这个问题一般是相对函数而言的, 也就是java中的方法参数, 那么我们先来回顾一下在程序设计语言中有关参数传递给方法（或函数）的两个专业术语: 按值调用（call by value） 按引用调用（call by reference）所谓的按值调用表示方法接收的是调用着提供的值, 而按引用调用则表示方法接收的是调用者提供的变量地址(如果是C语言的话来说就是指针啦, 当然java并没有指针的概念). 这里我们需要注意的是一个方法可以修改传递引用所对应的变量值, 而不能修改传递值调用所对应的变量值, 这句话相当重要, 这是按值调用与引用调用的根本区别. 基本数据类型的传递前面说过java中并不存在引用调用, 这点是没错的, 因为java程序设计语言确实是采用了按值调用, 即call by value. 也就是说方法得到的是所有参数值的一个拷贝, 方法并不能修改传递给它的任何参数变量的内容. 下面来看一个例子:12345678910111213public class CallByValue &#123; private static int x=10; public static void updateValue(int value)&#123; value = 3 * value; &#125; public static void main(String[] args) &#123; System.out.println("调用前x的值: "+x); updateValue(x); System.out.println("调用后x的值: "+x); &#125; 运行程序, 结果如下:12调用前x的值: 10调用后x的值: 10 可以看到x的值并没有变化, 接下来我们一起来看一下具体的执行过程: 分析:1）value被初始化为x值的一个拷贝（也就是10）2）value被乘以3后等于30, 但注意此时x的值仍为10！3）这个方法结束后, 参数变量value不再使用, 被回收.结论: 当传递方法参数类型为基本数据类型（数字以及布尔值）时, 一个方法是不可能修改一个基本数据类型的参数. 引用数据类型的传递当然java中除了基本数据类型还有引用数据类型, 也就是对象引用, 那么对于这种数据类型又是怎么样的情况呢？还是一样先来看一个例子:声明一个User对象类型:1234567891011121314151617181920public class User &#123; private String name; private int age; public User(String name, int age) &#123; this.name=name; this.age=age; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; &#125; 执行类如下:1234567891011121314public class CallByValue &#123; private static User user=null; public static void updateUser(User student)&#123; student.setName("Lishen"); student.setAge(18); &#125; public static void main(String[] args) &#123; user = new User("zhangsan",26); System.out.println("调用前user的值: "+user.toString()); updateUser(user); System.out.println("调用后user的值: "+user.toString()); &#125; 运行结果如下:12调用前user的值: User [name=zhangsan, age=26]调用后user的值: User [name=Lishen, age=18] 很显然, User的值被改变了, 也就是说方法参数类型如果是引用类型的话, 引用类型对应的值将会被修改, 下面我们来分析一下这个过程: 过程分析:1）student变量被初始化为user值的拷贝, 这里是一个对象的引用.2）调用student变量的set方法作用在这个引用对象上, user和student同时引用的User对象内部值被修改.3）方法结束后, student变量不再使用, 被释放, 而user还是没有变, 依然指向User对象.结论: 当传递方法参数类型为引用数据类型时, 一个方法将修改一个引用数据类型的参数所指向对象的值. 再来举个例子虽然到这里两个数据类型的传递都分析完了, 也明白的基本数据类型的传递和引用数据类型的传递区别, 前者将不会修改原数据的值, 而后者将会修改引用所指向对象的值. 可通过上面的实例我们可能就会觉得java同时拥有按值调用和按引用调用啊, 可惜的是这样的理解是有误导性的, 虽然上面引用传递表面上体现了按引用调用现象, 但是java中确实只有按值调用而没有按引用调用. 到这里估计不少人都蒙逼了, 下面我们通过一个反例来说明（回忆一下开头我们所说明的按值调用与按引用调用的根本区别）.12345678910111213141516171819202122232425public class CallByValue &#123; private static User user=null; private static User stu=null; /** * 交换两个对象 * @param x * @param y */ public static void swap(User x,User y)&#123; User temp =x; x=y; y=temp; &#125; public static void main(String[] args) &#123; user = new User("user",26); stu = new User("stu",18); System.out.println("调用前user的值: "+user.toString()); System.out.println("调用前stu的值: "+stu.toString()); swap(user,stu); System.out.println("调用后user的值: "+user.toString()); System.out.println("调用后stu的值: "+stu.toString()); &#125; 我们通过一个swap函数来交换两个变量user和stu的值, 在前面我们说过, 如果是按引用调用那么一个方法可以修改传递引用所对应的变量值, 也就是说如果java是按引用调用的话, 那么swap方法将能够实现数据的交换, 而实际运行结果是:1234调用前user的值: User [name=user, age=26]调用前stu的值: User [name=stu, age=18]调用后user的值: User [name=user, age=26]调用后stu的值: User [name=stu, age=18] 我们发现user和stu的值并没有发生变化, 也就是方法并没有改变存储在变量user和stu中的对象引用. swap方法的参数x和y被初始化为两个对象引用的拷贝, 这个方法交换的是这两个拷贝的值而已, 最终, 所做的事都是白费力气罢了. 在方法结束后x, y将被丢弃, 而原来的变量user和stu仍然引用这个方法调用之前所引用的对象.这个过程也充分说明了java程序设计语言对对象采用的不是引用调用, 实际上是对象引用进行的是值传递, 当然在这里我们可以简单理解为这就是按值调用和引用调用的区别, 而且必须明白即使java函数在传递引用数据类型时, 也只是拷贝了引用的值罢了, 之所以能修改引用数据是因为它们同时指向了一个对象, 但这仍然是按值调用而不是引用调用.总结: 一个方法不能修改一个基本数据类型的参数（数值型和布尔型） 一个方法可以修改一个引用所指向的对象状态, 但这仍然是按值调用而非引用调用 上面两种传递都进行了值拷贝的过程 最后 参考http://blog.csdn.net/javazejian/article/details/51192130http://blog.csdn.net/seu_calvin/article/details/70089977]]></content>
      <categories>
        <category>Programming</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Java basics</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu下使用IntelliJ IDEA的正确姿势]]></title>
    <url>%2F2017%2Fnote-of-learning-idea-under-ubuntu%2F</url>
    <content type="text"><![CDATA[Preface 公司里的大牛们用的IDE基本都是IDEA近墨者黑, 早就听闻IntelliJ IDEA这个大名, 只不过当初比较菜鸟还不会用(…虽然现在也还是个菜鸟=.=), 再不用就要被OUT了此篇把在Ubuntu下使用IDEA的学习经验记录下来(网上还是比较少资料解决Ubuntu下IDEA的问题Orz), 以便老了记性不好可以看一看… Install博主采用Toolbox App 方式安装.这样的好处是我们不用关心更新问题, 每次有新版本它都会提示, 我们是需要点一下Install就可以了, 不需要关心升级后的配置.还有一个好处是可以管理其他的IntelliJ软件（虽然博主只用他们的IDEA = =）…安装的时候注意配置安装路径: License 可参考 http://idea.lanyus.com/ 2018.1.5以前版本注册码可以自己读娘, 或者使用授权服务器 博主用的是基于docker的授权服务器: 12docker pull ilanyu/golang-reverseproxydocker run -d -p 6666:8888 ilanyu/golang-reverseproxy 也可以自己搭建一个基于docker的服务 = = https://github.com/masteranthoneyd/docker-jetlicense 部署到VPS上, nginx反向代理: 12345678910111213server &#123; listen 80; server_name 域名; location / &#123; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Host $http_host; proxy_set_header X-NginX-Proxy true; proxy_pass http://127.0.0.1:端口/; proxy_redirect off; &#125;&#125; 重启nginx: 1nginx -s reload Personal Setting博主的常用配置:一般会选择打开项目时最外层的窗口打开setting, 对全局生效. 文件修改后, 设置左边目录出现颜色变化 如果只有一行方法的代码默认要展开, 去掉这个勾 修改字体和字号Ubuntu下默认的字体还是让人看了有点不爽, 而且使用Ubuntu默认的字体工具栏可能会出现乱码.下面三个地方, 分别是窗口字体, 代码字体和控制台字体: 修改VM参数通过Toolbox可以简单地设置VM参数, 博主16G内存的主机的VM参数设置为123-Xms512m-Xmx1500m-XX:ReservedCodeCacheSize=500m 设置代码不区分大小写 禁止 import *IDEA默认检测到有5个相同包就会自动import *, 其实没必要, 需要哪个就import哪个. 设置不自动打开上一次最后关闭的项目 Postfix Completion这个本来就是默认开启的 可生成SreializableID在 setting&gt;Editor&gt;Inspections&gt;Java&gt;Serializtion Issues&gt;:钩上之后在需要生成的类上Alt+Enter就会出现了. 关闭代码拖拽功能一不小心手抖就改了代码…禁用！ 显示内存使用情况点击内存信息展示的那个条可以进行部分的内存回收 优化 Java 注释 优化方法链在Java8中特别是使用Stream API, ex:1list.stream().filter(func).distinct().skip(num).limit(num).map(func).peek(func).collect(func); 写成一行太长了！！勾上这个选项idea将自动帮我们优化: 钩上 Align when multiline 可对其方法链 会变成这样 1234list = list.stream() .filter(func) .distinct() ..... 多线程自动编译 设置统一编译JDK版本（关闭module JDK） Maven 自动下载源码 Keyboard shortcuts JetBrains官方快捷键手册: https://resources.jetbrains.com/storage/products/intellij-idea/docs/IntelliJIDEA_ReferenceCard.pdf 个人感觉Ubuntu下使用IDEA最大的一个不爽就是快捷键了, 想屎的感觉有木有, 各种没反应, 原来是快捷键冲突, 本来想改成Eclipse的风格, 但想了想好像不太合适.快捷键风格可以在setting -&gt; Keymap 里面这是, 博主使用安装时候idea默认配置的Default for XWin.先来大致分各类（纯属个人看法= =）: 导航（一般都可以在Navigate里面找到） Keyboard shortcut Declaration Ctrl+N 查找Java类 Ctrl+Shift+N 查找非Java文件 Ctrl+Shift+Alt+N 查找mvc接口、类中的方法或变量 Double Shift 查找所有 Ctrl+Alt+Left/Right 跳到光标的上/下一个位置 F2/Shift+F2 光标移动到下/上一个错误 Ctrl+Shift+Backspace 跳到上一个编辑处 Ctrl+Alt+B 跳到实现类/方法 Ctrl+U 跳到父类/方法 Alt+Up/Down 光标移动到上/下一个方法 Ctrl+F12 搜索当前文件方法 Ctrl+H/Ctrl+Shift+H 显示类/方法层级 F11/Shift+F11 当前行设置书签/显示所有书签 Ctrl+G 跳到指定行 查找/替换（一般在Edit的find里面） Keyboard shortcut Declaration Ctrl+F 文件内查找 Ctrl+R 文件内替换 F3/Shift+F3 查找下/上一个 Ctrl+Shift+F 目录内查找 Ctrl+Shift+R 目录内替换 Ctrl+F7 查找当前文件中的使用处 Alt+F7 查找被使用处 Ctrl+Alt+F7 显示被使用处 编辑 Keyboard shortcut Declaration Ctrl+D 重复代码,未选择代码时重复当前行 Ctrl+Y 删除当前行 Ctrl+Shift+Enter 补全语句 Ctrl+P 显示方法参数 Ctrl+Q 显示注释文档 Alt+Insert 生成代码,生成 Getter、Setter、构造器等 Ctrl+O/Ctrl+I 重写父类方法/实现接口方法 Ctrl+W 选择代码块,连续按会增加选择外层的代码块 Ctrl+Shift+W 与“Ctrl+W”相反,减少选择代码块 Ctrl+Alt+L 格式化代码 Ctrl+Alt+O 优化 Imports Ctrl+Shift+J 合并多行为一行 Ctrl+Shift+U 对选中内容进行大小写切换 Ctrl+Shift+]/[ 选中到代码块的开始/结束 Ctrl+Delete/Ctrl+Backspace 删除从光标所在位置到单词结束/开头处 Ctrl+F4 关闭当前编辑页 Alt+J/Ctrl+Alt+Shift+J 匹配下一个/全部与当前选中相同的代码 Alt+Shift+J “Alt+J”的反选 Alt+Shift+Insert,然后Shift+Up/Down 同时编辑多行(退出此Column模式也是“Alt+Shift+Insert”) 调试 Keyboard shortcut Declaration F8/F7 单步调试,不进入函数内部/进入函数内部 Shift+F8 跳出函数 Alt+F9 运行到断点 Alt+F8 执行表达式查看结果 F9 继续执行,进入下一个断点或执行完程序 Ctrl+Shift+F8 查看断点 重构 Keyboard shortcut Declaration F6 移动类 Alt+Delete 安全删除,删除前会提示调用处 Shift+F6 重命名 Ctrl+F6 重构方法参数、Exception 等 Ctrl+Alt+M 提取为新方法 Ctrl+Alt+V 提取为新变量 Ctrl+Alt+F 提取为对象新属性 Ctrl+Alt+C 提取为新静态常量 Ctrl+Alt+P 提取为方法参数 Ctrl+Shift+Alt+P 提取为函数式参数 Ctrl+Alt+Shift+T 重构一切 PluginLombok1.首先在IDEA里面安装使用lombok编写简略风格代码的插件,打开IDEA的Settings面板, 并选择Plugins选项, 然后点击 “Browse repositories..”在输入框输入”lombok”, 得到搜索结果, 选择第二个, 点击安装, 然后安装提示重启IDEA, 安装成功; 还需要在IDEA中开启支持: 2.在自己的项目里添加lombok的编译支持(maven项目),在pom文件里面添加如下indenpence 12345&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.18&lt;/version&gt;&lt;/dependency&gt; 3.然后就可以尽情在自己项目里面编写简略风格的Java代码咯12345678910111213141516171819202122232425package com.lombok;import lombok.Data;import lombok.EqualsAndHashCode;import java.util.List;@Data@EqualsAndHashCode(callSuper = false)public class Student &#123; String name; int sex; Integer age; String address; List&lt;String&gt; books;&#125;//使用Student类对象Student student = new Student();student.setName(name);student.setAge(age);student.setAddress(address);student.setBooks(Arrays.asList(books)); 4.常用注解 @Getter and @Setter: 生成getter / setter方法, 默认生成的方法是public的, 如果要修改方法修饰符可以设置AccessLevel的值, 例如: @Getter(access = AccessLevel.PROTECTED) @ToString: 生成toString()方法, 可以这样设置不包含哪些字段@ToString(exclude = &quot;id&quot;) / @ToString(exclude = {&quot;id&quot;,&quot;name&quot;}), 如果继承的有父类的话, 可以设置callSuper 让其调用父类的toString()方法, 例如: @ToString(callSuper = true) @NoArgsConstructor, @RequiredArgsConstructor, @AllArgsConstructor: @NoArgsConstructor生成一个无参构造方法. 当类中有final字段没有被初始化时, 编译器会报错, 此时可用@NoArgsConstructor(force = true), 然后就会为没有初始化的final字段设置默认值 0 / false / null. 对于具有约束的字段（例如@NonNull字段）, 不会生成检查或分配, 因此请注意, 正确初始化这些字段之前, 这些约束无效. @RequiredArgsConstructor会生成构造方法（可能带参数也可能不带参数）, 如果带参数, 这参数只能是以final修饰的未经初始化的字段, 或者是以@NonNull注解的未经初始化的字段@RequiredArgsConstructor(staticName = &quot;of&quot;)会生成一个of()的静态方法, 并把构造方法设置为私有. @AllArgsConstructor 生成一个全参数的构造方法. @Data: @Data 包含了@ToString, @EqualsAndHashCode, @Getter / @Setter和@RequiredArgsConstructor的功能. @Accessors: 主要用于控制生成的getter和setter, 此注解有三个参数: fluent boolean值, 默认为false. 此字段主要为控制生成的getter和setter方法前面是否带get/set；chain boolean值, 默认false. 如果设置为true, setter返回的是此对象, 方便链式调用方法prefix 设置前缀 例如: @Accessors(prefix = &quot;abc&quot;) private String abcAge 当生成get/set方法时, 会把此前缀去掉. @Synchronized: 给方法加上同步锁. @Builder: @Builder注释为你的类生成复杂的构建器API: 1Person.builder().name(&quot;Adam Savage&quot;).city(&quot;San Francisco&quot;).job(&quot;Mythbusters&quot;).job(&quot;Unchained Reaction&quot;).build(); @NonNull: 如其名, 不能为空, 否则抛出NullPointException Log类: 1234567891011121314@CommonsLogCreates private static final org.apache.commons.logging.Log log = org.apache.commons.logging.LogFactory.getLog(LogExample.class);@JBossLogCreates private static final org.jboss.logging.Logger log = org.jboss.logging.Logger.getLogger(LogExample.class);@LogCreates private static final java.util.logging.Logger log = java.util.logging.Logger.getLogger(LogExample.class.getName());@Log4jCreates private static final org.apache.log4j.Logger log = org.apache.log4j.Logger.getLogger(LogExample.class);@Log4j2Creates private static final org.apache.logging.log4j.Logger log = org.apache.logging.log4j.LogManager.getLogger(LogExample.class);@Slf4jCreates private static final org.slf4j.Logger log = org.slf4j.LoggerFactory.getLogger(LogExample.class);@XSlf4jCreates private static final org.slf4j.ext.XLogger log = org.slf4j.ext.XLoggerFactory.getXLogger(LogExample.class); Lombok的功能不仅如此, 更详细请看features Docker Integration可以通过IDEA链接Docker API, 前提是开启了Docker API ZookeeperZookeeper UI, 支持删除操作 K8s工具：Kubernetes参考 https://plugins.jetbrains.com/plugin/10485-kubernetes 支持编辑 Kubernetes 资源文件，如下： 可以比较方便的查看yaml中的各项 placeholder 的默认值，且可以方便的链接到value位置。 GsonFormat复制一段JSON格式字符串 POJO to JSON为了测试需要，我们需要将简单 Java 领域对象转成 JSON 字符串方便用 postman 或者 curl 模拟数据。详细使用文档，参考：https://plugins.jetbrains.com/plugin/9686-pojo-to-json Grep Console参考：https://plugins.jetbrains.com/plugin/7125-grep-console Free Mybatis Plugin可以直接从Mapper文件跳转到xml: MyBatisCodeHelper-Pro插件地址: https://github.com/gejun123456/MyBatisCodeHelper-Pro Crack: https://github.com/pengzhile/MyBatisCodeHelper-Pro-Crack Ali规约插件 P3C插件地址: https://github.com/alibaba/p3c文档: https://github.com/alibaba/p3c/blob/master/idea-plugin/README_cn.md FindBugs装完之后右键最下面会多出一个FindBugs的选项 Maven Helper这个主要可以分析maven依赖冲突. 安装之后, 打开pom.xml文件, 会看到多了一个Dependency Analyzer的面板, 点击可以进入分析面板: 另外, 右键项目也会多两个Maven的bar: Statistic这个插件可以统计代码数量: Stackoverflow看名字就知道这个是干嘛的啦, 在plugin repostories直接搜索stackoverflow就找得到 重启后随便选中内容右键就可以看到 Nyan progress bar这个是彩虹版的进度条… Background Image Plus这是一个设置背景图的插件 Translation详细使用文档，参考：https://plugins.jetbrains.com/plugin/8579-translation 快捷键: 翻译: Ctrl + Shift + Y 翻译并替换: Ctrl + Shift + X Enso它可以将测试名转化成一个句子, 一目了然地显示测试的内容. 这意味着当你在注视任何类的时候, Enso 都会展示其说明文档. activate-power-mode 或 Power mode ||这个抖动的窗口老年人实在受不了… Skills演出模式此模式将IDEA弄到最大, 可以让你只关注一个类里面的代码, 进行毫无干扰的coding. 可以使用Alt+V快捷键, 弹出View视图, 然后选择Enter Presentation Mode 若Alt+V没有设置快捷键, 可在Keymap中设置: 退出: 使用ALT+V弹出view视图, 然后选择Exit Presentation Mode 即可. Inject language 编辑JSON如果使用IDEA在编写JSON字符串的时候, 然后要一个一个\去转义双引号的话, 就实在太不应该了, 又烦又容易出错. 在IDEA可以使用Inject language帮我们自动转义双引号. 然后搜索json: 选择完后. 鼠标焦点自动会定位在双引号里面, 这个时候你再次使用alt+enter就可以看到 : 选中Edit JSON Fragment并回车, 就可以看到编辑JSON文件的视图了: 使用快捷键移动分割线有时候想要拖拉项目视图的分割线: 可以先alt+1把鼠标焦点定位到project视图里, 然后直接使用ctrl+shift+左右箭头来移动分割线. 再按esc返回代码. 把鼠标定位到project视图里使用alt+F1, 弹出Select in视图, 然后选择Project View中的Project, 回车, 就可以立刻定位到类的位置了. 使用esc或者F4跳回代码. 自动生成not null判断语句变量后输入.not或者.nn: 更多模板可查看设置中的Postfix Completion. 生成 Try Catch使用Ctrl + w选中区域后按下Ctrl + Shift + t: VM Options可以通过ToolBox或IDEA选项里面设置 优化参数(32G内存): 12345678910111213141516171819202122-server-Xms2048m-Xmx4096m-Xmn1024m-XX:MetaspaceSize=256m-XX:MaxMetaspaceSize=2048m-XX:ReservedCodeCacheSize=512m-XX:+UseG1GC-XX:-UseParNewGC-XX:-UseConcMarkSweepGC-XX:SoftRefLRUPolicyMSPerMB=200-XX:+UseCompressedOops-ea-Dsun.io.useCanonCaches=false-Djava.net.preferIPv4Stack=true-XX:+HeapDumpOnOutOfMemoryError-XX:-OmitStackTraceInFastThrow-Dsun.awt.keepWorkingSetOnMinimize=true-Dide.no.platform.update=true-Djdk.http.auth.tunneling.disabledSchemes=&quot;&quot;-javaagent:/home/ybd/data/application/jetbrains/JetbrainsCrack.jar-XX:MaxJavaStackTraceDepth=10000 部分参数说明: -Xms2048m: 初始时内存大小, 至少为Xmx的二分之一 -Xmx2048m: 最大内存大小, 若总内存小于2GB, 至少为总内存的四分之一；若总内存大于2GB, 设为1-4GB -XX:+UseG1GC -XX:-UseParNewGC -XX:-UseConcMarkSweepGC: 设置使用G1垃圾收集器 -server: JVM以server的方式运行, 启动速度慢, 运行速度快 -Dsun.awt.keepWorkingSetOnMinimize=true: 让IDEA最小化后阻止JVM对其进行修剪 Conflict of keyboard shortcuts快捷键有冲突, 创建脚本并执行:123456#!/bin/bash gsettings set org.gnome.desktop.wm.keybindings toggle-shaded "[]" gsettings set org.gnome.settings-daemon.plugins.media-keys screencast "[]"gsettings set org.gnome.desktop.wm.keybindings switch-to-workspace-left "[]" gsettings set org.gnome.desktop.wm.keybindings switch-to-workspace-right "[]"gsettings set org.gnome.desktop.wm.keybindings begin-move "[]" 如果是习惯Windows下的快捷键, 那么可以禁用TTY（IDEA Ctrl+Alt+F1-6冲突）: 1234567FILE_NAME=/usr/share/X11/xorg.conf.d/50-novtswitch.conf &amp;&amp;\sudo touch $&#123;FILE_NAME&#125; &amp;&amp; \sudo tee $&#123;FILE_NAME&#125; &lt;&lt; EOF Section &quot;ServerFlags&quot;Option &quot;DontVTSwitch&quot; &quot;true&quot;EndSectionEOF 目前发现的快捷键冲突: 1、Ctrl+Alt+方向, 直接到系统设置里面改: 2、安装了搜狗之后, 按Ctrl+Alt+B会启动虚拟键盘, 所以在输入法里面打开Fcitx设置, 在附加组件里面, 点击高级, 再把虚拟键盘的选项去掉:然后注销或重启电脑. 3、Ctrl+Alt+S, 这个在键盘设置里面找了很久, 原来这玩意在输入法设置里面, 点开输入法全局配置, 把显示高级选项钩上, 就会看到很多快捷键, 我都把它们干掉了. Finally IDEA真的智能到没朋友…如果喜欢IDEA这款软件, 并且有经济能力的, 请付费购买~]]></content>
      <categories>
        <category>IDE</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>IDE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM知识杂汇]]></title>
    <url>%2F2017%2Fjvm-knowledge-collect-01%2F</url>
    <content type="text"><![CDATA[前言 想要深刻地理解Java, 那么就要深入地理解底层——JVM(Java Virtual Machine | Java虚拟机).JVM（Java Virtual Machine）Java 虚拟机是整个 java 平台的基石, 是 java 系统实现硬件无关与操作系统无关的关键部分, 是保障用户机器免于恶意代码损害的屏障. Java开发人员不需要了解JVM是如何工作的, 但是, 了解 JVM 有助于我们更好的开（通）发（过） java（公司） 程（面）序（试）博主经过一番查阅, 找到了自认为写的好的一些文章, 并记录总结, 方便不定时的看.希望每次看都会有新的领悟, 不断提高自己. Java虚拟机架构什么是JVM要想说明白什么 JVM 就不得不提另外两个概念, JRE 和 JDK, 初学者总是把这几个概念搞混.JVM, JRE, JDK 都是 Java 语言的支柱, 他们分工协作. 但不同的是 JDK 和 JRE 是真实存在的, 而 JVM 是一个抽象的概念, 并不真实存在. JDKJDK(Java Development Kit) 是 Java 语言的软件开发工具包（SDK）. JDK 物理存在, 是 programming tools、JRE 和 JVM 的一个集合. JREJRE（Java Runtime Environment）Java 运行时环境, JRE 物理存在, 主要由Java API 和 JVM 组成, 提供了用于执行 Java 应用程序最低要求的环境. JVM（Java Virtual Machine）JVM(Java Virtual Machine) 是一种软件实现, 执行像物理机程序的机器（即电脑）.本来, Java被设计基于从物理机器分离实现WORA（ 写一次, 随处运行 ）的虚拟机上运行, 虽然这个目标已经几乎被遗忘.JVM 并不是专为 Java 所实现的运行时, 实际上只要有其他编程语言的编译器能生成正确 Java bytecode 文件, 则这个语言也能实现在JVM上运行.因此, JVM 通过执行 Java bytecode 可以使 java 代码在不改变的情况下运行在各种硬件之上. JVM实现了Java语言最重要的特征: 即平台无关性.平台无关性原理: 编译后的 Java程序（.class文件）由JVM执行. JVM屏蔽了与具体平台相关的信息, 使程序可以在多种平台上不加修改地运行. Java虚拟机在执行字节码时, 把字节码解释成具体平台上的机器指令执行. 因此实现Java平台无关性. JVM结构图JVM = 类加载器 classloader+ 执行引擎 executionengine + 运行时数据区域 runtime data area首先Java源代码文件被Java编译器编译为字节码文件, 然后JVM中的类加载器加载完毕之后, 交由JVM执行引擎执行. 在整个程序执行过程中, JVM中的运行时数据区（内存）会用来存储程序执行期间需要用到的数据和相关信息.因此, 在Java中我们常常说到的内存管理就是针对这段空间进行管理（如何分配和回收内存空间）. ClassLoaderClassLoader把硬盘上的class文件加载到JVM中的运行时数据区域, 但是它不负责这个类文件能否执行, 而这个是执行引擎负责的. 执行引擎作用: 执行字节码, 或者执行本地方法. Runtime DataAreaJVM运行时数据区 (JVM RuntimeArea)其实就是指 JVM在运行期间, 其对JVM内存空间的划分和分配. JVM在运行时将数据划分为了以下几个区域来存储.程序员写的所有程序都被加载到运行时数据区域中.（图注: JDK1.7已经把常量池转移到堆里面了！） PC寄存器（The pc Register）（1）每一个Java线程都有一个PC寄存器, 用以记录当前执行到哪个指令.（2）用于存储每个线程下一步将执行的JVM指令, 如该方法是Java方法, 则记录的是正在执行的虚拟机字节码地址, 如该方法为native的, 则计数器值为空.（3）此内存区域是唯一一个在JVM中没有规定任何OutOfMemoryError情况的区域. JVM栈（Java Virtual Machine Stacks）（1）JVM栈是线程私有的, 并且生命周期与线程相同. 并且当线程运行完毕后, 相应内存也就被自动回收.（2）栈里面存放的元素叫栈帧, 每个函数从调用到执行结束, 其实是对应一个栈帧的入栈和出栈.（栈帧好像很复杂的样子, 其实它很简单！）它里面具体存放的是执行的函数的一些数据, 如局部变量、操作数栈（执行引擎计算时需要）, 方法出口等等.（3）这个区域可能有两种异常: 如果线程请求的栈深度大于虚拟机所允许的深度, 将抛出StackOverflowError异常（如: 将一个函数反复递归自己, 最终会出现这种异常）. 如果JVM栈可以动态扩展（大部分JVM是可以的）, 当扩展时无法申请到足够内存则抛出OutOfMemoryError异常. 下面来实现一个栈溢出:12345678910111213141516171819202122package org.antd.test;public class StackOverFlowMock &#123; int num; public int getNum() &#123; return num; &#125; public void stackOver()&#123; num++; stackOver(); &#125; public static void main(String[] args) &#123; StackOverFlowMock stackOverFlowTest = new StackOverFlowMock(); try &#123; stackOverFlowTest.stackOver(); &#125; catch (Throwable t) &#123; System.out.println("迭代深度: "+stackOverFlowTest.getNum()); t.printStackTrace(); &#125; &#125;&#125; 输出为:12345678迭代深度: 17781java.lang.StackOverflowError at org.antd.test.StackOverFlowMock.stackOver(StackOverFlowMock.java:10) at org.antd.test.StackOverFlowMock.stackOver(StackOverFlowMock.java:10) at org.antd.test.StackOverFlowMock.stackOver(StackOverFlowMock.java:10) at org.antd.test.StackOverFlowMock.stackOver(StackOverFlowMock.java:10) at org.antd.test.StackOverFlowMock.stackOver(StackOverFlowMock.java:10) at org.antd.test.StackOverFlowMock.stackOver(StackOverFlowMock.java:10) 本地方法栈（Native Method Stacks）（1）本地方法栈与虚拟机栈所发挥的作用很相似, 他们的区别在于虚拟机栈为执行Java代码方法服务, 而本地方法栈是为Native方法服务.（2）和JVM栈一样, 这个区域也会抛出StackOverflowError和OutOfMemoryError异常. 方法区（Method Area）（1）在方法区中, 存储了每个类的信息、静态变量等. 如, 当程序中通过getName、isInterface等方法来获取信息时, 这些数据来源于方法区.（2）方法区域是全局共享的, 比如每个线程都可以访问同一个类的静态变量.（3）由于使用反射机制的原因, 虚拟机很难推测哪个类信息不再使用, 因此这块区域的回收很难！另外, 对这块区域主要是针对常量池回收, 值得注意的是JDK1.7已经把常量池转移到堆里面了.（4）同样, 当方法区无法满足内存分配需求时, 会抛出OutOfMemoryError. 下面演示一下造成方法区内的OOM场景.执行之前, 可以把虚拟机的参数-XXpermSize和-XX: MaxPermSize限制方法区大小.那么实现一下OOM:1234567891011121314151617public class HeapOomMock &#123; public static void main(String[] args) &#123; List&lt;byte[]&gt; list = new ArrayList&lt;byte[]&gt;(); int i = 0; boolean flag = true; while (flag) &#123; try &#123; i++; list.add(new byte[1024 * 1024]);// 每次增加一个1M大小的数组对象 &#125; catch (Throwable e) &#123; flag = false; System.out.println("count=" + i);// 记录运行的次数 e.printStackTrace(); &#125; &#125; &#125;&#125; 控制台输出:123count=3422java.lang.OutOfMemoryError: Java heap space at org.antd.test.HeapOomMock.main(HeapOomMock.java:14) 运行时常量池（Runtime Constant Pool）（1）存放类中固定的常量信息、方法引用信息等, 其空间从方法区域（JDK1.7后为堆空间）中分配.（2）Class文件中除了有类的版本、字段、方法、接口等描述等信息外, 还有就是常量表(constant_pool table), 用于存放编译期已可知的常量, 这部分内容将在类加载后进入方法区（永久代）存放. 但是Java语言并不要求常量一定只有编译期预置入Class的常量表的内容才能进入方法区常量池, 运行期间也可将新内容放入常量池（最典型的String.intern()方法）.（3）当常量池无法在申请到内存时会抛出OutOfMemoryError异常.再来一段代码展示以下:123456//不断将字符串添加到常量池, 最终导致内存不足抛出方法区的OOM List&lt;String&gt; list =new ArrayList&lt;String&gt;(); int i =0; while(true)&#123; list.add(String.valueOf(i).intern()); &#125; String的intern函数的作用就不多赘述了, 在这篇博文了解String类的intern()方法有所介绍. 关于JDK1.6和JDK1.7之后常量池位置的变化对该函数的影响, 也在链接文中阐述了. Java堆（1）Java堆是JVM所管理的最大的一块内存. 它是被所有线程共享的一块内存区域, 在虚拟机启动时创建.（2）几乎所有的实例对象都是在这块区域中存放. （JIT编译器貌似不是这样的）.（3）Java堆是垃圾搜集管理的主要战场. 所有Java堆可以细分为: 新生代和老年代. 再细致分就是把新生代分为: Eden空间、FromSurvivor空间、To Survivor空间.（4）根据Java虚拟机规范的规定, Java堆可以处于物理上不连续的内存空间中, 只要逻辑上是连续的即可, 就像我们的磁盘空间一样. 如果在堆中没有内存完成实例分配, 并且堆也无法再扩展时, 将会抛出OutOfMemoryError异常. 堆和栈的区别这是一个非常常见的面试题, 主要从以下几个方面来回答. 各司其职最主要的区别就是栈内存用来存储局部变量和方法调用.而堆内存用来存储Java中的对象. 无论是成员变量、局部变量还是类变量, 它们指向的对象都存储在堆内存中. 空间大小栈的内存要远远小于堆内存, 如果你使用递归的话, 那么你的栈很快就会充满并产生StackOverFlowError. 独有还是共享栈内存归属于线程的私有内存, 每个线程都会有一个栈内存, 其存储的变量只能在其所属线程中可见.而堆内存中的对象对所有线程可见, 可以被所有线程访问. 异常错误如果线程请求的栈深度大于虚拟机所允许的深度, 将抛出StackOverflowError异常.如果JVM栈可以动态扩展（大部分JVM是可以的）, 当扩展时无法申请到足够内存则抛出OutOfMemoryError异常.而堆内存没有可用的空间存储生成的对象, JVM会抛出java.lang.OutOfMemoryError. 以上便是关于JVM架构的相关知识. 通过String类的intern()了解内存建模与常量池引言什么都先不说, 先看下面这个引入的例子:123String str1 = new String("SEU")+ new String("Calvin"); System.out.println(str1.intern() == str1);System.out.println(str1 == "SEUCalvin"); JDK版本1.8, 输出结果为:12truetrue 再将上面的例子加上一行代码:1234String str2 = "SEUCalvin";//新加的一行代码, 其余不变 String str1 = new String("SEU")+ new String("Calvin"); System.out.println(str1.intern() == str1);System.out.println(str1 == "SEUCalvin"); 再运行, 结果为:12false false 是不是感觉莫名其妙, 新定义的str2好像和str1没有半毛钱的关系, 怎么会影响到有关str1的输出结果呢？其实这都是intern()方法搞的鬼！看完这篇文章, 你就会明白.在JVM架构一文中也有介绍, 在JVM运行时数据区中的方法区有一个常量池, 但是发现在JDK1.6以后常量池被放置在了堆空间, 因此常量池位置的不同影响到了String的intern()方法的表现. 深入了解后发现还是值得写下来记录一下的. 为了确保文章的实时更新, 实时修改可能出错的地方, 请确保这篇是原文, 而不是无脑转载来的“原创文”, 原文链接为: http://blog.csdn.net/seu_calvin/article/details/52291082. 为什么要介绍intern()方法intern()方法设计的初衷, 就是重用String对象, 以节省内存消耗. 这么说可能有点抽象, 那么就用例子来证明.1234567891011121314151617181920static final int MAX = 100000; static final String[] arr = new String[MAX]; public static void main(String[] args) throws Exception &#123; //为长度为10的Integer数组随机赋值 Integer[] sample = new Integer[10]; Random random = new Random(1000); for (int i = 0; i &lt; sample.length; i++) &#123; sample[i] = random.nextInt(); &#125; //记录程序开始时间 long t = System.currentTimeMillis(); //使用/不使用intern方法为10万个String赋值, 值来自于Integer数组的10个数 for (int i = 0; i &lt; MAX; i++) &#123; arr[i] = new String(String.valueOf(sample[i % sample.length])); //arr[i] = new String(String.valueOf(sample[i % sample.length])).intern(); &#125; System.out.println((System.currentTimeMillis() - t) + "ms"); System.gc(); &#125; 这个例子也比较简单, 就是为了证明使用intern()比不使用intern()消耗的内存更少.先定义一个长度为10的Integer数组, 并随机为其赋值, 在通过for循环为长度为10万的String对象依次赋值, 这些值都来自于Integer数组. 两种情况分别运行, 可通过Window&gt;Preferences&gt;Java&gt;InstalledJREs设置JVM启动参数为-agentlib:hprof=heap=dump,format=b, 将程序运行完后的hprof置于工程目录下. 再通过MAT插件查看该hprof文件.两次实验结果如下:从运行结果来看, 不使用intern()的情况下, 程序生成了101762个String对象, 而使用了intern()方法时, 程序仅生成了1772个String对象. 自然也证明了intern()节省内存的结论.细心的同学会发现使用了intern()方法后程序运行时间有所增加. 这是因为程序中每次都是用了new String后又进行intern()操作的耗时时间, 但是不使用intern()占用内存空间导致GC的时间是要远远大于这点时间的. 深入认识intern()方法JDK1.7后, 常量池被放入到堆空间中, 这导致intern()函数的功能不同, 具体怎么个不同法, 且看看下面代码, 这个例子是网上流传较广的一个例子, 分析图也是直接粘贴过来的, 这里自己的理解去解释这个例子:123456789String s = new String("1"); s.intern();String s2 = "1"; System.out.println(s == s2); String s3 = new String("1") + new String("1"); s3.intern(); String s4 = "11"; System.out.println(s3 == s4); 输出结果为:12JDK1.6以及以下: false false JDK1.7以及以上: false true 再分别调整上面代码2.3行、7.8行的顺序:123456789String s = new String("1"); String s2 = "1"; s.intern(); System.out.println(s == s2); String s3 = new String("1") + new String("1"); String s4 = "11"; s3.intern(); System.out.println(s3 == s4); 输出结果为:12JDK1.6以及以下: false false JDK1.7以及以上: false false 下面依据上面代码对intern()方法进行分析 JDK1.6在JDK1.6中所有的输出结果都是 false, 因为JDK1.6以及以前版本中, 常量池是放在 Perm 区（属于方法区）中的, 熟悉JVM的话应该知道这是和堆区完全分开的.使用引号声明的字符串都是会直接在字符串常量池中生成的, 而 new 出来的 String 对象是放在堆空间中的. 所以两者的内存地址肯定是不相同的, 即使调用了intern()方法也是不影响的. 如果不清楚String类的“==”和equals()的区别可以查看这篇博文Java面试——从Java堆、栈角度比较equals和==的区别.intern()方法在JDK1.6中的作用是: 比如String s=new String(&quot;SEU_Calvin&quot;), 再调用s.intern(), 此时返回值还是字符串&quot;SEU_Calvin&quot;, 表面上看起来好像这个方法没什么用处. 但实际上, 在JDK1.6中它做了个小动作: 检查字符串池里是否存在&quot;SEU_Calvin&quot;这么一个字符串, 如果存在, 就返回池里的字符串；如果不存在, 该方法会把&quot;SEU_Calvin&quot;添加到字符串池中, 然后再返回它的引用. 然而在JDK1.7中却不是这样的, 后面会讨论. JDK1.7针对JDK1.7以及以上的版本, 我们将上面两段代码分开讨论. 先看第一段代码的情况:123456789String s = new String("1"); s.intern(); String s2 = "1"; System.out.println(s == s2); String s3 = new String("1") + new String("1"); s3.intern(); String s4 = "11"; System.out.println(s3 == s4); String s = newString(&quot;1&quot;), 生成了常量池中的“1” 和堆空间中的字符串对象.s.intern(), 这一行的作用是s对象去常量池中寻找后发现”1”已经存在于常量池中了.String s2 = &quot;1&quot;, 这行代码是生成一个s2的引用指向常量池中的“1”对象.结果就是 s 和 s2 的引用地址明显不同. 因此返回了false. String s3 = new String(&quot;1&quot;) + newString(&quot;1&quot;), 这行代码在字符串常量池中生成“1” , 并在堆空间中生成s3引用指向的对象（内容为”11”）. 注意此时常量池中是没有 “11”对象的.s3.intern(), 这一行代码, 是将 s3中的“11”字符串放入 String 常量池中, 此时常量池中不存在“11”字符串, JDK1.6的做法是直接在常量池中生成一个 “11” 的对象.但是在JDK1.7中, 常量池中不需要再存储一份对象了, 可以直接存储堆中的引用. 这份引用直接指向 s3 引用的对象, 也就是说s3.intern() == s3会返回true.String s4 = &quot;11&quot;, 这一行代码会直接去常量池中创建, 但是发现已经有这个对象了, 此时也就是指向 s3 引用对象的一个引用. 因此s3 == s4返回了true. 下面继续分析第二段代码:再把第二段代码贴一下便于查看:123456789String s = new String("1"); String s2 = "1"; s.intern(); System.out.println(s == s2); String s3 = new String("1") + new String("1"); String s4 = "11"; s3.intern(); System.out.println(s3 == s4); String s = newString(&quot;1&quot;), 生成了常量池中的“1” 和堆空间中的字符串对象.String s2 = &quot;1&quot;, 这行代码是生成一个s2的引用指向常量池中的“1”对象, 但是发现已经存在了, 那么就直接指向了它.s.intern(), 这一行在这里就没什么实际作用了. 因为”1”已经存在了.结果就是 s 和 s2 的引用地址明显不同. 因此返回了false. String s3 = new String(&quot;1&quot;) + newString(&quot;1&quot;), 这行代码在字符串常量池中生成“1” , 并在堆空间中生成s3引用指向的对象（内容为”11”）. 注意此时常量池中是没有 “11”对象的.String s4 = &quot;11&quot;, 这一行代码会直接去生成常量池中的”11”.s3.intern(), 这一行在这里就没什么实际作用了. 因为”11”已经存在了.结果就是 s3 和 s4 的引用地址明显不同. 因此返回了false.为了确保文章的实时更新, 实时修改可能出错的地方, 请确保这篇是原文, 而不是无脑转载来的“原创文”, 原文链接为: http://blog.csdn.net/seu_calvin/article/details/52291082. 总结终于要做Ending了. 现在再来看一下开篇给的引入例子, 是不是就很清晰了呢.123String str1 = new String("SEU") + new String("Calvin"); System.out.println(str1.intern() == str1); System.out.println(str1 == "SEUCalvin"); str1.intern()==str1就是上面例子中的情况, str1.intern()发现常量池中不存在“SEUCalvin”, 因此指向了str1. &quot;SEUCalvin&quot;在常量池中创建时, 也就直接指向了str1了. 两个都返回true就理所当然啦.那么第二段代码呢:1234String str2 = "SEUCalvin";//新加的一行代码, 其余不变 String str1 = new String("SEU")+ new String("Calvin"); System.out.println(str1.intern() == str1); System.out.println(str1 == "SEUCalvin"); 也很简单啦, str2先在常量池中创建了“SEUCalvin”, 那么str1.intern()当然就直接指向了str2, 你可以去验证它们两个是返回的true. 后面的&quot;SEUCalvin&quot;也一样指向str2. 所以谁都不搭理在堆空间中的str1了, 所以都返回了false.好了, 本篇对intern的作用以及在JDK1.6和1.7中的实现原理的介绍就到此为止了. 希望能给你带来帮助. 内存管理和垃圾回收何为GCJava与C语言相比的一个优势是, 可以通过自己的JVM自动分配和回收内存空间.垃圾回收机制是由垃圾搜集器Garbage Collection来实现的, GC是后台一个低优先级的守护进程. 在内存中低到一定限度时才会自动运行, 因此垃圾回收的时间是不确定的. 为何要这样设计: 因为GC也要消耗CPU等资源, 如果GC执行过于频繁会对Java的程序的执行产生较大的影响, 因此实行不定期的GC. 与GC有关的是: JVM运行时数据区中的堆（对象实例会存储在这里）和 gabagecollector方法.垃圾回收GC只能回收通过new关键字申请的内存（在堆上）, 但是堆上的内存并不完全是通过new申请分配的. 还有一些本地方法, 这些内存如果不手动释放, 就会导致内存泄露, 所以需要在finalize中用本地方法(nativemethod)如free操作等, 再使用gc方法.1System.gc(); 何为垃圾Java中那些不可达的对象就会变成垃圾. 对象之间的引用可以抽象成树形结构, 通过树根（GC Roots）作为起点, 从这些树根往下搜索, 搜索走过的链称为引用链.当一个对象到GC Roots没有任何引用链相连时, 则证明这个对象为可回收的对象.可以作为GC Roots的主要有以下几种:（1）栈帧中的本地变量表所引用的对象.（2）方法区中类静态属性和常量引用的对象.（3）本地方法栈中JNI（Native方法）引用的对象.123456//垃圾产生的情况举例: //1.改变对象的引用, 如置为null或者指向其他对象 Object obj1 = new Object(); Object obj2 = new Object(); obj1 = obj2; //obj1成为垃圾 obj1 = obj2 = null ; //obj2成为垃圾 12345//2.引用类型 //第2句在内存不足的情况下会将String对象判定为可回收对象, 第3句无论什么情况下String对象都会被判定为可回收对象 String str = new String("hello"); SoftReference&lt;String&gt; sr = new SoftReference&lt;String&gt;(new String("java")); WeakReference&lt;String&gt; wr = new WeakReference&lt;String&gt;(new String("world")); 12345//3.循环每执行完一次, 生成的Object对象都会成为可回收的对象 for(int i=0;i&lt;10;i++) &#123; Object obj = new Object(); System.out.println(obj.getClass()); &#125; 1234567//4.类嵌套 class A&#123; A a; &#125; A x = new A();//分配了一个空间 x.a = new A();//又分配了一个空间 x = null;//产生两个垃圾 1234567891011//5.线程中的垃圾 calss A implements Runnable&#123; void run()&#123; //.... &#125; &#125; //main A x = new A(); x.start(); x=null; //线程执行完成后x对象才被认定为垃圾 四种引用类型强引用1Object obj = new Object(); 这里的obj引用便是一个强引用, 强引用不会被GC回收. 即使抛出OutOfMemoryError错误, 使程序异常终止. 软引用如果内存空间足够, 垃圾回收器就不会回收它, 如果内存空间不足了, 就会回收这些对象的内存. 软引用可用来实现内存敏感的高速缓存.软引用可以和一个引用队列（ReferenceQueue）联合使用, 如果软引用所引用的对象被垃圾回收, Java虚拟机就会把这个软引用加入到与之关联的引用队列中. 弱引用弱引用与软引用的区别在于: 垃圾回收器一旦发现了弱引用的对象, 不管当前内存空间足够与否, 都会回收它的内存. 不过由于垃圾回收器是一个优先级很低的线程, 因此不一定会很快发现那些弱引用的对象.弱引用可以和一个引用队列（ReferenceQueue）联合使用, 如果弱引用所引用的对象被垃圾回收, Java虚拟机就会把这个弱引用加入到与之关联的引用队列中. 虚引用虚引用与软引用和弱引用的一个区别在于: 虚引用必须和引用队列（ReferenceQueue）联合使用. 当垃圾回收器发现一个对象有虚引用时, 就会把这个虚引用对象加入到与之关联的引用队列中. 此时该对象并没有被GC回收. 而是要等到引用队列被真正的处理后才会被回收.程序可以通过判断引用队列中是否已经加入了虚引用, 来了解被引用的对象是否将要被垃圾回收.（由于Object.finalize()方法的不安全性、低效性, 常常使用虚引用完成对象回收前的资源释放工作. ）这里特别需要注意: 当JVM将虚引用插入到引用队列的时候, 虚引用执行的对象内存还是存在的. 但是PhantomReference并没有暴露API返回对象. 所以如果想做清理工作, 需要继承PhantomReference类, 以便访问它指向的对象. 如NIO直接内存的自动回收, 就使用到了sun.misc.Cleaner. 典型的垃圾回收算法在确定了哪些垃圾可以被回收后, 垃圾搜集器要做的事情就是开始进行垃圾回收, 但是这里面涉及到一个问题是: 如何高效地进行垃圾回收.下面讨论几种常见的垃圾搜集算法. Mark-Sweep（标记-清除）算法标记-清除算法分为两个阶段: 标记阶段和清除阶段.标记阶段的任务是标记出所有需要被回收的对象, 清除阶段就是回收被标记的对象所占用的空间.标记-清除算法实现起来比较容易, 但是有一个比较严重的问题就是容易产生内存碎片, 碎片太多可能会导致后续过程中需要为大对象分配空间时无法找到足够的空间而提前触发GC. Copying（复制）算法Copying算法将可用内存按容量划分为大小相等的两块, 每次只使用其中的一块. 当这一块的内存用完了, 就将还存活着的对象复制到另外一块上面, 然后再把第一块内存上的空间一次清理掉, 这样就不容易出现内存碎片的问题, 并且运行高效.但是该算法导致能够使用的内存缩减到原来的一半. 而且, 该算法的效率跟存活对象的数目多少有很大的关系, 如果存活对象很多, 那么Copying算法的效率将会大大降低. （这也是为什么后面提到的新生代采用Copying算法） Mark-Compact（标记-整理）算法为了解决Copying算法的缺陷, 充分利用内存空间, 提出了Mark-Compact算法.该算法标记阶段标记出所有需要被回收的对象, 但是在完成标记之后不是直接清理可回收对象, 而是将存活的对象都移向一端, 然后清理掉端边界以外的所有内存（只留下存活对象）. 以上三种算法对比它们的共同点主要有以下两点:1、三个算法都基于根搜索算法去判断一个对象是否应该被回收, 而支撑根搜索算法可以正常工作的理论依据, 就是语法中变量作用域的相关内容. 因此, 要想防止内存泄露, 最根本的办法就是掌握好变量作用域, 而不应该使用前面内存管理杂谈一章中所提到的C/C++式内存管理方式. 2、在GC线程开启时, 或者说GC过程开始时, 它们都要暂停应用程序（stop the world）. 它们的区别按照下面几点来给各位展示. （&gt;表示前者要优于后者, =表示两者效果一样）效率: 复制算法&gt;标记-整理算法&gt;标记-清除算法（此处的效率只是简单的对比时间复杂度, 实际情况不一定如此）. 内存整齐度: 复制算法=标记-整理算法&gt;标记-清除算法. 内存利用率: 标记-整理算法=标记-清除算法&gt;复制算法. 可以看到标记-清除算法是比较落后的算法了, 但是后两种算法却是在此基础上建立的, 俗话说“吃水不忘挖井人”, 因此各位也莫要忘记了标记-清除这一算法前辈. 而且, 在某些时候, 标记-清除也会有用武之地. 到此我们已经将三个算法了解清楚了, 可以看出, 效率上来说, 复制算法是当之无愧的老大, 但是却浪费了太多内存, 而为了尽量兼顾上面所提到的三个指标, 标记-整理算法相对来说更平滑一些, 但效率上依然不尽如人意, 它比复制算法多了一个标记的阶段, 又比标记-清除多了一个整理内存的过程.难道就没有一种最优算法吗？当然是没有的, 这个世界是公平的, 任何东西都有两面性, 试想一下, 你怎么可能找到一个又漂亮又勤快又有钱又通情达理, 性格又合适, 家境也合适, 身高长相等等等等都合适的女人？就算你找到了, 至少有一点这个女人也肯定不满足, 那就是她不会爱上你. 你是不是想说你比博主强太多了, 那博主只想对你说, 高富帅是不会爬在电脑前看技术文章的, 0.0.但是古人就是给力, 古人说了, 找媳妇不一定要找最好的, 而是要找最合适的, 听完这句话, 瞬间感觉世界美好了许多.算法也是一样的, 没有最好的算法, 只有最合适的算法.既然这三种算法都各有缺陷, 高人们自然不会容许这种情况发生. 因此, 高人们提出可以根据对象的不同特性, 使用不同的算法处理, 类似于萝卜白菜各有所爱的原理. 于是奇迹发生了, 高人们终于找到了GC算法中的神级算法—–分代搜集算法. Generational Collection（分代搜集）算法分代搜集算法是针对对象的不同特性, 而使用适合的算法, 这里面并没有实际上的新算法产生. 与其说分代搜集算法是第四个算法, 不如说它是对前三个算法的实际应用.分代搜集算法是目前大部分JVM的垃圾搜集器采用的算法.它的核心思想是将堆区划分为老年代（Tenured Generation）和新生代（Young Generation）, 老年代的特点是每次垃圾搜集时只有少量对象需要被回收, 而新生代的特点是每次垃圾回收时都有大量的对象需要被回收, 那么就可以在不同代的采取不同的最适合的搜集算法. 目前大部分垃圾搜集器对于新生代都采取Copying算法, 因为新生代中每次垃圾回收都要回收大部分对象, 也就是说需要复制的操作次数较少, 该算法效率在新生代也较高. 但是实际中并不是按照1: 1的比例来划分新生代的空间的, 一般来说是将新生代划分为一块较大的Eden空间和两块较小的Survivor空间, 每次使用Eden空间和其中的一块Survivor空间, 当进行回收时, 将还存活的对象复制到另一块Survivor空间中, 然后清理掉Eden和A空间. 在进行了第一次GC之后, 使用的便是Eden space和B空间了, 下次GC时会将存活对象复制到A空间, 如此反复循环. 当对象在Survivor区躲过一次GC的话, 其对象年龄便会加1, 默认情况下, 对象年龄达到15时, 就会移动到老年代中. 一般来说, 大对象会被直接分配到老年代, 所谓的大对象是指需要大量连续存储空间的对象, 最常见的一种大对象就是大数组, 比如: byte[] data = new byte[4*1024*1024].当然分配的规则并不是百分之百固定的, 这要取决于当前使用的是哪种垃圾搜集器组合和JVM的相关参数. 这些搬运工作都是GC完成的, GC不仅负责在Heap中搬运实例, 同时负责回收存储空间.最后, 因为每次回收都只回收少量对象, 所以老年代一般使用的是标记整理算法. 注意, 在方法区中有一个永久代（Permanet Generation）, 它用来存储class类、常量、方法描述等. 对永久代的回收主要回收两部分内容: 废弃常量和无用的类.有关查看垃圾回收信息的JVM常见配置方式:1-XX:+PrintGCDetails 最后介绍一下有关堆的JVM常见配置方式:1234567-Xss //选置栈内存的大小 -Xms: //初始堆大小 -Xmx: //最大堆大小 -XX:NewSize=n: //设置年轻代大小 -XX:NewRatio=n: //设置年轻代和年老代的比值. 比如设置为3, 表示年轻代与年老代比值为1: 3 -XX:SurvivorRatio=n: //年轻代中Eden区与两个Survivor区的比值. 注意Survivor区有两个. 比如设置为3, 表示Eden: Survivor=3: 2, 一个Survivor区占整个年轻代的1/5. -XX:MaxPermSize=n: //设置持久代大小 典型的垃圾回收器垃圾搜集算法是内存回收的理论基础, 而垃圾搜集器就是内存回收的具体实现.下面介绍一下HotSpot（JDK 7)虚拟机提供的几种垃圾搜集器, 用户可以根据自己的需求组合出各个年代使用的搜集器. Serial&amp;Serial OldSerial和Serial Old搜集器是最基本最古老的搜集器, 是一个单线程搜集器, 并且在它进行垃圾搜集时, 必须暂停所有用户线程. Serial搜集器是针对新生代的搜集器, 采用的是Copying算法, Serial Old搜集器是针对老年代的搜集器, 采用的是Mark-Compact算法. 它的优点是实现简单高效, 但是缺点是会给用户带来停顿. ParNewParNew搜集器是Serial搜集器的多线程版本, 使用多个线程进行垃圾搜集. Parallel ScavengeParallel Scavenge搜集器是一个新生代的多线程搜集器（并行搜集器）, 它在回收期间不需要暂停其他用户线程, 其采用的是Copying算法, 该搜集器与前两个搜集器有所不同, 它主要是为了达到一个可控的吞吐量. Parallel OldParallel Old是Parallel Scavenge搜集器的老年代版本（并行搜集器）, 使用多线程和Mark-Compact算法. CMSCMS（Current Mark Sweep）搜集器是一种以获取最短回收停顿时间为目标的搜集器, 它是一种并发搜集器, 采用的是Mark-Sweep算法. G1G1搜集器是当今搜集器技术发展最前沿的成果, 它是一款面向服务端应用的搜集器, 它能充分利用多CPU、多核环境. 因此它是一款并行与并发搜集器, 并且它能建立可预测的停顿时间模型.最后介绍一下有关搜集器设置的JVM常见配置方式:1234567891011-XX:+UseSerialGC: //设置串行搜集器 -XX:+UseParallelGC: //设置并行搜集器 -XX:+UseParalledlOldGC: //设置并行年老代搜集器 -XX:+UseConcMarkSweepGC: //设置并发搜集器 //并行搜集器设置 -XX:ParallelGCThreads=n: //设置并行搜集器搜集时使用的CPU数, 并行搜集线程数 -XX:MaxGCPauseMillis=n: //设置并行搜集最大暂停时间 -XX:GCTimeRatio=n: //设置垃圾回收时间占程序运行时间的百分比, 公式为1/(1+n) //并发搜集器设置 -XX:+CMSIncrementalMode: //设置为增量模式. 适用于单CPU情况 -XX:ParallelGCThreads=n: //设置并发搜集器年轻代搜集方式为并行搜集时, 使用的CPU数. 并行搜集线程数 Java类加载机制总结 类加载器的组织结构类加载器 ClassLoader是具有层次结构的, 也就是父子关系. 其中, Bootstrap是所有类加载器的父亲.（1）Bootstrapclass loader: 启动类加载器当运行Java虚拟机时, 这个类加载器被创建, 它负责加载虚拟机的核心类库, 如java.lang.*等.（2）Extensionclass loader: 标准扩展类加载器用于加载除了基本 API之外的一些拓展类.（3）AppClassLoader: 加载应用程序和程序员自定义的类.运行下面的程序, 结果也显示出来了:从运行结果可以看出加载器之间的父子关系, ExtClassLoader的父Loader返回了null原因是BootstrapLoader（启动类加载器）是用C语言实现的, 找不到一个确定的返回父Loader的方式. 类的加载机制类被加载到虚拟机内存包括加载、链接、初始化几个阶段. 其中链接又细化分为验证、准备、解析.这里需要注意的是, 解析阶段在某些情况下可以在初始化阶段之后再开始, 这是为了支持Java的运行时绑定. 各个阶段的作用整理如下: 加载阶段加载阶段可以使用系统提供的类加载器(ClassLoader)来完成, 也可以由用户自定义的类加载器完成, 开发人员可以通过定义类加载器去控制字节流的获取方式.（1）通过类的全名产生对应类的二进制数据流（注意, 若未找到该类文件, 只有在类实际使用时才抛出错误）.（2）分析并将这些二进制数据流转换为方法区的运行时数据结构.（3）创建代表这个类的java.lang.Class对象. 作为方法区这些数据的访问入口. 链接阶段（实现 Java 的动态性的重要一步）（1）验证: 主要的目的是确保class文件的字节流中包含的信息符合当前虚拟机的要求, 并且不会危害虚拟机自身安全. 验证点可能包括: class文件格式规范、这个类是否继承了不允许被继承的类(被final修饰的)、如果这个类的父类是抽象类, 是否实现了起父类或接口中要求实现的所有方法、不能把一个父类对象赋值给子类数据类型、方法的访问性(private、protected、public、default)是否可被当前类访问等等.（2）准备: 准备阶段为类的成员变量分配内存空间并设置类变量初始值的阶段, 这些变量所使用的内存都在方法区中分配. 所有原始类型的值都为0. 如float为0f、 int为0、boolean为0、引用类型为null.（3）解析: 解析阶段是把虚拟机中常量池的符号引用替换为直接引用的过程. 初始化类初始化时类加载的最后一步, 前面除了加载阶段用户可以通过自定义类加载器参与以外, 其余都是虚拟机主导和控制. 到了初始化阶段, 才是真正执行类中定义Java程序代码. 初始化阶段, 根据程序中的定制, 初始化类变量.初始化过程其实是执行类构造器方法的过程.（类构造器方法是由编译器自动搜集类中所有类变量的赋值动作和静态语句块中的语句合并产生的. ）12345678//静态语句块中只能访问定义在静态语句块之前的变量, 定义在它之后的变量可以赋值, 但不能访问 public class Test&#123; static&#123; i=0;//給变量赋值, 可以通过编译 System.out.print(i);//这句编译器会提示非法向前引用 &#125; static int i=1; &#125; 初始化过程会被触发执行的条件汇总:（1）使用new关键字实例化对象、读取或设置一个类的静态字段（被final修饰、已在编译器把结果放入常量池的静态字段除外）的时候, 以及调用类的静态方法*的时候.（2）对类进行反射调用的时候.（3）当初始化一个类的时候, 如果发现其父类还没有进行过初始化, 则进行父类的初始化.（4）JVM启动时, 用户指定执行的主类**（包含main方法所在类）, 虚拟机会先初始化这个类. 【关于构造器方法拓展知识】（可以不看）（1）类构造器&lt;clinit&gt;()方法与类的构造函数不同, 它不需要显式调用父类构造, 虚拟机会保证在子类&lt;clinit&gt;()方法执行之前, 父类的&lt;clinit&gt;()方法已经执行完毕. 因此在虚拟机中的第一个执行的&lt;clinit&gt;()方法的类肯定是java.lang.Object.（2）由于父类的&lt;clinit&gt;()方法先执行, 也就意味着父类中定义的静态语句块要优先于子类的变量赋值操作.（3）&lt;clinit&gt;()方法对于类或接口来说并不是必须的, 如果一个类中没有静态语句, 也没有变量赋值的操作, 那么编译器可以不为这个类生成&lt;clinit&gt;()方法.（4）接口中不能使用静态语句块, 和类不同的是, 执行接口的&lt;clinit&gt;()方法不需要先执行父接口的&lt;clinit&gt;()方法. 只有当父接口中定义的变量被使用时, 父接口才会被初始化. 另外, 接口的实现类在初始化时也一样不会执行接口的&lt;clinit&gt;()方法.（5）虚拟机会保证一个类的&lt;clinit&gt;()方法在多线程环境中被正确加锁和同步, 可能会导致阻塞. 类的整个加载过程触发的的三种方式（1）由 new 关键字创建一个类的实例.（2）调用 Class.forName() 方法, 通过反射加载类.（3）调用某个ClassLoader实例的loadClass()方法. 三者的区别汇总如下:（1）方法1和2都是使用的当前类加载器（this.getClass.getClassLoader）. 方法3由用户指定类加载器并且加载的类与当前类分属不同的命名空间.（2）方法1是静态加载, 2、3是动态加载.（3）对于两种动态加载, 区别如下.123Class.forName(className); //实际上是调用的是: Class.forName(className, true, this.getClass().getClassLoader());//第二个参数设置Class被loading后是不是必须被初始化, 默认初始化 123ClassLoader.loadClass(className); //实际上调用的是: ClassLoader.loadClass(name, false);//第二个参数指Class是否被链接, 默认为false 通过上面的描述, 如果程序依赖于Class是否被初始化, 就必须用Class.forName(name)了 自定义类加载器 为什么需要自定义类加载器网上的大部分自定义类加载器文章, 几乎都是贴一段实现代码, 然后分析一两句自定义ClassLoader的原理. 但是个人觉得首先得把为什么需要自定义加载器这个问题搞清楚, 因为如果不明白它的作用的情况下, 还要去学习它显然是很让人困惑的.首先介绍自定义类的应用场景:（1）加密: Java代码可以轻易的被反编译, 如果你需要把自己的代码进行加密以防止反编译, 可以先将编译后的代码用某种加密算法加密, 类加密后就不能再用Java的ClassLoader去加载类了, 这时就需要自定义ClassLoader在加载类的时候先解密类, 然后再加载.（2）从非标准的来源加载代码: 如果你的字节码是放在数据库、甚至是在云端, 就可以自定义类加载器, 从指定的来源加载类.（3）以上两种情况在实际中的综合运用: 比如你的应用需要通过网络来传输 Java 类的字节码, 为了安全性, 这些字节码经过了加密处理. 这个时候你就需要自定义类加载器来从某个网络地址上读取加密后的字节代码, 接着进行解密和验证, 最后定义出在Java虚拟机中运行的类. 双亲委派模型在实现自己的ClassLoader之前, 我们先了解一下系统是如何加载类的, 那么就不得不介绍双亲委派模型的特点和实现过程.双亲委派模型特点:该模型要求除了顶层的Bootstrapclassloader启动类加载器外, 其余的类加载器都应当有自己的父类加载器. 子类加载器和父类加载器不是以继承（Inheritance）的关系来实现, 而是通过组合（Composition）关系来复用父加载器的代码.1234567891011121314151617181920212223242526272829//双亲委派模型的工作过程源码 protected synchronized Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException &#123; // First, check if the class has already been loaded Class c = findLoadedClass(name); if (c == null) &#123; try &#123; if (parent != null) &#123; c = parent.loadClass(name, false); &#125; else &#123; c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // ClassNotFoundException thrown if class not found // from the non-null parent class loader //父类加载器无法完成类加载请求 &#125; if (c == null) &#123; // If still not found, then invoke findClass in order to find the class //子加载器进行类加载 c = findClass(name); &#125; &#125; if (resolve) &#123;//判断是否需要链接过程, 参数传入 resolveClass(c); &#125; return c; &#125; 双亲委派模型的工作过程如下:（1）代码中一开始的判空操作是当前 ClassLoader从自己已经加载的类中查询是否此类已经加载, 如果已经加载则直接返回原来已经加载的类. （每个类加载器都有自己的加载缓存, 当一个类被加载了以后就会放入缓存, 等下次加载的时候就可以直接返回）（2）当前 ClassLoader的缓存中没有找到被加载的类的时候, 它自己不会尝试去加载该类, 而是委托父类加载器去加载, 如代码c = parent.loadClass(name, false)所示（父类加载器采用同样的策略, 递归了loadClass函数）, 首先查看自己的缓存, 没有就委托父类的父类去加载, 一直到 BootStrap ClassLoader. 如代码所示, 如果父加载器为空则默认使用启动类加载器（BootStrap ClassLoader）作为父加载器去加载, 如代码findBootstrapClassOrNull(name)所示（为何父类为BootStrap ClassLoader会返回空, 原因在Java类加载机制总结中介绍过了）.（3）如果BootStrapClassLoader加载失败（例如在$JAVA_HOME/jre/lib里未查找到该class）, 会使用ExtClassLoader来尝试加载； 若ExtClassLoader也加载失败, 则会使用AppClassLoader来加载, 如果AppClassLoader也加载失败, 则会抛出ClassNotFoundException. 最后再调用当前加载器的findClass()方法进行加载. 双亲委派模型的好处:（1）主要是为了安全性, 避免用户自己编写的类动态替换Java的一些核心类, 比如 String.（2）同时也避免重复加载, 因为 JVM中区分不同类, 不仅仅是根据类名, 相同的class文件被不同的 ClassLoader加载就是不同的两个类. 自定义类加载器（1）从上面源码可以看出, 在调用loadClass方法时, 会先根据委派模型在父加载器中加载, 如果加载失败, 则会调用自己的findClass方法来完成加载.（2）因此我们自定义的类加载器只需要继承ClassLoader, 并覆盖findClass方法.（3）下面是一个实际例子, 在该例中我们用自定义的类加载器去加载我们事先准备好的class文件. 自定义一个People.java类做例子12345678910111213141516171819202122public class People &#123; //该类写在记事本里, 在用javac命令行编译成class文件, 放在d盘根目录下 private String name; public People() &#123;&#125; public People(String name) &#123; this.name = name; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public String toString() &#123; return "I am a people, my name is " + name; &#125; &#125; 自定义类加载器自定义一个类加载器, 需要继承ClassLoader类, 并实现findClass方法. 其中defineClass方法可以把二进制流字节组成的文件转换为一个java.lang.Class（只要二进制字节流的内容符合Class文件规范）.1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class MyClassLoader extends ClassLoader &#123; public MyClassLoader() &#123; &#125; public MyClassLoader(ClassLoader parent) &#123; super(parent); &#125; protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; File file = new File("D:/People.class"); try&#123; byte[] bytes = getClassBytes(file); //defineClass方法可以把二进制流字节组成的文件转换为一个java.lang.Class Class&lt;?&gt; c = this.defineClass(name, bytes, 0, bytes.length); return c; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return super.findClass(name); &#125; private byte[] getClassBytes(File file) throws Exception &#123; // 这里要读入.class的字节, 因此要使用字节流 FileInputStream fis = new FileInputStream(file); FileChannel fc = fis.getChannel(); ByteArrayOutputStream baos = new ByteArrayOutputStream(); WritableByteChannel wbc = Channels.newChannel(baos); ByteBuffer by = ByteBuffer.allocate(1024); while (true)&#123; int i = fc.read(by); if (i == 0 || i == -1) break; by.flip(); wbc.write(by); by.clear(); &#125; fis.close(); return baos.toByteArray(); &#125; &#125; 在主函数里使用123456MyClassLoader mcl = new MyClassLoader(); Class&lt;?&gt; clazz = Class.forName("People", true, mcl); Object obj = clazz.newInstance(); System.out.println(obj); System.out.println(obj.getClass().getClassLoader());//打印出我们的自定义类加载器 运行结果 至此关于自定义ClassLoader的内容总结完毕. Tomcat与Eclipse性能调优Tomcat服务器优化JDK内存优化根据服务器物理内容情况配置相关参数优化tomcat性能. 当应用程序需要的内存超出堆的最大值时虚拟机就会提示内存溢出, 并且导致应用服务崩溃. 因此一般建议堆的最大值设置为可用内存的最大值的80%. Tomcat默认可以使用的内存为128MB, 在较大型的应用项目中, 这点内存是不够的, 需要调大.Tomcat默认可以使用的内存为128MB,Windows下,在文件/bin/catalina.bat, Unix下, 在文件/bin/catalina.sh的前面, 增加如下设置: JAVA_OPTS=’-Xms【初始化内存大小】 -Xmx【可以使用的最大内存】 -XX:PermSize=64M -XX:MaxPermSize=128m’ 需要把几个参数值调大. 例如: JAVA_OPTS=’-Xms256m -Xmx512m’ 表示初始化内存为256MB, 可以使用的最大内存为512MB. 参数详解:123456-server 启用jdk 的 server 版；-Xms java虚拟机初始化时的最小内存；-Xmx java虚拟机可使用的最大内存；-XX:PermSize 内存永久保留区域-XX:MaxPermSize 内存最大永久保留区域 -Xmn jvm最小内存 32G 内存配置示例:1JAVA_OPTS=&quot;$JAVA_OPTS -Xms10g -Xmx10g -XX:PermSize=1g -XX:MaxPermSize=2g -Xshare:off -Xmn1024m Tomcat线程优化在Tomcat配置文件server.xml中的配置中, 和连接数相关的参数有:maxThreads: Tomcat使用线程来处理接收的每个请求. 这个值表示Tomcat可创建的最大的线程数. 默认值150.acceptCount: 指定当所有可以使用的处理请求的线程数都被使用时, 可以放到处理队列中的请求数, 超过这个数的请求将不予处理. 默认值10.minSpareThreads: Tomcat初始化时创建的线程数. 默认值25.maxSpareThreads: 一旦创建的线程超过这个值, Tomcat就会关闭不再需要的socket线程. 默认值75.enableLookups: 是否反查域名, 默认值为true. 为了提高处理能力, 应设置为falseconnnectionTimeout: 网络连接超时, 默认值60000, 单位: 毫秒. 设置为0表示永不超时, 这样设置有隐患的. 通常可设置为30000毫秒.maxKeepAliveRequests: 保持请求数量, 默认值100. bufferSize: 输入流缓冲大小, 默认值2048 bytes.compression: 压缩传输, 取值on/off/force, 默认值off. 其中和最大连接数相关的参数为maxThreads和acceptCount. 如果要加大并发连接数, 应同时加大这两个参数.32G 内存配置示例:123&lt;Connector port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot; connectionTimeout=&quot;20000&quot; maxThreads=&quot;1000&quot; minSpareThreads=&quot;60&quot; maxSpareThreads=&quot;600&quot; acceptCount=&quot;120&quot; redirectPort=&quot;8443&quot; URIEncoding=&quot;utf-8&quot;/&gt; Eclipse调优eclipse.ini配置:12345678910111213141516171819202122232425-startupplugins/org.eclipse.equinox.launcher_1.3.100.v20150511-1540.jar--launcher.libraryplugins/org.eclipse.equinox.launcher.win32.win32.x86_64_1.1.300.v20150602-1417-productorg.eclipse.epp.package.jee.product--launcher.defaultActionopenFile--launcher.XXMaxPermSize512M-showsplashorg.eclipse.platform--launcher.XXMaxPermSize512m--launcher.defaultActionopenFile--launcher.appendVmargs-vmargs-Dosgi.requiredJavaVersion=1.7-Xms2048m-Xmx2048m-Xverify:none-XX:+PrintGCDetails -XX:+PrintGCDateStamps-Xloggc:gc.log 最后附上两张来自 无敌码农 的图片: 参考并转载于: http://blog.csdn.net/seu_calvin/article/details/51404589http://blog.csdn.net/seu_calvin/article/details/51892567http://blog.csdn.net/seu_calvin/article/details/52301541http://www.importnew.com/23774.htmlhttp://www.importnew.com/23774.html 更多JVM汇总请看: Jvm系列文章 关于Jvm知识看这一篇就够了]]></content>
      <categories>
        <category>Programming</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java开发人员最常犯的10个错误以及35个代码性能优化小结]]></title>
    <url>%2F2017%2Fjava-dev-ten-mistake-and-some-advice%2F</url>
    <content type="text"><![CDATA[前言 人非圣贤孰能无过, 编程更是一门要求非常严谨的学问, 难免会在敲代码时一个不留神就产生一个BUG, 解决一个BUG难免又会出现十个BUG.代码优化, 一个很重要的课题. 可能有些人觉得没用, 一些细小的地方有什么好修改的, 改与不改对于代码的运行效率有什么影响呢？这个问题我是这么考虑的, 就像大海里面的鲸鱼一样, 它吃一条小虾米有用吗？没用, 但是, 吃的小虾米一多之后, 鲸鱼就被喂饱了. 代码优化也是一样, 如果项目着眼于尽快无BUG上线, 那么此时可以抓大放小, 代码的细节可以不精打细磨；但是如果有足够的时间开发、维护代码, 这时候就必须考虑每个可以优化的细节了, 一个一个细小的优化点累积起来, 对于代码的运行效率绝对是有提升的.下面博主就分享一下Java开发人员最常犯的10个错误以及一些代码优化, 也希望自己把这些优化当成习惯融入平时. 一、把数组转成ArrayList为了将数组转换为ArrayList, 开发者经常会这样做:1List&lt;String&gt; list = Arrays.asList(arr); 使用Arrays.asList()方法可以得到一个ArrayList, 但是得到这个ArrayList其实是定义在Arrays类中的一个私有的静态内部类. 这个类虽然和java.util.ArrayList同名, 但是并不是同一个类. java.util.Arrays.ArrayList类中实现了set(), get(), contains()等方法, 但是并没有定义向其中增加元素的方法. 也就是说通过Arrays.asList()得到的ArrayList的大小是固定的. 如果在开发过程中, 想得到一个真正的ArrayList对象（java.util.ArrayList的实例）, 可以通过以下方式:1ArrayList&lt;String&gt; arrayList = new ArrayList&lt;String&gt;(Arrays.asList(arr)); java.util.ArrayList中包含一个可以接受集合类型参数的构造函数. 因为java.util.Arrays.ArrayList这个内部类继承了AbstractList类, 所以, 该类也是Collection的子类. 二、判断一个数组是否包含某个值在判断一个数组中是否包含某个值的时候, 开发者经常这样做:12Set&lt;String&gt; set = new HashSet&lt;String&gt;(Arrays.asList(arr));return set.contains(targetValue); 在在Java中如何高效的判断数组中是否包含某个元素一文中, 深入分析过, 以上方式虽然可以实现功能, 但是效率却比较低. 因为将数组压入Collection类型中, 首先要将数组元素遍历一遍, 然后再使用集合类做其他操作. 在判断一个数组是否包含某个值的时候, 推荐使用for循环遍历的形式或者使用Apache Commons类库中提供的ArrayUtils类的contains方法. 三、在循环中删除列表中的元素在讨论这个问题之前, 先考虑以下代码的输出结果:12345ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;(Arrays.asList("a","b","c","d"));for(int i=0;i&lt;list.size();i++)&#123; list.remove(i);&#125;System.out.println(list); 输出结果:1[b,d] 以上代码的目的是想遍历删除list中所有元素, 但是结果却没有成功. 原因是忽略了一个关键的问题: 当一个元素被删除时, 列表的大小缩小并且下标也会随之变化, 所以当你想要在一个循环中用下标删除多个元素的时候, 它并不会正常的生效. 也有些人知道以上代码的问题就由于数组下标变换引起的. 所以, 他们想到使用增强for循环的形式:123456ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;(Arrays.asList("a","b","c","d"));for(String s:list)&#123; if(s.equals("a"))&#123; list.remove(s); &#125;&#125; 但是, 很不幸的是, 以上代码会抛出ConcurrentModificationException, 有趣的是, 如果在remove操作后增加一个break, 代码就不会报错:1234567ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;(Arrays.asList(&quot;a&quot;,&quot;b&quot;,&quot;c&quot;,&quot;d&quot;));for(String s:list)&#123; if(s.equals(&quot;a&quot;))&#123; list.remove(s); break; &#125;&#125; 在Java中的fail-fast机制一文中, 深入分析了几种在遍历数组的同时删除其中元素的方法以及各种方法存在的问题. 其中就介绍了上面的代码出错的原因. 迭代器（Iterator）是工作在一个独立的线程中, 并且拥有一个 mutex 锁. 迭代器被创建之后会建立一个指向原来对象的单链索引表, 当原来的对象数量发生变化时, 这个索引表的内容不会同步改变, 所以当索引指针往后移动的时候就找不到要迭代的对象, 所以按照 fail-fast 原则迭代器会马上抛出java.util.ConcurrentModificationException异常. 所以, 正确的在遍历过程中删除元素的方法应该是使用Iterator:123456789ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;(Arrays.asList("a", "b", "c", "d"));Iterator&lt;String&gt; iter = list.iterator();while (iter.hasNext()) &#123; String s = iter.next(); if (s.equals("a")) &#123; iter.remove(); &#125;&#125; next()方法必须在调用remove()方法之前调用. 如果在循环过程中先调用remove(), 再调用next(), 就会导致异常ConcurrentModificationException. 原因如上. 四、HashTable 和 HashMap 的选择了解算法的人可能对HashTable比较熟悉, 因为他是一个数据结构的名字. 但在Java里边, 用HashMap来表示这样的数据结构. Hashtable和HashMap的一个关键性的不同是, HashTable是同步的, 而HashMap不是. 所以通常不需要HashTable, HashMap用的更多. HashMap完全解读、Java中常见亲属比较等文章中介绍了他们的区别和如何选择. 五、使用原始集合类型在Java里边, 原始类型和无界通配符类型很容易混合在一起. 以Set为例, Set是一个原始类型, 而Set&lt; ? &gt;是一个无界通配符类型. （可以把原始类型理解为没有使用泛型约束的类型） 考虑下面使用原始类型List作为参数的代码:12345678public static void add(List list, Object o)&#123; list.add(o);&#125;public static void main(String[] args)&#123; List&lt;String&gt; list = new ArrayList&lt;String&gt;(); add(list, 10); String s = list.get(0);&#125; 上面的代码将会抛出异常:java.lang.ClassCastException: java.lang.Integer cannot be cast to java.lang.String 使用原始集合类型是很危险的, 因为原始集合类型跳过了泛型类型检查, 是不安全的. Set、Set&lt; ? &gt;和Set&lt; Object &gt;之间有很大差别. 关于泛型, 可以参考下列文章: 《成神之路-基础篇》Java基础知识——泛型 六、访问级别程序员们经常使用public作为类中的字段的修饰符, 因为这样可以很简单的通过引用得到值, 但这并不是好的设计, 按照经验, 分配给成员变量的访问级别应该尽可能的低. 参考Java中的四种访问级别 七、ArrayList与LinkedList的选择当程序员们不知道ArrayList与LinkedList的区别时, 他们经常使用ArrayList, 因为它看起来比较熟悉. 然而, 它们之前有巨大的性能差别. 在ArrayList vs LinkedList vs Vector 区别、Java中常见亲属比较等文章中介绍过, 简而言之, 如果有大量的增加删除操作并且没有很多的随机访问元素的操作, 应该首先LinkedList. （LinkedList更适合从中间插入或者删除（链表的特性）） 八、可变与不可变在为什么Java要把字符串设计成不可变的一文中介绍过, 不可变对象有许多的优点, 比如简单, 安全等等. 同时, 也有人提出疑问: 既然不可变有这么多好处, 为什么不把所有类都搞成不可变的呢？ 通常情况下, 可变对象可以用来避免产生过多的中间对象. 一个经典的实例就是连接大量的字符串, 如果使用不可变的字符串, 将会产生大量的需要进行垃圾回收的对象. 这会浪费CPU大量的时间, 使用可变对象才是正确的方案(比如StringBuilder).1234String result=&quot;&quot;;for(String s: arr)&#123; result = result + s;&#125; StackOverflow中也有关于这个的讨论. 九、父类和子类的构造函数首先, 我们都知道: 如果一个类没有定义构造函数, 编译器将会插入一个无参数的默认构造函数. 如果一个类中定义了一个带参数的构造函数, 那么编译器就不会再帮我们创建无参的构造函数. Super类中定义了一个带参数的构造函数. 编译器将不会插入默认的无参数构造函数. 我们还应该知道: 子类的所有构造函数（无论是有参还是无参）在执行时, 都会调用父类的无参构造函数. 所以, 编译器试图调用Super类中的无参构造函数. 但是父类默认的构造函数未定义, 编译器就会报出这个错误信息.要解决这个问题, 可以简单的通过 1)在父类中添加一个Super()构造方法, 就像这样: 1public Super()&#123;&#125; 2)移除自定义的父类构造函数 3)在子类的构造函数中调用父类的super(value). 十、””还是构造函数？关于这个问题, 也是程序员经常出现困惑的地方, 在该如何创建字符串, 使用” “还是构造函数？中也介绍过. 如果你只需要创建一个字符串, 你可以使用双引号的方式, 如果你需要在堆中创建一个新的对象, 你可以选择构造函数的方式. 在String d = new String(&quot;abcd&quot;)时, 因为字面值“abcd”已经是字符串类型, 那么使用构造函数方式只会创建一个额外没有用处的对象. 35个Java代码性能优化总结代码优化的目标是: 减小代码的体积 提高代码运行的效率 1、尽量指定类、方法的final修饰符带有final修饰符的类是不可派生的. 在Java核心API中, 有许多应用final的例子, 例如java.lang.String, 整个类都是final的. 为类指定final修饰符可以让类不可以被继承, 为方法指定final修饰符可以让方法不可以被重写. 如果指定了一个类为final, 则该类所有的方法都是final的. Java编译器会寻找机会内联所有的final方法, 内联对于提升Java运行效率作用重大, 具体参见Java运行期优化. 此举能够使性能平均提高50%. 2、尽量重用对象特别是String对象的使用, 出现字符串连接时应该使用StringBuilder/StringBuffer代替. 由于Java虚拟机不仅要花时间生成对象, 以后可能还需要花时间对这些对象进行垃圾回收和处理, 因此, 生成过多的对象将会给程序的性能带来很大的影响. 3、尽可能使用局部变量调用方法时传递的参数以及在调用中创建的临时变量都保存在栈中速度较快, 其他变量, 如静态变量、实例变量等, 都在堆中创建, 速度较慢. 另外, 栈中创建的变量, 随着方法的运行结束, 这些内容就没了, 不需要额外的垃圾回收. 4、及时关闭流Java编程过程中, 进行数据库连接、I/O流操作时务必小心, 在使用完毕后, 及时关闭以释放资源. 因为对这些大对象的操作会造成系统大的开销, 稍有不慎, 将会导致严重的后果. 5、尽量减少对变量的重复计算明确一个概念, 对方法的调用, 即使方法中只有一句语句, 也是有消耗的, 包括创建栈帧、调用方法时保护现场、调用方法完毕时恢复现场等. 所以例如下面的操作:12for (int i = 0; i &lt; list.size(); i++)&#123;...&#125; 建议替换为: 12for (int i = 0, int length = list.size(); i &lt; length; i++)&#123;...&#125; 这样, 在list.size()很大的时候, 就减少了很多的消耗 6、尽量采用懒加载的策略, 即在需要的时候才创建例如:1234String str = "aaa";if (i == 1)&#123;list.add(str);&#125; 建议替换为:123456if (i == 1)&#123;String str = "aaa";list.add(str);&#125; 7、慎用异常异常对性能不利. 抛出异常首先要创建一个新的对象, Throwable接口的构造函数调用名为fillInStackTrace()的本地同步方法, fillInStackTrace()方法检查堆栈, 收集调用跟踪信息. 只要有异常被抛出, Java虚拟机就必须调整调用堆栈, 因为在处理过程中创建了一个新的对象. 异常只能用于错误处理, 不应该用来控制程序流程. 8、不要在循环中使用try…catch…, 应该把其放在最外层除非不得已. 如果毫无理由地这么写了, 只要你的领导资深一点、有强迫症一点, 八成就要骂你为什么写出这种垃圾代码来了. 9、如果能估计到待添加的内容长度, 为底层以数组方式实现的集合、工具类指定初始长度比如ArrayList、LinkedLlist、StringBuilder、StringBuffer、HashMap、HashSet等等, 以StringBuilder为例:（1）StringBuilder() // 默认分配16个字符的空间（2）StringBuilder(int size) // 默认分配size个字符的空间（3）StringBuilder(String str) // 默认分配16个字符+str.length()个字符空间可以通过类（这里指的不仅仅是上面的StringBuilder）的来设定它的初始化容量, 这样可以明显地提升性能. 比如StringBuilder吧, length表示当前的StringBuilder能保持的字符数量. 因为当StringBuilder达到最大容量的时候, 它会将自身容量增加到当前的2倍再加2, 无论何时只要StringBuilder达到它的最大容量, 它就不得不创建一个新的字符数组然后将旧的字符数组内容拷贝到新字符数组中—-这是十分耗费性能的一个操作. 试想, 如果能预估到字符数组中大概要存放5000个字符而不指定长度, 最接近5000的2次幂是4096, 每次扩容加的2不管, 那么:（1）在4096 的基础上, 再申请8194个大小的字符数组, 加起来相当于一次申请了12290个大小的字符数组, 如果一开始能指定5000个大小的字符数组, 就节省了一倍以上的空间（2）把原来的4096个字符拷贝到新的的字符数组中去这样, 既浪费内存空间又降低代码运行效率. 所以, 给底层以数组实现的集合、工具类设置一个合理的初始化容量是错不了的, 这会带来立竿见影的效果. 但是, 注意, 像HashMap这种是以数组+链表实现的集合, 别把初始大小和你估计的大小设置得一样, 因为一个table上只连接一个对象的可能性几乎为0. 初始大小建议设置为2的N次幂, 如果能估计到有2000个元素, 设置成new HashMap(128)、new HashMap(256)都可以. 10、当复制大量数据时, 使用System.arraycopy()命令12345public static void arraycopy(Object src, int srcPos, Object dest, int destPos, int length) src:源数组； srcPos:源数组要复制的起始位置；dest:目的数组； destPos:目的数组放置的起始位置； length:复制的长度. 注意: src and dest都必须是同类型或者可以进行转换类型的数组．有趣的是这个函数可以实现自己到自己复制, 比如:12int[] fun =&#123;0,1,2,3,4,5,6&#125;; System.arraycopy(fun,0,fun,3,3); 则结果为: {0,1,2,0,1,2,6};实现过程是这样的, 先生成一个长度为length的临时数组,将fun数组中srcPos到srcPos+length-1之间的数据拷贝到临时数组中, 再执行System.arraycopy(临时数组,0,fun,3,3). 11、乘法和除法使用移位操作例如:12345for (val = 0; val &lt; 100000; val += 5)&#123;a = val * 8;b = val / 2;&#125; 用移位操作可以极大地提高性能, 因为在计算机底层, 对位的操作是最方便、最快的, 因此建议修改为:12345for (val = 0; val &lt; 100000; val += 5)&#123;a = val &lt;&lt; 3;b = val &gt;&gt; 1;&#125; 移位操作虽然快, 但是可能会使代码不太好理解, 因此最好加上相应的注释. 12、循环内不要不断创建对象引用例如:1234for (int i = 1; i &lt;= count; i++)&#123;Object obj = new Object();&#125; 这种做法会导致内存中有count份Object对象引用存在, count很大的话, 就耗费内存了, 建议为改为:1Object obj = null;for (int i = 0; i &lt;= count; i++) &#123; obj = new Object(); &#125; 这样的话, 内存中只有一份Object对象引用, 每次new Object()的时候, Object对象引用指向不同的Object罢了, 但是内存中只有一份, 这样就大大节省了内存空间了. 13、基于效率和类型检查的考虑, 应该尽可能使用array, 无法确定数组大小时才使用ArrayList14、尽量使用HashMap、ArrayList、StringBuilder除非线程安全需要, 否则不推荐使用Hashtable、Vector、StringBuffer, 后三者由于使用同步机制而导致了性能开销 15、不要将数组声明为public static final因为这毫无意义, 这样只是定义了引用为static final, 数组的内容还是可以随意改变的, 将数组声明为public更是一个安全漏洞, 这意味着这个数组可以被外部类所改变 16、尽量在合适的场合使用单例使用单例可以减轻加载的负担、缩短加载的时间、提高加载的效率, 但并不是所有地方都适用于单例, 简单来说, 单例主要适用于以下三个方面:（1）控制资源的使用, 通过线程同步来控制资源的并发访问（2）控制实例的产生, 以达到节约资源的目的（3）控制数据的共享, 在不建立直接关联的条件下, 让多个不相关的进程或线程之间实现通信 17、尽量避免随意使用静态变量要知道, 当某个对象被定义为static的变量所引用, 那么gc通常是不会回收这个对象所占有的堆内存的, 如:1234public class A&#123; private static B b = new B();&#125; 18、及时清除不再需要的会话为了清除不再活动的会话, 许多应用服务器都有默认的会话超时时间, 一般为30分钟. 当应用服务器需要保存更多的会话时, 如果内存不足, 那么操作系统会把部分数据转移到磁盘, 应用服务器也可能根据MRU（最近最频繁使用）算法把部分不活跃的会话转储到磁盘, 甚至可能抛出内存不足的异常. 如果会话要被转储到磁盘, 那么必须要先被序列化, 在大规模集群中, 对对象进行序列化的代价是很昂贵的. 因此, 当会话不再需要时, 应当及时调用HttpSession的invalidate()方法清除会话.此时静态变量b的生命周期与A类相同, 如果A类不被卸载, 那么引用B指向的B对象会常驻内存, 直到程序终止. 19、实现RandomAccess接口的集合比如ArrayList, 应当使用最普通的for循环而不是foreach循环来遍历这是JDK推荐给用户的. JDK API对于RandomAccess接口的解释是: 实现RandomAccess接口用来表明其支持快速随机访问, 此接口的主要目的是允许一般的算法更改其行为, 从而将其应用到随机或连续访问列表时能提供良好的性能. 实际经验表明, 实现RandomAccess接口的类实例, 假如是随机访问的, 使用普通for循环效率将高于使用foreach循环；反过来, 如果是顺序访问的, 则使用Iterator会效率更高. 可以使用类似如下的代码作判断:123456if (list instanceof RandomAccess)&#123; for (int i = 0; i &lt; list.size(); i++)&#123;&#125;&#125;else&#123;Iterator&lt;?&gt; iterator = list.iterable(); while (iterator.hasNext())&#123;iterator.next()&#125;&#125; foreach循环的底层实现原理就是迭代器Iterator, 参见Java语法糖1: 可变长度参数以及foreach循环原理. 所以后半句”反过来, 如果是顺序访问的, 则使用Iterator会效率更高”的意思就是顺序访问的那些类实例, 使用foreach循环去遍历. 20、使用同步代码块替代同步方法这点在多线程模块中的synchronized锁方法块一文中已经讲得很清楚了, 除非能确定一整个方法都是需要进行同步的, 否则尽量使用同步代码块, 避免对那些不需要进行同步的代码也进行了同步, 影响了代码执行效率. 21、将常量声明为static final, 并以大写命名这样在编译期间就可以把这些内容放入常量池中, 避免运行期间计算生成常量的值. 另外, 将常量的名字以大写命名也可以方便区分出常量与变量 22、不要创建一些不使用的对象, 不要导入一些不使用的类这毫无意义, 如果代码中出现”The value of the local variable i is not used”、”The import java.util is never used”, 那么请删除这些无用的内容 23、程序运行过程中避免使用反射关于, 请参见反射. 反射是Java提供给用户一个很强大的功能, 功能强大往往意味着效率不高. 不建议在程序运行过程中使用尤其是频繁使用反射机制, 特别是Method的invoke方法, 如果确实有必要, 一种建议性的做法是将那些需要通过反射加载的类在项目启动的时候通过反射实例化出一个对象并放入内存—-用户只关心和对端交互的时候获取最快的响应速度, 并不关心对端的项目启动花多久时间. 24、使用数据库连接池和线程池这两个池都是用于重用对象的, 前者可以避免频繁地打开和关闭连接, 后者可以避免频繁地创建和销毁线程 25、使用带缓冲的输入输出流进行IO操作带缓冲的输入输出流, 即BufferedReader、BufferedWriter、BufferedInputStream、BufferedOutputStream, 这可以极大地提升IO效率. 26、顺序插入和随机访问比较多的场景使用ArrayList, 元素删除和中间插入比较多的场景使用LinkedList这个, 理解ArrayList和LinkedList的原理就知道了 27、不要让public方法中有太多的形参public方法即对外提供的方法, 如果给这些方法太多形参的话主要有两点坏处:1、违反了面向对象的编程思想, Java讲求一切都是对象, 太多的形参, 和面向对象的编程思想并不契合2、参数太多势必导致方法调用的出错概率增加至于这个”太多”指的是多少个, 3、4个吧. 比如我们用JDBC写一个insertStudentInfo方法, 有10个学生信息字段要插如Student表中, 可以把这10个参数封装在一个实体类中, 作为insert方法的形参. 28、字符串变量和字符串常量equals的时候将字符串常量写在前面这是一个比较常见的小技巧了, 如果有以下代码:1234String str = "123";if (str.equals("123")) &#123;...&#125; 建议修改为:12345String str = "123";if ("123".equals(str))&#123;...&#125; 这么做主要是可以避免空指针异常 29、请知道, 在java中if (i == 1)和if (1 == i)是没有区别的, 但从阅读习惯上讲, 建议使用前者平时有人问, ”if (i == 1)”和”if (1== i)”有没有区别, 这就要从C/C++讲起.在C/C++中, ”if (i == 1)”判断条件成立, 是以0与非0为基准的, 0表示false, 非0表示true, 如果有这么一段代码:1234567int i = 2;if (i == 1)&#123;...&#125;else&#123;...&#125; C/C++判断”i==1″不成立, 所以以0表示, 即false. 但是如果:1int i = 2;if (i = 1) &#123; ... &#125;else&#123; ... &#125; 万一程序员一个不小心, 把”if (i == 1)”写成”if (i = 1)”, 这样就有问题了. 在if之内将i赋值为1, if判断里面的内容非0, 返回的就是true了, 但是明明i为2, 比较的值是1, 应该返回的false. 这种情况在C/C++的开发中是很可能发生的并且会导致一些难以理解的错误产生, 所以, 为了避免开发者在if语句中不正确的赋值操作, 建议将if语句写为:1int i = 2;if (1 == i) &#123; ... &#125;else&#123; ... &#125; 这样, 即使开发者不小心写成了”1 = i”, C/C++编译器也可以第一时间检查出来, 因为我们可以对一个变量赋值i为1, 但是不能对一个常量赋值1为i.但是, 在Java中, C/C++这种”if (i = 1)”的语法是不可能出现的, 因为一旦写了这种语法, Java就会编译报错”Type mismatch: cannot convert from int to boolean”. 但是, 尽管Java的”if (i == 1)”和”if (1 == i)”在语义上没有任何区别, 但是从阅读习惯上讲, 建议使用前者会更好些. 33、把一个基本数据类型转为字符串, 基本数据类型.toString()是最快的方式、String.valueOf(数据)次之、数据+””最慢把一个基本数据类型转为一般有三种方式, 我有一个Integer型数据i, 可以使用i.toString()、String.valueOf(i)、i+”&quot;三种方式, 三种方式的效率如何, 看一个测试:1234567891011121314151617181920212223242526public static void main(String[] args)&#123; int loopTime = 50000;Integer i = 0; long startTime = System.currentTimeMillis(); for (int j = 0; j &lt; loopTime; j++)&#123;String str = String.valueOf(i);&#125;System.out.println("String.valueOf(): " + (System.currentTimeMillis() - startTime) + "ms");startTime = System.currentTimeMillis(); for (int j = 0; j &lt; loopTime; j++)&#123;String str = i.toString();&#125;System.out.println("Integer.toString(): " + (System.currentTimeMillis() - startTime) + "ms");startTime = System.currentTimeMillis(); for (int j = 0; j &lt; loopTime; j++)&#123;String str = i + "";&#125;System.out.println("i + \"\": " + (System.currentTimeMillis() - startTime) + "ms");&#125; 运行结果为:1String.valueOf(): 11ms Integer.toString(): 5ms i + "": 25ms 所以以后遇到把一个基本数据类型转为String的时候, 优先考虑使用toString()方法. 至于为什么, 很简单:1、String.valueOf()方法底层调用了Integer.toString()方法, 但是会在调用前做空判断2、Integer.toString()方法就不说了, 直接调用了3、i + “”底层使用了StringBuilder实现, 先用append方法拼接, 再用toString()方法获取字符串三者对比下来, 明显是2最快、1次之、3最慢. 34、使用最有效率的方式去遍历Map遍历Map的方式有很多, 通常场景下我们需要的是遍历Map中的Key和Value, 那么推荐使用的、效率最高的方式是:1234567891011121314151617181920public static void main(String[] args)&#123;HashMap&lt;String, String&gt; hm = new HashMap&lt;String, String&gt;();hm.put("111", "222");Set&lt;Map.Entry&lt;String, String&gt;&gt; entrySet = hm.entrySet();Iterator&lt;Map.Entry&lt;String, String&gt;&gt; iter = entrySet.iterator(); while (iter.hasNext())&#123;Map.Entry&lt;String, String&gt; entry = iter.next();System.out.println(entry.getKey() + "\t" + entry.getValue());&#125;&#125; 如果你只是想遍历一下这个Map的key值, 那用”Set&lt;String&gt; keySet = hm.keySet();”会比较合适一些 35、对资源的close()建议分开操作意思是, 比如我有这么一段代码:1234567891011try&#123;XXX.close();YYY.close();&#125;catch (Exception e)&#123;...&#125; 建议修改为:12345678910try&#123; XXX.close(); &#125;catch (Exception e) &#123; ... &#125;try&#123; YYY.close(); &#125;catch (Exception e) &#123; ... &#125; 虽然有些麻烦, 却能避免资源泄露. 我们想, 如果没有修改过的代码, 万一XXX.close()抛异常了, 那么就进入了cath块中了, YYY.close()不会执行, YYY这块资源就不会回收了, 一直占用着, 这样的代码一多, 是可能引起资源句柄泄露的. 而改为下面的写法之后, 就保证了无论如何XXX和YYY都会被close掉. 参考 Top 10 Mistakes Java Developers Makehttp://www.hollischuang.com/archives/1360http://www.jianshu.com/p/436943216526]]></content>
      <categories>
        <category>Programming</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于Hexo搭建个人博客——进阶篇(从入门到入土)]]></title>
    <url>%2F2017%2Fbuild-blog-hexo-advanced%2F</url>
    <content type="text"><![CDATA[前言好久没更新了, 因为懒- -前面介绍了Hexo的一些基本搭建→基于Hexo+github+coding搭建个人博客——基础篇(从菜鸟到放弃)对于追求装X的博主来说, 基本的搭建是满足不了的, 接下来整理了一下各方面的细节优化, 包括页面字体大小、配色、背景、SEO(搜索引擎优化)、域名绑定、DNS域名解析实现负载均衡等.关于NexT主题的很多配置、插件都可以在官方文档找到答案, 那么博主只是整理了一些官方没怎么提及的细节优化. 解决Hexo命令fs.SyncWriteStream问题请看解决Hexo命令fs.SyncWriteStream问题 高度定制优化篇集成Mod分享组件 Step1、获取 AppKey在 Mob 注册账号后, 点击头像进入后台, 选择 shareSDK 添加一个 Web应用: Step2、在主题配置文件中添加配置:123mob_share: enable: true appkey: ******** Step3、在next/layout/_partials/share/里面添加mob_share.swig:1234567891011121314151617181920212223242526272829303132333435&lt;!--MOB SHARE BEGIN--&gt;&lt;div class=&quot;-hoofoo-share-title&quot;&gt;分享到: &lt;/div&gt;&lt;div class=&quot;-hoofoo-share-buttons&quot;&gt; &lt;div class=&quot;-mob-share-weibo -hoofoo-share-weibo -hoofoo-share-ui-button&quot;&gt;&lt;i class=&quot;fa fa-weibo&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt;&lt;/div&gt; &lt;div class=&quot;-mob-share-weixin -hoofoo-share-weixin -hoofoo-share-ui-button&quot;&gt;&lt;i class=&quot;fa fa-weixin&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt;&lt;/div&gt; &lt;div class=&quot;-mob-share-qq -hoofoo-share-qq -hoofoo-share-ui-button&quot;&gt;&lt;i class=&quot;fa fa-qq&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt;&lt;/div&gt; &lt;div class=&quot;-mob-share-twitter -hoofoo-share-twitter -hoofoo-share-ui-button&quot;&gt;&lt;i class=&quot;fa fa-twitter&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt;&lt;/div&gt; &lt;div class=&quot;-hoofoo-share-more -hoofoo-share-ui-button -mob-share-open&quot;&gt;&lt;i class=&quot;fa fa-ellipsis-h&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;-mob-share-ui&quot; style=&quot;display: none&quot;&gt; &lt;ul class=&quot;-mob-share-list&quot;&gt; &lt;li class=&quot;-mob-share-weibo&quot;&gt;&lt;p&gt;新浪微博&lt;/p&gt;&lt;/li&gt; &lt;li class=&quot;-mob-share-weixin&quot;&gt;&lt;p&gt;微信&lt;/p&gt;&lt;/li&gt; &lt;li class=&quot;-mob-share-qzone&quot;&gt;&lt;p&gt;QQ空间&lt;/p&gt;&lt;/li&gt; &lt;li class=&quot;-mob-share-qq&quot;&gt;&lt;p&gt;QQ好友&lt;/p&gt;&lt;/li&gt; &lt;li class=&quot;-mob-share-tencentweibo&quot;&gt;&lt;p&gt;腾讯微博&lt;/p&gt;&lt;/li&gt; &lt;li class=&quot;-mob-share-renren&quot;&gt;&lt;p&gt;人人网&lt;/p&gt;&lt;/li&gt; &lt;li class=&quot;-mob-share-kaixin&quot;&gt;&lt;p&gt;开心网&lt;/p&gt;&lt;/li&gt; &lt;li class=&quot;-mob-share-douban&quot;&gt;&lt;p&gt;豆瓣&lt;/p&gt;&lt;/li&gt; &lt;li class=&quot;-mob-share-youdao&quot;&gt;&lt;p&gt;有道云笔记&lt;/p&gt;&lt;/li&gt; &lt;li class=&quot;-mob-share-mingdao&quot;&gt;&lt;p&gt;明道&lt;/p&gt;&lt;/li&gt; &lt;li class=&quot;-mob-share-pengyou&quot;&gt;&lt;p&gt;朋友网&lt;/p&gt;&lt;/li&gt; &lt;li class=&quot;-mob-share-facebook&quot;&gt;&lt;p&gt;Facebook&lt;/p&gt;&lt;/li&gt; &lt;li class=&quot;-mob-share-twitter&quot;&gt;&lt;p&gt;Twitter&lt;/p&gt;&lt;/li&gt; &lt;li class=&quot;-mob-share-pocket&quot;&gt;&lt;p&gt;Pocket&lt;/p&gt;&lt;/li&gt; &lt;li class=&quot;-mob-share-google&quot;&gt;&lt;p&gt;Google+&lt;/p&gt;&lt;/li&gt; &lt;li class=&quot;-mob-share-tumblr&quot;&gt;&lt;p&gt;Tumblr&lt;/p&gt;&lt;/li&gt; &lt;li class=&quot;-mob-share-instapaper&quot;&gt;&lt;p&gt;Instapaper&lt;/p&gt;&lt;/li&gt; &lt;li class=&quot;-mob-share-linkedin&quot;&gt;&lt;p&gt;Linkedin&lt;/p&gt;&lt;/li&gt; &lt;/ul&gt; &lt;div class=&quot;-mob-share-close&quot;&gt;取消&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;-mob-share-ui-bg&quot;&gt;&lt;/div&gt;&lt;script id=&quot;-mob-share&quot; src=&quot;http://f1.webshare.mob.com/code/mob-share.js?appkey=&#123;&#123;theme.mob_share.appkey&#125;&#125;&quot;&gt;&lt;/script&gt;&lt;!--MOB SHARE END--&gt; Step4、在next/layout/post.swig中添加条件分支:1234567891011&#123;% if theme.jiathis %&#125; &#123;% include &apos;_partials/share/jiathis.swig&apos; %&#125; &#123;% elseif theme.baidushare %&#125; &#123;% include &apos;_partials/share/baidushare.swig&apos; %&#125; &#123;% elseif theme.add_this_id %&#125; &#123;% include &apos;_partials/share/add-this.swig&apos; %&#125; &#123;% elseif theme.duoshuo_shortname and theme.duoshuo_share %&#125; &#123;% include &apos;_partials/share/duoshuo_share.swig&apos; %&#125; &#123;% elseif theme.mob_share.enable %&#125; &#123;% include &apos;_partials/share/mob_share.swig&apos; %&#125;&#123;% endif %&#125; Step5、在next/source/css/_common/components/third-party/里添加样式文件mob_share.styl:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980.-hoofoo-share-buttons&#123; display: inline-block;&#125;.-hoofoo-share-title&#123; font-size: 1.1em; font-weight: 200;&#125;.-hoofoo-share-ui-button&#123; cursor: pointer; background-color: #555; color: #fff; font-size: 24px; line-height: 40px; width: 40px; height: 40px; margin: 10px; border-radius: 25px; float: left; transition: background 0.4s; -moz-transition: background 0.4s; /* Firefox 4 */ -webkit-transition: background 0.4s; /* Safari 和 Chrome */ -o-transition: background 0.4s;&#125;.-hoofoo-share-weibo:hover&#123; background-color: #cf3f41;&#125;.-hoofoo-share-weixin:hover&#123; background-color: #18a01a;&#125;.-hoofoo-share-qq:hover&#123; background-color: #950c0c;&#125;.-hoofoo-share-twitter:hover&#123; background-color: #2ab3e6;&#125;.-hoofoo-share-more:hover&#123; background-color: #777;&#125;.-mob-share-weixin-qrcode-content&#123; border-radius: 4px; -webkit-box-shadow: 0 10px 25px rgba(0, 0, 0, 0.5); -moz-box-shadow: 0 10px 25px rgba(0, 0, 0, 0.5); -o-box-shadow: 0 10px 25px rgba(0, 0, 0, 0.5); box-shadow: 0 10px 25px rgba(0, 0, 0, 0.5);&#125;.-mob-share-weixin-qrcode&#123; margin: 5% !important; width: 90% !important; height: auto !important;&#125;.-mob-share-weixin-qrcode-close &#123; background-image: url(&apos;/lib/fancybox/source/fancybox_sprite.png&apos;) !important;//因为兼容问题把vendor改成了lib, 根据自己的路径修改&#125;.-mob-share-weixin-qrcode-close &#123; overflow: hidden; line-height: 100px !important; position: absolute !important; top: -18px !important; right: -18px !important; width: 36px !important; height: 36px !important; cursor: pointer !important; z-index: 8040 !important;&#125;/*Retina graphics!*/@media only screen and (-webkit-min-device-pixel-ratio: 1.5), only screen and (min--moz-device-pixel-ratio: 1.5), only screen and (min-device-pixel-ratio: 1.5)&#123; .-mob-share-weixin-qrcode-close &#123; background-image: url(&apos;/lib/fancybox/source/fancybox_sprite@2x.png&apos;) !important;//因为兼容问题把vendor改成了lib, 根据自己的路径修改 background-size: 44px 152px !important; /*The size of the normal image, half the size of the hi-res image*/ &#125;&#125;.-mob-share-close&#123; height: 4em !important; font-size: 0.8em !important; line-height: 4em !important; background: #555 !important; color: #fff !important;&#125; Step6、同一目录下的 third-party.styl 中添加:1@import &quot;mob_share&quot;; Step7、在next/layout/_scripts/third-party/里添加脚本文件mob_share.swig: 12345678&#123;% if theme.mob_share.enable %&#125;&lt;script type=&quot;text/javascript&quot;&gt; //微信二维码点击背景关闭 $(&apos;body&apos;).delegate(&apos;.-mob-share-weixin-qrcode-bg&apos;,&apos;click&apos;, function()&#123; $(&quot;.-mob-share-weixin-qrcode-close&quot;).trigger(&quot;click&quot;); &#125;); &lt;/script&gt;&#123;% endif %&#125; Step8、在next/layout/_layout.swig的body标签结束前添加:1&#123;% include &apos;_scripts/third-party/mob_share.swig&apos; %&#125; 添加顶部加载条打开/themes/next/layout/_partials/head.swig文件, 添加如下代码:12&lt;script src=&quot;//cdn.bootcss.com/pace/1.0.2/pace.min.js&quot;&gt;&lt;/script&gt;&lt;link href=&quot;//cdn.bootcss.com/pace/1.0.2/themes/pink/pace-theme-flash.css&quot; rel=&quot;stylesheet&quot;&gt; 但是, 默认的是粉色的, 要改变颜色可以在/themes/next/layout/_partials/head.swig文件中添加如下代码（接在刚才link的后面）12345678910111213&lt;style&gt; .pace .pace-progress &#123; background: #ff009e; /*进度条颜色*/ height: 3px; &#125; .pace .pace-progress-inner &#123; box-shadow: 0 0 10px #ff009e, 0 0 5px #ff009e; /*阴影颜色*/ &#125; .pace .pace-activity &#123; border-top-color: #ff009e; /*上边框颜色*/ border-left-color: #ff009e; /*左边框颜色*/ &#125;&lt;/style&gt; 文章加密访问打开themes-&gt;next-&gt;layout-&gt;_partials-&gt;head.swig文件,插入这样一段代码:12345678910&lt;script&gt; (function()&#123; if(&apos;&#123;&#123; page.password &#125;&#125;&apos;)&#123; if (prompt(&apos;请输入文章密码&apos;) !== &apos;&#123;&#123; page.password &#125;&#125;&apos;)&#123; alert(&apos;密码错误！&apos;); history.back(); &#125; &#125; &#125;)();&lt;/script&gt; 然后在文章上写成类似这样:12345678910---title: Hello Worlddate: 2016/7/13 20:46:25categories:- Diarytags: - Testing - Another Tagpassword: 123456--- 博客更换Disqus评论由于多说即将关闭, 本站启用Disqus.既然Disqus已被墙, 那么为了对没有梯子的同学标示友好, 我们可以选择点击加载Disqus评论的方式, 这个问题貌似也得到了主题作者的关注-&gt; (NexT5.2.0)[https://github.com/iissnan/hexo-theme-next/milestone/7]具体做法如下:打开themes/next/layout/_partials/comments.swig, 在文件内容 &lt;div id=&quot;disqus_thread&quot;&gt;前面加入下面内容:123&lt;div style=&quot;text-align:center;&quot;&gt; &lt;button class=&quot;btn&quot; id=&quot;load-disqus&quot; onclick=&quot;disqus.load();&quot;&gt;加载 Disqus 评论&lt;/button&gt;&lt;/div&gt; 再打开themes/next/layout/_scripts/third-party/comments/disqus.swig, 需要替换原本的 Disqus 的加载的内容, 如果希望显示评论数量, 就保留 run_disqus_script(‘count.js’) 这一行, 这样页面载入时还会加载 disqus 的资源:1234run_disqus_script(&apos;count.js&apos;);&#123;% if page.comments %&#125; run_disqus_script(&apos;embed.js&apos;);&#123;% endif %&#125; 替换为下面的内容:12345678910111213var disqus = &#123; load : function disqus()&#123; if(typeof DISQUS !== 'object') &#123; (function () &#123; var s = document.createElement('script'); s.async = true; s.type = 'text/javascript'; s.src = '//' + disqus_shortname + '.disqus.com/embed.js'; (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s); &#125;()); $('#load-disqus').html("评论加载中, 请确保你有梯子, 若评论长时间未加载则你可能翻墙失败...").fadeOut(9000); //加载后移除按钮 &#125; &#125;&#125; 前面的 function run_disqus_script(disqus_script){}这一段, 不打算显示评论数量的话, 可以一起删掉, 不显示评论数量的话, 那么点击加载按钮之前, 网页是不会加载来自 Disqus 的资源的. NexT启用Disqus-Proxy 不翻墙也能使用Disqus 多说于2017.06.01停止了服务, 不得不选择其他的第三方评论服务, 试了一下国内的服务发现不是麻烦（例如需要备案）就是不靠谱或者界面不炫酷（装X嫌疑…） 还是使用Disqus吧…But, 这个早就被GWF隔离了, 虽然自己可以闪现过墙=.=, 但游客不一定都会这个技能…那么问题来了, 怎么做一个公共的梯子实现人人翻墙？在Gayhub全球最大同性交友网中发现, 早就有大神做了这样一个服务, 并选择了ciqulover(在此感谢大神的鼎力相助)的Disque-Proxy项目作为梯子.当然也还有其他的Disqus-Proxy -&gt; fooleap、 jiananshi Flow流程就没什么好说的了, 如上图, 在前端页面上测试 disqus 加载是否成功, 如果成功则显示 disqus 的评论框, 反之加载独立的评论框…具体请看https://ycwalker.com/2017/06/01/about-diqus-proxy/ Get Api-secretapi-secret 需要你在 Disqus Api 的官方网站上开启 API 权限, 申请成功后会得到这个秘钥. 并且需要在后台的 Settings =&gt; Community 里开启访客评论: Deploy Disqus-Proxy首先你得有一台可以访问Disqus的VPS[1]… 博主用的是Linode Docker方式启动: 1234docker run -d --name disqus-proxy --restart=always -p 5509:5509 \-e API_SECRECT=your_serect \-e SHORT_NAME=your_short_name \ycwalker/disqus-proxy-server 更多方式请移步到 https://github.com/ciqulover/disqus-proxy-server NexT ConfigurationCopy Static File将disqus-proxy项目中/build/static文件复制到博客../next/source/下.static文件中应该包含main.0d0338ae.js和main.0603c539.css. _config.yml在主题配置文件中添加:12345678910111213disqus_proxy: enable: true # 如果 disqus 账号名没设置 那么 disqus_proxy 也不会生效 username: ookamiantd # 下面两项你需要更改为自己服务器的域名和端口 server: disqus-proxy.yangbingdong.com port: 5509 # 端口号需要与后端设置一致 # 头像路径设置 defaultAvatar: /images/avatar/avatar-default.jpg adminAvatar: /images/avatar/avatar-admin.jpg # 脚本和 css 路径 js: /static/js/main.0d0338ae.js css: /static/css/main.0603c539.css comment.swig修改/next/layout/_partial/comment.swig, 在最后一个&lt;/div&gt;钱加上: 12345678910111213141516171819202122232425&lt;div id="disqus_proxy_thread"&gt;&lt;/div&gt; &lt;div id="disqus_thread"&gt;&lt;/div&gt; &#123;% if theme.disqus_proxy.enable %&#125; &lt;script type="text/javascript"&gt; window.disqusProxy = &#123; username: '&#123;&#123; theme.disqus_proxy.username &#125;&#125;', server: '&#123;&#123; theme.disqus_proxy.server &#125;&#125;', port: '&#123;&#123; theme.disqus_proxy.port &#125;&#125;', defaultAvatar: '&#123;&#123; theme.disqus_proxy.defaultAvatar &#125;&#125;', adminAvatar: '&#123;&#123; theme.disqus_proxy.adminAvatar &#125;&#125;', identifier: '&#123;&#123; page.path &#125;&#125;' &#125;; window.disqus_config = function () &#123; this.page.url = '&#123;&#123; page.permalink &#125;&#125;'; this.page.identifier = '&#123;&#123; page.path &#125;&#125;'; &#125;; window.onload=function()&#123; var s = document.createElement('script'); s.src = "&#123;&#123; theme.disqus_proxy.js &#125;&#125;"; s.async = true; document.body.appendChild(s); &#125; &lt;/script&gt; &lt;link rel="stylesheet" href="&#123;&#123; theme.disqus_proxy.css &#125;&#125;"&gt; &#123;% endif %&#125; 渲染效果:1234567891011121314151617181920212223&lt;div id="disqus_proxy_thread"&gt;&lt;/div&gt;&lt;div id="disqus_thread"&gt;&lt;/div&gt;&lt;script type="text/javascript"&gt; window.disqusProxy = &#123; username: 'ookamiantd', server: 'disqus-proxy.yangbingdong.com', port: '5509', defaultAvatar: '/images/avatar/avatar-default.jpg', adminAvatar: '/images/avatar/avatar-admin.jpg', identifier: '2017/disqus-proxy/' &#125;; window.disqus_config = function () &#123; this.page.url = 'http://ookamiantd.top/2017/disqus-proxy/'; this.page.identifier = '2017/disqus-proxy/'; &#125;; window.onload = function () &#123; var s = document.createElement('script'); s.src = "/static/js/main.0d0338ae.js"; s.async = true; document.body.appendChild(s); &#125;&lt;/script&gt;&lt;link rel="stylesheet" href="/static/css/main.0603c539.css"&gt; custom.styl可能由于改过样式还是本来就不兼容, 评论框一开始显示不出来, ciqulover大神帮我加了个样式之后就好了. 在/next/source/css/_custom/custom.styl中添加:12345#disqus_proxy_thread .post&#123; opacity: 1 !important; box-shadow: none !important; -webkit-box-shadow: none !important;&#125; 博主也对评论框乱入了一些样式例如头像旋转…具体请看main.0603c539.css Problem博主使用了hexo-all-minifier进行静态文件压缩, 不明原因导致那两个评论框的js和css压缩之后会报错, 所以对压缩选项作设置, 在站点配置文件中添加:123456789101112131415161718192021222324html_minifier: enable: true exclude: css_minifier: enable: true exclude: - '/home/ybd/GitRepo/blog/themes/next/source/static/css/main.0603c539.css'js_minifier: enable: true mangle: true output: compress: exclude: - '/home/ybd/GitRepo/blog/themes/next/source/static/js/*.*.js'image_minifier: enable: true interlaced: false multipass: false optimizationLevel: 2 pngquant: false progressive: false Show这是翻墙状态:这是disqus_proxy: 修改文章页宽打开themes/next/source/css/_variables/base.styl, 找到以下字段并修改为合适的宽度:1$content-desktop-large = 1000px 修改小型代码块颜色修改\themes\next\source\css\ _variables\base.styl文件, 加入自定义颜色:123456789$black-deep = #222$red = #ff2a2a$blue-bright = #87daff$blue = #0684bd$blue-deep = #262a30$orange = #fc6423// 下面是我自定义的颜色$my-code-foreground = #dd0055 // 用``围出的代码块字体颜色$my-code-background = #eee // 用``围出的代码块背景颜色 修改$code-background和$code-foreground的值:123456// Code &amp; Code Blocks // 用``围出的代码块 // -------------------------------------------------- $code-font-family = $font-family-monospace $code-font-size = 15px $code-background = $my-code-background $code-foreground = $my-code-foreground $code-border-radius = 4px 文章末尾追加版权信息找到themes/next/layout/_macro/post.swig, 在footer之前添加如下代码(添加之前确保已添加样式):12345678&lt;div&gt; &lt;p id=&quot;div-border-left-red&quot;&gt; &lt;b&gt;本文基于&lt;a target=&quot;_blank&quot; title=&quot;Creative Commons Attribution-ShareAlike 4.0 International (CC BY-SA 4.0)&quot; href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt; 知识共享署名-相同方式共享 4.0 &lt;/a&gt;国际许可协议发布&lt;/b&gt;&lt;br/&gt; &lt;span&gt; &lt;b&gt;本文地址: &lt;/b&gt;&lt;a href=&quot;&#123;&#123; url_for(page.path) &#125;&#125;&quot; title=&quot;&#123;&#123; page.title &#125;&#125;&quot;&gt;&#123;&#123; page.permalink &#125;&#125;&lt;/a&gt;&lt;br/&gt;&lt;b&gt;转载请注明出处, 谢谢！&lt;/b&gt; &lt;/span&gt; &lt;/p&gt;&lt;/div&gt; 添加文章结束标记同样在themes/next/layout/_macro/post.swig中, 在wechat-subscriber.swig之前添加如下代码:1&lt;div style=&quot;text-align:center;color: #ccc;font-size:14px;&quot;&gt;---------------- The End ----------------&lt;/div&gt; 添加热度在/themes/hexo-theme-next/layout/_macro/post.swig里面的下面的位置加上如下代码:12345678910111213141516171819&#123;% if post.categories and post.categories.length %&#125; &lt;span class=&quot;post-category&quot; &gt; &lt;/span&gt; &#123;% endif %&#125; &lt;!-- 在下面的位置加上如下代码 --&gt; &lt;span id=&quot;busuanzi_container_page_pv&quot;&gt; &amp;nbsp; | &amp;nbsp; 热度&amp;nbsp; &lt;span id=&quot;busuanzi_value_page_pv&quot;&gt;&lt;/span&gt;°C &lt;/span&gt; &lt;!-- 在上面的位置加上如上代码 --&gt; &#123;% if post.comments %&#125; &#123;% if (theme.duoshuo and theme.duoshuo.shortname) or theme.duoshuo_shortname %&#125; &lt;span class=&quot;post-comments-count&quot;&gt; &amp;nbsp; | &amp;nbsp; &lt;a href=&quot;&#123;&#123; url_for(post.path) &#125;&#125;#comments&quot; itemprop=&quot;discussionUrl&quot;&gt; &lt;span class=&quot;post-comments-count ds-thread-count&quot; data-thread-key=&quot;&#123;&#123; post.path &#125;&#125;&quot; itemprop=&quot;commentsCount&quot;&gt;&lt;/span&gt; &lt;/a&gt; &lt;/span&gt; 但是这有一个缺陷. 就是我们会发现在主页时显示的热度和进入博客后的热度不一样, 那是因为在主页时他显示的是主页这个页面的阅读量, 而不是博客的阅读量, 所以我们需要改变一些: 我们在/themes/hexo-theme-next/layout/_macro/目录下新建post-article.swig,把这些post.swig中的内容复制过去, 而且加上上面的统计代码, 然后在/themes/hexo-theme-next/layout/post.swig上面% import &#39;_macro/post.swig&#39; as post_template %中的post.swig改成post-article.swig, 这样子就解决啦. 就是在主页上的博客名字下面不会有阅读人数, 进入博客才能看见 添加Fork me on GitHub去网址https://github.com/blog/273-github-ribbons挑选自己喜欢的样式, 并复制代码, 添加到themes\next\layout\_layout.swig的body标签之内即可记得把里面的url换成自己的! 把侧边栏头像变成圆形, 并且鼠标停留在上面发生旋转效果 修改themes\next\source\css\_common\components\sidebar\sidebar-author.styl:1234567891011121314151617181920212223242526272829.site-author-image &#123; display: block; margin: 0 auto; padding: $site-author-image-padding; max-width: $site-author-image-width; height: $site-author-image-height; border: site-author-image-border-color; /* start*/ border-radius: 50% webkit-transition: 1.4s all; moz-transition: 1.4s all; ms-transition: 1.4s all; transition: 1.4s all; /* end */&#125;/* start */.site-author-image:hover &#123; background-color: #55DAE1; webkit-transform: rotate(360deg) scale(1.1); moz-transform: rotate(360deg) scale(1.1); ms-transform: rotate(360deg) scale(1.1); transform: rotate(360deg) scale(1.1);&#125;/* end */ 修改链接文字样式打开themes\next\source\css\_common\components\post\post.styl添加以下代码:12345678910.post-body p a&#123; color: #0593d3; border-bottom: none; &amp;:hover &#123; color: #ff106c; text-decoration: underline; &#125;&#125; themes/next/source/css/_common/components/post/post-title.styl修改为:123456789.posts-expand .post-title-link &#123; display: inline-block; border-bottom: none; line-height: 1.2; vertical-align: top; &amp;::before &#123; ...... 为next主题的主页文章添加阴影效果打开themes/next/source/css/_custom/custom.styl文件添加:1234567.post &#123; margin-top: 60px; margin-bottom: 60px; padding: 25px; -webkit-box-shadow: 0 0 5px rgba(202, 203, 203, .5); -moz-box-shadow: 0 0 5px rgba(202, 203, 204, .5); &#125; 为next主题添加nest背景特效背景的几何线条是采用的nest效果, 一个基于html5 canvas绘制的网页背景效果, 非常赞！来自github的开源项目canvas-nest 特性 不依赖任何框架或者内库, 比如不依赖jQuery, 使用原生的javascript. 非常小, 只有1.66kb, 如果开启gzip, 可以更小. 非常容易实现, 配置简单, 即使你不是web开发者, 也能简单搞定. 使用非常简单 color: 线条颜色, 默认: ‘0,0,0’ ；三个数字分别为(R,G,B), 注意用,分割 opacity: 线条透明度（0~1）, 默认: 0.5 count: 线条的总数量, 默认: 150 zIndex: 背景的z-index属性, css属性用于控制所在层的位置, 默认: -1 eg : 1&lt;script type=&quot;text/javascript&quot; color=&quot;255,132,0&quot; opacity=&apos;0.6&apos; zIndex=&quot;-2&quot; count=&quot;99&quot; src=&quot;//cdn.bootcss.com/canvas-nest.js/1.0.1/canvas-nest.min.js&quot;&gt;&lt;/script&gt; 不足: CPU占用过高 如何添加?修改代码打开next/layout/_layout.swig, 在&lt;/body&gt;之前添加如下代码:12345&#123;% if theme.canvas_nest %&#125;&lt;script type=&quot;text/javascript&quot; src=&quot;//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js&quot;&gt;&lt;/script&gt;&#123;% endif %&#125; 修改主题配置文件打开/next/_config.yml, 添加以下代码:123456# --------------------------------------------------------------# background settings# --------------------------------------------------------------# add canvas-nest effect# see detail from https://github.com/hustcc/canvas-nest.jscanvas_nest: true 至此, 大功告成, 运行hexo clean 和 hexo g hexo s之后就可以看到效果了 添加音乐去往网易云音乐搜索喜欢的音乐, 点击生成外链播放器, 复制代码直接放到博文末尾即可, height设为0可隐藏播放器, 但仍然可以播放音乐, auto设成0可手动播放, 默认是1自动播放, 可把代码放到themes/next/layout/_custom/sidebar.swig文件里, 播放器会显示在站点预览中 添加注脚安装插件:1npm install hexo-reference --save 用法如下:1this is a basic footnote[/^1] ##用的时候把/去掉 在文章末尾添加:1[/^1]: basic footnote content ##用的时候把/去掉 eg:this is a basic footnote[1] 自定义页面执行hexo new page &quot;guestbook&quot;之后, 那怎么在博客中加进去呢？找到\next\_config.yml下的memu, 把guestbook加进去:1234567menu: home: / categories: /categories #about: /about archives: /archives tags: /tags guestbook: /guestbook 图标网站: http://fontawesome.io/icons/ 在/themes/hexo-theme-next/languages/zh-Hans.yml的目录下（这里默认你使用的是简体中文, 若是其他语言更改相应的yml就行）, 在memu下加一句即可:1guestbook: 留言 添加字数统计和阅读时间安装插件1npm install hexo-wordcount --save 通过以上安装后, 你可以在你的模板文件后者.md文件加入以下相关的标签实现本插件的功能字数统计:WordCount阅读时长预计:Min2Read总字数统计: TotalCount 修改post.swig模板找到themes\next\layout\_macro\post.swig并打开插入以下代码:12345678910111213141516171819202122232425262728293031323334&#123;# LeanCould PageView #&#125; &#123;% if theme.leancloud_visitors.enable %&#125; &lt;span id=&quot;&#123;&#123; url_for(post.path) &#125;&#125;&quot; class=&quot;leancloud_visitors&quot; data-flag-title=&quot;&#123;&#123; post.title &#125;&#125;&quot;&gt; &amp;nbsp; | &amp;nbsp; &lt;span class=&quot;post-meta-item-icon&quot;&gt; &lt;i class=&quot;fa fa-eye&quot;&gt;&lt;/i&gt; &lt;/span&gt; &lt;span class=&quot;post-meta-item-text&quot;&gt;&#123;&#123;__(&apos;post.visitors&apos;)&#125;&#125; &lt;/span&gt; &lt;span class=&quot;leancloud-visitors-count&quot;&gt;&lt;/span&gt; &lt;/span&gt; &#123;% endif %&#125; #以下部分为: 字数统计、阅读时长插入代码 &lt;span class=&quot;post-time&quot;&gt; &amp;nbsp; | &amp;nbsp; &lt;span class=&quot;post-meta-item-icon&quot;&gt; &lt;i class=&quot;fa fa-calendar-o&quot;&gt;&lt;/i&gt; &lt;/span&gt; &lt;span class=&quot;post-meta-item-text&quot;&gt;字数统计:&lt;/span&gt; &lt;span class=&quot;post-count&quot;&gt;&#123;&#123; wordcount(post.content) &#125;&#125;(字)&lt;/span&gt; &lt;/span&gt; &lt;span class=&quot;post-time&quot;&gt; &amp;nbsp; | &amp;nbsp; &lt;span class=&quot;post-meta-item-icon&quot;&gt; &lt;i class=&quot;fa fa-calendar-o&quot;&gt;&lt;/i&gt; &lt;/span&gt; &lt;span class=&quot;post-meta-item-text&quot;&gt;阅读时长:&lt;/span&gt; &lt;span class=&quot;post-count&quot;&gt;&#123;&#123; min2read(post.content) &#125;&#125;(分)&lt;/span&gt; &lt;/span&gt;#以上部分为: 字数统计、阅读时长插入代码 修改footer修改之后的样子大概是这样的: 1、找到 \themes\next\layout\partials\下面的footer.swig文件, 打开会发现, 如下图的语句: 第一个框 是下面侧栏的“日期❤ XXX”如果想像我一样加东西, 一定要在双大括号外面写. 如: xxx,当然你要是想改彻底可以变量都删掉, 看个人意愿. 第二个, 是图一当中 “由Hexo驱动” 的Hexo链接, 先给删掉防止跳转, 如果想跳转当然也可以自己写地址, 至于中文一会处理. 注意删除的时候格式不能错, 只把&lt;a&gt;...&lt;/a&gt;标签这部分删除即可, 留着两个单引号’’,否则会出错哦. 第三个框也是最后一个了, 这个就是更改图一后半部分“主题-Next.XX”,这个比较爽直接将..都删掉, 同样中文“主题”一会处理, 删掉之后在上一行 ‘-’后面可以随意加上你想显示的东西, 不要显示敏感信息哟, 请自重. 2、接下来, 处理剩余的中文信息. 找到这个地方\themes\next\languages\ 下面的语言文件zh-Hans.yml（这里以中文为例, 有的习惯用英文的配置文件, 道理一样, 找对应位置即可）打开之后, 如图: 给博客添加吉祥物 详细信息: https://github.com/EYHN/hexo-helper-live2d/blob/master/README.zh-CN.md 效果图: 安装依赖: 12npm install --save hexo-helper-live2dnpm install --save live2d-widget-model-wanko 站点配置添加: 12345678910111213141516171819202122# hexo-helper-live2d配置, 参考https://github.com/EYHN/hexo-helper-live2d/blob/master/README.zh-CN.mdlive2d: enable: true scriptFrom: local pluginRootPath: live2dw/ pluginJsPath: lib/ pluginModelPath: assets/ tagMode: false debug: false model: scale: 1 use: live2d-widget-model-wanko display: superSample: 2 # 超采样等级 width: 100 height: 100 position: left # 位置 mobile: show: false react: opacityDefault: 0.9 # 默认透明度 opacityOnHover: 0.5 # 鼠标移上透明度 侧栏加入已运行的时间themes/next/layout/_custom中添加sidebar.swig文件: themes/next/layout/_custom链接1234567891011121314151617181920212223242526&lt;div id="days"&gt;&lt;/div&gt; &lt;script&gt; function show_date_time()&#123; window.setTimeout("show_date_time()", 1000); BirthDay=new Date("01/10/2017 12:34:56"); today=new Date(); timeold=(today.getTime()-BirthDay.getTime()); sectimeold=timeold/1000 secondsold=Math.floor(sectimeold); msPerDay=24*60*60*1000 e_daysold=timeold/msPerDay daysold=Math.floor(e_daysold); e_hrsold=(e_daysold-daysold)*24; hrsold=setzero(Math.floor(e_hrsold)); e_minsold=(e_hrsold-hrsold)*60; minsold=setzero(Math.floor((e_hrsold-hrsold)*60)); seconds=setzero(Math.floor((e_minsold-minsold)*60)); document.getElementById('days').innerHTML="已运行"+daysold+"天"+hrsold+"小时"+minsold+"分"+seconds+"秒"; &#125;function setzero(i)&#123; if (i&lt;10) &#123;i="0" + i&#125;; return i;&#125;show_date_time();&lt;/script&gt; 在themes/next/layout/_macro/sidebar.swig中的&lt;/section&gt;之前添加 1&#123;% include &apos;../_custom/sidebar.swig&apos; %&#125; 样式: themes/next/source/css/_custom/custom.styl1234567// 自定义的侧栏时间样式#days &#123; display: block; color: #fffa74; font-size: 14px; margin-top: 15px;&#125; 更改标签云（tagcloud）的颜色themes/next/layout/page.swig找到tagcloud并替换: 1&#123;&#123; tagcloud(&#123;min_font: 13, max_font: 31, amount: 1000, color: true, start_color: &apos;#9733EE&apos;, end_color: &apos;#FF512F&apos;&#125;) &#125;&#125; 设置动态titlethemes/next/source/js/src下创建dytitle.js: 12345678910111213141516var OriginTitile = document.title;var titleTime;document.addEventListener(&apos;visibilitychange&apos;, function () &#123; if (document.hidden) &#123; $(&apos;[rel=&quot;shortcut icon&quot;]&apos;).attr(&apos;href&apos;, &quot;/TEP.png&quot;); document.title = &apos;w(ﾟДﾟ)w 出BUG啦！！！！&apos;; clearTimeout(titleTime); &#125; else &#123; $(&apos;[rel=&quot;shortcut icon&quot;]&apos;).attr(&apos;href&apos;, &quot;/favicon.png&quot;); document.title = &apos;♪(^∇^*)又好了. . . &apos; + OriginTitile; titleTime = setTimeout(function () &#123; document.title = OriginTitile; &#125;, 2000); &#125;&#125;); 修改themes/next/layout/layout.swing,在 &lt;/body&gt; 之前添加: : 1&lt;script type=&quot;text/javascript&quot; src=&quot;/js/src/dytitle.js&quot;&gt;&lt;/script&gt; 修改文章底部的那个带#号的标签修改模板/themes/next/layout/_macro/post.swig, 搜索 rel=&quot;tag&quot;&gt;#, 将 # 换成&lt;i class=&quot;fa fa-tag&quot;&gt;&lt;/i&gt; 元素微调自定义篇那么如何把字体、页宽、按钮大小等等一些细节的东西调到自己喜欢的样式呢？那就是通过浏览器元素定位, 调到自己喜欢的样式, 然后加到themes/next/source/css/_custom/custom.styl文件下面. 定位元素用谷歌或者火狐浏览器打开博客页面, 按下F12进入调试先点击定位按钮, 然后选择元素, 然后在定位出来的样式进行修改, 调到自己喜欢的样子, 就像这样↓ 添加到样式文件打开themes/next/source/css/_custom/custom.styl, 把调试好的样式加进去, 保存后Ctrl+F5就能看到效果了, 前提是在本地运行的, 下面列出博主的一些自定义样式:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122// Custom styles.// 页面头部背景.header &#123; background:url(https://cdn.yangbingdong.com/img/header/header_background.jpg);&#125;// 子标题.site-subtitle&#123; font-size: 15px; color: white; &#125;// 标题.site-title &#123; font-size: 40px; font-weight: bold;&#125;// 标题背景.brand&#123; background: transparent;&#125;// 菜单栏.menu &#123; margin-top: 20px; padding-left: 0; text-align: center; background: rgba(240, 240, 240, 0.5); margin-left: auto; margin-right: auto; width: 530px; border-radius: initial;&#125;// 菜单图表链接 以及 超链接样式a &#123; color: rgba(0,0,0,0.8);&#125;a:hover &#123; color: #ff106c; border-bottom-color: #ff106c;&#125;// 菜单字体大小.menu .menu-item a &#123; font-size: 14px;&#125;.menu .menu-item a:hover &#123; border-bottom-color: #ff106c;&#125;// 文章背景框框.post &#123; margin-top: 10px; margin-bottom: 40px; padding: 18px; -webkit-box-shadow: 0 0 5px rgba(202, 203, 203, 0.8); &#125;// 站点描述.site-description &#123; font-size: 16px;&#125;// 头部inner.header-inner &#123; padding: 45px 0 25px; width: 700px;&#125;// 作者名.site-author-name &#123; font-family: &apos;Comic Sans MS&apos;, sans-serif; font-size: 20px;&#125;// 文章之间的分割线.posts-expand .post-eof &#123; margin: 40px auto 40px; background: white;&#125;// 按钮样式.btn &#123; margin-top: 20px;&#125;// ``代码块样式code &#123; color: #E6006B; background: white; border-radius: 3px;&#125;// 文章```代码块顶部样式.highlight figcaption &#123; margin: 0em; padding: 0.5em; background: #eee; border-bottom: 1px solid #e9e9e9;&#125;.highlight figcaption a &#123; color: rgb(80, 115, 184);&#125;// 文章标题动态效果 next/source/css/_common/components/post/post-title.styl中.posts-expand .post-title-link确保`position: relative;`属性存在, 如果需要标题呈现链接效果颜色, 将`color`元素去除即可.posts-expand .post-title-link::before &#123; background-image: linear-gradient(90deg, #a166ab 0%, #ef4e7b 25%, #f37055 50%, #ef4e7b 75%, #a166ab 100%);&#125;// 文章内标题样式（左边的竖线）.post-body h2, h3, h4, h5, h6 &#123; border-left: 4px solid #657b83; padding-left: 10px;&#125;.post-body h1 &#123; border-left: 5px solid #657b83; padding-left: 10px;&#125;body &#123; color: #444; font-size: 16px;&#125; 但并不是所有的样式都能调, 像页宽, 多说评论的样式在custom.styl文件是无效的. 好玩的样式先在themes/next/source/css/_custom/custom.styl中添加以下样式:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221// 下载样式a#download &#123;display: inline-block;padding: 0 10px;color: #000;background: transparent;border: 2px solid #000;border-radius: 2px;transition: all .5s ease;font-weight: bold;&amp;:hover &#123;background: #000;color: #fff;&#125;&#125;/ /颜色块-黄span#inline-yellow &#123;display:inline;padding:.2em .6em .3em;font-size:80%;font-weight:bold;line-height:1;color:#fff;text-align:center;white-space:nowrap;vertical-align:baseline;border-radius:0;background-color: #f0ad4e;&#125;// 颜色块-绿span#inline-green &#123;display:inline;padding:.2em .6em .3em;font-size:80%;font-weight:bold;line-height:1;color:#fff;text-align:center;white-space:nowrap;vertical-align:baseline;border-radius:0;background-color: #5cb85c;&#125;// 颜色块-蓝span#inline-blue &#123;display:inline;padding:.2em .6em .3em;font-size:80%;font-weight:bold;line-height:1;color:#fff;text-align:center;white-space:nowrap;vertical-align:baseline;border-radius:0;background-color: #2780e3;&#125;// 颜色块-紫span#inline-purple &#123;display:inline;padding:.2em .6em .3em;font-size:80%;font-weight:bold;line-height:1;color:#fff;text-align:center;white-space:nowrap;vertical-align:baseline;border-radius:0;background-color: #9954bb;&#125;// 左侧边框红色块级p#div-border-left-red &#123;display: block;padding: 10px;margin: 10px 0;border: 1px solid #ccc;border-left-width: 5px;border-radius: 3px;border-left-color: #df3e3e;&#125;// 左侧边框黄色块级p#div-border-left-yellow &#123;display: block;padding: 10px;margin: 10px 0;border: 1px solid #ccc;border-left-width: 5px;border-radius: 3px;border-left-color: #f0ad4e;&#125;// 左侧边框绿色块级p#div-border-left-green &#123;display: block;padding: 10px;margin: 10px 0;border: 1px solid #ccc;border-left-width: 5px;border-radius: 3px;border-left-color: #5cb85c;&#125;// 左侧边框蓝色块级p#div-border-left-blue &#123;display: block;padding: 10px;margin: 10px 0;border: 1px solid #ccc;border-left-width: 5px;border-radius: 3px;border-left-color: #2780e3;&#125;// 左侧边框紫色块级p#div-border-left-purple &#123;display: block;padding: 10px;margin: 10px 0;border: 1px solid #ccc;border-left-width: 5px;border-radius: 3px;border-left-color: #9954bb;&#125;// 右侧边框红色块级p#div-border-right-red &#123;display: block;padding: 10px;margin: 10px 0;border: 1px solid #ccc;border-right-width: 5px;border-radius: 3px;border-right-color: #df3e3e;&#125;// 右侧边框黄色块级p#div-border-right-yellow &#123;display: block;padding: 10px;margin: 10px 0;border: 1px solid #ccc;border-right-width: 5px;border-radius: 3px;border-right-color: #f0ad4e;&#125;// 右侧边框绿色块级p#div-border-right-green &#123;display: block;padding: 10px;margin: 10px 0;border: 1px solid #ccc;border-right-width: 5px;border-radius: 3px;border-right-color: #5cb85c;&#125;// 右侧边框蓝色块级p#div-border-right-blue &#123;display: block;padding: 10px;margin: 10px 0;border: 1px solid #ccc;border-right-width: 5px;border-radius: 3px;border-right-color: #2780e3;&#125;// 右侧边框紫色块级p#div-border-right-purple &#123;display: block;padding: 10px;margin: 10px 0;border: 1px solid #ccc;border-right-width: 5px;border-radius: 3px;border-right-color: #9954bb;&#125;// 上侧边框红色p#div-border-top-red &#123;display: block;padding: 10px;margin: 10px 0;border: 1px solid #ccc;border-top-width: 5px;border-radius: 3px;border-top-color: #df3e3e;&#125;// 上侧边框黄色p#div-border-top-yellow &#123;display: block;padding: 10px;margin: 10px 0;border: 1px solid #ccc;border-top-width: 5px;border-radius: 3px;border-top-color: #f0ad4e;&#125;// 上侧边框绿色p#div-border-top-green &#123;display: block;padding: 10px;margin: 10px 0;border: 1px solid #ccc;border-top-width: 5px;border-radius: 3px;border-top-color: #5cb85c;&#125;// 上侧边框蓝色p#div-border-top-blue &#123;display: block;padding: 10px;margin: 10px 0;border: 1px solid #ccc;border-top-width: 5px;border-radius: 3px;border-top-color: #2780e3;&#125;// 上侧边框紫色p#div-border-top-purple &#123;display: block;padding: 10px;margin: 10px 0;border: 1px solid #ccc;border-top-width: 5px;border-radius: 3px;border-top-color: #9954bb;&#125; 用法如下: 文字增加背景色块站点配置文件 , 主题配置文件12&lt;span id=&quot;inline-blue&quot;&gt;站点配置文件&lt;/span&gt;, &lt;span id=&quot;inline-purple&quot;&gt;主题配置文件&lt;/span&gt; 引用边框变色如果没有安装成功, 那可能就是墙的原因. 建议下载 Node.js 直接安装. 关于更多基本操作和基础知识, 请查阅 Hexo 与 NexT 官方文档.12&lt;p id=&quot;div-border-left-red&quot;&gt;如果没有安装成功, 那可能就是墙的原因. 建议下载 `Node.js` 直接安装. &lt;/p&gt;&lt;p id=&quot;div-border-top-blue&quot;&gt;关于更多基本操作和基础知识, 请查阅 [Hexo](https://hexo.io/zh-cn/) 与 [NexT](http://theme-next.iissnan.com/) 官方文档.&lt;/p&gt; 在文档中增加图标 支持MarkdownHexo 支持 GitHub Flavored Markdown 的所有功能, 甚至可以整合 Octopress 的大多数插件. 一件部署只需一条指令即可部署到Github Pages, 或其他网站 丰富的插件Hexo 拥有强大的插件系统, 安装插件可以让 Hexo 支持 Jade, CoffeeScript. 123456- &lt;i class=&quot;fa fa-pencil&quot;&gt;&lt;/i&gt;支持Markdown&lt;i&gt;Hexo 支持 GitHub Flavored Markdown 的所有功能, 甚至可以整合 Octopress 的大多数插件. &lt;/i&gt;- &lt;i class=&quot;fa fa-cloud-upload&quot;&gt;&lt;/i&gt;一件部署&lt;i&gt;只需一条指令即可部署到Github Pages, 或其他网站&lt;/i&gt;- &lt;i class=&quot;fa fa-cog&quot;&gt;&lt;/i&gt;丰富的插件&lt;i&gt;Hexo 拥有强大的插件系统, 安装插件可以让 Hexo 支持 Jade, CoffeeScript. &lt;/i&gt; &lt;i class=&quot;fa fa-github&quot;&gt;&lt;/i&gt;&lt;i class=&quot;fa fa-github fa-lg&quot;&gt;&lt;/i&gt;&lt;i class=&quot;fa fa-github fa-2x&quot;&gt;&lt;/i&gt; 采用的是Font Awesome的图标. 图形边框效果 Download Now12&lt;a id=&quot;download&quot; href=&quot;https://git-scm.com/download/win&quot;&gt;&lt;i class=&quot;fa fa-download&quot;&gt;&lt;/i&gt;&lt;span&gt; Download Now&lt;/span&gt;&lt;/a&gt; 这也是调用了Font Awesome的方法. 代码高亮相关先看一则代码 Hello World示例这是链接1234 public static void main(String[] args) &#123;+ System.out.println("Hello World!");- System.out.println("Hello World!"); &#125; 正确姿势, 代码片段开头: 1[language] [title] [url] [link-text] [language] 是代码语言的名称, 用来设置代码块颜色高亮, 非必须； [title] 是顶部左边的说明, 非必须； [url] 是顶部右边的超链接地址, 非必须； [link text] 如它的字面意思, 超链接的名称, 非必须. 这 4 项应该是根据空格来分隔, 而不是[], 故请不要加[]. 除非如果你想写后面两个, 但不想写前面两个, 那么就必须加[]了, 要这样写: [] [] [url] [link text]. 首先关于代码块颜色高亮, 高亮的模式可以在主题配置文件中设置: 123456# Code Highlight theme# Available value:# normal | night | night eighties | night blue | night bright# https://github.com/chriskempson/tomorrow-themehighlight_theme: normal 要颜色正确高亮, 代码语言的名称肯定要写对, 各种支持语言的名称可以查看这篇文章. 也可以在站点配置文件_config.yml中设置自动高亮: blog/_config.yml123456highlight: enable: true line_number: true# 代码自动高亮- auto_detect: false+ auto_detect: true 上边的diff是通过在[language]填写diff, 然后在相应代码前面加上-和+ 顶部的文字样式: 12345678910// 文章```代码块顶部样式.highlight figcaption &#123; margin: 0em; padding: 0.5em; background: #eee; border-bottom: 1px solid #e9e9e9;&#125;.highlight figcaption a &#123; color: rgb(80, 115, 184);&#125; 站点加速篇更改默认Google字体库访问系统总是会耗费一大部分的时间在加载google字体库上, 而且经常加载不成功. 方法一: 用国内的CDN库来替代主题中的google字体库, 到主题配置文件中设置默认字体库:1host: fonts.useso.com 方法二: 关掉字体库的引用, 默认加载本地字体库, 到主题配置文件设置:12font: enable: false 使用云盘存放图片资源由于Github的服务器在海外, 那么如果把图片也放到Github显然是不科学的, 而且Github的存储空间也有局限, 那么在这里博主推荐使用七牛云储存具体怎么做在之前的基础篇已经介绍过了, 详情请看→传送门 压缩代码安装插件:1npm install hexo-all-minifier --save 之后执行hexo g就会自动压缩但这有一个缺点, 就是本地运行也就是执行hexo s之后浏览器打开本地项目会很慢, 原因是每次点击一个链接它就会重新压缩一次, 所以建议本地调试的时候把项目根目录下的package.json中的&quot;hexo-all-minifier&quot;: &quot;0.0.14&quot;先删掉再调试,或者改成注释:123456789&quot;dependencies&quot;: &#123; . . . &quot;hexo-server&quot;: &quot;^0.2.0&quot;, &quot;hexo-wordcount&quot;: &quot;^2.0.1&quot;, &quot;this-is-compress-plugin&quot;: &#123; &quot;hexo-all-minifier&quot;: &quot;0.0.14&quot; &#125; 其实也没必要压缩代码, 牺牲了性能, 每次生成静态文件都太慢了, 得不偿失的感觉 SEO(搜索引擎优化)篇网站验证以下是几个搜索引擎的提交入口: 百度提交入口 Google提交入口 360提交入口 以百度为例, 谷歌的太简单就不说了:打开百度站长验证网站方式一: 文件验证 登录百度站长选择添加网站, 使用方式为文件验证 将下载的文件放到source文件下 由于hexo自动会对html文件进行渲染, 所以在站点配置文件中找到skip_render: 在后面添加文件名字, 如有多个用[a.html,b.html], eg:skip_render:[baidu_verify_tdOGHi8IQG.html, baidu_verify_vcJkI72f1e.html] 重新渲染文件 12hexo cleanhexo d -g 然后可以点击百度站长的验证按钮了 方式二: CNAME验证 去站长添加网站选择CNAME验证 把地址解析到zz.baidu.com 完成验证 就像这样↓ 添加并提交sitemap安装hexo的sitemap网站地图生成插件:12npm install hexo-generator-sitemap --savenpm install hexo-generator-baidu-sitemap --save 在站点配置文件中添加如下代码.123456# hexo sitemapsitemap: path: sitemap.xmlbaidusitemap: path: baidusitemap.xml 配置成功后, 会生成sitemap.xml和baidusitemap.xml, 前者适合提交给谷歌搜素引擎, 后者适合提交百度搜索引擎.百度sitemap提交如下↓ 验证成功之后就可以开始推送了, 这里说一下, Google的收录真的快的不要不要的, 第二天就能搜得到, 百度就不想说了, 不知道要等到猴年马月 主动推送安装主动推送插件:1 npm install hexo-baidu-url-submit --save 在根目录下, 把以下内容配置到站点配置文件中:12345baidu_url_submit: count: 3 ## 比如3, 代表提交最新的三个链接 host: www.henvyluk.com ## 在百度站长平台中注册的域名 token: your_token ## 请注意这是您的秘钥, 请不要发布在公众仓库里! path: baidu_urls.txt ## 文本文档的地址, 新链接会保存在此文本文档里 至于上面提到的your_token可在百度站长如下位置找到↓其次, 记得查看站点配置文件中url的值, 必须包含是百度站长平台注册的域名（一般有www）, 比如:123url: http://www.ookamiantd.toproot: /permalink: :year/:month/:day/:title/ 接下来添加一个新的deploy的类型:12345678# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy:- type: baidu_url_submitter- type: git repo: github: git@github.com:masteranthoneyd/masteranthoneyd.github.io.git,master coding: git@git.coding.net:ookamiantd/ookamiantd.git,master 执行hexo deploy的时候, 新的连接就会被推送了. 这里讲一下原理: 新链接的产生, hexo generate会产生一个文本文件, 里面包含最新的链接 新链接的提交, hexo deploy会从上述文件中读取链接, 提交至百度搜索引擎 自动推送把next主题配置文件中的baidu_push设置为true, 就可以了. 添加蜘蛛协议在/source/目录下新建一个robots.txt文件, 添加下面的一段代码:12345678910111213141516#hexo robots.txtUser-agent: *Allow: /Allow: /archives/Disallow: /vendors/Disallow: /js/Disallow: /css/Disallow: /fonts/Disallow: /vendors/Disallow: /fancybox/Sitemap: http://blog.tangxiaozhu.com/search.xmlSitemap: http://blog.tangxiaozhu.com/sitemap.xmlSitemap: http://blog.tangxiaozhu.com/baidusitemap.xml 然后到百度站长更新一下, 就像这样↓ 修改文章链接hexo默认的文章链接形式为domain/year/month/day/postname, 默认就是一个四级url, 并且可能造成url过长, 对搜索引擎是十分不友好的, 我们可以改成domain/postname的形式. 编辑站点配置文件文件, 修改其中的permalink字段为permalink: :title.html即可. 更改首页标题格式为「关键词-网站名称 - 网站描述」打开\themes\next\layout\index.swig文件, 找到这行代码:1&#123;% block title %&#125; &#123;&#123; config.title &#125;&#125; &#123;% endblock %&#125; 把它改成:123&#123;% block title %&#125; &#123;&#123; theme.keywords &#125;&#125; - &#123;&#123; config.title &#125;&#125; - &#123;&#123; theme.description &#125;&#125;&#123;% endblock %&#125; 自动给所有外部链接添加nofollow安装hexo-autonofollow, 在站点的根目录下执行以下命令:1npm install hexo-autonofollow --save 编辑站点配置文件, 新增以下内容到任意位置:12345nofollow: enable: true exclude: - exclude1.com - exclude2.com 多PC同步源码篇1.准备工作: 公司电脑和家里电脑配置git ssh密钥连接 2.上传blog到git: 此项建议先在blog进度最新的PC上进行, 否则会有版本冲突, 解决也比较麻烦. 在PC上建立git ssh密钥连接和建立新库respo在此略过: 编辑.gitignore文件: .gitignore文件作用是声明不被git记录的文件, blog根目录下的.gitignore是hexo初始化是创建的, 可以直接编辑, 建议.gitignore文件包括以下内容: 1234567.DS_Store Thumbs.db db.json *.log node_modules/ public/ .deploy*/ public内的文件可以根据source文件夹内容自动生成的, 不需要备份. 其他日志、压缩、数据库等文件也都是调试等使用, 也不需要备份. 初始化仓库:12git init git remote add origin &lt;server&gt; server是仓库的在线目录地址, 可以从git上直接复制过来, origin是本地分支, remote add会将本地仓库映射到托管服务器的仓库上. 添加本地文件到仓库并同步到git上:123git add . #添加blog目录下所有文件, 注意有个&apos;.&apos;(.gitignore里面声明的文件不在此内) git commit -m &quot;hexo source first add&quot; #添加更新说明 git push -u origin master #推送更新到git上 至此, git库上备份已完成. 3.将git的内容同步到另一台电脑: 假设之前将公司电脑中的blog源码内容备份到了git上, 现在家里电脑准备同步源码内容. 注意, 在同步前也要事先建好hexo的环境, 不然同步后本地服务器运行时会出现无法运行错误. 在建好的环境的主目录运行以下命令:1234git init #将目录添加到版本控制系统中 git remote add origin &lt;server&gt; #同上 git fetch --all #将git上所有文件拉取到本地 git reset --hard origin/master #强制将本地内容指向刚刚同步git云端内容 reset对所拉取的文件不做任何处理, 此处不用pull是因为本地尚有许多文件, 使用pull会有一些版本冲突, 解决起来也麻烦, 而本地的文件都是初始化生成的文件, 较拉取的库里面的文件而言基本无用, 所以直接丢弃. 4.家里电脑生成完文章并部署到服务器上后, 此时需要将新的blog源码文件更新到git托管库上, 不然公司电脑上无法获取最新的文章. 在本地文件中运行以下命令: 1git add . #将所有更新的本地文件添加到版本控制系统中 此时可以使用git status查看本地文件的状态. 然后对更改添加说明更推送到git托管库上: 12git commit -m &apos;更新信息说明&apos; git push 至此, 家里电脑更新的备份完成. 在公司电脑上使用时, 只需先运行:1git pull 获取的源码即为最新文件 插件总结篇部署插件1npm install hexo-deployer-git --save rss1npm install hexo-generator-feed --save Algolia此处有两个版本 第一（以0.2.0为例）: 在站点找到package.json, 把添加一行&quot;hexo-algolia&quot;: &quot;^0.2.0&quot;, 然后: 1npm install hexo-algolia --save 这个为旧版的algolia, 优点是全文索引, 缺点是字数太多会索引失败 第二: 直接安装 1npm install hexo-algolia --save hexo algolia 此处安装的应该是1.0.0之后的版本了, 优点是没有字数限制了（因为没有了全文索引）, 只会索引文章开头的部分字段. 但是需要在官网注册新key并且设置环境变量, 方法: https://github.com/iissnan/theme-next-docs/issues/162 sitemap12npm install hexo-generator-sitemap --savenpm install hexo-generator-baidu-sitemap --save 百度主动推送1npm install hexo-baidu-url-submit --save 分页插件1234npm install hexo-generator-index --savenpm install hexo-generator-archive --savenpm install hexo-generator-category --savenpm install hexo-generator-tag --save 站点配置文件:12345678910index_generator: per_page: 6archive_generator: per_page: 10 ##归档页面默认20篇文章标题 yearly: true ##生成年视图 monthly: true ##生成月视图tag_generator: per_page: 10 压缩插件1npm install hexo-all-minifier --save 七牛admin插件123npm install --save hexo-admin-qiniuhexo server -dopen http://localhost:4000/admin/ 站点配置文件:1234567admin: qiniuCfg: imageslim: true # 启动图片瘦身, 仅华东区bucket可以使用 AccessKey: &apos;your qiniu AK&apos; SecretKey: &apos;your qiniu SK&apos; BucketName: &apos;your BK Name&apos; bucketHost: &apos;you BK Host&apos; 注脚插件1npm install hexo-reference --save 字数与阅读时间插件1npm install hexo-wordcount --save 主题升级备份对于升级主题, 我们需要重新配置主题配置文件, 那么每次升级都要这么干吗？超麻烦！ NexT作者给我们的建议就是使用Data Files, 具体详情请戳进 Theme configurations using Hexo data files #328 图片链接全局替换由于七牛的测试域名已回收, 无奈只能备案换成自己的域名. 本案后在七牛添加CDN, 确认可以访问后, 利用sed进行全局替换: 1sed -i &quot;s/http:\/\/img.yangbingdong.com/https:\/\/cdn.yangbingdong.com/g&quot; ./* 最后一路摸爬滚打下来也挺折腾的, 不过确实满满的成就感, 学到了很多同时还要感谢很多很多的大神们的文章, 有一些都忘了收藏记录下来, 由衷地感谢 参考http://codepub.cn/2015/04/06/Github-Pages-personal-blog-from-Octopress-to-Hexo/http://codepub.cn/2016/03/20/Hexo-blog-theme-switching-from-Jacman-to-NexT-Mist/http://www.shellsec.com/news/34054.htmlhttps://www.0101tx.com/pages/hexonextsanf.htmlhttps://reuixiy.github.io/technology/computer/computer-aided-art/2017/06/09/hexo-next-optimization.html 1.basic footnote content ↩]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Git</tag>
        <tag>Github</tag>
        <tag>Node.js</tag>
        <tag>Coding</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu的Java开发环境基本搭建]]></title>
    <url>%2F2017%2Fubuntu-dev-environment-to-build%2F</url>
    <content type="text"><![CDATA[前言最近公司的电脑由于不明原因老是奔溃, 重装过两次, 在家里也比较喜欢折腾系统, 为了不用每次都度娘谷歌, 记录下来, 一条龙走过. 博主是搞爪哇开发的, 那么以下搭建针对的是爪哇环境开发 JDK以及配置环境变量通过Apt安装 https://linuxconfig.org/how-to-install-java-on-ubuntu-18-04-bionic-beaver-linux OpenJDKJDK8: 1sudo apt install openjdk-8-jdk JDK9: 1sudo apt install openjdk-9-jdk JDK11: 1sudo apt install openjdk-11-jdk OracleJDK注意: 这个安装可能有点慢, 建议使用代理. 1sudo add-apt-repository ppa:webupd8team/java &amp;&amp; sudo apt update JDK8: 1sudo apt install oracle-java8-set-default JDK9: 1sudo apt install oracle-java9-set-default 手动安装安装JDK安装之前当然是老规矩地下载jdk: Oracle JDK官方下载 1234567# 把jdk的文件移动到 /usr/local/ 目录下sudo mv ~/jdk*.tar.gz /usr/local/# 解压文件cd /usr/local/# sudo tar -zxvf jdk-8u101-linux-x64.tar.gz# 创建软链接sudo ln -s jdk1.8.0_101 jdk 如需更换jdk, 删除旧版本的软链接, 重新创建软链接指向新版即可 12sudo rm -rf jdksudo ln -s jdk* jdk 配置环境变量 放到 /usr/local 里面的程序, 建议使用系统变量. 用户变量 ~/.profile 文件是用户的私有配置文件 ~/.bashrc 是在bash里面使用的私有配置文件, 优先级在 .profile 文件之后 系统变量 /etc/profile 文件是系统的公用配置文件 /etc/bash.bashrc 是bash专用的配置文件, 优先级在 profile 文件之后 系统变量的配置, 不建议修改前面说到的两个文件, 而是建议在 /etc/profile.d/ 目录下, 创建一个 .sh 结尾 的文件. 1sudo vi /etc/profile.d/jdk.sh 环境变量的配置内容如下: 设置一个名为JAVA_HOME的变量, 并且使用export命令导出为环境变量, 如果不使用 export , 仅在当前shell里面有效 1export JAVA_HOME=/usr/local/jdk PATH不需要export, 因为早在其他的地方, 已经export过了！, \$JAVA_HOME 表示引用前面配置的 JAVA_HOME 变量, 分隔符一定是冒号, Windows是分号,最后再引用原来的PATH的值 1PATH=$JAVA_HOME/bin:$PATH 配置以后, 可以重新登录让配置生效, 也可以使用source临时加载配置文件. 使用source命令加载的配置, 仅在当前shell有效, 关闭以后失效. 1source /etc/profile.d/jdk.sh 查看jdk是否安装成功, 一下两条命令成功则安装成功 12java -versionjavac -version Scala环境更上面安装JDK类似 1、去 官网 下载最新地SDK 2、解压到 /usr/local 目录, 并创建软链接为 scala 3、在 /etc/profile.d 目录下创建 scala.sh , 输入以下信息: 12export SCALA_HOME=/usr/local/scalaPATH=$PATH:$SCALA_HOME/bin 4、查看是否安装成功12source /etc/profile.d/scala.shscala -version IDEEclipse直接在 Eclipse官方网站 下载相关版本Eclipse解压1sudo tar zxvf eclipse-jee-mars-2-linux-gtk-x86_64.tar.gz -C ~/IDE 创建快捷方式1. 在终端中执行如下命令1sudo gedit /usr/share/applications/eclipse.desktop 2. 粘贴并保存如下内容(注意更改相应的名字和目录)12345678910[Desktop Entry] Name=Eclipse Mars.2 Type=Application Exec=/home/ybd/IDE/eclipse Terminal=false Icon=/home/ybd/IDE/icon.xpm Comment=Integrated Development Environment NoDisplay=false Categories=Development;IDE; Name[en]=Eclipse Mars.2 通用设置window → preferences → 设置字体: general → appearance → color and font → basic → text font 编辑器背景颜色: general → editors → text editors → background color → RGB:85,123,208,#C7EDCC 工作空间字符编码: general → workspace 作者签名: java → code style → code templates → types 签名快捷键: alt + shift + j MyEclipseMyEclipse安装请看: Ubuntu16.04下MyEclipse安装与破解 IntelliJ IDEA之前听说过IDE[1], 都是大公司用的, 并没有用过日后再研究补上官网: http://www.jetbrains.com/idea/ 新公司好多大牛, 用的都是IDEA, 于是乎“近墨者黑”, 那么既然有机会跟大牛接触, 我也开始真正意义上的学习IDEA了 安装进过查阅, 我选择官方的盒子下载: http://www.jetbrains.com/toolbox/app/?fromMenu优点是可以自动更新 激活博主使用授权服务器, 可以自己搭建, 详情请看 这里 部署Tomcat若是服务器版切换root用户解压到 /opt/ 或者 /usr/local/ 下直接运行tomcat目录下bin/start.sh即可开启, 前提是配置好JDK 桌面版个人使用就解压到/home/{user}目录下就可以了 MySQL以及GUI工具基于Docker安装拉取镜像1docker pull mysql:5.7 运行实例12345678MYSQL=/home/ybd/data/docker/mysql &amp;&amp; \docker run --name=mysql -p 3306:3306 \-v $MYSQL/data:/var/lib/mysql \-e MYSQL_ROOT_PASSWORD=root -d mysql \--character-set-server=utf8mb4 \--collation-server=utf8mb4_unicode_ci \--sql-mode=STRICT_TRANS_TABLES,NO_ENGINE_SUBSTITUTION \--lower-case-table-names=1 终端链接1234sudo apt-get install mysql-client// 链接mysql -h 127.0.0.1 -P 3306 -u root -p 手动折腾安装以mysql5.7以上版本为例 –&gt; mysql-5.7.10-linux-glibc2.5-x86_64.tar.gz 必须要先安装依赖的libaio才能正常按照mysql12sudo apt-get updatesudo apt-get install libaio-dev 创建用户组以及用户12sudo groupadd mysqlsudo useradd -r -g mysql -s /bin/false mysql 尽量把mysql安装到/usr/local目录下面123456cd /usr/localsudo cp /home/data/software/DataBase/mysql/mysql-5.7.10-linux-glibc2.5-x86_64.tar.gz ./&lt;-- 解压缩安装包 --&gt;sudo tar zxvf mysql-5.7.10-linux-glibc2.5-x86_64.tar.gz&lt;-- 创建软连接 --&gt;sudo ln -s mysql-5.7.10-linux-glibc2.5-x86_64 mysql 创建必须的目录和进行授权12345cd mysqlsudo mkdir mysql-filessudo chmod 770 mysql-filessudo chown -R mysql .sudo chgrp -R mysql . 执行安装脚本12sudo bin/mysqld --initialize --user=mysql sudo bin/mysql_ssl_rsa_setup 在初始化的时候, 一定要仔细看屏幕, 最后大概有一行:[Note] A temporary password is generated for root@localhost: kklNBwkei1.t注意这是root的临时密码,记录下来以便后面修改密码！ 重新对一些主要的目录进行授权, 确保安全性12sudo chown -R root .sudo chown -R mysql data mysql-files 从默认的模板创建配置文件, 需要在文件中增加 skip-grant-tables , 以便启动mysql以后修改root用户的密码1sudo cp support-files/my-default.cnf ./my.cnf 测试启动, 修改密码1234# 后台启动mysqlsudo bin/mysqld_safe --user=mysql &amp; # 启动./bin/mysql -u root -p 方式一因为前面修改了my.cnf文件, 增加了 skip-grant-tables 参数, 所以不需要用户名即可登陆进去后立即修改root用户的密码, 密码的字段是 authentication_string1update mysql.user set authentication_string=password(&apos;root&apos;) where user=&apos;root&apos;; 修改密码后, 再把my.cnf里面的 skip-grant-tables 去掉 方式二修改密码也可以使用安装到时候提示到随机密码进行登录, 然后使用下面到命令修改密码.建议用下面的方式设置数据库的密码1alter user user() identified by &apos;root&apos;; 复制启动脚本到合适的位置1sudo cp support-files/mysql.server /etc/init.d/mysql (Optional)增加自动启动1sudo update-rc.d -f mysql defaults 增加mysql命令的路径到PATH环境变量1234sudo touch /etc/profile.d/mysql.shsudo chmod 777 /etc/profile.d/mysql.shsudo echo &quot;PATH=/usr/local/mysql/bin:\$PATH&quot; &gt; /etc/profile.d/mysql.shsudo chmod 644 /etc/profile.d/mysql.sh 到此, mysql的安装基本完成 修复乱码以及忽略大小写, 找到MySQL文件里的my.cnf在末尾添加12lower_case_table_names=1character_set_server=utf8 查看以及修改MySQL字符编码查看123mysql&gt; show variables like &apos;collation_%&apos;;mysql&gt; show variables like &apos;character_set_%&apos;; 修改1234567891011121314151617181920212223242526mysql&gt; set character_set_client=utf8;Query OK, 0 rows affected (0.00 sec)mysql&gt; set character_set_connection=utf8;Query OK, 0 rows affected (0.00 sec)mysql&gt; set character_set_database=utf8;Query OK, 0 rows affected (0.00 sec)mysql&gt; set character_set_results=utf8;Query OK, 0 rows affected (0.00 sec)mysql&gt; set character_set_server=utf8;Query OK, 0 rows affected (0.00 sec)mysql&gt; set character_set_system=utf8;Query OK, 0 rows affected (0.01 sec)mysql&gt; set collation_connection=utf8_general_ci;Query OK, 0 rows affected (0.01 sec)mysql&gt; set collation_database=utf8mb4_general_ci;Query OK, 0 rows affected (0.01 sec)mysql&gt; set collation_server=utf8mb4_general_ci;Query OK, 0 rows affected (0.01 sec) 如果登录mysql出现以下错误则可能配置未加载或服务未启动, 请重启系统, 然后启动mysql服务1sudo service mysql start 结束mysql服务1sudo service mysql stop 开启远程链接链接mysql后:12345678use mysql// 下面两个root分别是帐号密码GRANT ALL PRIVILEGES ON *.* TO &apos;root&apos;@&apos;%&apos; IDENTIFIED BY &apos;root&apos; WITH GRANT OPTION;// 刷新特权flush privileges;// 查看修改是否成功select host,user from user; Mysql GUI传统终端客户端1234sudo apt-get install mysql-client// 链接mysql -h 127.0.0.1 -P 3306 -u root -p 智能补全命令客户端这个一个智能补全并且高亮语法的终端客户端 mycli 安装: 1sudo apt install mycli 使用: 1234567891011121314151617181920212223242526272829303132333435363738394041424344$ mycli --helpUsage: mycli [OPTIONS] [DATABASE] A MySQL terminal client with auto-completion and syntax highlighting. Examples: - mycli my_database - mycli -u my_user -h my_host.com my_database - mycli mysql://my_user@my_host.com:3306/my_databaseOptions: -h, --host TEXT Host address of the database. -P, --port INTEGER Port number to use for connection. Honors $MYSQL_TCP_PORT. -u, --user TEXT User name to connect to the database. -S, --socket TEXT The socket file to use for connection. -p, --password TEXT Password to connect to the database. --pass TEXT Password to connect to the database. --ssl-ca PATH CA file in PEM format. --ssl-capath TEXT CA directory. --ssl-cert PATH X509 cert in PEM format. --ssl-key PATH X509 key in PEM format. --ssl-cipher TEXT SSL cipher to use. --ssl-verify-server-cert Verify server&apos;s &quot;Common Name&quot; in its cert against hostname used when connecting. This option is disabled by default. -v, --version Output mycli&apos;s version. -D, --database TEXT Database to use. -R, --prompt TEXT Prompt format (Default: &quot;\t \u@\h:\d&gt; &quot;). -l, --logfile FILENAME Log every query and its results to a file. --defaults-group-suffix TEXT Read MySQL config groups with the specified suffix. --defaults-file PATH Only read MySQL options from the given file. --myclirc PATH Location of myclirc file. --auto-vertical-output Automatically switch to vertical output mode if the result is wider than the terminal width. -t, --table Display batch output in table format. --csv Display batch output in CSV format. --warn / --no-warn Warn before running a destructive query. --local-infile BOOLEAN Enable/disable LOAD DATA LOCAL INFILE. --login-path TEXT Read this path from the login file. -e, --execute TEXT Execute command and quit. --help Show this message and exit. Navicat Premium破解 到官网下载对应系统版本, 这里选择linux版本, 并解压 到Github下载注册机, 并解压 安装wine 123sudo add-apt-repository ppa:ubuntu-wine/ppasudo apt-get updatesudo apt-get install wine1.8 进入注册机解压目录, 在此目录下打开命令窗口输入 1wine navicat-patcher.exe &lt;Navicat installation path&gt; ./RegPrivateKey.pem &lt;Navicat installation path&gt;就是Navicat中存放navicat.exe的根目录. 接着再用navicat-keygen.exe生成注册码, 使用命令 1wine navicat-keygen.exe -text ./RegPrivateKey.pem 你会被要求选择Navicat产品类别、语言以及输入主版本号. 之后会随机生成一个序列号. 产品选择Premium, 语言选择Simplified Chinese, 版本输入12（当然, 因为下载的是Navicat Premium12 简体中文版） 然后会出现一个序列号: 12Serial number:NAVA-DHCN-P2OI-DV46 接下来填写用户名和组织名, 随便写. 然后打开navicat, 然后断网 在注册界面填入序列号, 然后激活. 这时会提示要手动激活, ok就选这个. 一般来说在线激活肯定会失败, 这时候Navicat会询问你是否手动激活, 直接选吧. 在手动激活窗口你会得到一个请求码, 复制它并把它粘贴到keygen里. 最后别忘了连按至少两下回车结束输入. 1234567891011121314151617181920212223Your name: DoubleLabyrinthYour organization: DoubleLabyrinthInput request code (in Base64), input empty line to end:q/cv0bkTrG1YDkS+fajFdi85bwNVBD/lc5jBYJPOSS5bfl4DdtnfXo+RRxdMjJtEcYQnvLPi2LF0OB464brX9dqU29/O+A3qstSyhBq5//iezxfu2Maqca4y0rVtZgQSpEnZ0lBNlqKXv7CuTUYCS1pmtEPgwJysQTMUZf7tu5MR0cQ+hY/AlyQ9iKrQAMhHklqZslaisi8VsnoIqH56vfTyyUwUQXrFNc41qG5zZNsXu/NI79JOo7qTvcFHQT/k5cTadbKTxY+9c5eh+nF3JR7zEa2BDDfdQRLNvy4DTSyxdYXdsAk/YPU+JdWI+8ELaa0SuAuNzr5fEkD6NDSG2A==Request Info:&#123;&quot;K&quot;:&quot;NAVADHCNP2OIDV46&quot;, &quot;DI&quot;:&quot;Y2eJk9vrvfGudPG7Mbdn&quot;, &quot;P&quot;:&quot;WIN 8&quot;&#125;Response Info:&#123;&quot;K&quot;:&quot;NAVADHCNP2OIDV46&quot;,&quot;DI&quot;:&quot;Y2eJk9vrvfGudPG7Mbdn&quot;,&quot;N&quot;:&quot;DoubleLabyrinth&quot;,&quot;O&quot;:&quot;DoubleLabyrinth&quot;,&quot;T&quot;:1537630251&#125;License:oyoMYr9cfVGXeT7F1dqBwHsB/vvWj6SUL6aR+Kzb0lm5IyEj1CgovuSq+qMzFfx+oHMFaGKFg6viOY2hfJcrO2Vdq0hXZS/B/Ie3jBS2Ov37v8e3ufVajaH+wLkmEpLdxppCVLkDQjIHYR2IPz5s/L/RuWqDpEY4TPmGFF6q+xQMnqQA3vXPyG+JYMARXLruY1gCDLN30v3DpyOeqKmFjUqiHK5h8s0NYiH2OpMyaCpi12JsF23miP89ldQp3+SJ8moo0cNGy7sFp2gX9ol2zVoo7qxfYlLl03f7CALJ6im0sx4yBsmlzFDdvpQUbXk8YZ5rT4LML2Fx6Wgnnklb5g== 如果不出意外, 你会得到一个看似用Base64编码的激活码. 直接复制它, 并把它粘贴到Navicat的手动激活窗口, 最后点激活按钮. 如果没什么意外的话应该能成功激活. 创建快捷方式123cd /usr/share/applications/sudo touch navicat.desktopsudo vi navicat.desktop 加入以下内容12345678910[Desktop Entry]Encoding=UTF-8Name=NavicatComment=The Smarter Way to manage dadabaseExec=/bin/sh &quot;/home/ybd/Data/soft/application/navicat112_mysql_en_x64/start_navicat&quot;Icon=/home/ybd/Data/soft/application/navicat112_mysql_en_x64/Navicat/navicat.pngCategories=Application;Database;MySQL;navicatVersion=1.0Type=ApplicationTerminal=0 参考: https://www.52pojie.cn/thread-705020-1-1.html 后台运行1nohup /home/ybd/data/application/navicat/navicat120_premium_en_x64/start_navicat &gt; /dev/null 2&gt;&amp;1 &amp; Redis请看这里 Maven下载官网下载或者点击镜像获取 配置1、下载解压到自己的指定的目录后, 将命令放到/bin下:1sudo ln -s /自定义目录/apache-maven-3.3.9/bin/mvn /bin/mvn 2、添加环境变量老规矩, 在/etc/profile.d下创建一个maven.sh的文件:12sudo touch /etc/profile.d/maven.shsudo vi /etc/profile.d/maven.sh 输入以下内容:12export M2_HOME=/自定义目录/apache-maven-3.3.9export PATH=$&#123;M2_HOME&#125;/bin:$PATH 然后source一下:1source /etc/profile.d/maven.sh 查看是否配置成功:1mvn -v 输入内容如下:123456Apache Maven 3.3.9 (bb52d8502b132ec0a5a3f4c09453c07478323dc5; 2015-11-11T00:41:47+08:00)Maven home: /home/ybd/Data/application/maven/apache-maven-3.3.9Java version: 1.8.0_65, vendor: Oracle CorporationJava home: /usr/local/jdk1.8.0_65/jreDefault locale: zh_CN, platform encoding: UTF-8OS name: &quot;linux&quot;, version: &quot;4.4.0-67-generic&quot;, arch: &quot;amd64&quot;, family: &quot;unix&quot; 淘宝镜像12345678&lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;alimaven&lt;/id&gt; &lt;name&gt;aliyun maven&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;/mirror&gt;&lt;/mirrors&gt; MongoDB安装12345678sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv 0C49F3730359A14518585931BC711F9BA15703C6#下面命令针对ubuntu16.04版本, 在其他ubuntu版本系统请查看MongoDB官网echo &quot;deb [ arch=amd64,arm64 ] http://repo.mongodb.org/apt/ubuntu xenial/mongodb-org/3.4 multiverse&quot; | sudo tee /etc/apt/sources.list.d/mongodb-org-3.4.listsudo apt-get updatesudo apt-get install -y mongodb-org 安装完成后查看版本:1mongo -version 启动、重新启动和关闭mongodb命令:123sudo service mongod startsudo service mongod stopsudo service mongod restart 查看是否启动成功:1sudo cat /var/log/mongodb/mongod.log 在 mongod.log 日志中若出现如下信息, 说明启动成功:1[initandlisten] waiting for connections on port 27017 MongoDB 卸载删除 mongodb 包1sudo apt-get purge mongodb-org* 删除 MongoDB 数据库和日志文件12sudo rm -r /var/log/mongodbsudo rm -r /var/lib/mongodb MongoDB 使用shell命令模式输入mongo进入shell命令模式, 默认连接的数据库是test数据库, 命令如下:1➜ ~ mongo 常用操作命令: show dbs: 显示数据库列表show collections: 显示当前数据库中的集合（类似关系数据库中的表table）show users: 显示所有用户use yourDB: 切换当前数据库至yourDBdb.help() : 显示数据库操作命令db.yourCollection.help() : 显示集合操作命令, yourCollection是集合名 官方文档: https://docs.mongodb.com/master/tutorial/install-mongodb-on-ubuntu/ GUI客户端Robomongo RabbitMQ选择Docker安装. . . 不折腾了. . 12docker pull rabbitmq:3-managementdocker run -d --name rabbitmq -p 5673:5672 -p 15673:15672 --restart=always rabbitmq:3-management (注意版本, 是management) 浏览器打开localhost:15673, 默认帐号密码都是guest 集群: https://www.jianshu.com/p/624871c646b9 Pip1234sudo apt install python3-pip// for Python 2sudo apt install python-pip Kafka&amp;Zookeeper集群docker-compose.yml: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677version: &apos;3&apos;services: kafka1: image: wurstmeister/kafka:1.0.0 depends_on: - zoo1 - zoo2 - zoo3 ports: - &quot;9092:9092&quot; environment: KAFKA_LOG_DIRS: /kafka KAFKA_BROKER_ID: 1 KAFKA_CREATE_TOPICS: test:6:1 KAFKA_ADVERTISED_HOST_NAME: 192.168.6.113 KAFKA_ADVERTISED_PORT: 9092 KAFKA_ZOOKEEPER_CONNECT: zoo1:2181,zoo2:2181,zoo3:2181 kafka2: image: wurstmeister/kafka:1.0.0 depends_on: - zoo1 - zoo2 - zoo3 ports: - &quot;9093:9092&quot; environment: KAFKA_LOG_DIRS: /kafka KAFKA_BROKER_ID: 2 KAFKA_ADVERTISED_HOST_NAME: 192.168.6.113 KAFKA_ADVERTISED_PORT: 9093 KAFKA_ZOOKEEPER_CONNECT: zoo1:2181,zoo2:2181,zoo3:2181 kafka3: image: wurstmeister/kafka:1.0.0 depends_on: - zoo1 - zoo2 - zoo3 ports: - &quot;9094:9092&quot; environment: KAFKA_LOG_DIRS: /kafka KAFKA_BROKER_ID: 3 KAFKA_ADVERTISED_HOST_NAME: 192.168.6.113 KAFKA_ADVERTISED_PORT: 9094 KAFKA_ZOOKEEPER_CONNECT: zoo1:2181,zoo2:2181,zoo3:2181 zoo1: image: zookeeper:latest environment: ZOO_MY_ID: 1 SERVERS: zoo1,zoo2,zoo3 ports: - &quot;2181:2181&quot; - &quot;2888&quot; - &quot;3888&quot; zoo2: image: zookeeper:latest environment: ZOO_MY_ID: 2 SERVERS: zoo1,zoo2,zoo3 ports: - &quot;2182:2181&quot; - &quot;2888&quot; - &quot;3888&quot; zoo3: image: zookeeper:latest environment: ZOO_MY_ID: 3 SERVERS: zoo1,zoo2,zoo3 ports: - &quot;2183:2181&quot; - &quot;2888&quot; - &quot;3888&quot; 启动:1docker-compose up -d 测试: 1234567891011#创建主题docker exec -it $&#123;CONTAINER_ID&#125; /opt/kafka/bin/kafka-topics.sh --create --zookeeper zoo1:2181 --replication-factor 1 --partitions 1 --topic test#查看topic列表docker exec -it $&#123;CONTAINER_ID&#125; /opt/kafka/bin/kafka-topics.sh --list --zookeeper zoo1:2181#生产者docker exec -it $&#123;CONTAINER_ID&#125; /opt/kafka/bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test#消费者docker exec -it $&#123;CONTAINER_ID&#125; /opt/kafka/bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning Zookeeper UIhttps://github.com/DeemOpen/zkui 搭建ngrok配置 ngrok 是一个反向代理, 通过在公共的端点和本地运行的 Web 服务器之间建立一个安全的通道. ngrok 可捕获和分析所有通道上的流量, 便于后期分析和重放. 可以被使用来进行微信借口的本地调试. 在ngrok被墙之后, 我们需要通过ngrok开源的源码自行搭建ngrok服务. 参考地址: Ubuntu下配置安装ngrok搞了一上午, 服务运行起来了, 客户端也运行起来了, 浏览器就是访问不到！！不知道是不是因为个人电脑没有域名所以才访问不到, 日后再深究.无奈, 还好互联网开源精神无处不在, 某大神搭建的ngrok:http://www.qydev.com/客户端和教程都在里面哦. Update:Ngrok已搭建成功～ , 记录于self-hosted-build-ngrok-server 其他tunnel的代理服务器:natapp.cnwww.ngrok.cc 1.IDEA 全称IntelliJ IDEA, 是java语言开发的集成环境, IntelliJ在业界被公认为最好的java开发工具之一, 尤其在智能代码助手、代码自动提示、重构、J2EE支持、Ant、JUnit、CVS整合、代码审查、 创新的GUI设计等方面的功能可以说是超常的. IDEA是JetBrains公司的产品, 这家公司总部位于捷克共和国的首都布拉格, 开发人员以严谨著称的东欧程序员为主 ↩]]></content>
      <categories>
        <category>OperatingSystem</category>
        <category>Ubuntu</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>IDE</tag>
        <tag>JDK</tag>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git学习笔记]]></title>
    <url>%2F2017%2Fnote-of-learning-git%2F</url>
    <content type="text"><![CDATA[前言What is Git?Git是目前世界上最先进的分布式版本控制系统（没有之一）, 而且是一款免费、开源的分布式版本控制系统, 用于敏捷高效地处理任何或小或大的项目一直以来, 博主开发项目用的版本管理系用都是SVN[1], 其实早就听闻过Git, 一直没用过, 后来接触Github和Hexo博客框架, 才真正意义上开始接触Git, 感受就是高端大气上档次！ 简介Git是Linux系统的开发者Linus在2005年的时候, BitKeeper[2]的东家BitMover公司回收了Linux社区的免费使用权的情况下, 在仅仅的两周内Linus用C写出了一个分布式版本控制系统, 这就是Git（超级牛X）！从此, Linux系统的源码已经由Git管理了. 逐渐地, Git迅速成为最流行的分布式版本控制系统, 尤其是在Github上线之后, 无数开源项目开始迁移至GitHub, 包括jQuery, PHP, Ruby等等 Git安装在Debian或者Ubuntu Linux下的Git安装非常简单, 直接一条命令搞定1sudo apt-get install git Windows下的模拟环境安装起来比较复杂, 那么可以用牛人封装好的模拟环境加Git, 叫msysgit, 只需要下载一个exe然后双击安装可从https://git-for-windows.github.io/ 下载, 或者从廖雪峰老师的镜像 下载, 然后按默认选项安装安装完成后, 在开始菜单里找到“Git”-&gt;“Git Bash”, 蹦出一个类似命令行窗口的东西, 就说明Git安装成功 成功安装之后, 还需要配置一下全局个人信息:12git config --global user.name &quot;Your Name&quot;git config --global user.email &quot;email@example.com&quot; 每次提交, 都会记录这两个值, --global 参数, 表示你这台机器上所有的Git仓库都会使用这个配置可使用 git config -l 查看全局配置信息 运行前配置一般在新的系统上, 我们都需要先配置下自己的 Git 工作环境. 配置工作只需一次, 以后升级时还会沿用现在的配置. 配置文件如何生效对于 Git 来说, 配置文件的权重是仓库&gt;全局&gt;系统. Git 会使用这一系列的配置文件来存储你定义的偏好, 它首先会查找 /etc/gitconfig 文件（系统级）, 该文件含有对系统上所有用户及他们所拥有的仓库都生效的配置值. 接下来 Git 会查找每个用户的 ~/.gitconfig 文件（全局级）. 最后 Git 会查找由用户定义的各个库中Git目录下的配置文件 .git/config（仓库级）, 该文件中的值只对当前所属仓库有效. 以上阐述的三 层配置从一般到特殊层层推进, 如果定义的值有冲突, 以后面层中定义的为准, 例如: .git/config 和 /etc/gitconfig 的较量中, .git/config 取得了胜利. 查看配置格式: git config [--local|--global|--system] -l example: 1234567891011# 查看当前生效的配置git config -l# 查看仓库级的配置git config --local -l# 查看全局级的配置git config --global -l# 查看系统级的配置git config --system -l 修改配置格式: git config [--local|--global|--system] key value example: 12git config --global user.name ybdgit config --global user.email yangbingdong1994@gmail.com 创建仓库（Repository）创建一个目录并进入, 进行初始化仓库123mkdir repocd repogit init 目录下会多一个 .git 的隐藏文件, 现在要创建一个文件并提交到仓库1234567touch readvi read # 按a进入编辑 # 输入Git is a distributed version control system # 按下Esc, 并输入 &quot;:wq&quot; 保存退出git add README.md #添加文件到缓存区git commit -m &quot;first commit&quot; #将缓存区的文件提交到本地仓库 多个文件提交可用 git add -A 然后再 commit1234➜ repo git:(master) ✗ git commit -m &quot;first commit&quot;[master （根提交） 20717f5] first commit 1 file changed, 2 insertions(+) create mode 100644 read 操作的自由穿越要随时掌握工作区的状态: git status查看修改内容: git diff read查看版本历史信息 got log 或 git log --pretty=oneline 版本穿越退到上一个版本:1git reset --hard HEAD^ 上上一个版本就是 HEAD^^, 当然往上100个版本写100个^比较容易数不过来, 所以写成 HEAD~100要重返未来, 查看命令历史: git reflog 修改管理添加文件到缓存区: git add read 或 git add -A然后提交: git commit -m &quot;msg&quot;查看状态: git status每次修改, 如果不add到暂存区, 那就不会加入到commit中 撤销修改当你发现工作区的修改有错误的时候, 可丢弃工作区的修改:1git checkout -- read 命令 git checkout -- read 意思就是, 把 read 文件在工作区的修改全部撤销, 这里有两种情况: 一种是 read 自修改后还没有被放到暂存区, 现在, 撤销修改就回到和版本库一模一样的状态 一种是 read 已经添加到暂存区后, 又作了修改, 现在, 撤销修改就回到添加到暂存区后的状态 总之, 就是让这个文件回到最近一次 git commit 或 git add 时的状态注意！ git checkout -- file 命令中的 -- 很重要, 没有 -- 就变成了切换分支了 当你发现该文件修改错误并且已经提交到了缓存区, 这个时候可以把暂存区的修改撤销掉（unstage）, 重新放回工作区:1git reset HEAD read 然后再丢弃工作区中的修改:1git checkout -- read git reset命令既可以回退版本, 也可以把暂存区的修改回退到工作区. 当我们用HEAD时, 表示最新的版本 删除文件如果把工作区中的文件删除了, 那么工作区和版本库就不一致, git status 命令会立刻告诉你哪些文件被删除了现在有两个选择 一是确实要从版本库中删除该文件, 那就用命令删掉, 并且提交: 12git rm readgit commit -m &quot;delete&quot; 另一种情况是删错了, 因为版本库里还有呢, 所以可以很轻松地把误删的文件恢复到最新版本: 1git checkout -- read git checkout 其实是用版本库里的版本替换工作区的版本, 无论工作区是修改还是删除, 都可以“一键还原” 远程仓库那么学会了Git的基本操作之后, 对于分布式管理我们还需要有一个远程仓库供大家一起共同开发, 好在有一个全世界最大最神奇的同性交友网—— Github那么在使用Github之前呢, 我们需要设置一下与Github的SSH通讯:1. 创建SSH Key（已有.ssh目录的可以略过）1ssh-keygen -t rsa -C &quot;youremail@example.com&quot; 你需要把邮件地址换成你自己的邮件地址, 然后一路回车, 使用默认值即可, 由于这个Key也不是用于军事目的, 所以也无需设置密码如果一切顺利的话, 可以在用户主目录里找到 .ssh 目录, 里面有 id_rsa 和 id_rsa.pub 两个文件, 这两个就是SSH Key的秘钥对, id_rsa 是私钥, 不能泄露出去, id_rsa.pub 是公钥, 可以放心地告诉任何人 2. 登陆GitHub, 打开“Account settings”, “SSH Keys”页面, 然后, 点“Add SSH Key”, 填上任意Title, 在Key文本框里粘贴id_rsa.pub文件的内容, 最后点“Add Key” 添加远程仓库首先到Github创建一个仓库然后与本地关联:1git remote add origin git@github.com:your-name/repo-name.git 远程库的名字就是origin, 这是Git默认的叫法, 也可以改成别的, 但是origin这个名字一看就知道是远程库 下一步, 就可以把本地库的所有内容推送到远程库上:1git push -u origin master 把本地库的内容推送到远程, 用 git push 命令, 实际上是把当前分支 master 推送到远程由于远程库是空的, 我们第一次推送 master 分支时, 加上了 -u 参数, Git不但会把本地的 master 分支内容推送的远程新的 master 分支, 还会把本地的 master 分支和远程的 master 分支关联起来, 在以后的推送或者拉取时就可以简化命令 此后的推送都可以使用:1git push 从远程仓库克隆1git git@github.com:your-name/repo-name.git 标签管理查看tag列出所有tag:1git tag 这样列出的tag是按字母排序的, 和创建时间没关系. 如果只是想查看某些tag的话, 可以加限定:1git tag -l v1.* 这样就只会列出1.几的版本. 创建tag创建轻量级tag:1git tag 1.0.1 这样创建的tag没有附带其他信息, 与之相应的是带信息的tag,-m后面带的就是注释信息, 这样在日后查看的时候会很有用, 这种是普通tag, 还有一种有签名的tag:1git tag -a 1.0.1 -m &apos;first version&apos; 除了可以为当前的进度添加tag, 我们还可以为以前的commit添加tag:首先查看以前的commit1git log --oneline 假如有这样一个commit: 8a5cbc2 updated readme这样为他添加tag1git tag -a v1.1 8a5cbc2 删除tag很简单, 知道tag名称后:1git tag -d v1.0 删除远程分支:1git push origin --delete tag &lt;tagname&gt; 共享tag我们在执行git push的时候, tag是不会上传到服务器的, 比如现在的github, 创建tag后git push, 在github网页上是看不到tag的, 为了共享这些tag, 你必须这样:1git push origin --tags 分支管理分支相当与平行宇宙, 互不干扰, 哪天合并了就拥有了所有平行宇宙的特性 创建与合并分支 每次提交, Git都把它们串成一条时间线, 这条时间线就是一个分支. 截止到目前, 只有一条时间线, 在Git里, 这个分支叫主分支, 即 master 分支 一开始的时候, master 分支是一条线, Git用 master 指向最新的提交, 再用 HEAD 指向 master , 就能确定当前分支, 以及当前分支的提交点 当我们创建新的分支, 例如 dev 时, Git新建了一个指针叫 dev , 指向 master 相同的提交, 再把 HEAD 指向 dev , 就表示当前分支在 dev 上 Git创建一个分支很快, 因为除了增加一个 dev 指针, 改改 HEAD 的指向, 工作区的文件都没有任何变化 当 HEAD 指向 dev , 对工作区的修改和提交就是针对 dev 分支了, 比如新提交一次后, dev 指针往前移动一步, 而 master 指针不变 查看分支: git branch创建分支: git branch &lt;name&gt;切换分支: git checkout &lt;name&gt;创建+切换分支: git checkout -b &lt;name&gt;合并某分支到当前分支: git merge &lt;name&gt;删除分支: git branch -d &lt;name&gt; 解决冲突合并分支并不是每次都不会出问题, 如不同的分支对同一个文件同一行都被修改过, 就会出现以下情况那么再次合并有可能会冲突123456789101112131415➜ repo git:(master) git merge feature1 自动合并 read冲突（内容）: 合并冲突于 read自动合并失败, 修正冲突然后提交修正的结果. ➜ repo git:(master) ✗ git status 位于分支 master您有尚未合并的路径. （解决冲突并运行 &quot;git commit&quot;）未合并的路径: （使用 &quot;git add &lt;文件&gt;...&quot; 标记解决方案） 双方修改: read修改尚未加入提交（使用 &quot;git add&quot; 和/或 &quot;git commit -a&quot;） 这种情况必须手动解决然后再次 git add ., git commit -m &quot;commit&quot;, 打开文件可看到123456Git is a version control&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEADCreating a new branch is quick &amp; simple.=======Creating a new branch is quick AND simple.&gt;&gt;&gt;&gt;&gt;&gt;&gt; feature1 Git用&lt;&lt;&lt;&lt;&lt;&lt;&lt;, =======, &gt;&gt;&gt;&gt;&gt;&gt;&gt;标记出不同分支的内容, 那么经过合意, 不好意思, 大师兄说了, 在座的各位都是垃圾, 于是改成1Git,too fast too simple 再提交1234➜ repo git:(master) ✗ git add read ➜ repo git:(master) ✗ git commit -m &quot;conflict fixed&quot;[master 8933f88] conflict fixed➜ repo git:(master) ok了, 再次 add 和 commit , 现在 master 分支和feature1分支变成了这样 多PC协同开发当你从远程仓库克隆时, 实际上Git自动把本地的 master 分支和远程的 master 分支对应起来了, 并且, 远程仓库的默认名称是 origin 查看远程库的信息:查看简单信息: git remote查看详细信息: git remote -v查看远程仓库分支: git branch -r查看本地分支与远程分支的对应关系: git branch -vv 推送分支123git push origin &lt;branch&gt; git push -u origin &lt;branch&gt; # 第一次推送加-u可以把当前分支与远程分支关联起来 克隆分支并关联1234git clone git@github.com:youName/program.git # 默认克隆master分支到当前目录（包含分支文件目录）git clone -b &lt;branch&gt; git@github.com:youName/program.git ./# 克隆指定分支到指定文件目录下（不包含分支文件目录） 创建远程 origin 的 dev 分支到本地1git checkout -b &lt;branch&gt; origin/&lt;branch&gt; 关联本地分支与远程仓库分支1git branch --set-upstream &lt;branch&gt; origin/&lt;branch&gt; 同步更新Github Fork的项目1、fork项目并clone到本地 2、进入项目根目录 3、添加remote指向上游仓库 1git remote add upstream https://github.com/ORIGINAL_OWNER/ORIGINAL_REPOSITORY.git 4、把上游项目fetch下来 1git fetch upstream 5、merge到master 12git checkout mastergit merge upstream/master 6、push到自己的远程仓库, 搞定～ 最后Git真的异常强大, 但命令繁多, 需多加练习 参考: 廖雪峰老师的教程 附命令图一张: 1.集中式版本管理系统之一 ↩2.一个商业的版本控制系统 ↩]]></content>
      <categories>
        <category>Git/Github</category>
      </categories>
      <tags>
        <tag>Git</tag>
        <tag>Github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于Hexo+Github+Coding搭建个人博客——基础篇(从菜鸟到放弃)]]></title>
    <url>%2F2017%2Fbuild-blog-hexo-base%2F</url>
    <content type="text"><![CDATA[前言搭建此博客的动机以及好处在此就不多谈了, 之前已经表达过, 详情请看Start My Blog Trip — Power By Hexo记录一下搭建的基本过程以及遇到的一些问题, 仅供参考= =废话不多说, 进入主题 Hexo博客搭建的基础大致流程为: 安装Node.js →安装Git → 安装Hexo → 安装主题 → 本地测试运行 → 注册给github与coding并创建pages仓库 → 部署 这是博主的系统环境与版本:OS: Ubuntu16.04Node.js: 6.2.0Npm: 3.8.9Hexo: 3.2.2主题NexT: 5.1.0Git: 2.7.4 对于使用windows的童鞋, 可参考文章末尾处的参考链接, 步骤大同小异 以下提到的站点配置文件指的是博客文件根目录下的 _config.yml, 主题配置文件是主题文件夹下的 _config.yml, 童鞋们不要混淆了 安装Node.js Node.js的安装有很多种方式, Hexo的官方文档 建议是用nvm 安装, 但好多人都说不行, 所以找了另外两种方式安装windows的童鞋可参考安装Node.js 方法一: 二进制包直接解压配置在node.js的官网 下载二进制包来安装的, 下载过后, 解压, 设置软链接, 要不然每次都执行命令都要加上路径, 好麻烦123sudo ln -s /home/ybd/Data/soft/application/node-v6.2.0-linux-x64/bin/node /usr/local/bin/nodesudo ln -s /home/ybd/Data/soft/application/node-v6.2.0-linux-x64/bin/npm /usr/local/bin/npm 注意！源文件要写绝对路径, 否则会报错: 链接层数过多. 也可以直接将node可执行文件拷贝到 /usr/local/bin 目录下. 接下来就可以查看是否成功配置了12node -vnpm -v 方法二: 换源下载安装 6.x 版本:12curl -sL https://deb.nodesource.com/setup_6.x | sudo -E bash -sudo apt-get install -y nodejs 安装 8.x 版本:12curl -sL https://deb.nodesource.com/setup_8.x | sudo -E bash -sudo apt-get install -y nodejs npm 更换淘宝镜像:1npm config set registry https://registry.npm.taobao.org/ 方法三: 源文件编译安装在安装前, 首先需要配置安g++编译器1sudo apt-get install build-essential 去官网 下载源代码, 选择最后一项, Source Code解压到某一目录, 然后进入此目录,依次执行以下3条命令123./configuremakesudo make install 执行以下命令, 检测是否已经装好node.js1node -v npm安装, 一条命令即可解决1curl http://npmjs.org/install.sh | sudo sh 博主安装Node.js遇到的问题就是多次安装了不同版本的Node.js, 有的是安装在用户变量上, 有的是系统变量, 所以每次用的时候都要切换到root用户, 就算赋权 sudo chmod 777 file 都没有用, 所以折腾了很久才把Node.js完全卸载, 再重新安装 安装GitUbuntu系统下安装Git非常简单, 只需一条命令:1sudo apt-get install git windows下就直接到Git官网 下载安装即可 然后终端执行 git --version 查看是否安装成功 安装Hexo 什么是 Hexo？Hexo 是一个快速、简洁且高效的博客框架. Hexo 使用 Markdown（或其他渲染引擎）解析文章, 在几秒内, 即可利用靓丽的主题生成静态网页. 所有以上必备的应用程序安装完成后, 无论是在哪个操作系统, 之后的操作都一样 安装Hexo的非常简单, 只要一条命令, 前提是安装好Node.js与Git1npm install -g hexo-cli 如果npm安装hexo失败, 则很有可能是权限问题, 或者npm与node的版本不兼容（很少出现） 如果顺利安装完成, 理论上Hexo已经安装完成, 但在Ubuntu系统中, 比较坑的地方就是 hexo 命令居然放在了Node.js安装目录的 bin 文件夹下, 不能快捷地在终端把命令敲出来, 所以还是老规矩, 软链接走起1sudo ln -s /home/ybd/data/application/node-v7.4.0-linux-x64/bin/hexo /usr/local/bin/hexo 到此, Hexo的安装已基本完成, 可以先试一下Hello World. 解决Hexo命令fs.SyncWriteStream问题 nodejs版本更新到8.0之后, 运行hexo相关命令总会出现这么一行鬼东西:(node:538) [DEP0061] DeprecationWarning: fs.SyncWriteStream is deprecated.虽然不怎么影响大局, 当对于强迫症来说是一个噩梦！ nodejs从8.0开始已经弃用了fs.SyncWriteStream方法, 但是某些插件里面还是用到这个方法. 查看Hexo项目也有这个一条issue, 在hexo项目中其中有一个hexo-fs的插件调用了这个方法, 所以需要更新hexo-fs插件, 更新方法如下:1npm install hexo-fs --save 当然还有一些插件: 123npm install hexo-deployer-git@0.3.1 --savenpm install hexo-renderer-ejs@0.3.1 --savenpm install hexo-server@0.2.2 --save But, 问题木有得到解决啊！hexo命令有个-debug参数, 运行命令的时候加上这个参数, 可以定位问题: 123456789101112131415161718192021222324252627282930313233ybd@15ffab36a16c:~/blog$ hexo clean --debug03:01:16.464 DEBUG Hexo version: 3.3.903:01:16.467 DEBUG Working directory: ~/blog/03:01:16.539 DEBUG Config loaded: ~/blog/_config.yml03:01:16.613 DEBUG Plugin loaded: hexo-admin-qiniu(node:538) [DEP0061] DeprecationWarning: fs.SyncWriteStream is deprecated.03:01:16.655 DEBUG Plugin loaded: hexo-algolia03:01:16.657 DEBUG Plugin loaded: hexo-baidu-url-submit03:01:16.668 DEBUG Plugin loaded: hexo-deployer-git03:01:16.672 DEBUG Plugin loaded: hexo-fs03:01:16.674 DEBUG Plugin loaded: hexo-generator-archive03:01:16.677 DEBUG Plugin loaded: hexo-generator-baidu-sitemap03:01:16.678 DEBUG Plugin loaded: hexo-generator-category03:01:16.680 DEBUG Plugin loaded: hexo-generator-feed03:01:16.681 DEBUG Plugin loaded: hexo-generator-index03:01:16.682 DEBUG Plugin loaded: hexo-generator-tag03:01:16.826 DEBUG Plugin loaded: hexo-inject03:01:16.828 DEBUG Plugin loaded: hexo-renderer-ejs03:01:16.829 DEBUG Plugin loaded: hexo-generator-sitemap03:01:16.834 DEBUG Plugin loaded: hexo-renderer-marked03:01:16.836 DEBUG Plugin loaded: hexo-renderer-stylus03:01:16.881 DEBUG Plugin loaded: hexo-server03:01:16.912 DEBUG Plugin loaded: hexo-wordcount03:01:16.943 DEBUG Plugin loaded: hexo-reference03:01:16.946 DEBUG Script loaded: themes/next/scripts/merge-configs.js03:01:16.947 DEBUG Script loaded: themes/next/scripts/tags/button.js03:01:16.947 DEBUG Script loaded: themes/next/scripts/tags/center-quote.js03:01:16.947 DEBUG Script loaded: themes/next/scripts/tags/full-image.js03:01:16.947 DEBUG Script loaded: themes/next/scripts/tags/note.js03:01:16.948 DEBUG Script loaded: themes/next/scripts/tags/group-pictures.js03:01:16.949 DEBUG [hexo-inject] firing inject_ready03:01:16.951 INFO Deleted database.03:01:16.956 DEBUG Database saved 发现问题在hexo-admin-qiniu这个插件=.= 貌似也没怎么用这个插件, 那么就删掉吧:1nmp uninstall hexo-admin-qiniu --save 那个报错终于消失啦～～～ 本地启动Hello World与Hexo简单使用初始化随便建一个文件夹, 名字随便取, 博主取其名为blog, cd 到文件夹里, 先安装必要的文件, 执行以下命令:12hexo init # hexo会在目标文件夹建立网站所需要的所有文件npm install # 安装依赖包 本地启动有了必要的各种配置文件之后就可以在本地预览效果了12hexo g # 等同于hexo generate, 生成静态文件hexo s # 等同于hexo server, 在本地服务器运行 之后打开浏览器并输入IP地址 http://localhost:4000/ 查看, 效果如下 新建文章与页面12hexo new &quot;title&quot; # 生成新文章: \source\_posts\title.mdhexo new page &quot;title&quot; # 生成新的页面, 后面可在主题配置文件中配置页面 生成文章或页面的模板放在博客文件夹根目录下的 scaffolds/ 文件夹里面, 文章对应的是 post.md , 页面对应的是page.md, 草稿的是draft.md 编辑文章打开新建的文章\source\_posts\postName.md, 其中postName是hexo new &quot;title&quot;中的title12345678910title: Start My Blog Trip — Power By Hexo # 文章页面上的显示名称, 可以任意修改, 不会出现在URL中date: 2017-01-10 23:49:28 # 文章生成时间, 一般不改categories: diary # 文章分类目录, 多个分类使用[a,b,c]这种格式tags: [Hexo,diary] # 文章标签---#这里开始使用markdown格式输入你的正文. &lt;!--more--&gt; #more标签以下的内容要点击“阅读全文”才能看见 插入图片插入图片有三种方式 方式一在博客根目录的 source 文件夹下新建一个 img 文件夹专门存放图片, 在博文中引用的图片路径为 /img/图片名.后缀 1![](图片路径) 方式二对于那些想要更有规律地提供图片和其他资源以及想要将他们的资源分布在各个文章上的人来说, Hexo也提供了更组织化的方式来管理资源, 将站点配置文件中的 post_asset_folder 选项设为 true 来打开文章资源文件夹 1post_asset_folder: true 然后再博文中通过相对路径引用1&#123;% asset_img 图片文件名 %&#125; 方式三使用七牛云储存, 因为Github跟Coding项目容量有限, 而且Github的主机在国外, 访问速度较慢, 把图片放在国内的图床上是个更好的选择, 免费用户实名审核之后, 新建空间, 专门用来放置博客上引用的资源, 进入空间后点击「内容管理」, 再点击「上传」 上传完成之后点击关闭回到管理页面, 选中刚上传的图片, 最右边的操作点击复制链接即可然后在博文中通过地址引用1![](图片地址如: https://cdn.yangbingdong.com/img/build-hexo/copyUrl.png) 简单的命令总结一下简单的使用命令1234567hexo init [folder] # 初始化一个网站. 如果没有设置 folder , Hexo 默认在目前的文件夹建立网站hexo new [layout] &lt;title&gt; # 新建一篇文章. 如果没有设置 layout 的话, 默认使用 _config.yml 中的 default_layout 参数代替. 如果标题包含空格的话, 请使用引号括起来hexo version # 查看版本hexo clean # 清除缓存文件 (db.json) 和已生成的静态文件 (public)hexo g # 等于hexo generate # 生成静态文件hexo s # 等于hexo server # 本地预览hexo d # 等于hexo deploy # 部署, 可与hexo g合并为 hexo d -g 安装主题（以NexT为例）更多主题请看知乎专栏 复制主题Hexo 安装主题的方式非常简单, 只需要将主题文件拷贝至站点目录的 themes 目录下, 然后修改下配置文件即可在这我们使用git克隆最新版12cd your-hexo-sitegit clone https://github.com/iissnan/hexo-theme-next themes/next 启用主题打开站点配置文件, 找到 theme 字段, 并将其值更改为 next1theme: next 然后 hexo s 即可预览主题效果 更换主题外观NexT有三个外观, 博主用的是 Muse, 直接更改主题配置文件的 scheme 参数即可, 如果显示的是繁体中文, 那么站点配置文件中的 language: zh-CN123scheme: Muse#scheme: Mist#scheme: Pisces 在次执行 hexo clean 和 heox s 可预览效果大部分的设定都能在NexT的官方文档 里面找到, 如侧栏、头像、打赏、评论等等, 在此就不多讲了, 照着文档走就行了, 接下只是个性定制的问题 注册Github和Coding并分别创建Pages在本地运行没有问题的话, 那么可以部署到外网去, 在此之前, 先得有服务器让你的项目可以托管, 那么Github Page与Coding Page就是个很好的东西, 它们可以让我们访问静态文件, 而Hexo生成的恰恰是静态文件具体请查看 Coding Page 、 Github Page 那为什么要注册两个网站呢？因为Github是国外的服务器, 访问速度比较慢, 而Coding是国内的, 速度相对来说比较快, 在后面DNS解析的时候可以把国内的解析到Coding, 国外的解析到Github, 完美 GitHub注册Github帐号进入Github 首页进行注册, 用户名、邮箱和密码之后都需要用到, 自己记好, 不知道怎么注册的童鞋去问问度娘 创建Repository(Github Pages)Repository相当于一个仓库, 用来放置你的代码文件. 首先, 登陆进入Github, 选择首页中的 New repository 按钮创建时, 只需要填写Repository name即可, 可以顺便创建README文件, 就是红色那个钩, 当然这个名字的格式必须为{user_name}.github.io, 其中{user_name}必须与你的用户名一样, 这是github pages的特殊命名规范, 如下图请忽视红色警告, 那是因为博主已经有了一个pages项目 Coding注册Coding帐号国内的网站, 绝大部分都是中文的, 注册什么的就不说了,进入Coding 滚键盘就是了= = 创建项目(Coding Pages)Coding Pages请看 Coding Pages注册之后进入主页, 点击项目, 点击+, 项目名为你的用户名查看Pages 服务是否开启: 点击项目 -&gt; 代码 -&gt; Pages 服务, 若没有开启则点开启 配置SSH与Git那么我们有了两个免费的服务器之后, 就要绑定个人电脑与它们联系, 那就是SSH与Git绑定之后我们每次部署项目就不用输入帐号和密码 生成SSH Key1ssh-keygen -t rsa -C your_email@youremail.com 后面的 your_email@youremail.com 改为你的邮箱, 之后会要求确认路径和输入密码, 我们这使用默认的一路回车就行. 成功的话会在~/下生成 .ssh 文件夹, 进去, 打开 id_rsa.pub, 复制里面的key, 粗暴点就是 Ctrl+a 然后 Ctrl+c 添加SSH Key首先是Github, 登录Github, 右上角 头像 -&gt; Settings —&gt; SSH nd GPG keys —&gt; New SSH key . 把公钥粘贴到key中, 填好title并点击 Add SSH key 至于Coding, 登录进入主页, 点击 账户 —&gt; SSH公钥 —&gt; 输入key再点击 添加 验证成功与否验证github1ssh -T git@github.com 如果是第一次的会提示是否continue, 输入yes就会看到: You’ve successfully authenticated, but GitHub does not provide shell access . 这就表示已成功连上github!之前博主就是因为没有输入yes, 导致几次失败, 粗心地一路回车= =验证coding1ssh -T git@git.coding.net 同上, 按yes接下来我们要做的就是把本地仓库传到github上去, 在此之前还需要设置username和email, 因为github每次commit都会记录他们12git config --global user.name your namegit config --global user.email your_email@youremail.com 关于git可参考:史上最全github使用方法: github入门到精通Git学习笔记 部署到Github与Coding在此之前, 先安装Git部署插件1npm install hexo-deployer-git --save 打开站点配置文件, 拉到底部, 修改部署配置:1234567# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repo: github: git@github.com:masteranthoneyd/masteranthoneyd.github.io.git,master coding: git@git.coding.net:ookamiantd/ookamiantd.git,master 注意冒号后面是网站对应的用户名, 接着就是/, 然后再是你的项目名加上 .git,master保存后终端执行123hexo cleanhexo ghexo d 稍等片刻, 可能会由于环境、网络等原因, 部署的时间会有偏差, 有的人快有的慢部署完成后可在浏览器输入 yourName.github.io 或者 yourName.coding.me 都可以浏览到一个属于自己的博客了 ～ 绑定自定义域名开启Https 首先你需要一个域名, 这个就不说了, 可以去万网 分别对Coding以及Github解析 Coding在代码中找到Pages服务: 要注意的是需要按照提示添加CHAME记录, 比如博主的是ookamiantd.coding.me, 检验成功后才可绑定成功. Github 跟Coding一样, 需要添加CHAME记录, 记录值为对应的Pages域名, 比如博主的是masteranthoneyd.github.io 除此之外还需要在网站根目录添加一个CHAME文件, 内容为你的自定义域名 效果图: 至此, 境内外的小绿锁都开启了. 当然, 如果站内有部分资源不是https方式（比如图片）, 锁就绿不起来了. 总结最后用拙劣的语言总结一下博主搭建Hexo博客的体会, 六个字: 简洁但, 不简单.再六个字, 正如NexT官方说的: 精于心, 简于形= =貌似这个博客也不怎么简洁, 有点花俏, 装X嫌疑但无论怎样, 折腾这个博客让我受益匪浅, 正如之前听到的一句名言, 忘了谁说的: 不努力试一把, 又怎么会知道绝望…好像很有道理, 绝望中寻找光芒, 绝处逢生…嘿嘿嘿 参考 使用Hexo搭建个人博客(基于hexo3.0) Github Pages个人博客, 从Octopress转向HexoHexo 3.1.1 静态博客搭建指南Hexo官方文档NexT官方文档]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Git</tag>
        <tag>Github</tag>
        <tag>Node.js</tag>
        <tag>Coding</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu主题美化与常用软件记录]]></title>
    <url>%2F2017%2Fubuntu-todo-after-install%2F</url>
    <content type="text"><![CDATA[前言 时间已经来到了9102年, 当初的Ubuntu 18.04 LTS 版本已经回归GNOME环境, 各种主题优化教程也层出不穷了, 说明Ubuntu的使用人群也渐渐增加… 启动盘制作篇Windows中利用UltraISO制作在Windows环境下一般是通过 UltraISO 制作U盘启动盘（最好是FAT32格式）, 步骤通常如下（安装UltraISO前提下）: 选择并打开系统镜像（iso） 选择 启动 -&gt; 写入硬盘映像 , 会弹出一个写入硬盘映像的对话框 选择对应U盘 点击 便捷启动 -&gt; 写入新的驱动器引导扇区 -&gt; Syslinux 最后再点击 写入 等待完成即可 图就不贴了, 搜索引擎上一大堆. 接下来要介绍的是在Linux环境中制作启动盘 Linux中利用DD命令制作Step 1U盘插入电脑后, 用lsblk命令查看一下 12345678910111213$ lsblkNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTsda 8:0 0 111.8G 0 disk ├─sda1 8:1 0 512M 0 part /boot/efi├─sda2 8:2 0 14G 0 part /usr├─sda3 8:3 0 14G 0 part /opt├─sda4 8:4 0 4.7G 0 part /boot└─sda5 8:5 0 78.7G 0 part /homesdb 8:16 0 931.5G 0 disk ├─sdb1 8:17 0 745.1G 0 part /└─sdb2 8:18 0 8.4G 0 part [SWAP]sdc 8:32 1 14.5G 0 disk └─sdc4 8:36 1 14.5G 0 part /media/ybd/SSS_X64FRE_ 很明显, /media/ybd/SSS_X64FRE_这个挂载的就是U盘, U盘对应的路径是/dev/sdc如果不确定, 可以进去看一下文件目录. 找到对应的挂载目录很重要, 少有不慎, 可能会导致整个系统瘫痪 23333……….. Step 2需要卸载掉挂载的目录: 1umount /media/ybd/SSS_X64FRE_ 再用lsblk确认一下 123456789101112NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTsda 8:0 0 111.8G 0 disk ├─sda1 8:1 0 512M 0 part /boot/efi├─sda2 8:2 0 14G 0 part /usr├─sda3 8:3 0 14G 0 part /opt├─sda4 8:4 0 4.7G 0 part /boot└─sda5 8:5 0 78.7G 0 part /homesdb 8:16 0 931.5G 0 disk ├─sdb1 8:17 0 745.1G 0 part /└─sdb2 8:18 0 8.4G 0 part [SWAP]sdc 8:32 1 14.5G 0 disk └─sdc4 8:36 1 14.5G 0 part 可以看到已经没有挂载了 Step 3用dd命令将iso映像写入U盘（一般Linux的镜像是直接将整个安装系统包括引导直接压缩进iso当中） 1sudo dd if=ubuntu-16.04-desktop-amd64.iso of=/dev/sdc bs=1M 过程中不会有任何输入, 并且时间可能稍久, 完成后会输出这样的信息: 1234/dev/sdc bs=1M1520+0 records in1520+0 records out1593835520 bytes (1.6 GB) copied, 493.732 s, 3.2 MB/s 到此制作完成. 系统篇换源更换最佳源服务器, 打开 软件和更新（这里可以选择阿里的, 或者点击右边的 选择最佳服务器）: 更新之前的16.04是会安装很多用不上的软件, 好在18.04版本优化掉了, 最小安装保持干净系统 安装完系统之后, 需要更新一些补丁. Ctrl+Alt+T调出终端, 执行一下代码:1sudo apt update &amp;&amp; sudo apt upgrade -y &amp;&amp; sudo apt autoremove 关掉sudo的密码先修改默认编辑器为vim（默认为nano）: 1sudo update-alternatives --config editor 输入vim对应的序号回车即可 打开 visudo: 1sudo visudo 找到 1%sudo ALL=(ALL:ALL) ALL 修改为 1%sudo ALL=(ALL:ALL) NOPASSWD:ALL 这样所有sudo组内的用户使用sudo时就不需要密码了. Apt Fast https://github.com/ilikenwf/apt-fast apt-fast 是一个为 apt-get 和 aptitude 做的 shell 脚本封装，通过对每个包进行并发下载的方式可以大大减少 APT 的下载时间。apt-fast 使用 aria2c 下载管理器来减少 APT 下载时间。就像传统的 apt-get 包管理器一样，apt-fast 支持几乎所有的 apt-get 功能，如， install , remove , update , upgrade , dist-upgrade 等等，并且更重要的是它也支持 proxy。 12sudo add-apt-repository -y ppa:apt-fast/stable &amp;&amp; \sudo apt install -y apt-fast 之后就可以用 apt-fast 代替 apt 或 apt-get 命令了. Gdebi有时候安装deb包不满足依赖还需要手动执行sudo apt install -f, 我们可以使用gdebi解决这个问题: 1sudo apt install gdebi 之后使用sudo gdebi xxx.deb安装即可 Snap1sudo apt install -y snapd 配置代理1sudo systemctl edit snapd.service 123[Service]Environment=http_proxy=http://proxy:portEnvironment=https_proxy=http://proxy:port 12sudo systemctl daemon-reloadsudo systemctl restart snapd.service 常用命令1234567891011121314151617# 列出已经安装的snap包sudo snap list# 搜索要安装的snap包sudo snap find &lt;text to search&gt;# 安装一个snap包sudo snap install &lt;snap name&gt;# 更新一个snap包，如果你后面不加包的名字的话那就是更新所有的snap包sudo snap refresh &lt;snap name&gt;# 把一个包还原到以前安装的版本sudo snap revert &lt;snap name&gt;# 删除一个snap包sudo snap remove &lt;snap name&gt; 科学上网篇方式一: 下载Lantern如果为了更方便地科学上网, 建议下载Lantern （免费版限流）可在github（免翻墙）找到开源项目, 拉到下面README下载对应版本 12sudo dpkg -i lantern.debsudo chmod -R 777 /usr/bin/lantern 方式二: 自搭建 ShadowsocksAccess Blocked Sites(翻墙):VPS自搭建ShadowSocks与加速 主题美化篇推荐一个网站 Gnome Look, 这里面有大量的主题, 并且都是以压缩包形式的. 主题存放目录：/usr/share/themes 或 ~/.themes 图标存放目录：/usr/share/icons 或 ~/.icons 字体存放目录：/usr/share/fonts 或 ~/.fonts 其中 /usr/share 目录需要 root 权限才能修改，可以对文件管理提权后打开： 1sudo nautilus 并且注意一下解压后shell的主题文件夹的二级目录应该是/gnome-shell, 然后分别放到对应的目录, 就能在gnome-tweak工具里面识别了 GNOME美化依赖安装123456sudo apt install -y \gnome-tweak-tool \gnome-shell-extensions \chrome-gnome-shell \gtk2-engines-pixbuf \libxml2-utils 主题Sierra-gtk-theme https://github.com/vinceliuice/Sierra-gtk-theme 这是一款类苹果的主题… 12sudo add-apt-repository -y ppa:dyatlov-igor/sierra-themesudo apt install sierra-gtk-theme FlatabulousFlatabulous主题是一款Ubuntu下扁平化主题. 执行以下命令安装Flatabulous主题: 123sudo add-apt-repository ppa:noobslab/themes sudo apt update sudo apt install flatabulous-theme 该主题有配套的图标, 安装方式如下:123sudo add-apt-repository ppa:noobslab/icons sudo apt update sudo apt install ultra-flat-icons Arc-Theme https://github.com/horst3180/arc-theme 这也是一款很漂亮的主题 1sudo apt install arc-theme Sweethttps://www.gnome-look.org/p/1253385/ 图标Suru Plus https://www.opendesktop.org/p/1210408/ 1wget -qO- https://raw.githubusercontent.com/gusbemacbe/suru-plus/master/install.sh | sh 更换文件夹颜色(https://github.com/gusbemacbe/suru-plus-folders/blob/master/languages/en.md): 123456# 安装curl -fsSL https://raw.githubusercontent.com/gusbemacbe/suru-plus-folders/master/install.sh | sh# 查看颜色suru-plus-folders -l --theme Suru++# 更换suru-plus-folders -C cyan --theme Suru++ Papirus12sudo add-apt-repository -y ppa:papirus/papirussudo apt install papirus-icon-theme 或者下载最新的 deb 安装包项目地址 Paper12345sudo add-apt-repository -y ppa:snwh/pulpsudo apt install paper-icon-theme# 同时也可以安装 GTK 和 Cursor 主题sudo apt install paper-gtk-themesudo apt install paper-cursor-theme 项目地址 光标Capitaine Cursors https://www.gnome-look.org/p/1148692/ 12sudo add-apt-repository -y ppa:dyatlov-igor/la-capitainesudo apt install -y la-capitaine-cursor-theme Oxy Bluehttps://www.opendesktop.org/p/1274872/ 下载后解压到 /usr/share/themes 目录下 GNOME Extensions Ubuntu 18.04 抛弃了 Unity 桌面转而使用 Gnome ，所以 Gnome 桌面下的一些 Shell 扩展在 Ubuntu 18.04 中就可以使用了。 先上图… Chrome Gnome Shell首先安装 Chrome Gnome Shell ： 1sudo apt install chrome-gnome-shell 然后安装浏览器插件（谷歌浏览器）：Chrome 网上应用商店 浏览器插件安装完成后点击 插件图标 就能进入：Shell 扩展商店 Dash To DockDash To Dock: 虽然Ubuntu18已经有了一个Dock, 但定制性不强. 这个Dock插件提供了很多选项定制, 个人比较喜欢的一个选项就是隔离工作区. Topicons PlusTopicons Plus 任务图标栏 任务图标栏使用默认的图标, 如何让他使用自定义的图标主题呢？比如使用 Papirus , 它支持 hardcode-tray 脚本来实现 安装 hardcode-tray 123sudo add-apt-repository ppa:andreas-angerer89/sni-qt-patchedsudo apt updatesudo apt install sni-qt sni-qt:i386 hardcode-tray inkscape 转换图标 1hardcode-tray --conversion-tool Inkscape Nvidia GPU Temperature IndicatorNvidia GPU Temperature Indicator 显卡温度指示器 User ThemesUser Themes 可以使用shell-theme: Other以下是其他的Gnome 扩展推荐 : 扩展 简要功能描述 Applications Menu 在顶部添加一个应用程序入口 Coverflow Alt-Tab Alt Tab 切换应用（更酷炫的界面） Dash to Dock Dock （大名鼎鼎） EasyScreenCast 录屏工具（录制质量优秀） Extension update notifier 自动推送所有扩展的更新信息 Internet speed meter / NetSpeed 顶栏显示当前网络速度 OpenWeather 顶栏显示天气情况（支持中文） Dynamic Top Bar 动态调整状态栏透明度 Places Status Indicator 提供快捷目录入口（同文件管理器） Popup dict Switcher 一键开关划词翻译 Removable Drive Menu 移除可移动设备 Screenshot Tool 截图工具（挺方便） Sound Input &amp; Output Device Chooser 更方便的调整声音、亮度 System-monitor / System-monitor 在状态栏中显示系统信息（很多类型） 若出现安装失败，请检查 是否满足相关依赖 。 Oh-My-Zsh安装终端采用zsh和oh-my-zsh, 既美观又简单易用, 主要是能提高你的逼格！！！ 首先, 安装zsh: 1sudo apt-get install zsh 接下来我们需要下载 oh-my-zsh 项目来帮我们配置 zsh, 采用wget安装(需要先安装git)1sh -c &quot;$(wget https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh -O -)&quot; 重启后生效. 语法高亮安装插件highlight, 高亮语法: 12cd ~/.oh-my-zsh/custom/plugins &amp;&amp;\git clone git://github.com/zsh-users/zsh-syntax-highlighting.git 在Oh-my-zsh的配置文件中~/.zshrc中添加插件 1plugins=( [plugins...] zsh-syntax-highlighting) 重新打开终端即可生效！ 调色最后, 修改以下配色, 会让你的终端样式看起来更舒服, 在终端任意地方右键, 进入配置文件(profile)-&gt;外观配置(profile Preferences), 弹出如下界面, 进入colors一栏: 其中, 文字和背景采用系统主题, 透明度设为10%, 下面的palette样式采用Tango, 这样一通设置后, 效果如下: 推荐配色: 文本颜色: #00FF00 粗体字颜色: 与文本颜色相同 背景颜色: #002B36 主题在~/.oh-my-zsh/themes中查看主题. 然后编辑~/.zshrc, 找到ZSH_THEME修改为你想要的主题即可（感觉ys这个主题不错）. agnoster, bullet-train 这两款主题也不错, 但需要先安装一些 字体样式: 12345git clone https://github.com/powerline/fonts.git --depth=1cd fonts./install.shcd ..rm -rf fonts 装完后需要在终端配置Powerline字体. 其他主题: https://github.com/bhilburn/powerlevel9k 字体Ubuntu自带的字体不太好看, 所以采用文泉译微米黑/正黑替代, 效果会比较好, 毕竟是国产字体！ 1sudo apt install fonts-wqy-microhei fonts-wqy-zenhei 然后通过gnome-tweak-tool来替换字体 GRUB 2 主题 由于安装了多系统, 恰好Ubuntu的GRUB2提供了切换系统的选择, 但是界面不咋样 前往 https://www.gnome-look.org/browse/cat/109/ 选择一款合适自己的主题安装 博主推荐 Grub-theme-vimix Blur grub 或者 fallout-grub-theme 根据提示下载源码执行安装脚本即可. 但某些主题只提供主题包并没有安装脚本, 则我们需要手动安装: 首先下载主题包，多为压缩包，解压出文件。使用 sudo nautilus 打开文件管理器。 定位到目录：/boot/grub，在该目录下 新建文件夹 ：themes，把解压出的文件拷贝到文件夹中。 方案一：手写配置文件 接着（终端下）使用 gedit 修改 grub 文件： 1sudo gedit /etc/default/grub 在该文件末尾添加： 12# GRUB_THEME=&quot;/boot/grub/themes/主题包文件夹名称/theme.txt&quot;GRUB_THEME=&quot;/boot/grub/themes/fallout-grub-theme-master/theme.txt&quot; 方案二：利用软件 Grub Customizer 添加 PPA ： 1sudo add-apt-repository ppa:danielrichter2007/grub-customizer 安装软件： 1sudo apt install grub-customizer 最后 更新配置文件： 1sudo update-grub 谈到 grub 就不得不谈到 /boot/grub/grub.cfg ，这个文件才是事实上的配置文件，所谓更新就是重新生成 grub.cfg 。 GDM 登录背景图 修改之前可以备份一下ubuntu.css文件, 避免错了改不会来… 更换登录界面的背景图需要修改文件 ubuntu.css，它位于 /usr/share/gnome-shell/theme 。 1sudo gedit /usr/share/gnome-shell/theme/ubuntu.css 在文件中找到关键字 lockDialogGroup，如下行： 123#lockDialogGroup &#123; background: #2c001e url(resource:///org/gnome/shell/theme/noise-texture.png); background-repeat: repeat; &#125; 修改图片路径即可，样例如下： 12345#lockDialogGroup &#123; background: #2c001e url(file:///home/ybd/data/pic/spain.jpg); background-repeat: no-repeat; background-size: cover; background-position: center; &#125; 其中file:///home/ybd/data/pic/spain.jpg为图片路径. 开机动画 查找喜欢的开机动画: https://www.gnome-look.org/browse/cat/108/order/latest 几个不错的动画: UbuntuStudio - Suade Mint Floral ArcOS-X-Flatabulous 下面说安装流程: 首先下载并解压自己喜欢的开机动画; 把解压后的文件夹复制到 /usr/share/plymouth/themes/ 文件夹下; 1sudo cp $&#123;caton-path&#125; /usr/share/plymouth/themes/ -r 编辑配置文件: 1sudo gedit /etc/alternatives/default.plymouth 把后两行修改为: 123[script]ImageDir=/usr/share/plymouth/themes/$&#123;theme-directory&#125;ScriptFile=/usr/share/plymouth/themes/$&#123;theme-directory&#125;/$&#123;script-file-name&#125; 其中: ${theme-directory} 是你的主题文件夹名; ${script-file-name} 是主题文件夹下后缀为 .script 文件的文件名. 重启即可. 壁纸推荐推荐几个不错的壁纸下载网站: https://wallpapershome.com https://pixabay.com https://alpha.wallhaven.cc/ 软件篇 Java开发者的环境搭建请看: Ubuntu的Java开发环境基本搭建 搜狗输入法卸载ibus. 1sudo apt-get remove ibus 清除ibus配置. 1sudo apt-get purge ibus 卸载顶部面板任务栏上的键盘指示. 1sudo apt-get remove indicator-keyboard 安装fcitx输入法框架 1sudo apt install fcitx-table-wbpy fcitx-config-gtk 切换为 Fcitx输入法 1im-config -n fcitx im-config 配置需要重启系统才能生效 1sudo shutdown -r now 点击下载 Sogou For Linux -&gt; Download Now 1wget http://cdn2.ime.sogou.com/dl/index/1524572264/sogoupinyin_2.2.0.0108_amd64.deb?st=ryCwKkvb-0zXvtBlhw5q4Q&amp;e=1529739124&amp;fn=sogoupinyin_2.2.0.0108_amd64.deb 安装搜狗输入法 1sudo dpkg -i sogoupinyin_2.2.0.0108_amd64.deb 修复损坏缺少的包 1sudo apt-get install -f 打开 Fcitx 输入法配置 1fcitx-config-gtk3 问题: 输入法皮肤透明 123fcitx设置 &gt;&gt; 附加组件 &gt;&gt; 勾选高级 &gt;&gt; 取消经典界面Configure&gt;&gt; Addon &gt;&gt;Advanced&gt;&gt;Classic 再次重启. Wechat for Ubuntu下载地址:https://github.com/geeeeeeeeek/electronic-wechat/releases博主的百度盘 (密码: 9bpi) (提取路径: UbuntuTools -&gt; wechat4Ubuntu) 下载最新版本, 解压后打开目录里面的electronic-wechat, 然后创建个软连接换个图标拉倒桌面就可以了 上面的 electronic-wechat 已不再维护. 另外, Github中还有一个Linux版的Wechat: https://github.com/eNkru/electron-wechat 或者也可以使用 Deepin Wine QQWine-QQ Appimage版本Github: https://github.com/askme765cs/Wine-QQ-TIM 下载玩对应的Appimage后, 右键属性, 在权限中允许执行, 然后可以直接打开了 QQ轻聊版 这种方式比较麻烦, 可以直接才上面的Appimage 虽然不太想安装QQ, 但工作时候团队交流需要, QQ国际版又太难看, 所以装个Deepin的轻聊版.工具包下载: 博主的百度盘 (密码: 9bpi) (提取路径: UbuntuTools&gt;qq4Ubuntu) 内含文件: crossover_16.0.0-1.deb crossover16crack.tar.gz apps.com.qq.im.light_7.9.14308deepin0_i386.deb crossover安装与破解这个轻聊版是Deepin的作品, 要在Ubuntu上使用, 就要安装crossover, 很不幸这玩意是收费的, 很幸运的是这玩意是可以破解的.1、安装的工具包下载下来解压后会有三个文件, 首先先安装crossover_16.0.0-1.deb, 缺少依赖就执行一下sudo apt -f install, 安装完后先不要打开crossover.2、在命令行输入sudo nautilus打开一个root权限的文件管理器3、把破解文件 (crossover16crack-&gt;winewrapper.exe.so) 替换路径: /opt/cxoffice/lib/wine下的winewrapper.exe.so文件. 提示已有文件, 点“替换”破解完成. Deepin QQ轻聊版1、用归档管理器打开apps.com.qq.im.light_7.9.14308deepin0_i386.deb2、点开 data.tar.xz 找到 ./opt/cxoffice/support3、把 apps.com.qq.im.light 这个文件夹提取出来4、在命令行输入sudo nautilus打开一个root权限的文件管理器5、然后将这个文件夹复制到系统的 /opt/cxoffice/support 下6、然后打开 crossover , 发现多了一个容器 , 点击图标即可运行QQ轻聊版7、如果运行后出现乱码, 把 Windows 系统下的 %systemroot%\fonts\simsun.ttf (simsun.ttc) 复制到容器的对应文件夹就可以 GUI-SmartGitgit的一个GUI: 123sudo add-apt-repository ppa:eugenesan/ppasudo apt updatesudo apt install smartgithg Typora(Markdown编辑器)官方 安装方法如下: 123wget -qO - https://typora.io/linux/public-key.asc | sudo apt-key add -sudo add-apt-repository -y &apos;deb https://typora.io/linux ./&apos;sudo apt install typora GIF制作软件 Peek123sudo add-apt-repository ppa:peek-developers/stablesudo apt updatesudo apt install peek 终端执行peek即可运行 StarUml这个一款绘图工具下载: http://staruml.io/download安装依赖: https://launchpad.net/ubuntu/trusty/amd64/libgcrypt11/1.5.3-2ubuntu4.5然后dpkg安装就好了, 如果还有依赖直接apt install -f修复一下就好.安装好之后修改LicenseManagerDomain.js查找: 1dpkg -S staruml | grep LicenseManagerDomain.js 修改:1sudo gedit /opt/staruml/www/license/node/LicenseManagerDomain.js 如下:12345678910111213141516171819202122232425262728293031323334(function () &#123; &quot;use strict&quot;; var NodeRSA = require(&apos;node-rsa&apos;); function validate(PK, name, product, licenseKey) &#123; var pk, decrypted; return &#123; name: &quot;yangbingdong&quot;, product: &quot;StarUML&quot;, licenseType: &quot;vip&quot;, quantity: &quot;yangbingdong.com&quot;, licenseKey: &quot;later equals never!&quot; &#125;; try &#123; pk = new NodeRSA(PK); decrypted = pk.decrypt(licenseKey, &apos;utf8&apos;); &#125; catch (err) &#123; return false; &#125; var terms = decrypted.trim().split(&quot;\n&quot;); if (terms[0] === name &amp;&amp; terms[1] === product) &#123; return &#123; name: name, product: product, licenseType: terms[2], quantity: terms[3], licenseKey: licenseKey &#125;; &#125; else &#123; return false; &#125; &#125; ...... 改完打开StarUml -&gt; Help -&gt; Enter License, 不是输入任何东西直接确定 VirtualBox1sudo apt install virtualbox KVMKVM要求我们的CPU支持硬件虚拟化(hardware virtualization)．在终端里输入下面的命令来查看CPU是否支持硬件虚拟化: 1egrep -c &apos;(svm|vmx)&apos; /proc/cpuinfo 如果上面的命令返回数字０, 就表示CPU不支持硬件虚拟化, 那么我们就只能使用Virtualbox或VMware来创建虚拟机了．如果返回的数字大于０, 那么表示CPU支持硬件虚拟化, 我们就能使用KVM来创建虚拟机． 安装: 1sudo apt install qemu-kvm libvirt-bin ubuntu-vm-builder bridge-utils virt-manager virtinst virt-viewer Dash里打开virt-manager: SecureCRTInstall官方下载地址（选择Linux版deb包）: https://www.vandyke.com/download/securecrt/download.html 1sudo dpkg -i scrt-8.3.2-1584.ubuntu16-64.x86_64.deb Crack准备: 12wget http://download.boll.me/securecrt_linux_crack.pl &amp;&amp; \sudo apt install perl 查看一下SecureCRT的安装路径: 123whereis SecureCRT# 不出意外应该是在 /usr/bin/SecureCRT 运行perl脚本: 1sudo perl securecrt_linux_crack.pl /usr/bin/SecureCRT 然后按照提示手动输入License即可 WPS去 wps官网 下载wps for Linux.先不要执行dpkg -i 去执行安装. 这个地方有个问题, 就是ubuntu 16 版本不支持32位的支持库, 所以需要安装一下支持库.32位的支持库名为: ia32-libs安装的时候会提示有替代包, 需要安装替代包. 1sudo apt install lib32ncurses5 lib32z1 还是不要执行dpkg -i , 因为即使现在安装还是会缺少一个依赖. 这个依赖是libpng-12.0. 不过这个在默认的apt 仓库里没有. 所以需要手动下载一下.下载地址: https://packages.debian.org/zh-cn/wheezy/amd64/libpng12-0/download 1sudo dpkg -i libpng12-0_1.2.49-1+deb7u2_amd64.deb 最后:1sudo dpkg -i wps-office_10.1.0.5672~a21_amd64.deb Chrome到chrome官网 下载linux版的chrome.不能翻墙的小朋友可以到博主的百度盘 (密码: 9bpi)1sudo dpkg -i google-chrome-stable_current_amd64.deb 或者通过apt安装: 1234sudo wget https://repo.fdzh.org/chrome/google-chrome.list -P /etc/apt/sources.list.d/ &amp;&amp; \wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo apt-key add - &amp;&amp; \sudo apt update &amp;&amp; \sudo apt install google-chrome-stable XMind 8 CrackSetup一款思维导图软件, 前往 XMind官网 下载压缩包. 解压后先执行一下解压包根目录下的setup.sh: 1sudo sh setup.sh Crack 将XMindCrack.jar复制到根目录的plugins文件中 以文本格式打开根目录中 XMind.ini 在最后一行添加-javaagent:../plugins/XMindCrack.jar 禁止XMind访问网络: 在host文件中添加127.0.0.1 www.xmind.net, 然后重启网络sudo /etc/init.d/networking restart 打开XMind输入序列号 XMindCrack.jar与序列号如果有需要可以私聊博主. 截图ShutterUbuntu下很强大的一款截图软件 1sudo apt install shutter 设置快捷键: 打开系统设置 -&gt; 键盘 -&gt; 快捷键 -&gt; 自定义快捷键 -&gt; 点击&quot; + &quot;名字随便起, 命令: shutter -s点击确定, 再点禁用, 键盘按下ctrl+alt+a, 完成设置 编辑按钮变成程灰色解决方法需要3个deb包: libgoocanvas-common libgoocanvas3 libgoo-canvas-perl 或者: 博主的百度盘 (密码: 9bpi) (提取路径: UbuntuTools -&gt; shutter-1804-editor.zip) 依次使用dpkg命令安装, 报错使用sudo apt-get -f install修复 最后重启Shutter进程就好了 Deepin Screenshot这个是Deepin开发的截图工具, 目前已经可以在软件商店中找到: 1sudo apt install deepin-screenshot 然后跟上面的Shutter一样设置快捷键就可以了, 命令是deepin-screenshot 系统清理软件 BleachBit1sudo apt install -y bleachbit 多协议下载器 Aria2 aria2: https://github.com/aria2/aria2 部分使用说明: https://aria2c.com/usage.html 一般在Linux环境中下载东西都是比较不友好的, 不支持多种协议, 方式单一, 但这款Aria2就是为了解决多协议问题而诞生的, 配合UI界面可以很方便地随心所欲地下载. 直接安装1sudo apt install aria2 添加配置文件: 1234sudo mkdir /etc/aria2sudo touch /etc/aria2/aria2.sessionsudo chmod 777 /etc/aria2/aria2.sessionsudo gedit /etc/aria2/aria2.conf 配置文件可参考: https://github.com/fsaimon/aria2.conf 后台运行: 1sudo aria2c --conf-path=/etc/aria2/aria2.conf -D GUI Uget chrome 扩展 YAAW for Chrome 通过 Docker 搭建 Aria2 以及 AriaNg Web UI 博主选择使用Docker 参考 aria2-ariang-docker 以及 aria2-ariang-x-docker-compose 配置aria2.conf这个文件是从作者地 Github下载下来的, 主要加了代理, 而这个代理是 sock5 通过 privoxy 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566#所有协议代理all-proxy=http://192.168.6.113:8118#用户名#rpc-user=user#密码#rpc-passwd=passwd#上面的认证方式不建议使用,建议使用下面的token方式#设置加密的密钥#rpc-secret=token#允许rpcenable-rpc=true#允许所有来源, web界面跨域权限需要rpc-allow-origin-all=true#允许外部访问，false的话只监听本地端口rpc-listen-all=true#RPC端口, 仅当默认端口被占用时修改#rpc-listen-port=6800#最大同时下载数(任务数), 路由建议值: 3max-concurrent-downloads=5#断点续传continue=true#同服务器连接数max-connection-per-server=5#最小文件分片大小, 下载线程数上限取决于能分出多少片, 对于小文件重要min-split-size=2M#单文件最大线程数, 路由建议值: 5split=10#下载速度限制max-overall-download-limit=0#单文件速度限制max-download-limit=0#上传速度限制max-overall-upload-limit=0#单文件速度限制max-upload-limit=0#断开速度过慢的连接#lowest-speed-limit=0#验证用，需要1.16.1之后的release版本#referer=*#文件保存路径, 默认为当前启动位置# dir=/user-files/superuser/dir=/data#文件缓存, 使用内置的文件缓存, 如果你不相信Linux内核文件缓存和磁盘内置缓存时使用, 需要1.16及以上版本#disk-cache=0#另一种Linux文件缓存方式, 使用前确保您使用的内核支持此选项, 需要1.15及以上版本(?)enable-mmap=true#文件预分配, 能有效降低文件碎片, 提高磁盘性能. 缺点是预分配时间较长#所需时间 none &lt; falloc ? trunc « prealloc, falloc和trunc需要文件系统和内核支持file-allocation=prealloc# General Optionslog=/var/log/aria2.log#You can set either debug, info, notice, warn or error.log-level=error## 进度保存相关 ### 从会话文件中读取下载任务input-file=/root/conf/aria2.session# 在Aria2退出时保存`错误/未完成`的下载任务到会话文件save-session=/root/conf/aria2.session# 定时保存会话, 0为退出时才保存, 需1.16.1以上版本, 默认:0save-session-interval=10# BT trackers from https://raw.githubusercontent.com/ngosang/trackerslist/master/trackers_best.txtbt-tracker=udp://tracker.leechers-paradise.org:6969/announce, udp://tracker.internetwarriors.net:1337/announce, udp://tracker.opentrackr.org:1337/announce, udp://9.rarbg.to:2710/announce, udp://tracker.coppersurfer.tk:6969/announce, udp://exodus.desync.com:6969/announce, udp://explodie.org:6969/announce, http://tracker3.itzmx.com:6961/announce, udp://tracker1.itzmx.com:8080/announce, udp://tracker.tiny-vps.com:6969/announce, udp://thetracker.org:80/announce, udp://open.demonii.si:1337/announce, udp://denis.stalker.upeer.me:6969/announce, udp://bt.xxx-tracker.com:2710/announce, http://tracker4.itzmx.com:2710/announce, udp://tracker2.itzmx.com:6961/announce, udp://tracker.torrent.eu.org:451/announce, udp://tracker.port443.xyz:6969/announce, udp://tracker.cyberia.is:6969/announce, udp://open.stealth.si:80/announce 使用h5ai作为文件管理器1234567891011121314151617181920212223242526272829version: &apos;3.4&apos;services: h5ai: image: bixidock/h5ai volumes: - /home/ybd/data/docker/aria2/data:/var/www restart: always aria2: image: wahyd4/aria2-ui:h5ai ports: - &quot;8000:80&quot; - &quot;6800:6800&quot; volumes: # - /some_folder:/root/conf/key - /home/ybd/data/docker/aria2/config/aria2.conf:/root/conf/aria2.conf - /home/ybd/data/docker/aria2/config/aria2.session:/root/conf/aria2.session - /home/ybd/data/docker/aria2/cache/dht.dat:/root/.cache/aria2/dht.dat - /home/ybd/data/docker/aria2/data:/data environment: - DOMAIN=:80 # - SSL=true # - RPC_SECRET=Hello # - ARIA2_USER=admin # - ARIA2_PWD=password # - ENABLE_AUTH=true links: - h5ai:file-manager restart: always 查看文件h5ai： http://localhost:8000 AriaNg： http://localhost:8000/aria2/ 注意地址后面一定要带/ 百度网盘相关BaiduExporter 官方是这么说明的 Chrome : Click Settings -&gt; Extensions, drag BaiduExporter.crx file to the page, install it, or check Developer mode -&gt; Load unpacked extension, navigate to the chrome/release folder. Firefox : Open about:debugging in Firefox, click “Load Temporary Add-on” and navigate to the chrome/release folder, select manifest.json, click OK. 1、到 Github 下载源码 2、打开Chrome -&gt; 扩展程序 -&gt; 勾选开发者模式 -&gt; 加载已解压的扩展程序 , 然后会弹出文件框, 找到刚才下载的源码, 找到chrome -&gt; release, 添加成功！ 3、打开百度云盘网页版, 勾选需要下载的文件, 在上方会出现导出下载地选项, 通过设置可以修改RCP地址 BaiduPCS-Go这里还有一个很有意思的通过终端与百度盘交互的项目: https://github.com/iikira/BaiduPCS-Go 百度网盘直接下载助手1、安装 Tampermonkey Chrome插件, 这个主要是管理脚本的, 下面安装百度云盘脚本需要用到 2、进入 百度网盘直接下载助手(显示直接下载入口) , 点击安装或者install,完了直接刷新界面, 进入到自己的百度云盘选择所需的下载文件即可. Stardict火星译王1sudo apt install stardict 安装词库: 进入http://download.huzheng.org/选择所需词库并下载, a为下载的词库名, 然后重启stardict 12tar -xjvf a.tar.bz2mv a /usr/share/stardict/dic 备份工具 Timeshift12sudo add-apt-repository -y ppa:teejee2008/ppasudo apt install -y timeshift 硬件信息I-Nex这是一个类似CPU-Z的工具 下载链接: https://launchpad.net/i-nex/+download Hardinfo1sudo apt install hardinfo -y Deepin Wine For Ubuntu这个项目是 Deepin-wine 环境的 Ubuntu 移植版, 可以在 Ubuntu 上运行 Tim, 微信, 网易云音乐, 百度云网盘, 迅雷等 Windows 软件: https://github.com/wszqkzqk/deepin-wine-ubuntu 这个是 Docker 版本的: https://github.com/RokasUrbelis/docker-wine-linux 其他设置篇exfat驱动1sudo apt install exfat-fuse exfat-utils Grub2设置引导等待时间Ubuntu系统的Grub2菜单的相关信息在读取/boot/grub/grub.cfg文件, 不过Ubuntu官方不建议直接修改这个文件, 想要修改Grub2的等待时间还可以修改/etc/deafalt/grub来实现. 具体的修改方法如下: 1sudo gedit /etc/default/grub 将GRUB_TIMEOUT=10中的10改为你想要修改的等待时间, 比如3, 网上很多的教程都是到这一步, 其实是不行的, 估计都是乱转一气. 到这里还有最重要的一步, 就是使用#号将GRUB_HIDDEN_TIMEOUT=0标注,然后再次回到终端, 输入下面的命令刷新/boot/grub/grub.cfg文件:1sudo update-grub2 Grub Customizer12sudo add-apt-repository -y ppa:danielrichter2007/grub-customizersudo apt install grub-customizer 修改保存后更新配置文件: 1sudo update-grub 启动项管理1gnome-session-properties 统一Win10和Ubuntu18.04双系统的时间装了双系统会出现win10中的时间总是慢8个小时（时区不对） 1统一Win10和Ubuntu18.04双系统的时间 方式一1timedatectl set-local-rtc 1 --adjust-system-clock 方式二123sudo apt install ntpdatesudo ntpdate time.windows.comsudo hwclock --localtime --systohc 提高逼格screenfetch1sudo apt install screenfetch edex-ui https://github.com/GitSquared/edex-ui 在Release页面中下载AppImage运行即可: 终端高逼格屏保12sudo apt install cmatrixcmatrix -b 够骚气. . . 键盘输入声音特效（Tickys）官网 或者 博主的百度盘 (密码: 9bpi) Tickeys依赖 gksu, 然而 gksu 在Ubuntu18之后被移除了, 所以想要安装还需要装回 gksu: 123456789cat &lt;&lt;EOF | sudo tee /etc/apt/sources.list.d/artful.listdeb http://archive.ubuntu.com/ubuntu/ artful universeEOFsudo apt updatesudo apt install -i gksusudo dpkg -i tickeys_0.2.5_amd64.deb# 如有依赖未安装sudo apt install -f 然后通过sudo tickeys来打开 (sudo tickeys -c 打开CLI版本) 附录软件图标（.desktop）文件位置 /usr/share/applications # 大部分启动图标都在此 ~/.local/share/applications # 一部分本地图标 /var/lib/snapd/desktop/applications # snap 类软件在此 gsetting 与 dconfgsetting 与 dconf 是 Linux Gnome下实现对应用程序的配置及管理功能的工具. gsetting命令: 12345678910#gsettings list-schemas 显示系统已安装的不可重定位的schema#gsettings list-relocatable-schemas 显示已安装的可重定位的schema#gsettings list-children SCHEMA 显示指定schema的children，其中SCHEMA指xml文件中schema的id属性值，例如实例中的&quot;org.lili.test.app.testgsettings&quot;#gsettings list-keys SCHEMA 显示指定schema的所有项(key)#gsettings range SCHEMA KEY 查询指定schema的指定项KEY的有效取值范围#gsettings get SCHEMA KEY 显示指定schema的指定项KEY的值#gsettings set SCHEMA KEY VALUE 设置指定schema的指定项KEY的值为VALUE#gsettings reset SCHEMA KEY 恢复指定schema的指定项KEY的值为默认值#gsettings reset-recursively SCHEMA 恢复指定schema的所有key的值为默认值#gsettings list-recursively [SCHEMA]如果有SCHEMA参数，则递归显示指定schema的所有项(key)和值(value)，如果没有SCHEMA参数，则递归显示所有schema的所有项(key)和值(value) dconf 可以实现配置的导入与导出: 123456789dconf dump /org/gnome/shell/extensions/dynamic-top-bar/ &gt; ~/backup.txtdconf load /org/gnome/shell/extensions/topicons/ &lt;&lt;- EOF[/]icon-size=24icon-spacing=12tray-pos=&apos;right&apos;tray-order=1EOF 也可以使用 dconf-editor 对其进行管理 1sudo apt install -y dconf-editor 终端写出图形文字Text to ASCII Art Generator Finally 参考: https://inkss.cn/2018/09/12/ubuntu-1804-installation-record/ https://www.jianshu.com/p/23b0d3015db8 https://blog.diqigan.cn/posts/ubuntu-18-10-beautify.html 使用Ubuntu的这一路过来真的是跌跌撞撞, 一路摸爬滚打不断解决各种奇怪的系统问题, 磨合了也有好长一段日子, 重装系统的次数也数不过来了. . . 给我最大的收获并不是觉得自己用Ubuntu用得多牛X, 而是锻炼意志. . . 本文将定期更新, 与时俱进~]]></content>
      <categories>
        <category>OperatingSystem</category>
        <category>Ubuntu</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu16.04下MyEclipse安装与破解]]></title>
    <url>%2F2017%2Fubuntu-myeclipse-crack%2F</url>
    <content type="text"><![CDATA[前言 之前一直用的是Eclipse Luna, 没有用MyEclipse是因为它收钱的- -, 去新公司工作需要用到MyEclipse, 下载安装happy地试用了将近一个月, 不幸, 试用期已过. 身为一个开源爱好者, 不想去用破解的（虚伪 - -）, 也不想出钱, 博主秉着屌丝的意志, 一番折腾过后, 搞定. 以下是经过参考与总结得到的操作步骤, 博主用的是Linux的发行版Ubuntu, 所以以下步骤针对Ubuntu系统, win与mac的步骤也大同小异. 下载与安装首先, 请前往MyEclipse的官网 下载相应系统的版本, 我选择的是MyEclipse-2015-stable-3.0-offline-installer-linux.run, 进入放置安装文件的目录, 右键在终端打开安装文件 1./MyEclipse-2015-stable-3.0-offline-installer-linux.run 按Nest设置一下安装路径完成安装, 安装完之后不要选择运行MyEclipse 破解之前请不要开启你的MyEclipse, 要保持刚安装完的状态, 如果你已经开过了, 卸载重装吧——否则你就会遭遇打开编译器, 然后校验失败, 报错关闭 破解与运行首先请前往博主的百度盘（密码: kv25）下载对应的破解工具, 我的MyEclipse版本是2015-stable-3.0, 所以在这以此版本作为示范. 下载到本地解压后并进入目录会有以下文件 打开注册机进入MyEclipse2015_keygen, 双击打开注册机cracker2015.jar, 失败的话, 用java命令打开cracker2015.jar, 前提都是你要安装了JDK并且配置好环境, JDK版本最好不要太旧, 我的是1.8 当前目录终端执行: 1java -jar cracker2015.jar 运行之后出现如下界面 ↓ 开始生成注册信息 在算号器填好Usercode,UserCode可以随意输入 选择版本: 由于Bling版功能最全, 所以我选择了这个版本（其他版本也可以） 然后点击”SystemId”按钮, 就会出现一行ID值, 如果提示 Cannot find JNIWrapper native library (jniwrap.dll) in java.library.path:这样的错误, 不要紧, 再点一下应该就出来了, 还是没有的话请注意权限问题 点击Active 保存破解信息: 点Tools下的SaveProperites把破解信息（注册码）保存到文件 （注意不要手残去点RebuildKey- - !） copy文件把plugins文件中的文件复制到MyEclipse的plugins文件夹中, 覆盖原文件 运行MyEclipse打开了MyEclipse, 点击菜单栏中的MyEclipse-&gt;Subscription information, 激活成功, 激动ing=.= 最后以上是博主在Ubuntu中安装破解MyEclipse的总结过程, 对于不同的环境, 不同的版本, 不同的操作, 有可能会导致一些不一样的小问题, 那么可以在一下参考中找到一些答案 参考: Myeclipse 2015 stable 1.0 完美破解方法Myeclipse 2016 CI 6 破解]]></content>
      <categories>
        <category>IDE</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>IDE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Start My Blog Trip — Power By Hexo]]></title>
    <url>%2F2017%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Life is a generic method like [ public Life doSomething(T t){} ],T is the part of life that requires you to play in a period of time,and the method will return a life you expect if you to be T. —— 沃·兹基硕德 为什么要写博客？除了可以将自己在工作学习中的一些知识及经验记录下来. 不断积累知识, 不断总结经验以外, 更重要的是 为了保持逼格, 不要停止写作 . 虽然高中的语文从来都没有及格过, 作文也写得挺烂, 但我会尽力得用我拙劣的语言把每一篇博客都写好… 引用一下别人的话 喜欢写Blog的人, 会经历三个阶段第一阶段, 刚接触Blog, 觉得很新鲜, 试着选择一个免费空间来写.第二阶段, 发现免费空间限制太多, 就自己购买域名和空间, 搭建独立博客.第三阶段, 觉得独立博客的管理太麻烦, 最好在保留控制权的前提下, 让别人来管, 自己只负责写文章. 之前学习的时候, 看别人的一些文章、博客跟着造轮子, 然而过几天就不记得了又要到搜索引擎翻一番看一看, 觉得很麻烦（因为博主比较懒= =）. 然后决定自己注册一个博客论坛整理一下知识点, 之后发现大神们都有自己的搭建博客, 都很不错, 于是乎跟着造轮子, 几天折腾, 总算把这个博客搭建完成并且做了一些优化. 语文不好, 废话也不多说了, 我个人搭建Hexo博客的过程-&gt;传送门.最后, 请允许我分享一篇很好的文章: 《为什么你要写博客？》 为什么你要写博客？ 一个选择我知道现在可能说这话有点不合时宜, 毕竟博客时代都已经过去了, 再号召大家用过就好像时的东西是不是有点逆流而上？ 我曾经也问过自己这个问题, 但是我觉得, 博客时代过去跟我们要开博客是没有多大关系的, 就好像你的读书时代已经过去你就不再读书一样. 判断一件事情值不值得去做有一个方法: 在一张白纸的左边写不值得做的原因, 然后在右边写值得做的原因, 写完一比较, 一权衡, 自然能够得出结果. 大家都成年人了, 你会觉得这样思考分析总结的过程才是正确的思考的方法吧？ 所以, 我在这里列出要写（独立）博客的原因, 供大家去选择, 然后填在你白纸的右边. 注意, 我不是给你一个建议, 而是提供一个选择, 这个选择蕴藏着我也不知道的可能. 博客的内容写博客不难, 你可以当作是生活的记录, 但是这样的记录没有任何的意义. 写要对得住写本身, 写出来的东西应该是思考的结果. 我认为, 如果你要开一个博客, 博客的内容应该是这样的: 1、 不是生活杂记、不是流水账、不是牢骚、不是抱怨、不是心情琐记……； 2、 有目的地写, 要务实, 追求质量； 3、 承认真实的自己, 不要吹嘘, 不要装逼, 无需讨好读者； 4、 记录自己学习、思考、总结的过程； 5、 分享你的故事、所得、感想、经验； 6、你对钱怎么看, 你认为赚到多少钱是足够的？如果你明天一早醒来, 已经有足够的钱, 你将会如何继续安排自己的生活？ 7、对你来说, 什么是理想的性生活？什么是理想的性道德, 在你的性道德观中, 什么样的性生活是禁忌的, 需要避免的, 什么样的性生活是美好的, 需要得到鼓励和发展的？ 8、你的择友标准是什么？什么样的人你会愿意交往, 什么样的人你会拒绝和他交往？ 9、你对死亡怎么看？你希望自己活到多少岁, 你准备怎么度过从现在到死亡的这段时间？如果你要立遗嘱, 这份遗嘱会怎么写？ 以上的这九个问题摘自《很少人能顺畅回答这9个问题——心理治疗刚开始医生常常会先问你的 》by 李孟潮. 这些问题的答案你可以选择不发, 但是我强烈地建议写下来, 只有在写的时候你才可以慎重地思考这些问题, 而不会回避跳过或者留下空白, 这是接受自己的第一步. 提供持续学习的动力例如, 我为自己设限每天写一千字, 信息的不断输出给我带来恐惧, 我害怕有一天我写无可写, 于是我不停地阅读, 通过个人的知识管理促使自己不断学习, 提高核心竞争力. 详细的知识管理可以看我的这篇文章: 《个人知识管理的方法》, 回复「知识」可见 积累更多的知识写并不是单纯的写. 例如你写着写着, 你突然忘记了一个概念, 于是上网找, 找回来这个概念的时候, 你重温这个概念, 可能还会顺便看了一下这个概念的其他东西. 例如你需要获取第一手的资料, 寻找信息来源本身就是一个知识积累的过程, 同时, 你慢慢就学会了鉴别知识: 什么是没有用的心灵鸡汤, 什么是不值得关注的吐槽名人, 还有, 在这个过程中, 你还养成你的心智. 提高将事情讲清楚的能力很多东西你以为懂了, 但当你在写下来的时候, 你就觉得无从下手了. 如果一件事情你不能讲清楚, 十有八九你还没有完全理解. 将事情写下来, 慢慢就可以提高你的逻辑思维能力, 分析能力, 写会迫使你在你脑中搭建一个有条理的框架. 例如我写这篇文章一样, 我就将值得写博客的原因一点一点地罗列出来, 事情就更加清晰, 你也可以更好的思考问题. 分享带来的连锁反应 “通过分享, 你获得了直接而快速的回报, 你最终或许会发现你已将版权和“保留所有权利”抛诸脑后. 新的经济学准则是: 参与你作品的人越多, 回报越高. 在分享主义里, 如果你愿意你可以保留所有权, 但是我乐于分享. ” by 毛向辉 《分享主义: 一场思维革命》 互联网精神其中最重要的就是分享主义, 基于分享主义, 你可以享受到社会化及互联网给你带来的种种便利和好处, 你分享了一个知识, 你就成为了互联网中的一个点, 这个点的大小由你自己来决定, 互联网的大潮会将你的这个点推送到它所能触及的每个角落, 让需要的人得到, 同时, 你的这个点也会继续扩大, 连接到整个网络, 这个点有可能连接成一张网, 而你就是这张网的中心. 帮你找到志同道合的人在微博, 在朋友圈, 你可能找不到跟你志同道合的人, 而在博客, 你可以通过看他的几篇文章就迅速地理解认同这个人, 即使你没有见过这个人, 但你也可以通过这种关联来相互学习. 如果你在一个领域有相当的了解, 你将这些内容发在网络上, 网络上跟你志趣相投的人也会被你吸引过来, 根据吸引力法则, 你是怎样的人你就被怎么样的人吸引, 这就是博客所能赋予你的魅力. 即使博客没有被他人关注, 我们依然可以找到同好, 你可以自己将博文转载到其他站点, 人们会通过搜索引擎找到你, 有邮件、微博等工具, 我们不乏与他人交流的途径. by Gabriel Weinberg《Why I blog》 记录成长隔一段时间, 你再回头看你写的博客, 你会发现自己正在通过这样的方式在不断的成长, 这种成长在自己眼里是一种财富, 在别人眼里是一张地图, 你得到了收获, 不断修正自己的错误, 别人得到了指引, 避免走弯路. 更多的情况是当你回望自己的时候你会发现自己是一个傻逼, so what, that is what I am！ 培养持续做一件事情的能力开始是坚持, 后来是习惯, 接着喜欢. 以后当有人对你说, 「你写那么多有用的东西, 你真的很厉害啊！」你可以笑而不语, 也可以大声说道: 「你妹, 你不知道我开始的时候多么痛苦！」 让你长久地去跑步, 你可能做不到；让你每个月看一本书, 你也可能做不到；但让你持续地写一个博客, 你可以做得到. 你不相信？你不试试你怎么知道？ 默默地持续做一件事是一种难得的能力, 也是一种难得的品质. 讨论反思每人都会有思维的盲点, 就好像这篇文章一样, 可能你觉得我可能说得不对, 你可以反驳我, 我欢迎这种讨论, 因为讨论的过程中会产生各种的思维的碰撞, 这种碰撞会让你反思, 也会激发出你新的灵感, 这种讨论反思给自己的带来巨大的受益. 互联网给你的反馈就是让你承受更多, 接受更多, 成为一个更好的人. 搜寻到你意想不到东西世界不止是你的家, 你的公司, 你的朋友圈, 你应该去发现一个更大的世界, 通过写博客, 你会知道世界上还有很多人像你一样在写博客, 这些人和知识正在世界的某个角落在等着你. 例如, 在写这篇文章的过程中, 我才知道了Gabriel Weinberg, 我才要将阳志平的博客重读一遍. 写的过程会让你有很多新的发现, 这些新的发现都值得你去再写下来, 总结分享出去. 一个人在做一件属于自己的事很多你认为自己很牛逼的事情都是自己一个人做出来. 别人在刷微博, 你在看书, 别人在看穿越剧, 你在学英文, 别人在去唱K, 你在写个人总结. 吃饭也要找同伴, 出游要找同伴, 看电影要找同伴, 你上一次一个人在做一件属于自己的事是在什么时候？ 如果你想要清晰地思考, 就必须远离人群. 但是走得越远, 你的处境就会越困难, 收到的阻力也会越大. 因为你没有迎合社会习俗, 而是一步步地与它背道而驰. 如果自己就是潮水的一部分 , 怎么能看见潮流的方向呢？你只能永远保持质疑, 问自己, 什么话是我不能说的？为什么？——Paul Graham《不能说的话》 互联网的身份识别 一个长期的价值博客是一份很好的简历. 这里的“简历”并非是狭义上的求职简历, 毕竟现在还没有到价值博客的时代, 很多人写博客都是到处转载或者干脆碎碎念, 正因此面试官未必拿个人博客当成了解一个人的更可靠窗口. 这里的“简历”是指一个让别人了解自己的窗口, 虽然我们未必做得到像罗永浩、Keso这样的博客, 个人的影响力已经足以支撑出一份事业（牛博和5gme）, 但至少你会因此而结识更多的人, 你的博客价值越高, 你结识的人就越牛, 跟牛人交流又会让你的眼界得到极大的开阔, 打开一扇又一扇你原本不知道的门, 于是你就变得更牛… 这是一个良性循环. by 刘未鹏 最后你可能想不到在白纸的左边（不值得写博客的原因）写什么了, 想不到写个「博客时代已经过去」或者「我没有时间」也可以, 但与此同时, 你也可以用那些时间去思考一下「怎么做到长期写一个价值博客」. 如果你不想思考, 也可以回复「价值」看看别人的建议.]]></content>
      <categories>
        <category>Essay</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
</search>
