<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Spring Boot应用集成Docker并结合Kafka、ELK管理Docker日志]]></title>
    <url>%2F2018%2Fspring-boot-docker-elk%2F</url>
    <content type="text"><![CDATA[微服务架构下，微服务在带来良好的设计和架构理念的同时，也带来了运维上的额外复杂性，尤其是在服务部署和服务监控上。单体应用是集中式的，就一个单体跑在一起，部署和管理的时候非常简单，而微服务是一个网状分布的，有很多服务需要维护和管理，对它进行部署和维护的时候则比较复杂。Spring Boot Docker Integration准备工作DockerIDE（使用IDEA）Maven环境Docker私有仓库集成Docker需要的插件docker-maven-plugin：https://github.com/spotify/docker-maven-pluginMaven setting.xml密码加密配置settings.xml配置私有库的访问：首先使用你的私有仓库访问密码生成主密码：1mvn --encrypt-master-password &lt;password&gt; 其次在settings.xml文件的同级目录创建settings-security.xml文件，将主密码写入： 1234&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;settingsSecurity&gt; &lt;master&gt;&#123;Ns0JM49fW9gHMTZ44n*****************=&#125;&lt;/master&gt;&lt;/settingsSecurity&gt; 最后使用你的私有仓库访问密码生成服务密码，将生成的密码写入到settings.xml的&lt;services&gt;中（可能会提示目录不存在，解决方法是创建一个.m2目录并把settings-security.xml复制进去） 12mvn --encrypt-password &lt;password&gt;&#123;D9YIyWYvtYsHayLjIenj***********=&#125; 12345678&lt;server&gt; &lt;id&gt;docker-registry&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;&#123;gKLNhblk/SQHBMooM******************=&#125;&lt;/password&gt; &lt;configuration&gt; &lt;email&gt;yangbingdong1994@gmail.com&lt;/email&gt; &lt;/configuration&gt;&lt;/server&gt; 构建基础镜像Dockerfile： 123456789101112FROM frolvlad/alpine-oraclejdk8:slimMAINTAINER ybd &lt;yangbingdong1994@gmail.com&gt;ARG TZ ARG HTTP_PROXYENV TZ=$&#123;TZ:-&quot;Asia/Shanghai&quot;&#125; http_proxy=$&#123;HTTP_PROXY&#125; https_proxy=$&#123;HTTP_PROXY&#125;RUN apk update &amp;&amp; \ apk add --no-cache &amp;&amp; \ apk add curl bash tree tzdata &amp;&amp; \ ln -snf /usr/share/zoneinfo/$TZ /etc/localtime &amp;&amp; \ echo $TZ &gt; /etc/timezone ENV http_proxy=ENV https_proxy= 构建： 1docker build --build-arg HTTP_PROXY=192.168.6.113:8118 -t yangbingdong/docker-oraclejdk8 . 其中HTTP_PROXY是sock5代理转过来的http代理，通过--build-arg参数传入，注意不能是127.0.0.1或localhost。 开始集成编写Dockerfile在src/main下面新建docker文件夹，并创建Dockerfile： 1234567FROM yangbingdong/docker-oraclejdk8:latestMAINTAINER yangbingdong &lt;yangbingdong1994@gmail.com&gt;ENV PROJECT_NAME=&quot;@project.build.finalName@.@project.packaging@&quot; JAVA_OPTS=&quot;&quot;ADD $PROJECT_NAME app.jarRUN sh -c &apos;touch /app.jar&apos;CMD [&quot;sh&quot;, &quot;-c&quot;, &quot;java $JAVA_OPTS -Djava.security.egd=file:/dev/./urandom -Dspring.profiles.active=$&#123;ACTIVE:-docker&#125; -jar /app.jar&quot;]# ENTRYPOINT [ &quot;sh&quot;, &quot;-c&quot;, &quot;java $JAVA_OPTS -Djava.security.egd=file:/dev/./urandom -jar /app.jar&quot; ] 通过@@动态获取打包后的项目名（需要插件，下面会介绍） Dspring.profiles.active=${ACTIVE:-docker}可以通过docker启动命令-e ACTIVE=docker参数修改配置 pom文件添加Docker插件在完整的pom.xml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495&lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-boot.version&#125;&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;repackage&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;!-- resources插件，使用@变量@形式获取Maven变量到Dockerfile中 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;version&gt;$&#123;resources.plugin.version&#125;&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;prepare-dockerfile&lt;/id&gt; &lt;phase&gt;validate&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;copy-resources&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;!-- 编译后Dockerfile的输出位置 --&gt; &lt;outputDirectory&gt;$&#123;dockerfile.compiled.position&#125;&lt;/outputDirectory&gt; &lt;resources&gt; &lt;!-- Dockerfile位置 --&gt; &lt;resource&gt; &lt;directory&gt;$&#123;project.basedir&#125;/src/main/docker&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;!-- 集成Docker maven 插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;docker-maven-plugin&lt;/artifactId&gt; &lt;version&gt;$&#123;docker-maven-plugin.version&#125;&lt;/version&gt; &lt;executions&gt; &lt;!-- 打包时构建镜像 --&gt; &lt;execution&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;build&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;!-- 部署时推送镜像到私有库 --&gt; &lt;execution&gt; &lt;id&gt;push-image&lt;/id&gt; &lt;phase&gt;install&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;push&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;imageName&gt;$&#123;docker.registry.url&#125;/$&#123;docker.registry.name&#125;/$&#123;project.artifactId&#125;:$&#123;docker-latest-tag&#125;&lt;/imageName&gt; &lt;imageName&gt;$&#123;docker.registry.url&#125;/$&#123;docker.registry.name&#125;/$&#123;project.artifactId&#125;:$&#123;project.version&#125;&lt;/imageName&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;!-- 是否构建镜像 --&gt; &lt;skipDocker&gt;$&#123;docker.skip.build&#125;&lt;/skipDocker&gt; &lt;!--最后镜像产生了两个tag，版本和和最新的--&gt; &lt;forceTags&gt;true&lt;/forceTags&gt; &lt;imageTags&gt; &lt;imageTag&gt;$&#123;project.version&#125;&lt;/imageTag&gt; &lt;imageTag&gt;$&#123;docker-latest-tag&#125;&lt;/imageTag&gt; &lt;/imageTags&gt; &lt;!--install阶段也上传，否则只有deploy阶段上传--&gt; &lt;pushImage&gt;$&#123;docker.push.image&#125;&lt;/pushImage&gt; &lt;!-- 配置镜像名称，遵循Docker的命名规范： springio/image --&gt; &lt;imageName&gt;$&#123;docker.registry.url&#125;/$&#123;docker.registry.name&#125;/$&#123;project.artifactId&#125;&lt;/imageName&gt; &lt;!-- Dockerfile位置，由于配置了编译时动态获取Maven变量，真正的Dockerfile位于位于编译后位置 --&gt; &lt;dockerDirectory&gt;$&#123;dockerfile.compiled.position&#125;&lt;/dockerDirectory&gt; &lt;resources&gt; &lt;resource&gt; &lt;targetPath&gt;/&lt;/targetPath&gt; &lt;directory&gt;$&#123;project.build.directory&#125;&lt;/directory&gt; &lt;include&gt;$&#123;project.build.finalName&#125;.jar&lt;/include&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;!-- push到私有的hub --&gt; &lt;serverId&gt;docker-registry&lt;/serverId&gt; &lt;registryUrl&gt;$&#123;docker.registry.url&#125;&lt;/registryUrl&gt; &lt;/configuration&gt; &lt;/plugin&gt;&lt;/plugins&gt; 主要properties: 123456789101112&lt;properties&gt; &lt;!-- ########## Docker 相关变量 ########## --&gt; &lt;resources.plugin.version&gt;3.0.2&lt;/resources.plugin.version&gt; &lt;docker-maven-plugin.version&gt;1.0.0&lt;/docker-maven-plugin.version&gt; &lt;!-- resource插件编译Dockerfile后的位置--&gt; &lt;dockerfile.compiled.position&gt;$&#123;project.build.directory&#125;/docker&lt;/dockerfile.compiled.position&gt; &lt;docker.skip.build&gt;true&lt;/docker.skip.build&gt; &lt;docker.push.image&gt;false&lt;/docker.push.image&gt; &lt;docker.registry.url&gt;192.168.0.202:8080&lt;/docker.registry.url&gt; &lt;docker.registry.name&gt;dev-images&lt;/docker.registry.name&gt; &lt;docker-latest-tag&gt;latest&lt;/docker-latest-tag&gt;&lt;/properties&gt; 说明： 这里的serverId要与maven setting.xml里面的一样 Dockerfile构建文件在src/main/docker中 如果Dockerfile文件需要maven构建参数（比如需要构建后的打包文件名等），则使用@@占位符（如@project.build.finalName@）原因是Sping Boot 的pom将resource插件的占位符由${}改为@@，非继承Spring Boot 的pom文件，则使用${}占位符 如果不需要动态生成Dockerfile文件，则可以将Dockerfile资源拷贝部分放入docker-maven-plugin插件的&lt;resources&gt;配置里 spring-boot-maven-plugin插件一定要在其他构建插件之上，否则打包文件会有问题。 命令构建如果&lt;pushImage&gt;false&lt;/pushImage&gt;则install阶段将不提交Docker镜像，只有maven的deploy阶段才提交。 1mvn clean install 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364[INFO] --- spring-boot-maven-plugin:1.5.9.RELEASE:repackage (default) @ eureka-center-server ---[INFO] [INFO] --- docker-maven-plugin:1.0.0:build (default) @ eureka-center-server ---[INFO] Using authentication suppliers: [ConfigFileRegistryAuthSupplier, NoOpRegistryAuthSupplier][WARNING] Ignoring run because dockerDirectory is set[INFO] Copying /home/ybd/data/git-repo/bitbucket/ms-iba/eureka-center-server/target/eureka-center-server-0.0.1-SNAPSHOT.jar -&gt; /home/ybd/data/git-repo/bitbucket/ms-iba/eureka-center-server/target/docker/eureka-center-server-0.0.1-SNAPSHOT.jar[INFO] Copying /home/ybd/data/git-repo/bitbucket/ms-iba/eureka-center-server/target/docker/eureka-center-server-0.0.1-SNAPSHOT.jar -&gt; /home/ybd/data/git-repo/bitbucket/ms-iba/eureka-center-server/target/docker/eureka-center-server-0.0.1-SNAPSHOT.jar[INFO] Copying /home/ybd/data/git-repo/bitbucket/ms-iba/eureka-center-server/target/docker/Dockerfile -&gt; /home/ybd/data/git-repo/bitbucket/ms-iba/eureka-center-server/target/docker/Dockerfile[INFO] Building image 192.168.6.113:8888/discover-server/eureka-center-serverStep 1/7 : FROM frolvlad/alpine-oraclejdk8:slim ---&gt; 491f45037124Step 2/7 : MAINTAINER ybd &lt;yangbingdong1994@gmail.com&gt; ---&gt; Using cache ---&gt; 016c2033bd32Step 3/7 : VOLUME /tmp ---&gt; Using cache ---&gt; d2a287b6ed52Step 4/7 : ENV PROJECT_NAME=&quot;eureka-center-server-0.0.1-SNAPSHOT.jar&quot; JAVA_OPTS=&quot;&quot; ---&gt; Using cache ---&gt; 34565a7de714Step 5/7 : ADD $PROJECT_NAME app.jar ---&gt; 64d9055ce969Step 6/7 : RUN sh -c &apos;touch /app.jar&apos; ---&gt; Running in 66f4eb550a57Removing intermediate container 66f4eb550a57 ---&gt; 93486965cad9Step 7/7 : CMD [&quot;sh&quot;, &quot;-c&quot;, &quot;java $JAVA_OPTS -Djava.security.egd=file:/dev/./urandom -Dspring.profiles.active=$&#123;ACTIVE:-docker&#125; -jar /app.jar&quot;] ---&gt; Running in 8b42c471791fRemoving intermediate container 8b42c471791f ---&gt; 2eb3dbbab6c5ProgressMessage&#123;id=null, status=null, stream=null, error=null, progress=null, progressDetail=null&#125;Successfully built 2eb3dbbab6c5Successfully tagged 192.168.6.113:8888/discover-server/eureka-center-server:latest[INFO] Built 192.168.6.113:8888/discover-server/eureka-center-server[INFO] Tagging 192.168.6.113:8888/discover-server/eureka-center-server with 0.0.1-SNAPSHOT[INFO] Tagging 192.168.6.113:8888/discover-server/eureka-center-server with latest[INFO] Pushing 192.168.6.113:8888/discover-server/eureka-center-serverThe push refers to repository [192.168.6.113:8888/discover-server/eureka-center-server]40566d372b69: Pushed 40566d372b69: Layer already exists 4fd38f0d6712: Layer already exists d7cd646c41bd: Layer already exists ced237d13962: Layer already exists 2aebd096e0e2: Layer already exists null: null null: null [INFO] [INFO] --- maven-install-plugin:2.4:install (default-install) @ eureka-center-server ---[INFO] Installing /home/ybd/data/git-repo/bitbucket/ms-iba/eureka-center-server/target/eureka-center-server-0.0.1-SNAPSHOT.jar to /home/ybd/data/application/maven/maven-repo/com/iba/server/eureka-center-server/0.0.1-SNAPSHOT/eureka-center-server-0.0.1-SNAPSHOT.jar[INFO] Installing /home/ybd/data/git-repo/bitbucket/ms-iba/eureka-center-server/pom.xml to /home/ybd/data/application/maven/maven-repo/com/iba/server/eureka-center-server/0.0.1-SNAPSHOT/eureka-center-server-0.0.1-SNAPSHOT.pom[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 15.962 s[INFO] Finished at: 2017-12-25T13:33:39+08:00[INFO] Final Memory: 55M/591M[INFO] ------------------------------------------------------------------------ 可以看到本地以及私有仓库都多了一个镜像： 此处有个疑问，很明显看得出来这里上传了两个一样大小的包，不知道是不是同一个jar包，但id又不一样： 运行Docker运行程序 1docker run --name some-server -e ACTIVE=docker -p 8080:8080 -d [IMAGE] 添加运行时JVM参数只需要在Docker启动命令中加上-e &quot;JAVA_OPTS=-Xmx128m&quot;即可 Kafka、ELK collect logs 传统的应用可以将日志存到日志中，但集成Docker之后，日志怎么处理？放到容器的某个目录然后挂在出来？这样也可以，但这样就相当于给容器与外界绑定了一个状态，弹性伸缩怎么办？个人还是觉得通过队列与ELK管理Docker日志比较合理，而且Log4j2原生支持Kafka的Appender。 镜像准备Docker Hub中的ELK镜像并不是最新版本的，我们需要到官方的网站获取最新的镜像：https://www.docker.elastic.co 12345docker pull zookeeperdocker pull wurstmeister/kafka:1.0.0docker pull docker.elastic.co/elasticsearch/elasticsearch:6.2.3docker pull docker.elastic.co/kibana/kibana:6.2.3docker pull docker.elastic.co/logstash/logstash:6.2.3 注意ELK版本最好保持一致 程序Log4j2配置SpringBoot版本：2.0 log4j2.xml: 123456789101112131415161718192021222324252627282930&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;configuration status=&quot;OFF&quot; monitorInterval=&quot;30&quot;&gt; &lt;properties&gt; &lt;Property name=&quot;fileName&quot;&gt;logs&lt;/Property&gt; &lt;Property name=&quot;fileGz&quot;&gt;logs/7z&lt;/Property&gt; &lt;Property name=&quot;PID&quot;&gt;????&lt;/Property&gt; &lt;Property name=&quot;LOG_PATTERN&quot;&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; | %5p | $&#123;sys:PID&#125; | %15.15t | %-50.50c&#123;1.&#125; | %5L | %M | %msg%n%xwEx &lt;/Property&gt; &lt;/properties&gt; &lt;Appenders&gt; &lt;Console name=&quot;console&quot; target=&quot;SYSTEM_OUT&quot;&gt; &lt;ThresholdFilter level=&quot;info&quot; onMatch=&quot;ACCEPT&quot; onMismatch=&quot;DENY&quot;/&gt; &lt;PatternLayout pattern=&quot;$&#123;LOG_PATTERN&#125;&quot; charset=&quot;UTF-8&quot;/&gt; &lt;/Console&gt; &lt;Kafka name=&quot;kafka&quot; topic=&quot;log-collect&quot;&gt; &lt;ThresholdFilter level=&quot;info&quot; onMatch=&quot;ACCEPT&quot; onMismatch=&quot;DENY&quot;/&gt; &lt;PatternLayout pattern=&quot;$&#123;LOG_PATTERN&#125;&quot; charset=&quot;UTF-8&quot;/&gt; &lt;Property name=&quot;bootstrap.servers&quot;&gt;192.168.6.113:9092&lt;/Property&gt; &lt;/Kafka&gt; &lt;/Appenders&gt; &lt;Loggers&gt; &lt;AsyncRoot level=&quot;info&quot; includeLocation=&quot;true&quot;&gt; &lt;AppenderRef ref=&quot;console&quot;/&gt; &lt;AppenderRef ref=&quot;kafka&quot;/&gt; &lt;/AsyncRoot&gt; &lt;/Loggers&gt;&lt;/configuration&gt; bootstrap.servers是kafka的地址，接入Docker network之后可以配置成kafka:9092 topic要与下面Logstash的一致 更多配置请看官网 打印日志： 12345678910111213141516171819202122@Slf4j@Componentpublic class LogIntervalSender &#123; private AtomicInteger atomicInteger = new AtomicInteger(0); @Scheduled(fixedDelay = 2000) public void doScheduled() &#123; try &#123; int i = atomicInteger.incrementAndGet(); randomThrowException(i); log.info(&quot;&#123;&#125; send a message: the sequence is &#123;&#125; , random uuid is &#123;&#125;&quot;, currentThread().getName(), i, randomUUID()); &#125; catch (Exception e) &#123; log.error(&quot;catch an exception:&quot;, e); &#125; &#125; private void randomThrowException(int i) &#123; if (i % 10 == 0) &#123; throw new RuntimeException(&quot;this is a random exception, sequence = &quot; + i); &#125; &#125;&#125; Kafka Compose这里直接使用docker-compose（需要先创建外部网络）: 123456789101112131415161718192021222324252627282930313233343536373839version: &apos;3.4&apos;services: zoo: image: zookeeper:latest ports: - &quot;2181:2181&quot; restart: always deploy: mode: replicated replicas: 1 restart_policy: condition: on-failure delay: 60s max_attempts: 5 placement: constraints: - node.hostname == ybd-PC networks: - backend kafka: image: wurstmeister/kafka:1.0.0 ports: - &quot;9092:9092&quot; environment: KAFKA_ADVERTISED_HOST_NAME: 192.168.6.113 KAFKA_ZOOKEEPER_CONNECT: zoo:2181 volumes: - /var/run/docker.sock:/var/run/docker.sock depends_on: - zoo restart: always networks: - backendnetworks: backend: external: name: backend KAFKA_ADVERTISED_HOST_NAME是内网IP，本地调试用，Spring Boot应用使用Docker network可忽略这个 ELK Composelogstash.conf配置文件(注意下面的topics要与上面log4j2.xml中的一样): 12345678910111213141516171819202122input &#123; kafka &#123; bootstrap_servers =&gt; [&quot;kafka:9092&quot;] auto_offset_reset =&gt; &quot;latest&quot;# consumer_threads =&gt; 5 topics =&gt; [&quot;log-collect&quot;] &#125; &#125;filter &#123; #Only matched data are send to output.&#125;output &#123; stdout &#123; codec =&gt; rubydebug &#123; &#125; &#125; elasticsearch &#123; action =&gt; &quot;index&quot; #The operation on ES codec =&gt; rubydebug hosts =&gt; [&quot;elasticsearch:9200&quot;] #ElasticSearch host, can be array. index =&gt; &quot;logstash-%&#123;+YYYY.MM.dd&#125;&quot; #The index to write data to. &#125;&#125; docker-compose.yml: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546version: &apos;3.4&apos;services: elasticsearch: image: docker.elastic.co/elasticsearch/elasticsearch:6.2.3 ports: - &quot;9200:9200&quot; restart: always environment: - discovery.type=single-node - ES_JAVA_OPTS=-Xms512m -Xmx512m networks: - backend kibana: image: docker.elastic.co/kibana/kibana:6.2.3 ports: - &quot;5601:5601&quot; restart: always networks: - backend environment: - ELASTICSEARCH_URL=http://elasticsearch:9200 depends_on: - elasticsearch logstash: image: docker.elastic.co/logstash/logstash:6.2.3 ports: - &quot;4560:4560&quot; restart: always volumes: - /docker/elk/logstash/config/logstash.conf:/etc/logstash.conf networks: - backend depends_on: - elasticsearch entrypoint: - logstash - -f - /etc/logstash.conf# docker network create -d=overlay --attachable backendnetworks: backend: external: name: backend 通过这种方式管理容器应用的日志很舒服。]]></content>
      <categories>
        <category>Programming</category>
        <category>Java</category>
        <category>Spring Boot</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Docker</tag>
        <tag>Spring Boot</tag>
        <tag>Spring</tag>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[转载—自己动手写区块链]]></title>
    <url>%2F2018%2Fwrite-your-own-blockchain%2F</url>
    <content type="text"><![CDATA[区块链（英语：blockchain 或 block chain）是用分布式数据库识别、传播和记载信息的智能化对等网络, 也称为价值互联网。中本聪在2008年，于《比特币白皮书》中提出“区块链”概念，并在2009年创立了比特币社会网络，开发出第一个区块，即“创世区块”。区块链共享价值体系首先被众多的加密货币效仿，并在工作量证明上和算法上进行了改进，如采用权益证明和SCrypt算法。随后，区块链生态系统在全球不断进化，出现了首次代币发售ICO；智能合约区块链以太坊；“轻所有权、重使用权”的资产代币化共享经济； 和区块链国家。目前，人们正在利用这一共享价值体系，在各行各业开发去中心化电脑程序(Decentralized applications, Dapp)，在全球各地构建去中心化自主组织和去中心化自主社区(Decentralized autonomous society, DAS)。——来自维基百科比特币UTXO和去中心化系统的设计引用来自JoeCao大神的一段文章起因刚进2018年，区块链突然大火，程序员们可能莫名其妙，不就是一个分布式系统么，怎么突然就要改变互联网了？趁着这个东风，我们了解一些区块链基础知识。看看是否可以改变世界。UTXO是什么是Unspent Transaction Output（未消费交易输出）简写。这绝对是比特币的非常特殊的地方，理解UTXO也就理解了比特币去中心化的含义。说起UTXO必须先要介绍交易模型。以我们平时对交易的理解，我给张三转账了一笔100块钱，那就是我的账上的钱少了100，张三账上的钱多了100。我们再把问题稍微复杂一些，我和张三合起来买一个李四的一个商品390块钱。我的账户支付100，张三账户支付300，李四的帐户获得390，支付宝账户获得了10块钱的转账手续费。那么对这比交易的记录应该是这样的：这种记账方式常用在财务记账上。不过作为一个去中心化的系统，是没有一个中心化银行管理你的开户、销户、余额的。没有余额，怎么判断你的账上有100块钱？此时用户C必须将前面几次交易的比特币输出作为下一个关联交易的输入，具体见下图的no 321笔交易，用户C将前面获得的两次输出，作为输入放在了交易中，然后给自己输出1个比特币的找零（如果不给自己输出找零，那么这个差额就被矿工当成小费了，切记切记）。比特币的程序会判定，如果两个UTXO加在一起不够支付，则交易不成功。比特币UTXO使用有点像古代的银锭五两的银锭付给别人二两，需要通过夹剪将一整块银锭剪成两块，二两的给别人，三两的留给自己。对比：比特币在输出中重新创建一个新的UTXO作为给自己的找零要付给别人五两，手上有几块碎银子单都不足五两，则需要将碎银子一起付给对方。对比：比特币在输入中同时引用多个输出UTXO。这样的做法很繁琐，所以银两在古代并不是一个很普遍的支付方式（别被武侠片给骗了，大部分还是用铜钱）。比特币采用UTXO并不能很直观的去理解，但是为什么要用呢？使用UTXO的动机那么我们站在系统设计的角度猜测一下为什么中本聪会考虑使用UTXO。比特币是没有开户的过程的，一个本地计算生成公私钥就能构成一个合法的帐户，甚至有些用户为了一些“靓号”帐户，通过暴力运算生成天量的再也不会使用的帐户。去中心化系统无法跟踪每个账户的生成和销毁，这样的系统里面的帐户数量远大于未消费的输出数量，所以以UTXO来替代跟踪帐户交易的方式，消耗的系统资源会比较少 ；比特币有个比较好的特性是匿名性，很多人每次交易就换一对公私钥，交易输出的给自己的找零往往输出到一个另外的帐户下去，UTXO迎合了这种需求。而使用帐户就没那么灵活了。如果我使用余额系统，那么在生成一笔交易的时候，我首先要考虑的就是“幂等”问题，因为发出去的交易是给某个帐户加减钱，如果交易因为网络等原因重新发送，变成两笔交易重复扣钱，我就要哭了，这是在区块链里面著名的“重放攻击”。所以交易必须设计一个唯一的标识id让服务器知道这是同一笔交易。但是在去中心化系统中没有一个超级服务器统一分配交易ID，只能本地生成，而且跟踪这些交易ID的状态，也是一个很大的负担，因为我需要将区块链从创世块到现在所有的交易都遍历一遍，才能确定是是否是重复交易。如果用UTXO就可以避免这个问题，UTXO相比交易数少了不止一个数量级，而且UTXO只有两个状态—未消费、被消费，比特币只能有一个操作— 将为消费的UTXO变为已消费状态。不管我发送多少次交易，都会得到一个结果。在中本聪倡导每个cpu都是一票的去中心化社区，让每个节点都有能力去做计算是需要特别重视的，否则单个节点的计算能力要求过高，整个系统将向着“中心化”趋势滑下去。在比特币的实现中，是把所有的UTXO保存在一个单独的UTXOSet缓存中，截止2017年9月，这个缓存大概2.7Gb，与之对应，整个区块链的交易数据达到140Gb，UTXO缓存像是一个只保存了最终一个状态的git，整体的消耗负担小了很多很多。但是中本聪没想到，很多人现在把交易输出的脚本玩出花来了，导致很多UTXO创建出来就是不为消费用的，永远不会被消费掉，节点的负担越来越重。这才有了后续的BIP改进以及以太坊的账户模型。那又是一个很长的故事了…基础篇2018年开始区块链真是火啊。一夜暴富的例子一直在传说。今天我们就自己动手写一个基本的区块链。先简单的说一下区块链是个什么（相信你早就知道了）。区块链就是一个链表。把一堆区块串起来就是区块链。每个block有自己的数字签名（就是一串不规则看起来叼叼的字符串），同时包含有上一个block的数字签名，然后包含一些其他的data。大体就长这样：是不是很熟悉，链表。好，继续。数字签名是什么？就是hash。而且每个block含有前一个block的hash值，而且每个block自己的hash也是由前一个的hash计算得来的。如果前一个block（数据块）的数据发生改变，那么前一个的hash值也改变了，由此就会影响到之后的数据块的所有hash值。所以，通过计算和对比hash值这种方式我们就可以知道区块链是不是合法的，是不是已经被篡改。什么意思呢？意味着只要你修改了区块链中的任何一个块中的数据，都将会改变hash，从而破坏了整个链。好，不多说。上代码：block块定义先新建个block块：1234567891011121314public class Block &#123; public String hash; public String previousHash; private String data; //our data will be a simple message. private long timeStamp; //as number of milliseconds since 1/1/1970. //Block Constructor. public Block(String data,String previousHash ) &#123; this.data = data; this.previousHash = previousHash; this.timeStamp = new Date().getTime(); &#125;&#125; 你也看到了我们的Block里有四个字段，hash就是这个块自己的hash值，previousHash就是上一个块的hash值，data就是这个块所持有的数据，timeStamp就是一个时间记录。 数字签名生成接下来我们就需要生成数字签名。 有很多种的加密算法来生成数字签名。这里我们就选择SHA256。这里先新建一个工具类用来搞定这个件事情： 1234567891011121314151617181920212223242526272829303132333435363738import java.security.MessageDigest;//通过导入MessageDigest来使用SHA256public class StringUtil &#123; //Applies Sha256 to a string and returns the result. public static String applySha256(String input)&#123; try &#123; MessageDigest digest = MessageDigest.getInstance(&quot;SHA-256&quot;); //Applies sha256 to our input, byte[] hash = digest.digest(input.getBytes(&quot;UTF-8&quot;)); StringBuffer hexString = new StringBuffer(); // This will contain hash as hexidecimal for (int i = 0; i &lt; hash.length; i++) &#123; String hex = Integer.toHexString(0xff &amp; hash[i]); if(hex.length() == 1) hexString.append(&apos;0&apos;); hexString.append(hex); &#125; return hexString.toString(); &#125; catch(Exception e) &#123; throw new RuntimeException(e); &#125; &#125; //Short hand helper to turn Object into a json string public static String getJson(Object o) &#123; return new GsonBuilder().setPrettyPrinting().create().toJson(o); &#125; //Returns difficulty string target, to compare to hash. eg difficulty of 5 will return &quot;00000&quot; public static String getDificultyString(int difficulty) &#123; return new String(new char[difficulty]).replace(&apos;\0&apos;, &apos;0&apos;); &#125; &#125; 好，现在我们在Block里添加生成hash的方法： 12345678910//Calculate new hash based on blocks contentspublic String calculateHash() &#123; String calculatedhash = StringUtil.applySha256( previousHash + Long.toString(timeStamp) + Integer.toString(nonce) + data ); return calculatedhash;&#125; 然后我们在构造函数里添加hash值的计算： 12345678//Block Constructor. public Block(String data,String previousHash ) &#123; this.data = data; this.previousHash = previousHash; this.timeStamp = new Date().getTime(); this.hash = calculateHash(); //Making sure we do this after we set the other values.&#125; 一试身手现在是时候一试身手了。我们新建一个main类来玩耍一次： 1234567891011public static void main(String[] args) &#123; Block genesisBlock = new Block(&quot;Hi im the first block&quot;, &quot;0&quot;); System.out.println(&quot;block 1的hash值 : &quot; + genesisBlock.hash); Block secondBlock = new Block(&quot;Yo im the second block&quot;,genesisBlock.hash); System.out.println(&quot;block 2的hash值: &quot; + secondBlock.hash); Block thirdBlock = new Block(&quot;Hey im the third block&quot;,secondBlock.hash); System.out.println(&quot;block 3的hash值: &quot; + thirdBlock.hash);&#125; 输出结果如下： hash值是不一样的，因为每个block的时间戳不同。 现在每个块都有了自己的数字签名，并且这些数字签名都是基于每个块自身的信息以及前一个块的数字签名联合起来生成的数字签名。 但，现在还不能叫区块链。只是一个个区块。接下来就让我们把这些块装入一个ArrayList中： 1234567891011public static ArrayList&lt;Block&gt; blockchain = new ArrayList&lt;Block&gt;();public static void main(String[] args) &#123; //add our blocks to the blockchain ArrayList: blockchain.add(new Block(&quot;Hi im the first block&quot;, &quot;0&quot;)); blockchain.add(new Block(&quot;Yo im the second block&quot;,blockchain.get(blockchain.size()-1).hash)); blockchain.add(new Block(&quot;Hey im the third block&quot;,blockchain.get(blockchain.size()-1).hash)); String blockchainJson = new GsonBuilder().setPrettyPrinting().create().toJson(blockchain); System.out.println(blockchainJson);&#125; 现在看起来就比较紧凑了，也像个区块链的样子了： 检查区块链的完整性现在就让我们在ImportChain中创建一个isChainValid()方法，它会遍历链中每个块，然后对比hash值。这个方法做的事情就是检查hash变量的值是否等于计算出来的hash值以及上一个块的hash是否等于previousHash变量的值。 12345678910111213141516171819202122232425262728public static Boolean isChainValid() &#123; Block currentBlock; Block previousBlock; String hashTarget = new String(new char[difficulty]).replace(&apos;\0&apos;, &apos;0&apos;); //循环遍历每个块检查hash for(int i=1; i &lt; blockchain.size(); i++) &#123; currentBlock = blockchain.get(i); previousBlock = blockchain.get(i-1); //比较注册的hash和计算的hash: if(!currentBlock.hash.equals(currentBlock.calculateHash()) )&#123; System.out.println(&quot;Current Hashes not equal&quot;); return false; &#125; //比较上一个块的hash和注册的上一个hash（也就是previousHash） if(!previousBlock.hash.equals(currentBlock.previousHash) ) &#123; System.out.println(&quot;Previous Hashes not equal&quot;); return false; &#125; //检查hash是否被处理 if(!currentBlock.hash.substring( 0, difficulty).equals(hashTarget)) &#123; System.out.println(&quot;This block hasn&apos;t been mined&quot;); return false; &#125; &#125; return true;&#125; 对区块链中的块的任何更改都将导致此方法返回false。 On the bitcoin network nodes share their blockchains and the longest valid chain is accepted by the network. What’s to stop someone tampering with data in an old block then creating a whole new longer blockchain and presenting that to the network ? Proof of work. The hashcash proof of work system means it takes considerable time and computational power to create new blocks. Hence the attacker would need more computational power than the rest of the peers combined. 上面说的就是POW 。之后会介绍。 好，上面基本上把区块链搞完了。 现在我们开始新的征程吧！ 挖矿我们将要求矿工们来做POW，具体就是通过尝试不同的变量直到块的hash以几个0开头。 然后我们添加一个nonce（Number once）到calculateHash() 方法以及mineBlock()方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public class ImportChain &#123; public static ArrayList&lt;Block&gt; blockchain = new ArrayList&lt;Block&gt;(); public static int difficulty = 5; public static void main(String[] args) &#123; //add our blocks to the blockchain ArrayList: System.out.println(&quot;正在尝试挖掘block 1... &quot;); addBlock(new Block(&quot;Hi im the first block&quot;, &quot;0&quot;)); System.out.println(&quot;正在尝试挖掘block 2... &quot;); addBlock(new Block(&quot;Yo im the second block&quot;,blockchain.get(blockchain.size()-1).hash)); System.out.println(&quot;正在尝试挖掘block 3... &quot;); addBlock(new Block(&quot;Hey im the third block&quot;,blockchain.get(blockchain.size()-1).hash)); System.out.println(&quot;\nBlockchain is Valid: &quot; + isChainValid()); String blockchainJson = StringUtil.getJson(blockchain); System.out.println(&quot;\nThe block chain: &quot;); System.out.println(blockchainJson); &#125; public static Boolean isChainValid() &#123; Block currentBlock; Block previousBlock; String hashTarget = new String(new char[difficulty]).replace(&apos;\0&apos;, &apos;0&apos;); //loop through blockchain to check hashes: for(int i=1; i &lt; blockchain.size(); i++) &#123; currentBlock = blockchain.get(i); previousBlock = blockchain.get(i-1); //compare registered hash and calculated hash: if(!currentBlock.hash.equals(currentBlock.calculateHash()) )&#123; System.out.println(&quot;Current Hashes not equal&quot;); return false; &#125; //compare previous hash and registered previous hash if(!previousBlock.hash.equals(currentBlock.previousHash) ) &#123; System.out.println(&quot;Previous Hashes not equal&quot;); return false; &#125; //check if hash is solved if(!currentBlock.hash.substring( 0, difficulty).equals(hashTarget)) &#123; System.out.println(&quot;This block hasn&apos;t been mined&quot;); return false; &#125; &#125; return true; &#125; public static void addBlock(Block newBlock) &#123; newBlock.mineBlock(difficulty); blockchain.add(newBlock); &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041import java.util.Date;public class Block &#123; public String hash; public String previousHash; private String data; //our data will be a simple message. private long timeStamp; //as number of milliseconds since 1/1/1970. private int nonce; //Block Constructor. public Block(String data,String previousHash ) &#123; this.data = data; this.previousHash = previousHash; this.timeStamp = new Date().getTime(); this.hash = calculateHash(); //Making sure we do this after we set the other values. &#125; //Calculate new hash based on blocks contents public String calculateHash() &#123; String calculatedhash = StringUtil.applySha256( previousHash + Long.toString(timeStamp) + Integer.toString(nonce) + data ); return calculatedhash; &#125; //Increases nonce value until hash target is reached. public void mineBlock(int difficulty) &#123; String target = StringUtil.getDificultyString(difficulty); //Create a string with difficulty * &quot;0&quot; while(!hash.substring( 0, difficulty).equals(target)) &#123; nonce ++; hash = calculateHash(); &#125; System.out.println(&quot;Block已挖到!!! : &quot; + hash); &#125;&#125; 执行main，输出如下： 挖掘每一个块都需要一些时间，大概3秒钟。你可以调整难度，看看是如何影响挖矿时间的。 如果有人要窜改区块链中的数据，那么他们的区块链将是无效的，invalid。 他们将无法创建更长的区块链。 在你的网络中诚实的区块链有更大的时间优势来创建一个最长的链。 被篡改的区块链将无法追上更长、更有效的链。 除非它们比网络中的所有其他节点具有更快的计算速度。比如未来的量子计算机之类的东西。 好，我们已经完成了一个基本的区块链！ 总结一下我们的这个区块链： 每个区块上携带数据。 有数字签名。 必须通过POW来挖掘来验证新的区块。 可以验证数据是否合法和是否被修改。 原文链接 发起一笔交易上一文我们已经学会了写一个基本的区块链：自己动手写区块链（Java版）。 本文我们接着前文，继续深入。 本文我们将会做以下事情： 1、创建一个钱包（wallet）。 2、使用我们的前面创建的区块链发送一笔签名的交易出去。 3、还有其他更叼的事情等等。 听起来是不是就让人心动。 最后的结果就是我们有了自己的加密货币，是的，crypto coin。 前面我们已经构建了一个基本的区块链。但目前这个区块链的区块中的message是一些没有什么实际用途和意义的数据。本文我们就尝试让区块中能够存储一些交易数据（一个区块中可以存储多笔交易数据），这样我们就可以创建自己的加密货币（当然还是一个简单的），这里给我们的货币起个名字叫：“NoobCoin”。 1、创建钱包在加密货币（crypto-currencies）中，货币所有权被作为交易（transaction）在区块链上进行转移，参与者有一个收发资金的地址。 好，现在让我们创建一个钱包（Wallet）来持有pubkey和private key： 1import java.security.*; 123456public class Wallet &#123; public PrivateKey privateKey; public PublicKey publicKey;&#125; 公钥和私钥的用途是什么？ 对于我们的“noobcoin”，公钥（public key）就是我们的一个地址，address。 可以与其他人共享这个公钥，来接受支付。我们的私钥是用来签署（sign）我们的交易（transaction），所以除了私钥（private key）的所有者，没有人可以花我们的钱。用户将不得不对自己的私钥保密！我们还将公钥与交易（transaction）一起发送，它可以用来验证我们的签名是否有效，并且数据没有被篡改。 私钥用于对我们不希望被篡改的数据进行签名。公钥用于验证签名。 我们在一个KeyPair中生成我们的私钥和公钥。这里使用Elliptic-curve加密来生成KeyPair。现在我们就去Wallet类中添加一个方法generateKeyPair()，然后在构造函数中调用它： 1234567891011121314151617181920212223242526public class Wallet &#123; public PrivateKey privateKey; public PublicKey publicKey; public Wallet() &#123; generateKeyPair(); &#125; public void generateKeyPair() &#123; try &#123; KeyPairGenerator keyGen = KeyPairGenerator.getInstance(&quot;ECDSA&quot;,&quot;BC&quot;); SecureRandom random = SecureRandom.getInstance(&quot;SHA1PRNG&quot;); ECGenParameterSpec ecSpec = new ECGenParameterSpec(&quot;prime192v1&quot;); // Initialize the key generator and generate a KeyPair keyGen.initialize(ecSpec, random); //256 KeyPair keyPair = keyGen.generateKeyPair(); // Set the public and private keys from the keyPair privateKey = keyPair.getPrivate(); publicKey = keyPair.getPublic(); &#125;catch(Exception e) &#123; throw new RuntimeException(e); &#125; &#125;&#125; 这个方法就是负责生成公钥和私钥。具体就是通过Java.security.KeyPairGenerator来生成Elliptic Curve key对。然后把这个方法加入到Wallet的构造函数中。 现在我们已经有了一个大体的钱包类。接下来我们看看交易（transaction）类。 2. 交易和签名（Transactions &amp; Signatures）每笔交易将会携带如下数据： 1、资金发送方的公钥（地址）。 2、资金接收方的公钥（地址）。 3、要转移的资金金额。 4、输入（Inputs）。这个输入是对以前交易的引用，这些交易证明发件人拥有要发送的资金。 5、输出（Outputs），显示交易中收到的相关地址量。（这些输出作为新交易中的输入引用） 6、一个加密签名。证明地址的所有者是发起该交易的人，并且数据没有被更改。（例如：防止第三方更改发送的金额） 让我们创建交易类吧： 123456789101112131415161718192021222324252627282930313233import java.security.*;import java.util.ArrayList;public class Transaction &#123; public String transactionId; //Contains a hash of transaction* public PublicKey sender; //Senders address/public key. public PublicKey reciepient; //Recipients address/public key. public float value; //Contains the amount we wish to send to the recipient. public byte[] signature; //This is to prevent anybody else from spending funds in our wallet. public ArrayList&lt;TransactionInput&gt; inputs = new ArrayList&lt;TransactionInput&gt;(); public ArrayList&lt;TransactionOutput&gt; outputs = new ArrayList&lt;TransactionOutput&gt;(); private static int sequence = 0; //A rough count of how many transactions have been generated // Constructor: public Transaction(PublicKey from, PublicKey to, float value, ArrayList&lt;TransactionInput&gt; inputs) &#123; this.sender = from; this.reciepient = to; this.value = value; this.inputs = inputs; &#125; private String calulateHash() &#123; sequence++; //increase the sequence to avoid 2 identical transactions having the same hash return StringUtil.applySha256( StringUtil.getStringFromKey(sender) + StringUtil.getStringFromKey(reciepient) + Float.toString(value) + sequence ); &#125;&#125; 上面的TransactionInput和TransactionOutput类一会再新建。 我们的交易（Transaction）类还应该包含生成/验证签名和验证交易的相关方法。 注意这里，既有验证签名的方法，也有验证交易的方法。 但是，稍等… 先来说说签名的目的是什么？它们是如何工作的？ 签名在我们的区块链上执行两个非常重要的任务：首先，它能只允许所有者使用其货币；其次，在新区块被挖掘之前，它能防止其他人篡改其提交的交易（在入口点）。 私钥用于对数据进行签名，公钥可用于验证其完整性。 例如：Bob想给Sally发送2个NoobCoin，然后他们的钱包软件生成了这个交易并将其提交给矿工，以便将其包含在下一个块中。一名矿工试图将2枚货币的接收人改为Josh。不过，幸运的是，Bob已经用他的私钥签署了交易数据，允许任何人使用Bob的公钥去验证交易数据是否被更改（因为没有其他任何人的公钥能够验证交易）。 可以（从前面的代码块中）看到我们的签名就是一堆字节，所以现在创建一个方法来生成签名。我们首先需要的是StringUtil类中的几个helper方法： 1234567891011121314151617181920212223242526272829303132//Applies ECDSA Signature and returns the result ( as bytes ).public static byte[] applyECDSASig(PrivateKey privateKey, String input) &#123; Signature dsa; byte[] output = new byte[0]; try &#123; dsa = Signature.getInstance(&quot;ECDSA&quot;, &quot;BC&quot;); dsa.initSign(privateKey); byte[] strByte = input.getBytes(); dsa.update(strByte); byte[] realSig = dsa.sign(); output = realSig; &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; return output;&#125;//Verifies a String signaturepublic static boolean verifyECDSASig(PublicKey publicKey, String data, byte[] signature) &#123; try &#123; Signature ecdsaVerify = Signature.getInstance(&quot;ECDSA&quot;, &quot;BC&quot;); ecdsaVerify.initVerify(publicKey); ecdsaVerify.update(data.getBytes()); return ecdsaVerify.verify(signature); &#125;catch(Exception e) &#123; throw new RuntimeException(e); &#125;&#125;public static String getStringFromKey(Key key) &#123; return Base64.getEncoder().encodeToString(key.getEncoded());&#125; 不要过分担心这些方法具体的逻辑。你只需要知道的是：applyECDSASig方法接收发送方的私钥和字符串输入，对其进行签名并返回字节数组。verifyECDSASig接受签名、公钥和字符串数据，如果签名是有效的，则返回true，否则false。getStringFromKey从任意key返回编码的字符串。 现在让我们在Transaction类中使用这些签名方法，分别创建generateSignature()和verifiySignature()方法： 123456789public void generateSignature(PrivateKey privateKey) &#123; String data = StringUtil.getStringFromKey(sender) + StringUtil.getStringFromKey(reciepient) + Float.toString(value) ; signature = StringUtil.applyECDSASig(privateKey,data);&#125;public boolean verifySignature() &#123; String data = StringUtil.getStringFromKey(sender) + StringUtil.getStringFromKey(reciepient) + Float.toString(value) ; return StringUtil.verifyECDSASig(sender, data, signature);&#125; 在现实中，你可能希望签署更多的信息，比如使用的输出（outputs）/输入（inputs）和/或时间戳（time-stamp）（现在我们只签署了最基本的）。 在将新的交易添加到块中时，矿工将对签名进行验证。 当我们检查区块链的合法性的时候，其实也可以检查签名。 3.测试钱包（Wallets）和签名（Signatures）现在我们差不多完成了一半了，先来测试下已经完成的是不是可以正常工作。在NoobChain类中，让我们添加一些新变量并替换main方法的内容如下： 1234567891011121314151617181920212223242526272829import java.security.Security;import java.util.ArrayList;public class NoobChain &#123; public static ArrayList&lt;Block&gt; blockchain = new ArrayList&lt;Block&gt;(); public static int difficulty = 5; public static Wallet walletA; public static Wallet walletB; public static void main(String[] args) &#123; //Setup Bouncey castle as a Security Provider Security.addProvider(new org.bouncycastle.jce.provider.BouncyCastleProvider()); //Create the new wallets walletA = new Wallet(); walletB = new Wallet(); //Test public and private keys System.out.println(&quot;Private and public keys:&quot;); System.out.println(StringUtil.getStringFromKey(walletA.privateKey)); System.out.println(StringUtil.getStringFromKey(walletA.publicKey)); //Create a test transaction from WalletA to walletB Transaction transaction = new Transaction(walletA.publicKey, walletB.publicKey, 5, null); transaction.generateSignature(walletA.privateKey); //Verify the signature works and verify it from the public key System.out.println(&quot;Is signature verified&quot;); System.out.println(transaction.verifySignature()); &#125;&#125; 可以发现我们使用了boncey castle来作为安全实现的提供者。 还创建了两个钱包，钱包A和钱包B，然后打印了钱包A的私钥和公钥。还新建一笔交易。然后使用钱包A的公钥对这笔交易进行了签名。 输出: 嗯，签名验证是true，符合期望。 现在是时候小开心一下了。现在我们只需要创建和校验输出（outputs）和输入（inputs）然后把交易存储到区块链中。 4. 输入（Inputs）与输出（Outputs）1：加密货币是如何拥有的…如果你想拥有1个比特币，你必须收到1个比特币。总账不会真的给你添加一个比特币，从发送者那里减去一个比特币，发送者提到他/她以前收到一个比特币，然后创建一个交易输出，显示1比特币被发送到你的地址。（交易输入是对以前交易输出的引用。） 你的钱包余额是所有发送给你的未使用的交易输出的总和。 ps：这里略微有点绕，总之你就记住进账和出账这回事情。 从现在开始，我们将遵循比特币惯例并调用未使用的交易输出：UTXO。 好，让我们创建一个TransactionInput类： 12345678public class TransactionInput &#123; public String transactionOutputId; //Reference to TransactionOutputs -transactionId public TransactionOutput UTXO; //Contains the Unspent transaction output public TransactionInput(String transactionOutputId) &#123; this.transactionOutputId = transactionOutputId; &#125;&#125; 这个类将用于引用尚未使用的TransactionOutputs的值。transactionOutputId将用于查找相关的TransactionOutput，从而允许矿工检查你的所有权。 下面是TransactionOutput类： 12345678910111213141516171819202122import java.security.PublicKey;public class TransactionOutput &#123; public String id; public PublicKey reciepient; //also known as the new owner of these coins. public float value; //the amount of coins they own public String parentTransactionId; //the id of the transaction this output was created in //Constructor public TransactionOutput(PublicKey reciepient, float value, String parentTransactionId) &#123; this.reciepient = reciepient; this.value = value; this.parentTransactionId = parentTransactionId; this.id = StringUtil.applySha256(StringUtil.getStringFromKey(reciepient)+Float.toString(value)+parentTransactionId); &#125; //Check if coin belongs to you public boolean isMine(PublicKey publicKey) &#123; return (publicKey == reciepient); &#125;&#125; 交易输出将显示从交易发送到每一方的最终金额。当在新的交易中作为输入引用时，它们将作为你要发送的货币的证明，能够证明你有钱可发送。 5. 输入（Inputs）与输出（Outputs）2：处理交易……链中的块可能接收到许多交易，而区块链可能非常非常长，处理新交易可能需要数亿年的时间，因为我们必须查找并检查它的输入。要解决这个问题，我们就需要存在一个额外的集合（collection）来保存所有未使用的可被作为输入（inputs）的交易。在下面的ImportChain类中，添加一个所有UTXO的集合： 123456789101112public class ImportChain &#123; public static ArrayList&lt;Block&gt; blockchain = new ArrayList&lt;Block&gt;(); public static HashMap&lt;String,TransactionOutput&gt; UTXOs = new HashMap&lt;String,TransactionOutput&gt;(); public static int difficulty = 3; public static float minimumTransaction = 0.1f; public static Wallet walletA; public static Wallet walletB; public static Transaction genesisTransaction; public static void main(String[] args) &#123; 现在我们把之前的那些实现放在一起来处理一笔交易吧。先在Transaction类中的添加一个方法processTransaction： 12345678910111213141516171819202122232425262728293031323334353637public boolean processTransaction() &#123; if(verifySignature() == false) &#123; System.out.println(&quot;#Transaction Signature failed to verify&quot;); return false; &#125; //Gathers transaction inputs (Making sure they are unspent): for(TransactionInput i : inputs) &#123; i.UTXO = ImportChain.UTXOs.get(i.transactionOutputId); &#125; //Checks if transaction is valid: if(getInputsValue() &lt; ImportChain.minimumTransaction) &#123; System.out.println(&quot;Transaction Inputs to small: &quot; + getInputsValue()); return false; &#125; //Generate transaction outputs: float leftOver = getInputsValue() - value; //get value of inputs then the left over change: transactionId = calulateHash(); outputs.add(new TransactionOutput( this.reciepient, value,transactionId)); //send value to recipient outputs.add(new TransactionOutput( this.sender, leftOver,transactionId)); //send the left over &apos;change&apos; back to sender //Add outputs to Unspent list for(TransactionOutput o : outputs) &#123; ImportChain.UTXOs.put(o.id , o); &#125; //Remove transaction inputs from UTXO lists as spent: for(TransactionInput i : inputs) &#123; if(i.UTXO == null) continue; //if Transaction can&apos;t be found skip it ImportChain.UTXOs.remove(i.UTXO.id); &#125; return true;&#125; 还添加了getInputsValue方法。使用此方法，我们执行一些检查以确保交易是有效的，然后收集输入并生成输出。（要了解更多信息，请参阅代码中的注释行）。 重要的是，在最后，我们从UTXO的列表中删除input，这意味着交易输出只能作为一个输入使用一次…而且必须使用完整的输入值，因为发送方要将“更改”返回给自己。 红色箭头是输出。请注意，绿色输入是对以前输出的引用。 最后，让我们将钱包类更新为： 可以汇总得到的余额（通过循环遍历UTXO列表并检查事务输出是否为Mine()） 并可以生成交易。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172import java.security.*;import java.security.spec.ECGenParameterSpec;import java.util.ArrayList;import java.util.HashMap;import java.util.Map;public class Wallet &#123; public PrivateKey privateKey; public PublicKey publicKey; public HashMap&lt;String,TransactionOutput&gt; UTXOs = new HashMap&lt;String,TransactionOutput&gt;(); public Wallet() &#123; generateKeyPair(); &#125; public void generateKeyPair() &#123; try &#123; KeyPairGenerator keyGen = KeyPairGenerator.getInstance(&quot;ECDSA&quot;,&quot;BC&quot;); SecureRandom random = SecureRandom.getInstance(&quot;SHA1PRNG&quot;); ECGenParameterSpec ecSpec = new ECGenParameterSpec(&quot;prime192v1&quot;); // Initialize the key generator and generate a KeyPair keyGen.initialize(ecSpec, random); //256 KeyPair keyPair = keyGen.generateKeyPair(); // Set the public and private keys from the keyPair privateKey = keyPair.getPrivate(); publicKey = keyPair.getPublic(); &#125;catch(Exception e) &#123; throw new RuntimeException(e); &#125; &#125; public float getBalance() &#123; float total = 0; for (Map.Entry&lt;String, TransactionOutput&gt; item: ImportChain.UTXOs.entrySet())&#123; TransactionOutput UTXO = item.getValue(); if(UTXO.isMine(publicKey)) &#123; //if output belongs to me ( if coins belong to me ) UTXOs.put(UTXO.id,UTXO); //add it to our list of unspent transactions. total += UTXO.value ; &#125; &#125; return total; &#125; public Transaction sendFunds(PublicKey _recipient,float value ) &#123; if(getBalance() &lt; value) &#123; System.out.println(&quot;#Not Enough funds to send transaction. Transaction Discarded.&quot;); return null; &#125; ArrayList&lt;TransactionInput&gt; inputs = new ArrayList&lt;TransactionInput&gt;(); float total = 0; for (Map.Entry&lt;String, TransactionOutput&gt; item: UTXOs.entrySet())&#123; TransactionOutput UTXO = item.getValue(); total += UTXO.value; inputs.add(new TransactionInput(UTXO.id)); if(total value) break; &#125; Transaction newTransaction = new Transaction(publicKey, _recipient , value, inputs); newTransaction.generateSignature(privateKey); for(TransactionInput input: inputs)&#123; UTXOs.remove(input.transactionOutputId); &#125; return newTransaction; &#125;&#125; 你还可以添加一些其他功能到你的钱包类，比如保留记录你的交易历史记录等等。 6. 向块中添加交易现在已有了一个可以正常工作的交易处理系统，我们需要将它实现到我们的区块链中。我们把上一集中块里的无用的数据替换成一个交易列表，arraylist。 然而，在一个块中可能有1000个交易，太多的交易不能包括在散列计算中…… 没事，别担心，我们可以使用交易的merkle根，就是下面的那个getMerkleRoot()方法。 现在在StringUtils中添加一个helper方法getMerkleRoot()： 123456789101112131415161718192021public static String getMerkleRoot(ArrayList&lt;Transaction&gt; transactions) &#123; int count = transactions.size(); List&lt;String&gt; previousTreeLayer = new ArrayList&lt;String&gt;(); for(Transaction transaction : transactions) &#123; previousTreeLayer.add(transaction.transactionId); &#125; List&lt;String&gt; treeLayer = previousTreeLayer; while(count 1) &#123; treeLayer = new ArrayList&lt;String&gt;(); for(int i=1; i &lt; previousTreeLayer.size(); i+=2) &#123; treeLayer.add(applySha256(previousTreeLayer.get(i-1) + previousTreeLayer.get(i))); &#125; count = treeLayer.size(); previousTreeLayer = treeLayer; &#125; String merkleRoot = (treeLayer.size() == 1) ? treeLayer.get(0) : &quot;&quot;; return merkleRoot;&#125; 现在，我们把Block类加强一下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859import java.util.ArrayList;import java.util.Date;public class Block &#123; public String hash; public String previousHash; public String merkleRoot; public ArrayList&lt;Transaction&gt; transactions = new ArrayList&lt;Transaction&gt;(); //our data will be a simple message. public long timeStamp; //as number of milliseconds since 1/1/1970. public int nonce; //Block Constructor. public Block(String previousHash ) &#123; this.previousHash = previousHash; this.timeStamp = new Date().getTime(); this.hash = calculateHash(); //Making sure we do this after we set the other values. &#125; //Calculate new hash based on blocks contents public String calculateHash() &#123; String calculatedhash = StringUtil.applySha256( previousHash + Long.toString(timeStamp) + Integer.toString(nonce) + merkleRoot ); return calculatedhash; &#125; //Increases nonce value until hash target is reached. public void mineBlock(int difficulty) &#123; merkleRoot = StringUtil.getMerkleRoot(transactions); String target = StringUtil.getDificultyString(difficulty); //Create a string with difficulty * &quot;0&quot; while(!hash.substring( 0, difficulty).equals(target)) &#123; nonce ++; hash = calculateHash(); &#125; System.out.println(&quot;Block Mined!!! : &quot; + hash); &#125; //Add transactions to this block public boolean addTransaction(Transaction transaction) &#123; //process transaction and check if valid, unless block is genesis block then ignore. if(transaction == null) return false; if((previousHash != &quot;0&quot;)) &#123; if((transaction.processTransaction() != true)) &#123; System.out.println(&quot;Transaction failed to process. Discarded.&quot;); return false; &#125; &#125; transactions.add(transaction); System.out.println(&quot;Transaction Successfully added to Block&quot;); return true; &#125;&#125; 上面我们更新了Block构造函数，因为不再需要传入字符串数据（还记得上集中我们的Block构造函数传入了一个data的字符串，这里我们往块里添加的是交易，也就是transaction），并且在计算哈希方法中包含了merkle根。 并且新增了addTransaction方法来添加一笔交易，并且只有在交易被成功添加时才返回true。 ok，我们的区块链上交易所需的每个零部件都实现了。是时候运转一下了。 7. 大结局现在我们开始测试吧。发送货币进出钱包，并更新我们的区块链有效性检查。 但首先我们需要一个方法来引入新的币。有许多方法可以创建新的币，比如，在比特币区块链上：矿工可以将交易持有在自己手里，作为对每个块被开采的奖励。 这里，我们将只发行（release）我们希望拥有的所有货币，在第一个块（起源块）。就像比特币一样，我们将对起源块进行硬编码。 现在把``类更新，包含如下内容： 一个“创世纪”的块，它向钱包A发行100个新币。 帐户交易中的“更新的链”的有效性检查。 一些测试信息，让我们看到内部运行的细节信息。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148import java.security.Security;import java.util.ArrayList;import java.util.HashMap;//import java.util.Base64;//import com.google.gson.GsonBuilder;public class ImportChain &#123; public static ArrayList&lt;Block&gt; blockchain = new ArrayList&lt;Block&gt;(); public static HashMap&lt;String,TransactionOutput&gt; UTXOs = new HashMap&lt;String,TransactionOutput&gt;(); public static int difficulty = 3; public static float minimumTransaction = 0.1f; public static Wallet walletA; public static Wallet walletB; public static Transaction genesisTransaction; public static void main(String[] args) &#123; //add our blocks to the blockchain ArrayList: Security.addProvider(new org.bouncycastle.jce.provider.BouncyCastleProvider()); //Setup Bouncey castle as a Security Provider //Create wallets: walletA = new Wallet(); walletB = new Wallet(); Wallet coinbase = new Wallet(); //create genesis transaction, which sends 100 NoobCoin to walletA: genesisTransaction = new Transaction(coinbase.publicKey, walletA.publicKey, 100f, null); genesisTransaction.generateSignature(coinbase.privateKey); //manually sign the genesis transaction genesisTransaction.transactionId = &quot;0&quot;; //manually set the transaction id genesisTransaction.outputs.add(new TransactionOutput(genesisTransaction.reciepient, genesisTransaction.value, genesisTransaction.transactionId)); //manually add the Transactions Output UTXOs.put(genesisTransaction.outputs.get(0).id, genesisTransaction.outputs.get(0)); //its important to store our first transaction in the UTXOs list. System.out.println(&quot;Creating and Mining Genesis block... &quot;); Block genesis = new Block(&quot;0&quot;); genesis.addTransaction(genesisTransaction); addBlock(genesis); //testing Block block1 = new Block(genesis.hash); System.out.println(&quot;\nWalletA&apos;s balance is: &quot; + walletA.getBalance()); System.out.println(&quot;\nWalletA is Attempting to send funds (40) to WalletB...&quot;); block1.addTransaction(walletA.sendFunds(walletB.publicKey, 40f)); addBlock(block1); System.out.println(&quot;\nWalletA&apos;s balance is: &quot; + walletA.getBalance()); System.out.println(&quot;WalletB&apos;s balance is: &quot; + walletB.getBalance()); Block block2 = new Block(block1.hash); System.out.println(&quot;\nWalletA Attempting to send more funds (1000) than it has...&quot;); block2.addTransaction(walletA.sendFunds(walletB.publicKey, 1000f)); addBlock(block2); System.out.println(&quot;\nWalletA&apos;s balance is: &quot; + walletA.getBalance()); System.out.println(&quot;WalletB&apos;s balance is: &quot; + walletB.getBalance()); Block block3 = new Block(block2.hash); System.out.println(&quot;\nWalletB is Attempting to send funds (20) to WalletA...&quot;); block3.addTransaction(walletB.sendFunds( walletA.publicKey, 20)); System.out.println(&quot;\nWalletA&apos;s balance is: &quot; + walletA.getBalance()); System.out.println(&quot;WalletB&apos;s balance is: &quot; + walletB.getBalance()); isChainValid(); &#125; public static Boolean isChainValid() &#123; Block currentBlock; Block previousBlock; String hashTarget = new String(new char[difficulty]).replace(&apos;\0&apos;, &apos;0&apos;); HashMap&lt;String,TransactionOutput&gt; tempUTXOs = new HashMap&lt;String,TransactionOutput&gt;(); //a temporary working list of unspent transactions at a given block state. tempUTXOs.put(genesisTransaction.outputs.get(0).id, genesisTransaction.outputs.get(0)); //loop through blockchain to check hashes: for(int i=1; i &lt; blockchain.size(); i++) &#123; currentBlock = blockchain.get(i); previousBlock = blockchain.get(i-1); //compare registered hash and calculated hash: if(!currentBlock.hash.equals(currentBlock.calculateHash()) )&#123; System.out.println(&quot;#Current Hashes not equal&quot;); return false; &#125; //compare previous hash and registered previous hash if(!previousBlock.hash.equals(currentBlock.previousHash) ) &#123; System.out.println(&quot;#Previous Hashes not equal&quot;); return false; &#125; //check if hash is solved if(!currentBlock.hash.substring( 0, difficulty).equals(hashTarget)) &#123; System.out.println(&quot;#This block hasn&apos;t been mined&quot;); return false; &#125; //loop thru blockchains transactions: TransactionOutput tempOutput; for(int t=0; t &lt;currentBlock.transactions.size(); t++) &#123; Transaction currentTransaction = currentBlock.transactions.get(t); if(!currentTransaction.verifySignature()) &#123; System.out.println(&quot;#Signature on Transaction(&quot; + t + &quot;) is Invalid&quot;); return false; &#125; if(currentTransaction.getInputsValue() != currentTransaction.getOutputsValue()) &#123; System.out.println(&quot;#Inputs are note equal to outputs on Transaction(&quot; + t + &quot;)&quot;); return false; &#125; for(TransactionInput input: currentTransaction.inputs) &#123; tempOutput = tempUTXOs.get(input.transactionOutputId); if(tempOutput == null) &#123; System.out.println(&quot;#Referenced input on Transaction(&quot; + t + &quot;) is Missing&quot;); return false; &#125; if(input.UTXO.value != tempOutput.value) &#123; System.out.println(&quot;#Referenced input Transaction(&quot; + t + &quot;) value is Invalid&quot;); return false; &#125; tempUTXOs.remove(input.transactionOutputId); &#125; for(TransactionOutput output: currentTransaction.outputs) &#123; tempUTXOs.put(output.id, output); &#125; if( currentTransaction.outputs.get(0).reciepient != currentTransaction.reciepient) &#123; System.out.println(&quot;#Transaction(&quot; + t + &quot;) output reciepient is not who it should be&quot;); return false; &#125; if( currentTransaction.outputs.get(1).reciepient != currentTransaction.sender) &#123; System.out.println(&quot;#Transaction(&quot; + t + &quot;) output &apos;change&apos; is not sender.&quot;); return false; &#125; &#125; &#125; System.out.println(&quot;Blockchain is valid&quot;); return true; &#125; public static void addBlock(Block newBlock) &#123; newBlock.mineBlock(difficulty); blockchain.add(newBlock); &#125;&#125; 运行结果： 代码链接：https://github.com/importsource/blockchain-samples-transaction/tree/master 原文链接 最热门的3个基于Java的Blockchain库大家应该都听说过比特币、以太币或其他加密货币，这些名字在新闻中经常出现，但是作为Java开发人员，你们知道如何轻松地与Blockchain技术进行交互吗?下面是可以利用Blockchain的三大Java项目。这个列表是基于GitHub存储库的星序排列的。非常感谢你的评论和意见。 BitcoinJ你有没有觉得这个名字很有描述性呢?如果你想知道如何创建一个比特币钱包，并且管理节点之间的事务，那么你应该尝试一下BitcoinJ。这个项目有一个不断扩大的社区，里面包含非常好的文档资料，这对每个开发人员都是非常有利的。当然，作为一个试图获得声望的开源项目，它也存在一定的局限性。现在已经有几个已知的开放漏洞的安全问题，以及可扩展性问题。不过，如果你想了解比特币协议是如何运作的，这个项目将是非常有帮助的。个人意见:这并不适用于生产应用。 Web3j一个词——Ethereum（以太币），这是基于尖端技术的第二大加密货币。Web3j项目允许你使用Ethereum区块链，同时不必为平台编写集成代码。同样，核心功能是创建钱包，管理事务，以及智能合约包装器。Ethereum项目的一部分是一种称为Solidity的特殊语言，它是创建智能合约的实际标准。如果你想避免使用智能合约的底层实现细节，那就使用Web3j的智能合约包装器。如果这对一名开发人员来说还不够，那我需要告诉你，它包含很多好的文档和大量的例子，这也是使web3j成为我个人最爱的原因。 HyperLedger FabricHyperLedger Fabric是企业会用到的。Linux基金会的框架是区块链解决方案的主干。所以无论你想创建一个简单的PoC，还是一个生产应用程序，它都是一个强大的工具。该项目正在由Linux基金会成员积极组织开发。它的重点是创建和管理智能合约。主要特点是: 管理共享机密信息的渠道支持政策事务一致地向网络中的对等节点交付事务 如果你在软件区块链堆栈中包括了HyperLedger Fabric，那么我的建议是熟悉其他的HyperLedger项目。根据你的需要，可以选择各种不同的HyperLedger项目，这些项目将保证一个连贯的、可扩展的、易于维护的区块链基础设施。对于许多人来说，区块链将改变整个互联网，难道你不想成为其中的一部分吗?]]></content>
      <categories>
        <category>Programming</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Blockchain</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot 学习杂记]]></title>
    <url>%2F2018%2Fspring-boot-learning-hodgepodge%2F</url>
    <content type="text"><![CDATA[Spring Boot作为当下最流行的微服务项目构建基础，有的时候我们根本不需要额外的配置就能够干很多的事情，这得益于它的一个核心理念：“习惯优于配置”。。。说白的就是大部分的配置都已经按照最佳实践的编程规范配置好了本文基于 Spring Boot 2的学习杂记，还是与1.X版本还是有一定区别的构建依赖版本管理工程为什么要分开为两个工程？因为考虑到common工程也需要版本控制，但parent工程中依赖了common工程，所以common工程不能依赖parent工程（循环依赖），故例外抽离出一个dependencies的工程，专门用作依赖版本管理，而parent工程用作其他子工程的公共依赖。依赖版本管理工程跟下面父工程一样只有一个pom.xmlhttps://github.com/masteranthoneyd/spring-boot-learning/tree/master/spring-boot-parent-dependencies父工程https://github.com/masteranthoneyd/spring-boot-learning/blob/master/spring-boot-parent/pom.xml说明：&lt;packaging&gt; 为 pom 表示此会被打包成 pom 文件被其他子项目依赖。由于 Spring Boot 以及集成了 maven-surefire-plugin 插件，跳过测试只需要在 properties中添加 &lt;maven.test.skip&gt;true&lt;/maven.test.skip&gt;即可，等同 mvn package -Dmaven.test.skip=true，也可使用 &lt;skipTests&gt;true&lt;/skipTests&gt;，两者的区别在于 &lt;maven.test.skip&gt; 标签连 .class 文件都不会生成，而 &lt;skipTests&gt; 会编译生成 .class 文件子项目会继承父项目的 properties，若子项目重新定义属性，则会覆盖父项目的属性。&lt;dependencyManagement&gt; 管理依赖版本，不使用 &lt;parent&gt; 来依赖 Spring Boot，可以使用上面方式，添加 &lt;type&gt; 为 pom 以及 &lt;scope&gt; 为 import。&lt;pluginManagement&gt; 的功能类似于 &lt;dependencyManagement&gt;，在父项目中设置好插件属性，在子项目中直接依赖就可以，不需要每个子项目都配置一遍，当然了，子项目也可以覆盖插件属性。打包打包成可执行的Jar默认情况下Spring Boot打包出来的jar包是不可执行的，需要这样配置：1234567891011121314&lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-boot.version&#125;&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;repackage&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt;&lt;/plugins&gt; 打包之后会发现有两个jar，一个是本身的代码，一个是集成了Spring Boot的可运行jar： 打包依赖了Spring Boot的工具库只需要在打包插件spring-boot-maven-plugin中这样配置： 12345678910111213&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;none&lt;/phase&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 打包契约类12345678910111213141516171819202122&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;includes&gt; &lt;include&gt;com/yangbingdong/server/**/contract/**/*.class&lt;/include&gt; &lt;/includes&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;none&lt;/phase&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 然后指定该pom文件构建： 1mvn -f pom_own.xml package 配置文件：Properties 和 YAML配置文件的生效顺序，会对值进行覆盖 @TestPropertySource 注解 命令行参数 Java系统属性（System.getProperties()） 操作系统环境变量 只有在random.*里包含的属性会产生一个RandomValuePropertySource 在打包的jar外的应用程序配置文件（application.properties，包含YAML和profile变量） 在打包的jar内的应用程序配置文件（application.properties，包含YAML和profile变量） 在@Configuration类上的@PropertySource注解 默认属性（使用SpringApplication.setDefaultProperties指定） 配置随机值1234567roncoo.secret=$&#123;random.value&#125;roncoo.number=$&#123;random.int&#125;roncoo.bignumber=$&#123;random.long&#125;roncoo.number.less.than.ten=$&#123;random.int(10)&#125;roncoo.number.in.range=$&#123;random.int[1024,65536]&#125;读取使用注解：@Value(value = &quot;$&#123;roncoo.secret&#125;&quot;) 应用简单配置12345678#端口配置：server.port=8090#应用名spring.application.name=test-demo#时间格式化spring.jackson.date-format=yyyy-MM-dd HH:mm:ss#时区设置spring.jackson.time-zone=Asia/Chongqing 配置文件-多环境配置多环境配置的好处 不同环境配置可以配置不同的参数 便于部署，提高效率，减少出错 Properties多环境配置123456781. 配置激活选项spring.profiles.active=dev2.添加其他配置文件application.propertiesapplication-dev.propertiesapplication-prod.propertiesapplication-test.properties YAML多环境配置123456781.配置激活选项spring: profiles: active: dev2.在配置文件添加三个英文状态下的短横线即可区分---spring: profiles: dev 两种配置方式的比较 Properties配置多环境，需要添加多个配置文件，YAML只需要一个配件文件 书写格式的差异，yaml相对比较简洁，优雅 YAML的缺点：不能通过@PropertySource注解加载。如果需要使用@PropertySource注解的方式加载值，那就要使用properties文件。 如何使用1java -Dspring.profiles.active=dev -jar myapp.jar 热部署pom.xml添加依赖： 1234567891011121314151617181920&lt;dependencies&gt; &lt;!--支持热启动jar包--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;!-- optional=true,依赖不会传递，该项目依赖devtools；之后依赖该项目的项目如果想要使用devtools，需要重新引入 --&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;fork&gt;true&lt;/fork&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; application.yml配置文件中添加： 1234567spring: devtools: restart: #热部署生效 默认就是为true enabled: true #classpath目录下的WEB-INF文件夹内容修改不重启 exclude: WEB-INF/** 关于DevTools的键值如下：1234567891011121314151617181920# DEVTOOLS (DevToolsProperties)spring.devtools.livereload.enabled=true # Enable a livereload.com compatible server.spring.devtools.livereload.port=35729 # Server port.spring.devtools.restart.additional-exclude= # Additional patterns that should be excluded from triggering a full restart.spring.devtools.restart.additional-paths= # Additional paths to watch for changes.spring.devtools.restart.enabled=true # Enable automatic restart.spring.devtools.restart.exclude=META-INF/maven/**,META-INF/resources/**,resources/**,static/**,public/**,templates/**,**/*Test.class,**/*Tests.class,git.properties # Patterns that should be excluded from triggering a full restart.spring.devtools.restart.poll-interval=1000 # Amount of time (in milliseconds) to wait between polling for classpath changes.spring.devtools.restart.quiet-period=400 # Amount of quiet time (in milliseconds) required without any classpath changes before a restart is triggered.spring.devtools.restart.trigger-file= # Name of a specific file that when changed will trigger the restart check. If not specified any classpath file change will trigger the restart.# REMOTE DEVTOOLS (RemoteDevToolsProperties)spring.devtools.remote.context-path=/.~~spring-boot!~ # Context path used to handle the remote connection.spring.devtools.remote.debug.enabled=true # Enable remote debug support.spring.devtools.remote.debug.local-port=8000 # Local remote debug server port.spring.devtools.remote.proxy.host= # The host of the proxy to use to connect to the remote application.spring.devtools.remote.proxy.port= # The port of the proxy to use to connect to the remote application.spring.devtools.remote.restart.enabled=true # Enable remote restart.spring.devtools.remote.secret= # A shared secret required to establish a connection (required to enable remote support).spring.devtools.remote.secret-header-name=X-AUTH-TOKEN # HTTP header used to transfer the shared secret. 当我们修改了java类后，IDEA默认是不自动编译的，而spring-boot-devtools又是监测classpath下的文件发生变化才会重启应用，所以需要设置IDEA的自动编译： （1）File-Settings-Compiler-Build Project automatically （2）ctrl + shift + alt + /,选择Registry,勾上 Compiler autoMake allow when app running OK了，重启一下项目，然后改一下类里面的内容，IDEA就会自动去make了。 热部署可能会牺牲一定的系统性能，因为是动态的编译 使用为Undertow作为Web容器 Spring Boot内嵌容器支持Tomcat、Jetty、Undertow。根据 Tomcat vs. Jetty vs. Undertow: Comparison of Spring Boot Embedded Servlet Containers 这篇文章统计，Undertow的综合性能更好。 在Spring Boot 2中，已经把netty作为webflux的默认容器 与Tomcat性能对比以下是Undertow与Tomcat简单的性能测试（同样是默认配置） Tomcat: Undertow: 显然Undertow的吞吐量要比Tomcat高 Maven配置123456789101112131415161718192021222324252627282930&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;!-- 移除默认web容器，使用undertow --&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;如果是webflux，默认的容器的netty&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-webflux&lt;/artifactId&gt; &lt;exclusions&gt; &lt;!-- 移除默认web容器，使用undertow --&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-reactor-netty&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;!-- 使用高性能 Web 容器 undertow --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-undertow&lt;/artifactId&gt;&lt;/dependency&gt; 监听多个端口与HTTP2支持123456789101112131415// 在@Configuration的类中添加@bean@BeanUndertowEmbeddedServletContainerFactory embeddedServletContainerFactory() &#123; UndertowEmbeddedServletContainerFactory factory = new UndertowEmbeddedServletContainerFactory(); // 这里也可以做其他配置 // 支持HTTP2 factory.addBuilderCustomizers(builder -&gt; &#123; builder.setServerOption(UndertowOptions.ENABLE_HTTP2, true); // 监听多个端口 builder.addHttpListener(8080, &quot;0.0.0.0&quot;); &#125;); return factory;&#125; Undertow相关配置1234567891011121314151617181920212223# Undertow 日志存放目录server.undertow.accesslog.dir# 是否启动日志server.undertow.accesslog.enabled=false # 日志格式server.undertow.accesslog.pattern=common# 日志文件名前缀server.undertow.accesslog.prefix=access_log# 日志文件名后缀server.undertow.accesslog.suffix=log# HTTP POST请求最大的大小server.undertow.max-http-post-size=0 # 设置IO线程数, 它主要执行非阻塞的任务,它们会负责多个连接, 默认设置每个CPU核心一个线程server.undertow.io-threads=4# 阻塞任务线程池, 当执行类似servlet请求阻塞操作, undertow会从这个线程池中取得线程,它的值设置取决于系统的负载，默认数量为 CPU核心*8server.undertow.worker-threads=20# 以下的配置会影响buffer,这些buffer会用于服务器连接的IO操作,有点类似netty的池化内存管理# 每块buffer的空间大小,越小的空间被利用越充分server.undertow.buffer-size=1024# 每个区分配的buffer数量 , 所以pool的大小是buffer-size * buffers-per-regionserver.undertow.buffers-per-region=1024# 是否分配的直接内存server.undertow.direct-buffers=true 日志相关使用Log4j2 更多Log4j2配置请看：https://my.oschina.net/kkrgwbj/blog/734530 下面是 Log4j2 官方性能测试结果： Maven配置123456789101112131415161718192021222324252627282930&lt;!-- Spring Boot 依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;!-- 去除 logback 依赖 --&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- 日志 Log4j2 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-log4j2&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- Log4j2 异步支持 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.lmax&lt;/groupId&gt; &lt;artifactId&gt;disruptor&lt;/artifactId&gt; &lt;version&gt;3.3.8&lt;/version&gt;&lt;/dependency&gt; 注意：需要单独把spring-boot-starter里面的logging去除再引入spring-boot-starter-web，否则后面引入的starter模块带有的logging不会自动去除 application.yml简单配置1234logging: config: classpath:log4j2.xml # 指定log4j2配置文件的路径，默认就是这个 pattern: console: &quot;%clr&#123;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125;&#125;&#123;faint&#125; | %clr&#123;%5p&#125; | %clr&#123;%15.15t&#125;&#123;faint&#125; | %clr&#123;%-50.50c&#123;1.&#125;&#125;&#123;cyan&#125; | %5L | %clr&#123;%M&#125;&#123;magenta&#125; | %msg%n%xwEx&quot; # 控制台日志输出格式 log4j2.xml配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!-- Configuration后面的status，这个用于设置log4j2自身内部的信息输出，可以不设置，当设置成trace时， 你会看到log4j2内部各种详细输出。可以设置成OFF(关闭) 或 Error(只输出错误信息)。 30s 刷新此配置--&gt;&lt;configuration status=&quot;OFF&quot; monitorInterval=&quot;30&quot;&gt; &lt;!-- 日志文件目录、压缩文件目录、日志格式配置 --&gt; &lt;properties&gt; &lt;Property name=&quot;fileName&quot;&gt;/home/ybd/logs&lt;/Property&gt; &lt;Property name=&quot;fileGz&quot;&gt;/home/ybd/logs/7z&lt;/Property&gt; &lt;Property name=&quot;PID&quot;&gt;????&lt;/Property&gt; &lt;!--&lt;Property name=&quot;LOG_PATTERN&quot;&gt;%clr&#123;%d&#123;yyyy-MM-dd HH:mm:ss.SSS z&#125;&#125;&#123;faint&#125; %clr&#123;%5p&#125; %clr&#123;$&#123;sys:PID&#125;&#125;&#123;magenta&#125; %clr&#123;-&amp;#45;&amp;#45;&#125;&#123;faint&#125; %clr&#123;[%t]&#125;&#123;faint&#125; %clr&#123;%-40.40c&#123;1.&#125;&#125;&#123;cyan&#125; %clr&#123;:&#125;&#123;faint&#125; %m%n%xwEx &lt;/Property&gt;--&gt; &lt;Property name=&quot;LOG_PATTERN&quot;&gt;%clr&#123;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125;&#125;&#123;faint&#125; | %clr&#123;%5p&#125; | %clr&#123;$&#123;sys:PID&#125;&#125;&#123;magenta&#125; | %clr&#123;%15.15t&#125;&#123;faint&#125; | %clr&#123;%-50.50c&#123;1.&#125;&#125;&#123;cyan&#125; | %5L | %clr&#123;%M&#125;&#123;magenta&#125; | %msg%n%xwEx &lt;/Property&gt; &lt;/properties&gt; &lt;Appenders&gt; &lt;!-- 输出控制台日志的配置 --&gt; &lt;Console name=&quot;console&quot; target=&quot;SYSTEM_OUT&quot;&gt; &lt;!--控制台只输出level及以上级别的信息（onMatch），其他的直接拒绝（onMismatch）--&gt; &lt;ThresholdFilter level=&quot;info&quot; onMatch=&quot;ACCEPT&quot; onMismatch=&quot;DENY&quot;/&gt; &lt;!-- 输出日志的格式 --&gt; &lt;PatternLayout pattern=&quot;$&#123;LOG_PATTERN&#125;&quot; charset=&quot;UTF-8&quot;/&gt; &lt;/Console&gt; &lt;!-- 打印出所有的信息，每次大小超过size，则这size大小的日志会自动存入按年份-月份建立的文件夹下面并进行压缩，作为存档 --&gt; &lt;RollingRandomAccessFile name=&quot;infoFile&quot; fileName=&quot;$&#123;fileName&#125;/web-info.log&quot; immediateFlush=&quot;false&quot; filePattern=&quot;$&#123;fileGz&#125;/$$&#123;date:yyyy-MM&#125;/%d&#123;yyyy-MM-dd&#125;-%i.web-info.gz&quot;&gt; &lt;PatternLayout pattern=&quot;$&#123;LOG_PATTERN&#125;&quot; charset=&quot;UTF-8&quot;/&gt; &lt;Policies&gt; &lt;SizeBasedTriggeringPolicy size=&quot;20 MB&quot;/&gt; &lt;/Policies&gt; &lt;Filters&gt; &lt;!-- 只记录info和warn级别信息 --&gt; &lt;ThresholdFilter level=&quot;error&quot; onMatch=&quot;DENY&quot; onMismatch=&quot;NEUTRAL&quot;/&gt; &lt;ThresholdFilter level=&quot;info&quot; onMatch=&quot;ACCEPT&quot; onMismatch=&quot;DENY&quot;/&gt; &lt;/Filters&gt; &lt;!-- 指定每天的最大压缩包个数，默认7个，超过了会覆盖之前的 --&gt; &lt;DefaultRolloverStrategy max=&quot;50&quot;/&gt; &lt;/RollingRandomAccessFile&gt; &lt;!-- 存储所有error信息 --&gt; &lt;RollingRandomAccessFile name=&quot;errorFile&quot; fileName=&quot;$&#123;fileName&#125;/web-error.log&quot; immediateFlush=&quot;false&quot; filePattern=&quot;$&#123;fileGz&#125;/$$&#123;date:yyyy-MM&#125;/%d&#123;yyyy-MM-dd&#125;-%i.web-error.gz&quot;&gt; &lt;PatternLayout pattern=&quot;$&#123;LOG_PATTERN&#125;&quot; charset=&quot;UTF-8&quot;/&gt; &lt;Policies&gt; &lt;SizeBasedTriggeringPolicy size=&quot;50 MB&quot;/&gt; &lt;/Policies&gt; &lt;Filters&gt; &lt;!-- 只记录error级别信息 --&gt; &lt;ThresholdFilter level=&quot;error&quot; onMatch=&quot;ACCEPT&quot; onMismatch=&quot;DENY&quot;/&gt; &lt;/Filters&gt; &lt;!-- 指定每天的最大压缩包个数，默认7个，超过了会覆盖之前的 --&gt; &lt;DefaultRolloverStrategy max=&quot;50&quot;/&gt; &lt;/RollingRandomAccessFile&gt; &lt;/Appenders&gt; &lt;!-- Mixed sync/async --&gt; &lt;Loggers&gt; &lt;!--&lt;logger name=&quot;org.apache.http&quot; level=&quot;warn&quot;/&gt; &lt;logger name=&quot;org.springframework&quot; level=&quot;WARN&quot;/&gt; &lt;logger name=&quot;com.ibatis&quot; level=&quot;DEBUG&quot;/&gt; &lt;logger name=&quot;com.ibatis.common.jdbc.SimpleDataSource&quot; level=&quot;DEBUG&quot;/&gt; &lt;logger name=&quot;com.ibatis.common.jdbc.ScriptRunner&quot; level=&quot;DEBUG&quot;/&gt; &lt;logger name=&quot;com.ibatis.sqlmap.engine.impl.SqlMapClientDelegate&quot; level=&quot;DEBUG&quot;/&gt; &lt;logger name=&quot;java.sql.Connection&quot; level=&quot;DEBUG&quot; additivity=&quot;true&quot;/&gt; &lt;logger name=&quot;java.sql.Statement&quot; level=&quot;DEBUG&quot; additivity=&quot;true&quot;/&gt; &lt;logger name=&quot;java.sql.PreparedStatement&quot; level=&quot;=debug,stdout&quot; additivity=&quot;true&quot;/&gt; &lt;logger name=&quot;java.sql.ResultSet&quot; level=&quot;DEBUG&quot; additivity=&quot;true&quot;/&gt; &lt;logger name=&quot;org.apache&quot; level=&quot;WARN&quot;/&gt; &amp;lt;!&amp;ndash; 对包进行更详细的配置 &amp;ndash;&amp;gt; &amp;lt;!&amp;ndash; additivity表示是否追加,防止重复,因为root已经接收过一次了 &amp;ndash;&amp;gt; &lt;logger name=&quot;com.my.blog.website.dao&quot; level=&quot;DEBUG&quot; additivity=&quot;true&quot;&gt; &lt;appender-ref ref=&quot;db_log&quot;/&gt; &lt;/logger&gt; &lt;logger name=&quot;com.my.blog.website.controller&quot; level=&quot;DEBUG&quot; additivity=&quot;false&quot;&gt; &lt;appender-ref ref=&quot;service_log&quot;/&gt; &lt;/logger&gt; &lt;logger name=&quot;com.my.blog.website.service&quot; level=&quot;DEBUG&quot; additivity=&quot;false&quot;&gt; &lt;appender-ref ref=&quot;service_log&quot;/&gt; &lt;/logger&gt;--&gt; &lt;AsyncRoot level=&quot;debug&quot; includeLocation=&quot;true&quot;&gt; &lt;AppenderRef ref=&quot;console&quot;/&gt; &lt;AppenderRef ref=&quot;infoFile&quot;/&gt; &lt;AppenderRef ref=&quot;errorFile&quot;/&gt; &lt;/AsyncRoot&gt; &lt;/Loggers&gt;&lt;/configuration&gt; 也可以使用log4j2.yml需要引入依赖以识别： 12345&lt;!-- 加上这个才能辨认到log4j2.yml文件 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.dataformat&lt;/groupId&gt; &lt;artifactId&gt;jackson-dataformat-yaml&lt;/artifactId&gt;&lt;/dependency&gt; log4j2.yml: 1234567891011121314151617181920212223242526272829303132333435Configuration: status: &quot;OFF&quot; monitorInterval: 10 Properties: Property: - name: log.level.console value: debug - name: PID value: ???? - name: LOG_PATTERN value: &quot;%clr&#123;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125;&#125;&#123;faint&#125; | %clr&#123;%5p&#125; | %clr&#123;$&#123;sys:PID&#125;&#125;&#123;magenta&#125; | %clr&#123;%15.15t&#125;&#123;faint&#125; | %clr&#123;%-50.50c&#123;1.&#125;&#125;&#123;cyan&#125; | %5L | %clr&#123;%M&#125;&#123;magenta&#125; | %msg%n%xwEx&quot; Appenders: Console: #输出到控制台 name: CONSOLE target: SYSTEM_OUT ThresholdFilter: level: $&#123;sys:log.level.console&#125; # “sys:”表示：如果VM参数中没指定这个变量值，则使用本文件中定义的缺省全局变量值 onMatch: ACCEPT onMismatch: DENY PatternLayout: pattern: $&#123;LOG_PATTERN&#125; charset: UTF-8 Loggers: Root: level: info includeLocation: true AppenderRef: - ref: CONSOLE AsyncRoot: level: info includeLocation: true AppenderRef: - ref: CONSOLE 更多配置请参照：http://logging.apache.org/log4j/2.x/manual/layouts.html 日志配置文件中获取Application配置项Logback方法1: 使用logback-spring.xml，因为logback.xml加载早于application.properties，所以如果你在logback.xml使用了变量时，而恰好这个变量是写在application.properties时，那么就会获取不到，只要改成logback-spring.xml就可以解决。 方法2: 使用&lt;springProperty&gt;标签，例如： 1&lt;springProperty scope=&quot;context&quot; name=&quot;LOG_HOME&quot; source=&quot;logback.file&quot;/&gt; Log4j2只能写一个Lookup： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081@SuppressWarnings(&quot;unused&quot;)@Plugin(name = &quot;spring&quot;, category = StrLookup.CATEGORY)public class SpringEnvironmentLookup extends AbstractLookup &#123; private static LinkedHashMap profileYmlData; private static LinkedHashMap metaYmlData; private static boolean profileExist; private static Map&lt;String, String&gt; map = new HashMap&lt;&gt;(16); private static final String META_PROFILE = &quot;application.yml&quot;; private static final String PROFILE_PREFIX = &quot;application&quot;; private static final String PROFILE_SUFFIX = &quot;.yml&quot;; private static final String DEFAULT_PROFILE = &quot;application-dev.yml&quot;; private static final String SPRING_PROFILES_ACTIVE = &quot;spring.profiles.active&quot;; static &#123; try &#123; metaYmlData = new Yaml().loadAs(new ClassPathResource(META_PROFILE).getInputStream(), LinkedHashMap.class); Properties properties = System.getProperties(); String active = properties.getProperty(SPRING_PROFILES_ACTIVE); if (isBlank(active)) &#123; active = getValueFromData(SPRING_PROFILES_ACTIVE, SPRING_PROFILES_ACTIVE.split(&quot;\\.&quot;), metaYmlData); &#125; String configName = isNotBlank(active) ? PROFILE_PREFIX + &quot;-&quot; + active + PROFILE_SUFFIX : DEFAULT_PROFILE; ClassPathResource classPathResource = new ClassPathResource(configName); profileExist = classPathResource.exists(); if (profileExist) &#123; profileYmlData = new Yaml().loadAs(classPathResource.getInputStream(), LinkedHashMap.class); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); throw new RuntimeException(&quot;SpringEnvironmentLookup initialize fail&quot;); &#125; &#125; @Override public String lookup(LogEvent event, String key) &#123; return map.computeIfAbsent(key, SpringEnvironmentLookup::resolveYmlMapByKey); &#125; private static String resolveYmlMapByKey(String key) &#123; Assert.isTrue(isNotBlank(key), &quot;key can not be blank!&quot;); String[] keyChain = key.split(&quot;\\.&quot;); String value = null; if (profileExist) &#123; value = getValueFromData(key, keyChain, profileYmlData); &#125; if (isBlank(value)) &#123; value = getValueFromData(key, keyChain, metaYmlData); &#125; return value; &#125; private static String getValueFromData(String key, String[] keyChain, LinkedHashMap dataMap) &#123; int length = keyChain.length; if (length == 1) &#123; return getFinalValue(key, dataMap); &#125; String k; LinkedHashMap[] mapChain = new LinkedHashMap[length]; mapChain[0] = dataMap; for (int i = 0; i &lt; length; i++) &#123; if (i == length - 1) &#123; return getFinalValue(keyChain[i], mapChain[i]); &#125; k = keyChain[i]; Object o = mapChain[i].get(k); if (Objects.isNull(o)) &#123; return &quot;&quot;; &#125; if (o instanceof LinkedHashMap) &#123; mapChain[i + 1] = (LinkedHashMap) o; &#125; else &#123; throw new IllegalArgumentException(); &#125; &#125; return &quot;&quot;; &#125; private static String getFinalValue(String k, LinkedHashMap ymlData) &#123; return defaultIfNull((String) ymlData.get(k), &quot;&quot;); &#125;&#125; 然后在log4j2.xml中这样使用 ${spring:spring.application.name} 查看依赖树如果引入了某些jar包带有logback依赖，log4j2会失效，需要通过IDEA或Maven查找排除依赖： 1mvn dependency:tree Spring MVC 相关Spring MVC集成fastjson12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.46&lt;/version&gt;&lt;/dependency&gt; 两种方式： 方式一、实现WebMvcConfigurer12345678910111213141516171819202122@Configurationpublic class WebMvcMessageConvertConfig implements WebMvcConfigurer &#123; @Override public void configureMessageConverters(List&lt;HttpMessageConverter&lt;?&gt;&gt; converters) &#123; FastJsonHttpMessageConverter fastConverter = new FastJsonHttpMessageConverter(); SerializeConfig serializeConfig = SerializeConfig.globalInstance; serializeConfig.put(BigInteger.class, ToStringSerializer.instance); serializeConfig.put(Long.class, ToStringSerializer.instance); serializeConfig.put(Long.TYPE, ToStringSerializer.instance); FastJsonConfig fastJsonConfig = new FastJsonConfig(); fastJsonConfig.setCharset(Charset.forName(&quot;UTF-8&quot;)); fastJsonConfig.setSerializeConfig(serializeConfig); fastJsonConfig.setSerializerFeatures(SerializerFeature.PrettyFormat); fastJsonConfig.setDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;); fastConverter.setFastJsonConfig(fastJsonConfig); converters.add(fastConverter); &#125;&#125; 方式二、通过@Bean方式123456789101112131415161718192021@Configurationpublic class WebMvcMessageConvertConfig &#123; @Bean public HttpMessageConverters fastJsonHttpMessageConverter() &#123; FastJsonHttpMessageConverter fastConverter = new FastJsonHttpMessageConverter(); SerializeConfig serializeConfig = SerializeConfig.globalInstance; serializeConfig.put(BigInteger.class, ToStringSerializer.instance); serializeConfig.put(Long.class, ToStringSerializer.instance); serializeConfig.put(Long.TYPE, ToStringSerializer.instance); FastJsonConfig fastJsonConfig = new FastJsonConfig(); fastJsonConfig.setCharset(Charset.forName(Constant.CHARSET)); fastJsonConfig.setSerializeConfig(serializeConfig); fastJsonConfig.setSerializerFeatures(SerializerFeature.PrettyFormat); fastJsonConfig.setDateFormat(Constant.DATE_FORMAT); fastConverter.setFastJsonConfig(fastJsonConfig); return new HttpMessageConverters((HttpMessageConverter&lt;?&gt;) fastConverter); &#125;&#125; WebFlux上面针对的是Web MVC，对于Webflux目前不支持这种方式，只能先这么设置 1234spring: jackson: default-property-inclusion: non_null # 过滤值为null的字段 date-format: &quot;yyyy-MM-dd HH:mm:ss&quot; Spring Boot MVC特性Spring boot 在spring默认基础上，自动配置添加了以下特性 包含了ContentNegotiatingViewResolver和BeanNameViewResolver beans。 对静态资源的支持，包括对WebJars的支持。 自动注册Converter，GenericConverter，Formatter beans。 对HttpMessageConverters的支持。 自动注册MessageCodeResolver。 对静态index.html的支持。 对自定义Favicon的支持。 主动使用ConfigurableWebBindingInitializer bean 模板引擎的选择 FreeMarker Thymeleaf Velocity (1.4版本之后弃用，Spring Framework 4.3版本之后弃用) Groovy Mustache 注：jsp应该尽量避免使用，原因如下： jsp只能打包为：war格式，不支持jar格式，只能在标准的容器里面跑（tomcat，jetty都可以） 内嵌的Jetty目前不支持JSPs Undertow不支持jsps jsp自定义错误页面不能覆盖spring boot 默认的错误页面 开启GZIP算法压缩响应流1234server: compression: enabled: true # 启用压缩 min-response-size: 2048 # 对应Content-Length，超过这个值才会压缩 全局异常处理方式一：添加自定义的错误页面 html静态页面：在resources/public/error/ 下定义. 如添加404页面： resources/public/error/404.html页面，中文注意页面编码 模板引擎页面：在templates/error/下定义. 如添加5xx页面： templates/error/5xx.ftl 注：templates/error/ 这个的优先级比较resources/public/error/高 方式二：通过@ControllerAdvice12345678910111213141516171819202122232425@Slf4j@ControllerAdvice//@RestControllerAdvicepublic class ErrorExceptionHandler &#123; @ExceptionHandler(&#123; RuntimeException.class &#125;) @ResponseStatus(HttpStatus.OK) public ModelAndView processException(RuntimeException exception) &#123; log.info(&quot;自定义异常处理-RuntimeException&quot;); ModelAndView m = new ModelAndView(); m.addObject(&quot;roncooException&quot;, exception.getMessage()); m.setViewName(&quot;error/500&quot;); return m; &#125; @ExceptionHandler(&#123; Exception.class &#125;) @ResponseStatus(HttpStatus.OK) public ModelAndView processException(Exception exception) &#123; log.info(&quot;自定义异常处理-Exception&quot;); ModelAndView m = new ModelAndView(); m.addObject(&quot;roncooException&quot;, exception.getMessage()); m.setViewName(&quot;error/500&quot;); return m; &#125;&#125; 静态资源设置静态资源放到指定路径下 1spring.resources.static-locations=classpath:/META-INF/resources/,classpath:/static/ 自定义消息转化器12345@Bean public StringHttpMessageConverter stringHttpMessageConverter() &#123; StringHttpMessageConverter converter = new StringHttpMessageConverter(Charset.forName(&quot;UTF-8&quot;)); return converter; &#125; 自定义SpringMVC的拦截器有些时候我们需要自己配置SpringMVC而不是采用默认，比如增加一个拦截器 1234567891011121314151617181920212223public class MyInterceptor implements HandlerInterceptor &#123; @Override public void afterCompletion(HttpServletRequest arg0, HttpServletResponse arg1, Object arg2, Exception arg3) throws Exception &#123; System.out.println(&quot;拦截器MyInterceptor-------&gt;3、请求结束之后被调用，主要用于清理工作。&quot;); &#125; @Override public void postHandle(HttpServletRequest arg0, HttpServletResponse arg1, Object arg2, ModelAndView arg3) throws Exception &#123; System.out.println(&quot;拦截器MyInterceptor-------&gt;2、请求之后调用，在视图渲染之前，也就是Controller方法调用之后&quot;); &#125; @Override public boolean preHandle(HttpServletRequest arg0, HttpServletResponse arg1, Object arg2) throws Exception &#123; System.out.println(&quot;拦截器MyInterceptor-------&gt;1、请求之前调用，也就是Controller方法调用之前。&quot;); return true;//返回true则继续向下执行，返回false则取消当前请求 &#125;&#125; 1234567891011121314@Configurationpublic class InterceptorConfigurerAdapter extends WebMvcConfigurer &#123; /** * 该方法用于注册拦截器 * 可注册多个拦截器，多个拦截器组成一个拦截器链 */ @Override public void addInterceptors(InterceptorRegistry registry) &#123; // addPathPatterns 添加路径 // excludePathPatterns 排除路径 registry.addInterceptor(new MyInterceptor()).addPathPatterns(&quot;/*.*&quot;); super.addInterceptors(registry); &#125;&#125; 创建 Servlet、 Filter、Listener注解方式 直接通过@WebServlet、@WebFilter、@WebListener 注解自动注册 1234567891011121314@WebFilter(filterName = &quot;customFilter&quot;, urlPatterns = &quot;/*&quot;)public class CustomFilter implements Filter &#123; ...&#125;@WebListenerpublic class CustomListener implements ServletContextListener &#123; ...&#125;@WebServlet(name = &quot;customServlet&quot;, urlPatterns = &quot;/roncoo&quot;)public class CustomServlet extends HttpServlet &#123; ...&#125; 然后需要在**Application.java 加上@ServletComponentScan注解，否则不会生效。 注意：如果同时添加了@WebFilter以及@Component，那么会初始化两次Filter，并且会过滤所有路径+自己指定的路径 ，便会出现对没有指定的URL也会进行过滤 通过编码注册1234567891011121314151617181920212223242526272829303132333435363738@Configurationpublic class WebConfig &#123; @Bean public FilterRegistrationBean myFilter()&#123; FilterRegistrationBean registrationBean = new FilterRegistrationBean(); MyFilter filter = new MyFilter(); registrationBean.setFilter(filter); List&lt;String&gt; urlPatterns = new ArrayList&lt;&gt;(); urlPatterns.add(&quot;/*&quot;); registrationBean.setUrlPatterns(urlPatterns); registrationBean.setOrder(1); return registrationBean; &#125; @Bean public ServletRegistrationBean myServlet() &#123; MyServlet demoServlet = new MyServlet(); ServletRegistrationBean registrationBean = new ServletRegistrationBean(); registrationBean.setServlet(demoServlet); List&lt;String&gt; urlMappings = new ArrayList&lt;String&gt;(); urlMappings.add(&quot;/myServlet&quot;);////访问，可以添加多个 registrationBean.setUrlMappings(urlMappings); registrationBean.setLoadOnStartup(1); return registrationBean; &#125; @Bean public ServletListenerRegistrationBean myListener() &#123; ServletListenerRegistrationBean registrationBean = new ServletListenerRegistrationBean&lt;&gt;(); registrationBean.setListener(new MyListener()); registrationBean.setOrder(1); return registrationBean; &#125;&#125; Spring Interceptor与Servlet Filter的区别 Filter是基于函数回调的，而Interceptor则是基于Java反射的。 Filter依赖于Servlet容器，而Interceptor不依赖于Servlet容器。 Filter对几乎所有的请求起作用，而Interceptor只能对action请求起作用。 Interceptor可以访问Action的上下文，值栈里的对象，而Filter不能。 在action的生命周期里，Interceptor可以被多次调用，而Filter只能在容器初始化时调用一次。 Validation常用注解（大部分JSR中已有）123456789101112131415161718@Null 被注释的元素必须为 null @NotNull 被注释的元素必须不为 null @AssertTrue 被注释的元素必须为 true @AssertFalse 被注释的元素必须为 false @Min(value) 被注释的元素必须是一个数字，其值必须大于等于指定的最小值 @Max(value) 被注释的元素必须是一个数字，其值必须小于等于指定的最大值 @DecimalMin(value) 被注释的元素必须是一个数字，其值必须大于等于指定的最小值 @DecimalMax(value) 被注释的元素必须是一个数字，其值必须小于等于指定的最大值 @Size(max=, min=) 被注释的元素的大小必须在指定的范围内 @Digits (integer, fraction) 被注释的元素必须是一个数字，其值必须在可接受的范围内 @Past 被注释的元素必须是一个过去的日期 @Future 被注释的元素必须是一个将来的日期 @Pattern(regex=,flag=) 被注释的元素必须符合指定的正则表达式@NotBlank(message =) 验证字符串非null，且长度必须大于0 @Email 被注释的元素必须是电子邮箱地址 @Length(min=,max=) 被注释的字符串的大小必须在指定的范围内 @NotEmpty 被注释的字符串的必须非空 @Range(min=,max=,message=) 被注释的元素必须在合适的范围内 简单使用实体： 123456789101112131415@Datapublic class Foo &#123; @NotBlank private String name; @Min(18) private Integer age; @Pattern(regexp = &quot;^1([34578])\\d&#123;9&#125;$&quot;,message = &quot;手机号码格式错误&quot;) @NotBlank(message = &quot;手机号码不能为空&quot;) private String phone; @Email(message = &quot;邮箱格式错误&quot;) private String email;&#125; Controller: 12345678910111213141516@RestController@Slf4jpublic class FooController &#123; @PostMapping(&quot;/foo&quot;) public String foo(@Validated Foo foo, BindingResult bindingResult) &#123; log.info(&quot;foo: &#123;&#125;&quot;, foo); if (bindingResult.hasErrors()) &#123; for (FieldError fieldError : bindingResult.getFieldErrors()) &#123; log.error(&quot;valid fail: field = &#123;&#125;, message = &#123;&#125;&quot;, fieldError.getField(), fieldError.getDefaultMessage()); &#125; return &quot;fail&quot;; &#125; return &quot;success&quot;; &#125;&#125; 快速失效一般情况下，Validator并不会应为第一个校验失败为停止，而是一直校验完所有参数。我们可以通过设置快速失效： 123456789101112@Configurationpublic class ValidatorConfiguration &#123; @Bean public Validator validator()&#123; ValidatorFactory validatorFactory = Validation.byProvider( HibernateValidator.class ) .configure() .failFast( true )// .addProperty( &quot;hibernate.validator.fail_fast&quot;, &quot;true&quot; ) .buildValidatorFactory(); return validatorFactory.getValidator(); &#125;&#125; 这样在遇到第一个校验失败的时候就会停止对之后的参数校验。 分组校验 如果同一个类，在不同的使用场景下有不同的校验规则，那么可以使用分组校验。未成年人是不能喝酒的，而在其他场景下我们不做特殊的限制，这个需求如何体现同一个实体，不同的校验规则呢？ 添加分组： 12345678Class Foo&#123; @Min(value = 18,groups = &#123;Adult.class&#125;) private Integer age; public interface Adult&#123;&#125; public interface Minor&#123;&#125;&#125; Controller： 12345678910@RequestMapping(&quot;/drink&quot;)public String drink(@Validated(&#123;Foo.Adult.class&#125;) Foo foo, BindingResult bindingResult) &#123; if(bindingResult.hasErrors())&#123; for (FieldError fieldError : bindingResult.getFieldErrors()) &#123; //... &#125; return &quot;fail&quot;; &#125; return &quot;success&quot;;&#125; 自定义校验业务需求总是比框架提供的这些简单校验要复杂的多，我们可以自定义校验来满足我们的需求。自定义spring validation非常简单，主要分为两步。 1 自定义校验注解我们尝试添加一个“字符串不能包含空格”的限制。 123456789101112131415161718192021222324@Target(&#123;METHOD, FIELD, ANNOTATION_TYPE, CONSTRUCTOR, PARAMETER&#125;)@Retention(RUNTIME)@Documented@Constraint(validatedBy = &#123;CannotHaveBlankValidator.class&#125;)&lt;1&gt;public @interface CannotHaveBlank &#123; //默认错误消息 String message() default &quot;不能包含空格&quot;; //分组 Class&lt;?&gt;[] groups() default &#123;&#125;; //负载 Class&lt;? extends Payload&gt;[] payload() default &#123;&#125;; //指定多个时使用 @Target(&#123;FIELD, METHOD, PARAMETER, ANNOTATION_TYPE&#125;) @Retention(RUNTIME) @Documented @interface List &#123; CannotHaveBlank[] value(); &#125;&#125; 我们不需要关注太多东西，使用spring validation的原则便是便捷我们的开发，例如payload，List ，groups，都可以忽略。 &lt;1&gt; 自定义注解中指定了这个注解真正的验证者类。 2 编写真正的校验者类 1234567891011121314151617181920212223public class CannotHaveBlankValidator implements &lt;1&gt; ConstraintValidator&lt;CannotHaveBlank, String&gt; &#123; @Override public void initialize(CannotHaveBlank constraintAnnotation) &#123; &#125; @Override public boolean isValid(String value, ConstraintValidatorContext context &lt;2&gt;) &#123; //null时不进行校验 if (value != null &amp;&amp; value.contains(&quot; &quot;)) &#123; &lt;3&gt; //获取默认提示信息 String defaultConstraintMessageTemplate = context.getDefaultConstraintMessageTemplate(); System.out.println(&quot;default message :&quot; + defaultConstraintMessageTemplate); //禁用默认提示信息 context.disableDefaultConstraintViolation(); //设置提示语 context.buildConstraintViolationWithTemplate(&quot;can not contains blank&quot;).addConstraintViolation(); return false; &#125; return true; &#125;&#125; &lt;1&gt; 所有的验证者都需要实现ConstraintValidator接口，它的接口也很形象，包含一个初始化事件方法，和一个判断是否合法的方法 1234public interface ConstraintValidator&lt;A extends Annotation, T&gt; &#123; void initialize(A constraintAnnotation); boolean isValid(T value, ConstraintValidatorContext context);&#125; &lt;2&gt; ConstraintValidatorContext 这个上下文包含了认证中所有的信息，我们可以利用这个上下文实现获取默认错误提示信息，禁用错误提示信息，改写错误提示信息等操作。 &lt;3&gt; 一些典型校验操作，或许可以对你产生启示作用。 值得注意的一点是，自定义注解可以用在METHOD, FIELD, ANNOTATION_TYPE, CONSTRUCTOR, PARAMETER之上，ConstraintValidator的第二个泛型参数T，是需要被校验的类型。 手动校验可能在某些场景下需要我们手动校验，即使用校验器对需要被校验的实体发起validate，同步获得校验结果。理论上我们既可以使用Hibernate Validation提供Validator，也可以使用Spring对其的封装。在spring构建的项目中，提倡使用经过spring封装过后的方法，这里两种方法都介绍下： Hibernate Validation： 123456789Foo foo = new Foo();foo.setAge(22);foo.setEmail(&quot;000&quot;);ValidatorFactory vf = Validation.buildDefaultValidatorFactory();Validator validator = vf.getValidator();Set&lt;ConstraintViolation&lt;Foo&gt;&gt; set = validator.validate(foo);for (ConstraintViolation&lt;Foo&gt; constraintViolation : set) &#123; System.out.println(constraintViolation.getMessage());&#125; 由于依赖了Hibernate Validation框架，我们需要调用Hibernate相关的工厂方法来获取validator实例，从而校验。 在spring framework文档的Validation相关章节，可以看到如下的描述： Spring provides full support for the Bean Validation API. This includes convenient support for bootstrapping a JSR-303/JSR-349 Bean Validation provider as a Spring bean. This allows for a javax.validation.ValidatorFactory or javax.validation.Validator to be injected wherever validation is needed in your application. Use the LocalValidatorFactoryBean to configure a default Validator as a Spring bean: bean id=”validator” class=”org.springframework.validation.beanvalidation.LocalValidatorFactoryBean” The basic configuration above will trigger Bean Validation to initialize using its default bootstrap mechanism. A JSR-303/JSR-349 provider, such as Hibernate Validator, is expected to be present in the classpath and will be detected automatically. 上面这段话主要描述了spring对validation全面支持JSR-303、JSR-349的标准，并且封装了LocalValidatorFactoryBean作为validator的实现。值得一提的是，这个类的责任其实是非常重大的，他兼容了spring的validation体系和hibernate的validation体系，也可以被开发者直接调用，代替上述的从工厂方法中获取的hibernate validator。由于我们使用了springboot，会触发web模块的自动配置，LocalValidatorFactoryBean已经成为了Validator的默认实现，使用时只需要自动注入即可。 12345678910111213141516@AutowiredValidator globalValidator; &lt;1&gt;@RequestMapping(&quot;/validate&quot;)public String validate() &#123; Foo foo = new Foo(); foo.setAge(22); foo.setEmail(&quot;000&quot;); Set&lt;ConstraintViolation&lt;Foo&gt;&gt; set = globalValidator.validate(foo);&lt;2&gt; for (ConstraintViolation&lt;Foo&gt; constraintViolation : set) &#123; System.out.println(constraintViolation.getMessage()); &#125; return &quot;success&quot;;&#125; &lt;1&gt; 真正使用过Validator接口的读者会发现有两个接口，一个是位于javax.validation包下，另一个位于org.springframework.validation包下，注意我们这里使用的是前者javax.validation，后者是spring自己内置的校验接口，LocalValidatorFactoryBean同时实现了这两个接口。 &lt;2&gt; 此处校验接口最终的实现类便是LocalValidatorFactoryBean。 基于方法校验12345678910111213141516171819202122@RestController@Validated &lt;1&gt;public class BarController &#123; @RequestMapping(&quot;/bar&quot;) public @NotBlank &lt;2&gt; String bar(@Min(18) Integer age &lt;3&gt;) &#123; System.out.println(&quot;age : &quot; + age); return &quot;&quot;; &#125; @ExceptionHandler(ConstraintViolationException.class) public Map handleConstraintViolationException(ConstraintViolationException cve)&#123; Set&lt;ConstraintViolation&lt;?&gt;&gt; cves = cve.getConstraintViolations();&lt;4&gt; for (ConstraintViolation&lt;?&gt; constraintViolation : cves) &#123; System.out.println(constraintViolation.getMessage()); &#125; Map map = new HashMap(); map.put(&quot;errorCode&quot;,500); return map; &#125;&#125; &lt;1&gt; 为类添加@Validated注解 &lt;2&gt; &lt;3&gt; 校验方法的返回值和入参 &lt;4&gt; 添加一个异常处理器，可以获得没有通过校验的属性相关信息 基于方法的校验，个人不推荐使用，感觉和项目结合的不是很好。 统一处理验证异常1234567891011121314151617181920@ControllerAdvice@Componentpublic class GlobalExceptionHandler &#123; @ExceptionHandler @ResponseBody @ResponseStatus(HttpStatus.BAD_REQUEST) public String handle(ValidationException exception) &#123; if(exception instanceof ConstraintViolationException)&#123; ConstraintViolationException exs = (ConstraintViolationException) exception; Set&lt;ConstraintViolation&lt;?&gt;&gt; violations = exs.getConstraintViolations(); for (ConstraintViolation&lt;?&gt; item : violations) &#123; /**打印验证不通过的信息*/ System.out.println(item.getMessage()); &#125; &#125; return &quot;bad request, &quot; ; &#125;&#125; 参考：https://www.cnkirito.moe/2017/08/16/%E4%BD%BF%E7%94%A8spring%20validation%E5%AE%8C%E6%88%90%E6%95%B0%E6%8D%AE%E5%90%8E%E7%AB%AF%E6%A0%A1%E9%AA%8C/ 创建异步方法启动异步12345@Configuration@EnableAsyncpublic class SpringAsyncConfig &#123; &#125; 配置完这个就已经具备异步方法功能了，只需要在方法上面添加@Async即可 如果被@Async注解的方法所在类是基于接口实现的，想要直接注入实现类，需要添加：@EnableAsync(proxyTargetClass = true) 以使用CGLIB代理 编写异步方法1234@Asyncpublic void asyncMethodWithVoidReturnType() throws InterruptedException &#123; System.out.println(&quot;Execute method asynchronously. &quot; + Thread.currentThread().getName());&#125; 配置线程池在不配置线程池的情况下，Spring默认使用SimpleAsyncTaskExecutor，每一次的执行任务都会使用新的线程，性能不太好，所以我们可以自定义线程池 直接声明线程池12345678910111213141516@Configuration@EnableAsyncpublic class SpringAsyncConfig &#123; @Bean public Executor threadPoolTaskExecutor() &#123; ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor(); executor.setCorePoolSize(10); executor.setMaxPoolSize(20); executor.setQueueCapacity(500); executor.setKeepAliveSeconds(60); executor.setThreadNamePrefix(&quot;asyncExecutor-&quot;); executor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy()); executor.initialize(); return executor; &#125;&#125; 通过使用ThreadPoolTaskExecutor创建了一个线程池，同时设置了以下这些参数： 核心线程数10：线程池创建时候初始化的线程数 最大线程数20：线程池最大的线程数，只有在缓冲队列满了之后才会申请超过核心线程数的线程 缓冲队列500：用来缓冲执行任务的队列 允许线程的空闲时间60秒：当超过了核心线程出之外的线程在空闲时间到达之后会被销毁 线程池名的前缀：设置好了之后可以方便我们定位处理任务所在的线程池 线程池对拒绝任务的处理策略：这里采用了CallerRunsPolicy策略，当线程池没有处理能力的时候，该策略会直接在 execute 方法的调用线程中运行被拒绝的任务；如果执行程序已关闭，则会丢弃该任务 实现AsyncConfigurer 通过这种方式，可以对异常进行处理 AsyncConfigurer接口有两个方法： getAsyncExecutor(): 提供线程池 getAsyncUncaughtExceptionHandler(): 异步任务异常处理 1234567891011121314151617181920212223242526@Configuration@EnableAsyncpublic class SpringAsyncConfig implements AsyncConfigurer &#123; @Override public Executor getAsyncExecutor() &#123; ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor(); executor.setCorePoolSize(8); executor.setMaxPoolSize(42); executor.setQueueCapacity(500); executor.setThreadNamePrefix(&quot;MyExecutor-&quot;); executor.initialize(); return executor; &#125; @Override public AsyncUncaughtExceptionHandler getAsyncUncaughtExceptionHandler()&#123; return (ex, method, params) -&gt; &#123; ExceptionUtils.printRootCauseStackTrace(ex); System.out.println(&quot;Exception message - &quot; + ex.getMessage()); System.out.println(&quot;Method name - &quot; + method.getName()); for (Object param : params) &#123; System.out.println(&quot;Parameter value - &quot; + param); &#125; &#125;; &#125;&#125; 优雅关闭线程池有时候，存在关闭程序但还有异步任务在执行的情况，这时候，我们需要优雅地关闭线程池，只需要两个参数： 12executor.setWaitForTasksToCompleteOnShutdown(true);executor.setAwaitTerminationSeconds(60); Async使用指定线程池如果同时实现了AsyncConfigurer以及配置线程池，那么@Async默认使用AsyncConfigurer.getAsyncExecutor的线程池。 如果需要指定线程池可以这样 12@Async(&quot;threadPoolTaskExecutor&quot;)public void someMethod()&#123;...&#125; 获取异步执行结果Service： 123456@Async(&quot;threadPoolTaskExecutor&quot;)@Overridepublic Future&lt;String&gt; asyncMethodWithVoidReturnType() throws InterruptedException &#123; Thread.sleep(2000L); return AsyncResult.forValue(&quot;Execute method asynchronously. &quot; + Thread.currentThread().getName());&#125; Controller： 12345678910@GetMapping(&quot;/hello&quot;)public Mono&lt;String&gt; syaHello() throws InterruptedException, ExecutionException &#123; Future&lt;String&gt; stringFuture = someService.asyncMethodWithVoidReturnType(); while (!stringFuture.isDone())&#123; System.out.println(&quot;wait...&quot;); Thread.sleep(500L); &#125; System.out.println(stringFuture.get()); return Mono.just(&quot;Hello World&quot;);&#125; 执行结果： 123456wait...wait...wait...wait...wait...Execute method asynchronously. asyncExecutor-1 Spring定时任务启用： 12345678910111213141516171819@Configuration@EnableSchedulingpublic class SpringScheduleConfig implements SchedulingConfigurer &#123; @Override public void configureTasks(ScheduledTaskRegistrar taskRegistrar) &#123; taskRegistrar.setScheduler(taskExecutor()); &#125; @Bean public Executor taskExecutor() &#123; return new ScheduledThreadPoolExecutor(4, new BasicThreadFactory .Builder() .namingPattern(&quot;schedule-pool-thread-%d&quot;) .daemon(true) .build()); &#125;&#125; 定时任务： 123456private int i = 0;@Scheduled(fixedDelay=1000)public void doScheduled() &#123; System.out.println(Thread.currentThread().getName() + &quot; &quot; + ++i);&#125; 结果： 12345schedule-pool-thread-1 2schedule-pool-thread-2 3schedule-pool-thread-1 4schedule-pool-thread-3 5schedule-pool-thread-2 6 Spring启动后执行程序的几种方式@PostConstruct 或 InitializingBean通过@PostConstruct或实现InitializingBean实现初始化bean的时候干一些事情，两者区别在于InitializingBean是在属性设置完之后执行的，所以执行顺序是在@PostConstruct之前 由于此接口的方法afterPropertiesSet是在对象的所有属性被初始化后才会调用。当Spring的配置文件中设置类初始默认为”延迟初始”（default-lazy-init=&quot;true&quot;，此值默认为false）时， 类对象如果不被使用，则不会实例化该类对象。所以 InitializingBean子类不能用于在容器启动时进行初始化的工作，则应使用Spring提供的ApplicationListener接口来进行程序的初始化工作。 另外，如果需要InitializingBean子类对象在Spring容器启动时就初始化并则容器调用afterPropertiesSet方法则需要在类上增加org.springframework.context.annotation.Lazy注解并设置为false即可（也可通过spring配置bean时添加lazy-init=&quot;false&quot;)。 监听ContextRefreshedEvent通过监听ContextRefreshedEvent事件： 123456789101112public class ApplicationContextRefreshedEventListener implements ApplicationListener&lt;ContextRefreshedEvent&gt; &#123; @Override public void onApplicationEvent(ContextRefreshedEvent event) &#123; System.out.println(&quot;ContextRefreshedEvent process...&quot;); &#125;&#125;或者@EventListenerpublic void processContextRefreshedEvent(ContextRefreshedEvent event) throws InterruptedException &#123; log.info(&quot;ContextRefreshedEvent process...&quot;);&#125; Spring的事件处理是单线程的，所以如果一个事件被触发，除非所有的接收者得到消息，否则这些进程被阻止，流程将不会继续。因此，如果要使用事件处理，在设计应用程序时应小心。 Spring内置事件以下是Spring的内置事件 Spring 内置事件 描述 ContextRefreshedEvent ApplicationContext被初始化或刷新时，该事件被发布。这也可以在ConfigurableApplicationContext接口中使用refresh()方法来发生。 ContextStartedEvent 当使用ConfigurableApplicationContext接口中的start()方法启动ApplicationContext时，该事件被触发。你可以查询你的数据库，或者你可以在接受到这个事件后重启任何停止的应用程序。 ContextStoppedEvent 当使用ConfigurableApplicationContext接口中的stop()方法停止ApplicationContext时，该事件被触发。你可以在接受到这个事件后做必要的清理的工作。 ContextClosedEvent 当使用ConfigurableApplicationContext接口中的close()方法关闭ApplicationContext时，该事件被触发。一个已关闭的上下文到达生命周期末端；它不能被刷新或重启。 RequestHandledEvent 这是一个web-specific事件，告诉所有bean HTTP请求已经被服务。 Spring Boot 2.0新增事件在Spring Boot 2.0中对事件模型做了一些增强，主要就是增加了ApplicationStartedEvent事件，所以在2.0版本中所有的事件按执行的先后顺序如下： ApplicationStartingEvent ApplicationEnvironmentPreparedEvent ApplicationPreparedEvent ApplicationStartedEvent &lt;= 新增的事件 ApplicationReadyEvent ApplicationFailedEvent ApplicationRunner 或 CommandLineRunner实现ApplicationRunner或CommandLineRunner 1234567891011121314151617@SpringBootApplicationpublic class ProdSyncLayerApplication implements ApplicationRunner,CommandLineRunner&#123; public static void main(String[] args) &#123; SpringApplication.run(ProdSyncLayerApplication.class, args); &#125; @Override public void run(ApplicationArguments args) throws Exception &#123; System.out.println(&quot;ApplicationRunner...&quot;); &#125; @Override public void run(String... args) throws Exception &#123; System.out.println(&quot;CommandLineRunner...&quot;); &#125;&#125; ApplicationRunner比CommandLineRunner先执行 总结：以上三种方式的顺序跟其序号一样 onApplicationEvent执行两次问题applicationontext和使用MVC之后的webApplicationontext会两次调用上面的方法，如何区分这个两种容器呢？ 但是这个时候，会存在一个问题，在web 项目中（spring mvc），系统会存在两个容器，一个是root application context ,另一个就是我们自己的 projectName-servlet context（作为root application context的子容器）。 这种情况下，就会造成onApplicationEvent方法被执行两次。为了避免上面提到的问题，我们可以只在root application context初始化完成后调用逻辑代码，其他的容器的初始化完成，则不做任何处理，修改后代码 123456@Override public void onApplicationEvent(ContextRefreshedEvent event) &#123; if(event.getApplicationContext().getParent() == null)&#123;//root application context 没有parent，他就是老大. //需要执行的逻辑代码，当spring容器初始化完成后就会执行该方法。 &#125; &#125; 后续发现加上以上判断还是能执行两次，不加的话三次，最终研究结果使用以下判断更加准确：event.getApplicationContext().getDisplayName().equals(&quot;Root WebApplicationContext&quot;) Spring应用停止前执行程序的几种方式 监听ContextClosedEvent 实现DisposableBean或使用@PostConstruct，执行顺序：@PostConstruct &gt; DisposableBean 使用ShutdownHook: 12345678910111213141516171819202122public class ShutdownHook &#123; public static void main(String[] args) throws InterruptedException &#123; Runtime.getRuntime().addShutdownHook(new Thread(() -&gt; &#123; try (FileWriter fw = new FileWriter(&quot;hook.log&quot;)) &#123; // 假设记录日志/或者发送消息 fw.write(&quot;完成销毁操作,回收内存! &quot; + (new Date()).toString()); System.out.println(&quot;退出程序...&quot;); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;)); IntStream.range(0, 10).forEach(i -&gt; &#123; try &#123; System.out.println(&quot;正在工作...&quot;); Thread.sleep(2000L); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); &#125;&#125; 进行远程调试远程调试的概念 什么是远程调试：本地调用非本地的环境进行调试。 原理：两个VM之间通过socket协议进行通信，然后以达到远程调试的目的。 注意，如果 Java 源代码与目标应用程序不匹配，调试特性将不能正常工作。 java启动命令1java -Xdebug -Xrunjdwp:server=y,transport=dt_socket,address=8000,suspend=n –jar spring-boot-demo-SNAPSHOT.jar]]></content>
      <categories>
        <category>Programming</category>
        <category>Java</category>
        <category>Spring Boot</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring Boot</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL杂记]]></title>
    <url>%2F2018%2Fmysql-related-learning%2F</url>
    <content type="text"><![CDATA[PrefaceMySQL是什么就多说了。。。安装传统安装请见博主之前的一篇博文Docker版安装直接贴出docker-compose.yml:1234567891011121314151617181920version: &apos;3.5&apos;services: mysql: image: mysql:latest container_name: mysql ports: - &quot;3306:3306&quot; volumes: - ../data:/var/lib/mysql - ../conf:/etc/mysql/conf.d environment: - MYSQL_ROOT_PASSWORD=root restart: always networks: - backendnetworks: backend: external: true 配置文件（config-file.cnf，放在上面volumes中提到的../conf里）： 123456[mysqld]sql_mode = STRICT_TRANS_TABLES,NO_ENGINE_SUBSTITUTIONlower_case_table_names = 1character-set-server = utf8mb4collation-server = utf8mb4_unicode_ci 遇到问题虽然启动成功，但发现MySQL实例是关闭的，在启动日志中发现这一条信息 大概意思是权限全局可写，任何一个用户都可以写。MySQL担心这种文件被其他用户恶意修改，所以忽略掉这个配置文件。 结论：配置文件权限过大，会影响实例不能启动，或者不能关闭，需要修改为 644 问题得以解决~！ 客户端以及GUI传统终端客户端1234sudo apt-get install mysql-client// 链接mysql -h 127.0.0.1 -P 3306 -u root -p 智能补全命令客户端这个一个智能补全并且高亮语法的终端客户端 mycli 安装： 1sudo apt install mycli 使用： 1234567891011121314151617181920212223242526272829303132333435363738394041424344$ mycli --helpUsage: mycli [OPTIONS] [DATABASE] A MySQL terminal client with auto-completion and syntax highlighting. Examples: - mycli my_database - mycli -u my_user -h my_host.com my_database - mycli mysql://my_user@my_host.com:3306/my_databaseOptions: -h, --host TEXT Host address of the database. -P, --port INTEGER Port number to use for connection. Honors $MYSQL_TCP_PORT. -u, --user TEXT User name to connect to the database. -S, --socket TEXT The socket file to use for connection. -p, --password TEXT Password to connect to the database. --pass TEXT Password to connect to the database. --ssl-ca PATH CA file in PEM format. --ssl-capath TEXT CA directory. --ssl-cert PATH X509 cert in PEM format. --ssl-key PATH X509 key in PEM format. --ssl-cipher TEXT SSL cipher to use. --ssl-verify-server-cert Verify server&apos;s &quot;Common Name&quot; in its cert against hostname used when connecting. This option is disabled by default. -v, --version Output mycli&apos;s version. -D, --database TEXT Database to use. -R, --prompt TEXT Prompt format (Default: &quot;\t \u@\h:\d&gt; &quot;). -l, --logfile FILENAME Log every query and its results to a file. --defaults-group-suffix TEXT Read MySQL config groups with the specified suffix. --defaults-file PATH Only read MySQL options from the given file. --myclirc PATH Location of myclirc file. --auto-vertical-output Automatically switch to vertical output mode if the result is wider than the terminal width. -t, --table Display batch output in table format. --csv Display batch output in CSV format. --warn / --no-warn Warn before running a destructive query. --local-infile BOOLEAN Enable/disable LOAD DATA LOCAL INFILE. --login-path TEXT Read this path from the login file. -e, --execute TEXT Execute command and quit. --help Show this message and exit. Navicat Premium安装以及破解在另一篇博文里面。 WorkbenchMySQL官方开源GUI 下载地址：https://dev.mysql.com/downloads/workbench/ 索引相关如何判断数据库索引是否生效使用explain ... \G分析语句 (使用\G可格式化结果) 表结构： 不使用索引： 使用索引： 可以看到，使用explain显示了很多列，各个关键字的含义如下： table：顾名思义，显示这一行的数据是关于哪张表的； type：这是重要的列，显示连接使用了何种类型。从最好到最差的连接类型为：const、eq_reg、ref、range、indexhe和ALL（详情：https://dev.mysql.com/doc/refman/5.7/en/explain-output.html#explain-join-types）； possible_keys：显示可能应用在这张表中的索引。如果为空，没有可能的索引。可以为相关的域从where语句中选择一个合适的语句； key： 实际使用的索引。如果为NULL，则没有使用索引。很少的情况下，MySQL会选择优化不足的索引。这种情况下，可以在Select语句中使用USE INDEX（indexname）来强制使用一个索引或者用IGNORE INDEX（indexname）来强制MySQL忽略索引； key_len：使用的索引的长度。在不损失精确性的情况下，长度越短越好； ref：显示索引的哪一列被使用了，如果可能的话，是一个常数； rows：MySQL认为必须检查的用来返回请求数据的行数； Extra：关于MySQL如何解析查询的额外信息。 以下是Extra返回含义： Distinct:一旦MYSQL找到了与行相联合匹配的行，就不再搜索了 Not exists: MYSQL优化了LEFT JOIN，一旦它找到了匹配LEFT JOIN标准的行，就不再搜索了 Range checked for each Record（index map:#）:没有找到理想的索引，因此对于从前面表中来的每一个行组合，MYSQL检查使用哪个索引，并用它来从表中返回行。这是使用索引的最慢的连接之一 Using filesort: 看到这个的时候，查询就需要优化了。MYSQL需要进行额外的步骤来发现如何对返回的行排序。它根据连接类型以及存储排序键值和匹配条件的全部行的行指针来排序全部行 Using index: 列数据是从仅仅使用了索引中的信息而没有读取实际的行动的表返回的，这发生在对表的全部的请求列都是同一个索引的部分的时候 Using temporary 看到这个的时候，查询需要优化了。这里，MYSQL需要创建一个临时表来存储结果，这通常发生在对不同的列集进行ORDER BY上，而不是GROUP BY上 Where used 使用了WHERE从句来限制哪些行将与下一张表匹配或者是返回给用户。如果不想返回表中的全部行，并且连接类型ALL或index，这就会发生，或者是查询有问题不同连接类型的解释（按照效率高低的顺序排序） system 表只有一行：system表。这是const连接类型的特殊情况 const:表中的一个记录的最大值能够匹配这个查询（索引可以是主键或惟一索引）。因为只有一行，这个值实际就是常数，因为MYSQL先读这个值然后把它当做常数来对待 eq_ref:在连接中，MYSQL在查询时，从前面的表中，对每一个记录的联合都从表中读取一个记录，它在查询使用了索引为主键或惟一键的全部时使用 ref:这个连接类型只有在查询使用了不是惟一或主键的键或者是这些类型的部分（比如，利用最左边前缀）时发生。对于之前的表的每一个行联合，全部记录都将从表中读出。这个类型严重依赖于根据索引匹配的记录多少—越少越好 range:这个连接类型使用索引返回一个范围中的行，比如使用&gt;或&lt;查找东西时发生的情况 index: 这个连接类型对前面的表中的每一个记录联合进行完全扫描（比ALL更好，因为索引一般小于表数据） ALL:这个连接类型对于前面的每一个记录联合进行完全扫描，这一般比较糟糕，应该尽量避免 具体的各个列所能表示的值以及含义可以参考MySQL官方文档介绍，地址：https://dev.mysql.com/doc/refman/5.7/en/explain-output.html 哪些场景会造成索引失效 应尽量避免在 where 子句中使用 != 或 &lt;&gt; 操作符，否则引擎将放弃使用索引而进行全表扫描 尽量避免在 where 子句中使用 or 来连接条件，否则将导致引擎放弃使用索引而进行全表扫描，即使其中有条件带索引也不会使用，这也是为什么尽量少用 or 的原因 对于多列索引，不是使用的第一部分，则不会使用索引 如果列类型是字符串，那一定要在条件中将数据使用引号引用起来，否则不会使用索引 like的模糊查询以 % 开头，索引失效 应尽量避免在 where 子句中对字段进行表达式操作，这将导致引擎放弃使用索引而进行全表扫描 如： 1select id from t where num/2 = 100 1 应改为: 1select id from t where num = 100*2；1 应尽量避免在 where 子句中对字段进行函数操作，这将导致引擎放弃使用索引而进行全表扫描 例如： 1select id from t where substring(name,1,3) = &apos;abc&apos; – name;1 以abc开头的，应改成： 1select id from t where name like ‘abc%’ 1 例如： 1select id from t where datediff(day, createdate, &apos;2005-11-30&apos;) = 0 – &apos;2005-11-30&apos;;1 应改为: 1select id from t where createdate &gt;= &apos;2005-11-30&apos; and createdate &lt; &apos;2005-12-1&apos;; 不要在 where 子句中的 = 左边进行函数、算术运算或其他表达式运算，否则系统将可能无法正确使用索引 如果MySQL估计使用全表扫描要比使用索引快，则不使用索引 不适合键值较少的列（重复数据较多的列） 假如索引列TYPE有5个键值，如果有1万条数据，那么 WHERE TYPE = 1将访问表中的2000个数据块。再加上访问索引块，一共要访问大于2000个的数据块。如果全表扫描，假设10条数据一个数据块，那么只需访问1000个数据块，既然全表扫描访问的数据块少一些，肯定就不会利用索引了。 参考：http://blog.csdn.net/xlgen157387/article/details/79572598 JSON相关JSON支持 在MySQL 5.7.8中，MySQL支持由RFC 7159定义的本地JSON数据类型，它支持对JSON(JavaScript对象标记)文档中的数据进行有效访问. MySQL会对DML JSON数据自动验证。无效的DML JSON数据操作会产生错误. 优化的存储格式。存储在JSON列中的JSON文档转换为一种内部格式，允许对Json元素进行快速读取访问. MySQL Json类型支持通过虚拟列方式建立索引，从而增加查询性能提升. 函数语法mysql在json类型中增加了一些json相关的函数 可以参考如下 Name Description JSON_APPEND() (deprecated 5.7.9) Append data to JSON document JSON_ARRAY() Create JSON array JSON_ARRAY_APPEND() Append data to JSON document JSON_ARRAY_INSERT() Insert into JSON array -&gt; Return value from JSON column after evaluating path; equivalent to JSON_EXTRACT(). JSON_CONTAINS() Whether JSON document contains specific object at path JSON_CONTAINS_PATH() Whether JSON document contains any data at path JSON_DEPTH() Maximum depth of JSON document JSON_EXTRACT() Return data from JSON document -&gt;&gt; Return value from JSON column after evaluating path and unquoting the result; equivalent to JSON_UNQUOTE(JSON_EXTRACT()). JSON_INSERT() Insert data into JSON document JSON_KEYS() Array of keys from JSON document JSON_LENGTH() Number of elements in JSON document JSON_MERGE() (deprecated 5.7.22) Merge JSON documents, preserving duplicate keys. Deprecated synonym for JSON_MERGE_PRESERVE() JSON_MERGE_PATCH() Merge JSON documents, replacing values of duplicate keys JSON_MERGE_PRESERVE() Merge JSON documents, preserving duplicate keys JSON_OBJECT() Create JSON object JSON_PRETTY() Prints a JSON document in human-readable format, with each array element or object member printed on a new line, indented two spaces with respect to its parent. JSON_QUOTE() Quote JSON document JSON_REMOVE() Remove data from JSON document JSON_REPLACE() Replace values in JSON document JSON_SEARCH() Path to value within JSON document JSON_SET() Insert data into JSON document JSON_STORAGE_SIZE() Space used for storage of binary representation of a JSON document; for a JSON column, the space used when the document was inserted, prior to any partial updates JSON_TYPE() Type of JSON value JSON_UNQUOTE() Unquote JSON value JSON_VALID() Whether JSON value is valid 常见的就是JSON_EXTRACT()等 表结构 插入数据12INSERT INTO `user_json` VALUES (1, &apos;&#123;\&quot;name\&quot;: \&quot;yang\&quot;, \&quot;address\&quot;: \&quot;shenyang\&quot;&#125;&apos;);... JSON校验： 查询123select * from user_json where json_extract(data,&apos;$.name&apos;)=&apos;yang&apos;;select json_extract(data,&apos;$.name&apos;) from user_json where json_extract(data,&apos;$.name&apos;)=&apos;yang&apos;;select data-&gt;&apos;$.name&apos; from user_json where data-&gt;&apos;$.name&apos;=&apos;yang&apos;; 发现结果集是带有双引号的： 如果想要去除双引号一般来说我们这样: 12select JSON_UNQUOTE(json_extract(data,&apos;$.name&apos;))from user_json where json_extract(data,&apos;$.name&apos;)=&apos;yang&apos;;select data-&gt;&gt;&apos;$.name&apos; from user_json where data-&gt;&apos;$.name&apos;=&apos;yang&apos;; JSON如何建立索引json类型并不能建立索引，但我们可以通过虚拟列来建立索引 123ALTER TABLE user_json ADD COLUMN `virtual_name` varchar(20) GENERATED ALWAYS AS (data-&gt;&gt;&apos;$.name&apos;) VIRTUAL NULL AFTER `data`;ALTER TABLE user_json ADD KEY (virtual_name); 可以看到索引起作用了~ 像时间这些要把周一到周日建索引也是可以的： 1`dayofweek` tinyint(4) GENERATED ALWAYS AS (dayofweek(SomeDate)) VIRTUAL, 或者某些很麻烦的条件： 12alter table ApiLog add verb_url_hash varbinary(16) GENERATED ALWAYS AS (unhex(md5(CONCAT(verb, &apos; - &apos;, replace(url,&apos;.xml&apos;,&apos;&apos;))))) VIRTUAL;alter table ApiLog add key (verb_url_hash); MySQL存储引擎MyISAM与InnoDB区别MySQL默认存储引擎的变迁在MySQL 5.1之前的版本中，默认的搜索引擎是MyISAM，从MySQL 5.5之后的版本中，默认的搜索引擎变更为InnoDB。 MyISAM与InnoDB存储引擎的主要特点MyISAM存储引擎的特点是：表级锁、不支持事务和全文索引，适合一些CMS内容管理系统作为后台数据库使用，但是使用大并发、重负荷生产系统上，表锁结构的特性就显得力不从心； 以下是MySQL 5.7 MyISAM存储引擎的版本特性： InnoDB存储引擎的特点是：行级锁、事务安全（ACID兼容）、支持外键、不支持FULLTEXT类型的索引(5.6.4以后版本开始支持FULLTEXT类型的索引)。InnoDB存储引擎提供了具有提交、回滚和崩溃恢复能力的事务安全存储引擎。InnoDB是为处理巨大量时拥有最大性能而设计的。它的CPU效率可能是任何其他基于磁盘的关系数据库引擎所不能匹敌的。 以下是MySQL 5.7 InnoDB存储引擎的版本特性： 注意：InnoDB表的行锁也不是绝对的，假如在执行一个SQL语句时MySQL不能确定要扫描的范围，InnoDB表同样会锁全表，例如update table set num=1 where name like “a%”。 两种类型最主要的差别就是InnoDB支持事务处理与外键和行级锁。而MyISAM不支持。所以MyISAM往往就容易被人认为只适合在小项目中使用。 MyISAM与InnoDB性能测试下边两张图是官方提供的MyISAM与InnoDB的压力测试结果 可以看出，随着CPU核数的增加，InnoDB的吞吐量反而越好，而MyISAM，其吞吐量几乎没有什么变化，显然，MyISAM的表锁定机制降低了读和写的吞吐量。 事务支持与否MyISAM是一种非事务性的引擎，使得MyISAM引擎的MySQL可以提供高速存储和检索，以及全文搜索能力，适合数据仓库等查询频繁的应用； InnoDB是事务安全的； 事务是一种高级的处理方式，如在一些列增删改中只要哪个出错还可以回滚还原，而MyISAM就不可以了。 MyISAM与InnoDB构成上的区别（1）每个MyISAM在磁盘上存储成三个文件： 第一个文件的名字以表的名字开始，扩展名指出文件类型，.frm文件存储表定义。第二个文件是数据文件，其扩展名为.MYD (MYData)。第三个文件是索引文件，其扩展名是.MYI (MYIndex)。 （2）基于磁盘的资源是InnoDB表空间数据文件和它的日志文件，InnoDB 表的 大小只受限于操作系统文件的大小，一般为 2GB。 MyISAM与InnoDB表锁和行锁的解释MySQL表级锁有两种模式：表共享读锁（Table Read Lock）和表独占写锁（Table Write Lock）。什么意思呢，就是说对MyISAM表进行读操作时，它不会阻塞其他用户对同一表的读请求，但会阻塞对同一表的写操作；而对MyISAM表的写操作，则会阻塞其他用户对同一表的读和写操作。 InnoDB行锁是通过给索引项加锁来实现的，即只有通过索引条件检索数据，InnoDB才使用行级锁，否则将使用表锁！行级锁在每次获取锁和释放锁的操作需要消耗比表锁更多的资源。在InnoDB两个事务发生死锁的时候，会计算出每个事务影响的行数，然后回滚行数少的那个事务。当锁定的场景中不涉及Innodb的时候，InnoDB是检测不到的。只能依靠锁定超时来解决。 是否保存数据库表中表的具体行数InnoDB 中不保存表的具体行数，也就是说，执行select count(*) from table 时，InnoDB要扫描一遍整个表来计算有多少行，但是MyISAM只要简单的读出保存好的行数即可。 注意的是，当count(*)语句包含where条件时，两种表的操作是一样的。也就是 上述“6”中介绍到的InnoDB使用表锁的一种情况。 如何选择MyISAM适合：（1）做很多count 的计算；（2）插入不频繁，查询非常频繁，如果执行大量的SELECT，MyISAM是更好的选择；（3）没有事务。 InnoDB适合：（1）可靠性要求比较高，或者要求事务；（2）表更新和查询都相当的频繁，并且表锁定的机会比较大的情况指定数据引擎的创建；（3）如果你的数据执行大量的INSERT或UPDATE，出于性能方面的考虑，应该使用InnoDB表；（4）DELETE FROM table时，InnoDB不会重新建立表，而是一行一行的 删除；（5）LOAD TABLE FROM MASTER操作对InnoDB是不起作用的，解决方法是首先把InnoDB表改成MyISAM表，导入数据后再改成InnoDB表，但是对于使用的额外的InnoDB特性（例如外键）的表不适用。 要注意，创建每个表格的代码是相同的，除了最后的 TYPE参数，这一参数用来指定数据引擎。 其他区别1、对于AUTO_INCREMENT类型的字段，InnoDB中必须包含只有该字段的索引，但是在MyISAM表中，可以和其他字段一起建立联合索引。 2、DELETE FROM table时，InnoDB不会重新建立表，而是一行一行的删除。 3、LOAD TABLE FROMMASTER操作对InnoDB是不起作用的，解决方法是首先把InnoDB表改成MyISAM表，导入数据后再改成InnoDB表，但是对于使用的额外的InnoDB特性(例如外键)的表不适用。 4、 InnoDB存储引擎被完全与MySQL服务器整合，InnoDB存储引擎为在主内存中缓存数据和索引而维持它自己的缓冲池。 5、对于自增长的字段，InnoDB中必须包含只有该字段的索引，但是在MyISAM表中可以和其他字段一起建立联合索引。 6、清空整个表时，InnoDB是一行一行的删除，效率非常慢。MyISAM则会重建表。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[极致的追求：高性能并发框架 Disruptor]]></title>
    <url>%2F2018%2Fdisruptor-learning%2F</url>
    <content type="text"><![CDATA[PrefaceDisruptor是英国外汇交易公司LMAX开发的一个高性能队列，研发的初衷是解决内存队列的延迟问题（在性能测试中发现竟然与I/O操作处于同样的数量级）。基于Disruptor开发的系统单线程能支撑每秒600万订单，2010年在QCon演讲后，获得了业界关注。2011年，企业应用软件专家Martin Fowler专门撰写长文介绍。同年它还获得了Oracle官方的Duke大奖。目前，包括Apache Storm、Camel、Log4j2、Reactor在内的很多知名项目都应用或参考了Disruptor以获取高性能。其实Disruptor与其说是一个框架，不如说是一种设计思路，这个设计思路对于存在“并发、缓冲区、生产者—消费者模型、事务处理”这些元素的程序来说，Disruptor提出了一种大幅提升性能（TPS）的方案。听说小米也是用这个东东把亚马逊搞挂了：http://bbs.xiaomi.cn/t-13417592核心概念在理解Disruptor之前，我们需要看一下它的核心概念Ring Buffer: Ring Buffer通常被认为是Disruptor的主要方面，然而从3.0开始，Ring Buffer只负责存储和更新通过Disruptor的数据（Events）。 而且对于一些高级用例可以完全由用户替换。Sequence: Disruptor使用序列作为一种手段来确定特定组件的位置。 每个消费者（EventProcessor）都像Disruptor本身一样维护一个Sequence。 大部分并发代码依赖于这些Sequence值的移动，因此Sequence支持AtomicLong的许多当前特性。 事实上，与2版本之间唯一真正的区别是序列包含额外的功能，以防止序列和其他值之间的错误共享。Sequencer: Sequencer是Disruptor的真正核心。 这个接口的2个实现（单生产者，多生产者）实现了所有的并发算法，用于在生产者和消费者之间快速正确地传递数据。Sequence Barrier: 序列屏障由序列发生器产生，并包含对序列发生器的主要发布序列和任何相关消费者的序列的引用。 它包含确定消费者是否有任何事件可供处理的逻辑。Wait Strategy: 等待策略决定了消费者如何等待事件被生产者置于Disruptor中。Event: 从生产者到消费者的数据单位。 事件没有特定的代码表示，因为它完全由用户定义。EventProcessor: 用于处理来自Disruptor的事件的主事件循环，并拥有消费者序列的所有权。 有一个称为BatchEventProcessor的表示，它包含一个有效的事件循环实现，并将回调到EventHandler接口的已用提供的实现上。EventHandler: 由用户实现的界面，代表Disruptor的使用者。Producer: 这是调用Disruptor排入事件的用户代码。 这个概念在代码中也没有表示。Java内置队列以下内容来自美团点评技术团队博文Java的内置队列如下表所示。队列有界性锁数据结构ArrayBlockingQueuebounded加锁arraylistLinkedBlockingQueueoptionally-bounded加锁linkedlistConcurrentLinkedQueueunbounded无锁linkedlistLinkedTransferQueueunbounded无锁linkedlistPriorityBlockingQueueunbounded加锁heapDelayQueueunbounded加锁heap队列的底层一般分成三种：数组、链表和堆。其中，堆一般情况下是为了实现带有优先级特性的队列，暂且不考虑。我们就从数组和链表两种数据结构来看，基于数组线程安全的队列，比较典型的是ArrayBlockingQueue，它主要通过加锁的方式来保证线程安全；基于链表的线程安全队列分成LinkedBlockingQueue和ConcurrentLinkedQueue两大类，前者也通过锁的方式来实现线程安全，而后者以及上面表格中的LinkedTransferQueue都是通过原子变量compare and swap（以下简称“CAS”）这种不加锁的方式来实现的。通过不加锁的方式实现的队列都是无界的（无法保证队列的长度在确定的范围内）；而加锁的方式，可以实现有界队列。在稳定性要求特别高的系统中，为了防止生产者速度过快，导致内存溢出，只能选择有界队列；同时，为了减少Java的垃圾回收对系统性能的影响，会尽量选择array/heap格式的数据结构。这样筛选下来，符合条件的队列就只有ArrayBlockingQueue。ArrayBlockingQueue的问题ArrayBlockingQueue在实际使用过程中，会因为加锁和伪共享等出现严重的性能问题，我们下面来分析一下。加锁现实编程过程中，加锁通常会严重地影响性能。线程会因为竞争不到锁而被挂起，等锁被释放的时候，线程又会被恢复，这个过程中存在着很大的开销，并且通常会有较长时间的中断，因为当一个线程正在等待锁时，它不能做任何其他事情。如果一个线程在持有锁的情况下被延迟执行，例如发生了缺页错误、调度延迟或者其它类似情况，那么所有需要这个锁的线程都无法执行下去。如果被阻塞线程的优先级较高，而持有锁的线程优先级较低，就会发生优先级反转。Disruptor论文中讲述了一个实验：这个测试程序调用了一个函数，该函数会对一个64位的计数器循环自增5亿次。机器环境：2.4G 6核运算： 64位的计数器累加5亿次MethodTime (ms)Single thread300Single thread with CAS5,700Single thread with lock10,000Single thread with volatile write4,700Two threads with CAS30,000Two threads with lock224,000CAS操作比单线程无锁慢了1个数量级；有锁且多线程并发的情况下，速度比单线程无锁慢3个数量级。可见无锁速度最快。单线程情况下，不加锁的性能 &gt; CAS操作的性能 &gt; 加锁的性能。在多线程情况下，为了保证线程安全，必须使用CAS或锁，这种情况下，CAS的性能超过锁的性能，前者大约是后者的8倍。综上可知，加锁的性能是最差的。关于锁和CAS保证线程安全一般分成两种方式：锁和原子变量。锁采取加锁的方式，默认线程会冲突，访问数据时，先加上锁再访问，访问之后再解锁。通过锁界定一个临界区，同时只有一个线程进入。如上图所示，Thread2访问Entry的时候，加了锁，Thread1就不能再执行访问Entry的代码，从而保证线程安全。下面是ArrayBlockingQueue通过加锁的方式实现的offer方法，保证线程安全。123456789101112131415public boolean offer(E e) &#123; checkNotNull(e); final ReentrantLock lock = this.lock; lock.lock(); try &#123; if (count == items.length) return false; else &#123; insert(e); return true; &#125; &#125; finally &#123; lock.unlock(); &#125;&#125; 原子变量原子变量能够保证原子性的操作，意思是某个任务在执行过程中，要么全部成功，要么全部失败回滚，恢复到执行之前的初态，不存在初态和成功之间的中间状态。例如CAS操作，要么比较并交换成功，要么比较并交换失败。由CPU保证原子性。 通过原子变量可以实现线程安全。执行某个任务的时候，先假定不会有冲突，若不发生冲突，则直接执行成功；当发生冲突的时候，则执行失败，回滚再重新操作，直到不发生冲突。 如图所示，Thread1和Thread2都要把Entry加1。若不加锁，也不使用CAS，有可能Thread1取到了myValue=1，Thread2也取到了myValue=1，然后相加，Entry中的value值为2。这与预期不相符，我们预期的是Entry的值经过两次相加后等于3。 CAS会先把Entry现在的value跟线程当初读出的值相比较，若相同，则赋值；若不相同，则赋值执行失败。一般会通过while/for循环来重新执行，直到赋值成功。 代码示例是AtomicInteger的getAndAdd方法。CAS是CPU的一个指令，由CPU保证原子性。 123456789101112131415161718192021222324252627/** * Atomically adds the given value to the current value. * * @param delta the value to add * @return the previous value */public final int getAndAdd(int delta) &#123; for (;;) &#123; int current = get(); int next = current + delta; if (compareAndSet(current, next)) return current; &#125;&#125;/** * Atomically sets the value to the given updated value * if the current value &#123;@code ==&#125; the expected value. * * @param expect the expected value * @param update the new value * @return true if successful. False return indicates that * the actual value was not equal to the expected value. */public final boolean compareAndSet(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, valueOffset, expect, update);&#125; 在高度竞争的情况下，锁的性能将超过原子变量的性能，但是更真实的竞争情况下，原子变量的性能将超过锁的性能。同时原子变量不会有死锁等活跃性问题。 伪共享什么是共享下图是计算的基本结构。L1、L2、L3分别表示一级缓存、二级缓存、三级缓存，越靠近CPU的缓存，速度越快，容量也越小。所以L1缓存很小但很快，并且紧靠着在使用它的CPU内核；L2大一些，也慢一些，并且仍然只能被一个单独的CPU核使用；L3更大、更慢，并且被单个插槽上的所有CPU核共享；最后是主存，由全部插槽上的所有CPU核共享。 当CPU执行运算的时候，它先去L1查找所需的数据、再去L2、然后是L3，如果最后这些缓存中都没有，所需的数据就要去主内存拿。走得越远，运算耗费的时间就越长。所以如果你在做一些很频繁的事，你要尽量确保数据在L1缓存中。 另外，线程之间共享一份数据的时候，需要一个线程把数据写回主存，而另一个线程访问主存中相应的数据。 下面是从CPU访问不同层级数据的时间概念: 从CPU到 大约需要的CPU周期 大约需要的时间 主存 约60-80ns QPI 总线传输(between sockets, not drawn) 约20ns L3 cache 约40-45 cycles 约15ns L2 cache 约10 cycles 约3ns L1 cache 约3-4 cycles 约1ns 寄存器 1 cycle 可见CPU读取主存中的数据会比从L1中读取慢了近2个数量级。 缓存行Cache是由很多个cache line组成的。每个cache line通常是64字节，并且它有效地引用主内存中的一块儿地址。一个Java的long类型变量是8字节，因此在一个缓存行中可以存8个long类型的变量。 CPU每次从主存中拉取数据时，会把相邻的数据也存入同一个cache line。 在访问一个long数组的时候，如果数组中的一个值被加载到缓存中，它会自动加载另外7个。因此你能非常快的遍历这个数组。事实上，你可以非常快速的遍历在连续内存块中分配的任意数据结构。 下面的例子是测试利用cache line的特性和不利用cache line的特性的效果对比。 123456789101112131415161718192021222324252627282930public class CacheLineEffect &#123; //考虑一般缓存行大小是64字节，一个 long 类型占8字节 static long[][] arr; public static void main(String[] args) &#123; arr = new long[1024 * 1024][]; for (int i = 0; i &lt; 1024 * 1024; i++) &#123; arr[i] = new long[8]; for (int j = 0; j &lt; 8; j++) &#123; arr[i][j] = 0L; &#125; &#125; long sum = 0L; long marked = System.currentTimeMillis(); for (int i = 0; i &lt; 1024 * 1024; i+=1) &#123; for(int j =0; j&lt; 8;j++)&#123; sum = arr[i][j]; &#125; &#125; System.out.println(&quot;Loop times:&quot; + (System.currentTimeMillis() - marked) + &quot;ms&quot;); marked = System.currentTimeMillis(); for (int i = 0; i &lt; 8; i+=1) &#123; for(int j =0; j&lt; 1024 * 1024;j++)&#123; sum = arr[j][i]; &#125; &#125; System.out.println(&quot;Loop times:&quot; + (System.currentTimeMillis() - marked) + &quot;ms&quot;); &#125;&#125; 在2G Hz、2核、8G内存的运行环境中测试，速度差一倍。 结果：Loop times:30msLoop times:65ms 什么是伪共享ArrayBlockingQueue有三个成员变量： takeIndex：需要被取走的元素下标 putIndex：可被元素插入的位置的下标 count：队列中元素的数量 这三个变量很容易放到一个缓存行中，但是之间修改没有太多的关联。所以每次修改，都会使之前缓存的数据失效，从而不能完全达到共享的效果。 如上图所示，当生产者线程put一个元素到ArrayBlockingQueue时，putIndex会修改，从而导致消费者线程的缓存中的缓存行无效，需要从主存中重新读取。 这种无法充分使用缓存行特性的现象，称为伪共享。 对于伪共享，一般的解决方案是，增大数组元素的间隔使得由不同线程存取的元素位于不同的缓存行上，以空间换时间。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public class FalseSharing implements Runnable&#123; public final static long ITERATIONS = 500L * 1000L * 100L; private int arrayIndex = 0; private static ValuePadding[] longs; public FalseSharing(final int arrayIndex) &#123; this.arrayIndex = arrayIndex; &#125; public static void main(final String[] args) throws Exception &#123; for(int i=1;i&lt;10;i++)&#123; System.gc(); final long start = System.currentTimeMillis(); runTest(i); System.out.println(&quot;Thread num &quot;+i+&quot; duration = &quot; + (System.currentTimeMillis() - start)); &#125; &#125; private static void runTest(int NUM_THREADS) throws InterruptedException &#123; Thread[] threads = new Thread[NUM_THREADS]; longs = new ValuePadding[NUM_THREADS]; for (int i = 0; i &lt; longs.length; i++) &#123; longs[i] = new ValuePadding(); &#125; for (int i = 0; i &lt; threads.length; i++) &#123; threads[i] = new Thread(new FalseSharing(i)); &#125; for (Thread t : threads) &#123; t.start(); &#125; for (Thread t : threads) &#123; t.join(); &#125; &#125; public void run() &#123; long i = ITERATIONS + 1; while (0 != --i) &#123; longs[arrayIndex].value = 0L; &#125; &#125; public final static class ValuePadding &#123; protected long p1, p2, p3, p4, p5, p6, p7; protected volatile long value = 0L; protected long p9, p10, p11, p12, p13, p14; protected long p15; &#125; public final static class ValueNoPadding &#123; // protected long p1, p2, p3, p4, p5, p6, p7; protected volatile long value = 0L; // protected long p9, p10, p11, p12, p13, p14, p15; &#125;&#125; 在2G Hz，2核，8G内存, jdk 1.7.0_45 的运行环境下，使用了共享机制比没有使用共享机制，速度快了4倍左右。 结果：Thread num 1 duration = 447Thread num 2 duration = 463Thread num 3 duration = 454Thread num 4 duration = 464Thread num 5 duration = 561Thread num 6 duration = 606Thread num 7 duration = 684Thread num 8 duration = 870Thread num 9 duration = 823 把代码中ValuePadding都替换为ValueNoPadding后的结果：Thread num 1 duration = 446Thread num 2 duration = 2549Thread num 3 duration = 2898Thread num 4 duration = 3931Thread num 5 duration = 4716Thread num 6 duration = 5424Thread num 7 duration = 4868Thread num 8 duration = 4595Thread num 9 duration = 4540 备注：在jdk1.8中，有专门的注解@Contended来避免伪共享，更优雅地解决问题。 Disruptor的设计方案Disruptor通过以下设计来解决队列速度慢的问题： 环形数组结构 为了避免垃圾回收，采用数组而非链表。同时，数组对处理器的缓存机制更加友好。 元素位置定位 数组长度2^n，通过位运算，加快定位的速度。下标采取递增的形式。不用担心index溢出的问题。index是long类型，即使100万QPS的处理速度，也需要30万年才能用完。 无锁设计 每个生产者或者消费者线程，会先申请可以操作的元素在数组中的位置，申请到之后，直接在该位置写入或者读取数据。 下面忽略数组的环形结构，介绍一下如何实现无锁设计。整个过程通过原子变量CAS，保证操作的线程安全。 一个生产者写数据生产者单线程写数据的流程比较简单： 申请写入m个元素； 若是有m个元素可以写入，则返回最大的序列号。这儿主要判断是否会覆盖未读的元素； 若是返回的正确，则生产者开始写入元素。 图5 单个生产者生产过程示意图 多个生产者多个生产者的情况下，会遇到“如何防止多个线程重复写同一个元素”的问题。Disruptor的解决方法是，每个线程获取不同的一段数组空间进行操作。这个通过CAS很容易达到。只需要在分配元素的时候，通过CAS判断一下这段空间是否已经分配出去即可。 但是会遇到一个新问题：如何防止读取的时候，读到还未写的元素。Disruptor在多个生产者的情况下，引入了一个与Ring Buffer大小相同的buffer：available Buffer。当某个位置写入成功的时候，便把availble Buffer相应的位置置位，标记为写入成功。读取的时候，会遍历available Buffer，来判断元素是否已经就绪。 下面分读数据和写数据两种情况介绍。 读数据生产者多线程写入的情况会复杂很多： 申请读取到序号n； 若writer cursor &gt;= n，这时仍然无法确定连续可读的最大下标。从reader cursor开始读取available Buffer，一直查到第一个不可用的元素，然后返回最大连续可读元素的位置； 消费者读取元素。 如下图所示，读线程读到下标为2的元素，三个线程Writer1/Writer2/Writer3正在向RingBuffer相应位置写数据，写线程被分配到的最大元素下标是11。 读线程申请读取到下标从3到11的元素，判断writer cursor&gt;=11。然后开始读取availableBuffer，从3开始，往后读取，发现下标为7的元素没有生产成功，于是WaitFor(11)返回6。 然后，消费者读取下标从3到6共计4个元素。 写数据多个生产者写入的时候： 申请写入m个元素； 若是有m个元素可以写入，则返回最大的序列号。每个生产者会被分配一段独享的空间； 生产者写入元素，写入元素的同时设置available Buffer里面相应的位置，以标记自己哪些位置是已经写入成功的。 如下图所示，Writer1和Writer2两个线程写入数组，都申请可写的数组空间。Writer1被分配了下标3到下表5的空间，Writer2被分配了下标6到下标9的空间。 Writer1写入下标3位置的元素，同时把available Buffer相应位置置位，标记已经写入成功，往后移一位，开始写下标4位置的元素。Writer2同样的方式。最终都写入完成。 防止不同生产者对同一段空间写入的代码，如下所示： 123456789101112131415161718192021222324public long tryNext(int n) throws InsufficientCapacityException&#123; if (n &lt; 1) &#123; throw new IllegalArgumentException(&quot;n must be &gt; 0&quot;); &#125; long current; long next; do &#123; current = cursor.get(); next = current + n; if (!hasAvailableCapacity(gatingSequences, n, current)) &#123; throw InsufficientCapacityException.INSTANCE; &#125; &#125; while (!cursor.compareAndSet(current, next)); return next;&#125; 通过do/while循环的条件cursor.compareAndSet(current, next)，来判断每次申请的空间是否已经被其他生产者占据。假如已经被占据，该函数会返回失败，While循环重新执行，申请写入空间。 消费者的流程与生产者非常类似，这儿就不多描述了。Disruptor通过精巧的无锁设计实现了在高并发情形下的高性能。 等待策略生产者的等待策略暂时只有休眠1ns。 1LockSupport.parkNanos(1); 消费者的等待策略 名称 说明 适用场景 BlockingWaitStrategy 默认等待策略。和BlockingQueue的实现很类似，通过使用锁和条件（Condition）进行线程阻塞的方式，等待生产者唤醒(线程同步和唤醒)。此策略对于线程切换来说，最节约CPU资源，但在高并发场景下性能有限 CPU资源紧缺，吞吐量和延迟并不重要的场景 BusySpinWaitStrategy 死循环策略。消费者线程会尽最大可能监控缓冲区的变化，会占用所有CPU资源,线程一直自旋等待，比较耗CPU 通过不断重试，减少切换线程导致的系统调用，而降低延迟。推荐在线程绑定到固定的CPU的场景下使用 LiteBlockingWaitStrategy 通过线程阻塞的方式，等待生产者唤醒，比BlockingWaitStrategy要轻，某些情况下可以减少阻塞的次数 PhasedBackoffWaitStrategy 根据指定的时间段参数和指定的等待策略决定采用哪种等待策略 CPU资源紧缺，吞吐量和延迟并不重要的场景 SleepingWaitStrategy CPU友好型策略。会在循环中不断等待数据。可通过参数设置,首先进行自旋等待，若不成功，则使用Thread.yield()让出CPU，并使用LockSupport.parkNanos(1)进行线程睡眠，通过线程调度器重新调度；或一直自旋等待，所以，此策略数据处理数据可能会有较高的延迟，适合用于对延迟不敏感的场景，优点是对生产者线程影响小， 典型应用场景是异步日志 性能和CPU资源之间有很好的折中。延迟不均匀 TimeoutBlockingWaitStrategy 通过参数设置阻塞时间，如果超时则抛出异常 CPU资源紧缺，吞吐量和延迟并不重要的场景 YieldingWaitStrategy 低延时策略。消费者线程会不断循环监控RingBuffer的变化，在循环内部使用Thread.yield()让出CPU给其他线程，通过线程调度器重新调度 性能和CPU资源之间有很好的折中。延迟比较均匀 核心对象 RingBuffer：环形的一个数据结构，对象初始化时，会使用事件Event进行填充。Buffer的大小必须是2的幂次方，方便移位操作。 Event：无指定具体接口，用户自己实现，可以携带任何业务数据。 EventFactory：产生事件Event的工厂，由用户自己实现。 EventTranslator：事件发布的回调接口，由用户实现，负责将业务参数设置到事件中。 Sequencer：序列产生器，也是协调生产者和消费者及实现高并发的核心。有MultiProducerSequencer 和 SingleProducerSequencer两个实现类。 SequenceBarrier：拥有RingBuffer的发布事件Sequence引用和消费者依赖的Sequence引用。决定消费者消费可消费的Sequence。 EventHandler：事件的处理者，由用户自己实现。 EventProcessor：事件的处理器，单独在一个线程中运行。 WorkHandler：事件的处理者，由用户自己实现。 WorkProcessor：事件的处理器，单独在一个线程中运行。 WorkerPool：一组WorkProcessor的处理。 WaitStrategy：在消费者比生产者快时，消费者处理器的等待策略。 用例按照官方的指南，一般套路如下： 自定义事件类：例如 LongEvent 实现EventFactory&lt;T&gt;： 例如LongEventFactory implements EventFactory&lt;LongEvent&gt; 实现EventHandler&lt;T&gt;（消费者）：例如LongEventHandler implements EventHandler&lt;LongEvent&gt; 实现EventTranslatorOneArg&lt;T, E&gt;作为生产者，将业务转换为事件：例如LongEventTranslatorOneArg implements EventTranslatorOneArg&lt;LongEvent, ByteBuffer&gt; 提供线程池或线程工厂 定义buffer大小，它必须是2的幂，否则会在初始化时抛出异常。因为重点在于使用逻辑二进制运算符有着更好的性能；(例如:mod运算) 构建Disruptor&lt;T&gt; 启动disruptor，disruptor.start() 发布事件，驱动自行流转 基础事件生产与消费自定义事件12345678910111213package com.yangbingdong.springbootdisruptor.basic;import lombok.Data;/** * @author ybd * @date 18-1-31 * @contact yangbingdong@1994.gmail */@Datapublic class LongEvent &#123; private long value;&#125; 定义事件工厂12345678910111213141516171819package com.yangbingdong.springbootdisruptor.basic;import com.lmax.disruptor.EventFactory;import lombok.extern.slf4j.Slf4j;/** * @author ybd * @date 18-1-31 * @contact yangbingdong@1994.gmail */@Slf4jpublic class LongEventFactory implements EventFactory&lt;LongEvent&gt; &#123; @Override public LongEvent newInstance() &#123; log.info(&quot;logEventFactory create LongEvent...&quot;); return new LongEvent(); &#125;&#125; 定义消费者123456789101112131415161718package com.yangbingdong.springbootdisruptor.basic;import com.lmax.disruptor.EventHandler;import lombok.extern.slf4j.Slf4j;/** * @author ybd * @date 18-1-31 * @contact yangbingdong@1994.gmail */@Slf4jpublic class LongEventHandler implements EventHandler&lt;LongEvent&gt; &#123; @Override public void onEvent(LongEvent event, long sequence, boolean endOfBatch) &#123; log.info(&quot;handle event: &quot; + event); &#125;&#125; 定义生产者3.0版本之前123456789101112131415161718192021222324252627282930313233package com.yangbingdong.springbootdisruptor.basic;import com.lmax.disruptor.RingBuffer;import java.nio.ByteBuffer;/** * @author ybd * @date 18-1-31 * @contact yangbingdong@1994.gmail */public class LongEventProducer &#123; private final RingBuffer&lt;LongEvent&gt; ringBuffer; public LongEventProducer(RingBuffer&lt;LongEvent&gt; ringBuffer) &#123; this.ringBuffer = ringBuffer; &#125; public void onData(ByteBuffer bb) &#123; // Grab the next sequence long sequence = ringBuffer.next(); try &#123; // Get the entry in the Disruptor LongEvent event = ringBuffer.get(sequence); // for the sequence // Fill with data event.setValue(bb.getLong(0)); &#125; finally &#123; ringBuffer.publish(sequence); &#125; &#125;&#125; 3.0版本之后使用Translators123456789101112131415161718package com.yangbingdong.springbootdisruptor.basic;import com.lmax.disruptor.EventTranslatorOneArg;import java.nio.ByteBuffer;/** * @author ybd * @date 18-1-31 * @contact yangbingdong@1994.gmail */public class LongEventProducerWithTranslator implements EventTranslatorOneArg&lt;LongEvent, ByteBuffer&gt;&#123; @Override public void translateTo(LongEvent event, long sequence, ByteBuffer bb) &#123; event.setValue(bb.getLong(0)); &#125;&#125; 测试实例单生产者，单消费者1234567891011121314151617181920212223242526272829303132@Testpublic void singleProducerLongEventDefaultTest() throws InterruptedException &#123; // Executor that will be used to construct new threads for consumers Executor executor = Executors.newCachedThreadPool(); // The factory for the event LongEventFactory factory = new LongEventFactory(); // Specify the size of the ring buffer, must be power of 2. int bufferSize = 1 &lt;&lt; 3; // Construct the Disruptor Disruptor&lt;LongEvent&gt; disruptor = new Disruptor&lt;&gt;(factory, bufferSize, executor, ProducerType.SINGLE, new BlockingWaitStrategy()); // Connect the handler disruptor.handleEventsWith(new LongEventHandler()); // Start the Disruptor, starts all threads running disruptor.start(); // Get the ring buffer from the Disruptor to be used for publishing. RingBuffer&lt;LongEvent&gt; ringBuffer = disruptor.getRingBuffer(); LongEventProducer producer = new LongEventProducer(ringBuffer); ByteBuffer bb = ByteBuffer.allocate(8); for (long l = 0; l &lt; 100; l++) &#123; bb.putLong(0, l); producer.onData(bb); Thread.sleep(10); &#125;&#125; 新版的Disruptor不建议我们使用Executor，而使用ThreadFactory代替： 12345678910111213141516171819202122232425262728293031@Testpublic void singleProducerLongEventUseThreadFactoryTest() throws InterruptedException &#123; ThreadFactory threadFactory = new ThreadFactory() &#123; private final AtomicInteger index = new AtomicInteger(1); @Override public Thread newThread(Runnable r) &#123; return new Thread(null, r, &quot;disruptor-thread-&quot; + index.getAndIncrement()); &#125; &#125;; LongEventFactory factory = new LongEventFactory(); int bufferSize = 1 &lt;&lt; 3; Disruptor&lt;LongEvent&gt; disruptor = new Disruptor&lt;&gt;(factory, bufferSize, threadFactory, ProducerType.SINGLE, new BlockingWaitStrategy()); disruptor.handleEventsWith(new LongEventHandler()); disruptor.start(); RingBuffer&lt;LongEvent&gt; ringBuffer = disruptor.getRingBuffer(); LongEventProducer producer = new LongEventProducer(ringBuffer); ByteBuffer bb = ByteBuffer.allocate(8); for (long l = 0; l &lt; 100; l++) &#123; bb.putLong(0, l); producer.onData(bb); Thread.sleep(10); &#125;&#125; 新版Disruptor使用Translators： 12345678910111213141516171819202122232425262728293031@Testpublic void singleProducerLongEventUseTranslatorsTest() throws InterruptedException &#123; ThreadFactory threadFactory = new ThreadFactory() &#123; private final AtomicInteger index = new AtomicInteger(1); @Override public Thread newThread(Runnable r) &#123; return new Thread(null, r, &quot;disruptor-thread-&quot; + index.getAndIncrement()); &#125; &#125;; LongEventFactory factory = new LongEventFactory(); int bufferSize = 1 &lt;&lt; 3; Disruptor&lt;LongEvent&gt; disruptor = new Disruptor&lt;&gt;(factory, bufferSize, threadFactory, ProducerType.SINGLE, new BlockingWaitStrategy()); disruptor.handleEventsWith(new LongEventHandler()); disruptor.start(); RingBuffer&lt;LongEvent&gt; ringBuffer = disruptor.getRingBuffer(); LongEventProducerWithTranslator longEventProducerWithTranslator = new LongEventProducerWithTranslator(); ByteBuffer bb = ByteBuffer.allocate(8); for (long l = 0; l &lt; 100; l++) &#123; bb.putLong(0, l); ringBuffer.publishEvent(longEventProducerWithTranslator, bb); Thread.sleep(10); &#125;&#125; java8版： 123456789101112131415161718192021@SuppressWarnings(&quot;unchecked&quot;)@Testpublic void singleProducerLongEventJava8Test() &#123; int bufferSize = 1 &lt;&lt; 3; Disruptor&lt;LongEvent&gt; disruptor = new Disruptor&lt;&gt;(LongEvent::new, bufferSize, (ThreadFactory) Thread::new, ProducerType.SINGLE, new BlockingWaitStrategy()); disruptor.handleEventsWith((event, sequence, endOfBatch) -&gt; log.info(&quot;handle event: &quot; + event)); disruptor.start(); RingBuffer&lt;LongEvent&gt; ringBuffer = disruptor.getRingBuffer(); ByteBuffer bb = ByteBuffer.allocate(8); LongStream.range(0, 100) .forEach(tryLongConsumer(l -&gt; &#123; bb.putLong(0, l); ringBuffer.publishEvent((event, sequence, buffer) -&gt; event.setValue(buffer.getLong(0)), bb); Thread.sleep(10); &#125;));&#125; 多生产者，单消费者123456789101112131415161718192021222324252627282930313233343536373839@SuppressWarnings(&quot;unchecked&quot;)@Testpublic void multiProducerOneCustomerTest() throws InterruptedException &#123; CountDownLatch countDownLatch = new CountDownLatch(30); int bufferSize = 1 &lt;&lt; 6; Disruptor&lt;LongEvent&gt; disruptor = new Disruptor&lt;&gt;(LongEvent::new, bufferSize, Executors.defaultThreadFactory(), ProducerType.MULTI, new SleepingWaitStrategy()); disruptor.handleEventsWith((event, sequence, endOfBatch) -&gt; &#123; log.info(&quot;handle event: &#123;&#125;, sequence: &#123;&#125;, endOfBatch: &#123;&#125;&quot;, event, sequence, endOfBatch); countDownLatch.countDown(); &#125;); LongEventProducerWithTranslator longEventProducerWithTranslator = new LongEventProducerWithTranslator(); disruptor.start(); new Thread(() -&gt; produce(disruptor, longEventProducerWithTranslator, 0, 10)).start(); new Thread(() -&gt; produce(disruptor, longEventProducerWithTranslator, 10, 20)).start(); new Thread(() -&gt; produce(disruptor, longEventProducerWithTranslator, 20, 30)).start(); countDownLatch.await();&#125;private void produce(Disruptor&lt;LongEvent&gt; disruptor, LongEventProducerWithTranslator longEventProducerWithTranslator, int i, int i2) &#123; try &#123; RingBuffer&lt;LongEvent&gt; ringBuffer = disruptor.getRingBuffer(); ByteBuffer bb = ByteBuffer.allocate(8); for (long l = i; l &lt; i2; l++) &#123; bb.putLong(0, l); ringBuffer.publishEvent(longEventProducerWithTranslator, bb); TimeUnit.MILLISECONDS.sleep(20); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;&#125; 一个及以上生产者，多个消费者 先处理完c1和c2才处理c3： 1234567891011121314151617181920@Testpublic void multiCustomerOneProducerTest() throws InterruptedException &#123; int bufferSize = 1 &lt;&lt; 8; Disruptor&lt;LongEvent&gt; disruptor = new Disruptor&lt;&gt;(LongEvent::new, bufferSize, Executors.defaultThreadFactory(), ProducerType.MULTI, new YieldingWaitStrategy()); LongEventHandler c1 = new LongEventHandler(); LongEventHandler2 c2 = new LongEventHandler2(); LongEventHandler3 c3 = new LongEventHandler3(); disruptor.handleEventsWith(c1, c2).then(c3); LongEventProducerWithTranslator longEventProducerWithTranslator = new LongEventProducerWithTranslator(); disruptor.start(); new Thread(() -&gt; produce(disruptor, longEventProducerWithTranslator, 0, 100)).start(); TimeUnit.SECONDS.sleep(1);&#125; 从上图结果可以看出来c1和c2的顺序是不确定的，c3总是在最后。 如图，消费者1b消费时，必须保证消费者1a已经完成对该消息的消费；消费者2b消费时，必须保证消费者2a已经完成对该消息的消费；消费者c3消费时，必须保证消费者1b和2b已经完成对该消息的消费。 12345678910111213141516171819202122232425@SuppressWarnings(&quot;unchecked&quot;)@Testpublic void multiCustomerOneProducerTest2() throws InterruptedException &#123; int bufferSize = 1 &lt;&lt; 8; Disruptor&lt;LongEvent&gt; disruptor = new Disruptor&lt;&gt;(LongEvent::new, bufferSize, Executors.defaultThreadFactory(), ProducerType.SINGLE, new LiteBlockingWaitStrategy()); LongEventHandler c1a = new LongEventHandler(); LongEventHandler2 c2a = new LongEventHandler2(); LongEventHandler3 c1b = new LongEventHandler3(); LongEventHandler4 c2b = new LongEventHandler4(); disruptor.handleEventsWith(c1a, c2a); disruptor.after(c1a).then(c1b); disruptor.after(c2a).then(c2b); disruptor.after(c1b, c2b).then((EventHandler&lt;LongEvent&gt;) (event, sequence, endOfBatch) -&gt; System.out.println(&quot;last costumer \n&quot;)); LongEventProducerWithTranslator longEventProducerWithTranslator = new LongEventProducerWithTranslator(); disruptor.start(); new Thread(() -&gt; produce(disruptor, longEventProducerWithTranslator, 0, 30)).start(); TimeUnit.SECONDS.sleep(1);&#125; 再来一个复杂点的： 12345678910111213141516171819202122232425262728@SuppressWarnings(&quot;unchecked&quot;)@Testpublic void multiCustomerOneProducerTest3() throws InterruptedException &#123; int bufferSize = 1 &lt;&lt; 8; Disruptor&lt;LongEvent&gt; disruptor = new Disruptor&lt;&gt;(LongEvent::new, bufferSize, Executors.defaultThreadFactory(), ProducerType.SINGLE, new LiteBlockingWaitStrategy()); EventHandler a = (EventHandler&lt;LongEvent&gt;) (event, sequence, endOfBatch) -&gt; System.out.println(&quot;process a... event: &quot; + event); EventHandler b = (EventHandler&lt;LongEvent&gt;) (event, sequence, endOfBatch) -&gt; System.out.println(&quot;process b... event: &quot; + event); EventHandler c = (EventHandler&lt;LongEvent&gt;) (event, sequence, endOfBatch) -&gt; System.out.println(&quot;process c... event: &quot; + event); EventHandler d = (EventHandler&lt;LongEvent&gt;) (event, sequence, endOfBatch) -&gt; System.out.println(&quot;process d... event: &quot; + event); EventHandler e = (EventHandler&lt;LongEvent&gt;) (event, sequence, endOfBatch) -&gt; System.out.println(&quot;process e... a,b,c has completed, event: &quot; + event + &quot;\n&quot;); EventHandler f = (EventHandler&lt;LongEvent&gt;) (event, sequence, endOfBatch) -&gt; System.out.println(&quot;process f... d has completed, event: &quot; + event + &quot;\n&quot;); EventHandler g = (EventHandler&lt;LongEvent&gt;) (event, sequence, endOfBatch) -&gt; System.out.println(&quot;process g... e,f has completed, event: &quot; + event + &quot;\n\n&quot;); disruptor.handleEventsWith(a, b, c, d); disruptor.after(a, b, c).then(e); disruptor.after(d).then(f); disruptor.after(e, f).then(g); LongEventProducerWithTranslator longEventProducerWithTranslator = new LongEventProducerWithTranslator(); disruptor.start(); new Thread(() -&gt; produce(disruptor, longEventProducerWithTranslator, 0, 2)).start(); TimeUnit.SECONDS.sleep(1);&#125; 异常处理Disruptor默认会把异常包装成RuntimeException并抛出去，导致线程挂掉或阻塞，我们需要自定义异常处理器： 1234567891011121314151617disruptor.setDefaultExceptionHandler(new ExceptionHandler&lt;LongEvent&gt;() &#123; @Override public void handleEventException(Throwable ex, long sequence, LongEvent event) &#123; System.out.println(&quot;捕捉异常：&quot; + ex.getMessage()); System.out.println(&quot;处理异常逻辑...&quot;); &#125; @Override public void handleOnStartException(Throwable ex) &#123; System.out.println(&quot;handleOnStartException&quot;); &#125; @Override public void handleOnShutdownException(Throwable ex) &#123; System.out.println(&quot;handleOnShutdownException&quot;); &#125; &#125;); 从RingBuffer中移除对象 来自官方翻译：当通过Disruptor传递数据时，对象可能比预期寿命更长。 为避免发生这种情况，可能需要在处理事件后清除事件。 如果你有一个单一的事件处理程序清除在同一个处理程序中的值是足够的。 如果你有一连串的事件处理程序，那么你可能需要一个特定的处理程序放置在链的末尾来处理对象。 12345678910111213141516171819202122232425262728293031class ObjectEvent&lt;T&gt;&#123; T val; void clear() &#123; val = null; &#125;&#125;public class ClearingEventHandler&lt;T&gt; implements EventHandler&lt;ObjectEvent&lt;T&gt;&gt;&#123; public void onEvent(ObjectEvent&lt;T&gt; event, long sequence, boolean endOfBatch) &#123; // Failing to call clear here will result in the // object associated with the event to live until // it is overwritten once the ring buffer has wrapped // around to the beginning. event.clear(); &#125;&#125;public static void main(String[] args)&#123; Disruptor&lt;ObjectEvent&lt;String&gt;&gt; disruptor = new Disruptor&lt;&gt;( () -&gt; ObjectEvent&lt;String&gt;(), bufferSize, executor); disruptor .handleEventsWith(new ProcessingEventHandler()) .then(new ClearingObjectHandler());&#125; 消费者分片12345678910111213141516171819public final class MyHandler implements EventHandler&lt;ValueEvent&gt;&#123; private final long ordinal; private final long numberOfConsumers; public MyHandler(final long ordinal, final long numberOfConsumers) &#123; this.ordinal = ordinal; this.numberOfConsumers = numberOfConsumers; &#125; public void onEvent(final ValueEvent entry, final long sequence, final boolean onEndOfBatch) &#123; if ((sequence % numberOfConsumers) == ordinal) &#123; // Process the event &#125; &#125;&#125; 总结 代码：https://github.com/masteranthoneyd/spring-boot-learning/tree/master/spring-boot-disruptor 来自某大神的点评：“当对性能的追求达到这样的程度，以致对现代硬件构成的理解变得越来越重要。”这句话恰当地形容了Disruptor/LMAX在对性能方面的追求和失败。咦，失败？为什么会这么说呢？Disruptor当然是一个优秀的框架，我说的失败指的是在开发它的过程中，LMAX曽试图提高并发程序效率，优化、使用锁或借助其他模型，但是这些尝试最终失败了——然后他们构建了Disruptor。再提问：一个Java程序员在尝试提高他的程序性能的时候，需要了解很多硬件知识吗？我想很多人都会回答“不需要”，构建Disruptor的过程中，最初开发人员对这个问题的回答可能也是“不需要”，但是尝试失败后他们决定另辟蹊径。总的看下Disruptor的设计：锁到CAS、缓冲行填充、避免GC等，我感觉这些设计都在刻意“迁就”或者“依赖”硬件设计，这些设计更像是一种“(ugly)hack”（毫无疑问，Disruptor还是目前最优秀的方案之一）。 Disruptor可以说是工程级别的项目，通过各种高级的优化达到了性能的极致： 可选锁无关lock-free, 没有竞争所以非常快 所有访问者都记录自己的序号的实现方式，允许多个生产者与多个消费者共享相同的数据结构 在每个对象中都能跟踪序列号， 没有为伪共享和非预期的竞争 增加缓存行补齐， 提升cache缓存命中率 环形数组中的元素不会被删除]]></content>
      <categories>
        <category>Programming</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Disruptor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker可视化与管理工具]]></title>
    <url>%2F2018%2Fdocker-visual-management-and-orchestrate-tools%2F</url>
    <content type="text"><![CDATA[Preface在学习了Docker的基本操作之后，接下来就是Docker的管理部分了，这包括Docker的可视化管理以及集群管理。此篇主要记录Docker私有库的搭建，Docker编排工具的介绍以及使用，可视化管理工具的介绍以及搭建…Docker Registry &amp; MirrorHarborHarbor是一个用于存储和分发Docker镜像的企业级Registry服务器，通过添加一些企业必需的功能特性，例如安全、标识和管理等，扩展了开源Docker Distribution。作为一个企业级私有Registry服务器，Harbor提供了更好的性能和安全。提升用户使用Registry构建和运行环境传输镜像的效率。Harbor支持安装在多个Registry节点的镜像资源复制，镜像全部保存在私有Registry中， 确保数据和知识产权在公司内部网络中管控。另外，Harbor也提供了高级的安全特性，诸如用户管理，访问控制和活动审计等。基于角色的访问控制 - 用户与Docker镜像仓库通过“项目”进行组织管理，一个用户可以对多个镜像仓库在同一命名空间（project）里有不同的权限。镜像复制 - 镜像可以在多个Registry实例中复制（同步）。尤其适合于负载均衡，高可用，混合云和多云的场景。图形化用户界面 - 用户可以通过浏览器来浏览，检索当前Docker镜像仓库，管理项目和命名空间。AD/LDAP 支持 - Harbor可以集成企业内部已有的AD/LDAP，用于鉴权认证管理。审计管理 - 所有针对镜像仓库的操作都可以被记录追溯，用于审计管理。国际化 - 已拥有英文、中文、德文、日文和俄文的本地化版本。更多的语言将会添加进来。RESTful API - RESTful API 提供给管理员对于Harbor更多的操控, 使得与其它管理软件集成变得更容易。部署简单 - 提供在线和离线两种安装工具， 也可以安装到vSphere平台(OVA方式)虚拟设备。集成clair进行镜像安全漏洞扫描Harbor共由七个容器组成:a.harbor-adminserver:harbor系统管理服务b.harbor-db: 由官方mysql镜像构成的数据库容器c.harbor-jobservice:harbor的任务管理服务d.harbor-log:harbor的日志收集、管理服务e.harbor-ui:harbor的web页面服务f.nginx:负责流量转发和安全验证g.registry:官方的Docker registry，负责保存镜像Condition前置条件：1.需要Python2.7或以上2.Docker版本要在1.10或以上3.Docker compose版本要在1.6.0或以上DownloadRelease页面下载离线安装包（或在线也可以，不过安装的时候很慢）Config解压缩之后，目录下会生成harbor.conf文件，该文件就是Harbor的配置文件。123456789101112131415161718192021222324252627282930313233# 1. hostname设置访问地址，可以使用ip、域名，不可以设置为127.0.0.1或localhost# 2. 默认情况下，harbor使用的端口是80，若使用自定义的端口，除了要改docker-compose.yml文件中的配置外，# 这里的hostname也要加上自定义的端口，在docker login、push时会报错# hostname = $&#123;IP_ADDR&#125;:$&#123;PORT&#125;hostname = 192.168.1.102:8888# 访问协议，默认是http，也可以设置https，如果设置https，则nginx ssl需要设置onui_url_protocol = http# mysql数据库root用户默认密码root123，实际使用时修改下db_password = root123#Maximum number of job workers in job service max_job_workers = 3 #The path of secretkey storagesecretkey_path = /data# 启动Harbor后，管理员UI登录的密码，默认是Harbor12345# 若修改了此处的admin登录密码。则登录后台时使用修改后的密码harbor_admin_password = Harbor12345# 认证方式，这里支持多种认证方式，如LADP、本次存储、数据库认证。默认是db_auth，mysql数据库认证auth_mode = db_auth# 是否开启自注册self_registration = on# Token有效时间，默认30分钟token_expiration = 30# 用户创建项目权限控制，默认是everyone（所有人），也可以设置为adminonly（只能管理员）project_creation_restriction = everyone harbor默认监听80端口，我们修改为8888端口，同时docker-compose.yml也需要修改proxy的端口 还可以修改仓库的存储位置： Install运行安装脚本： 1./install.sh 集成clair漏洞扫描： 1./install.sh --with-clair 脚本会自动解压镜像文件并运行docker-compose 或者运行prepare文件再手动运行docker-compose 启动之后浏览器打开刚才修改的hostname 帐号密码默认是 admin/Harbor12345，可在配置文件harbor.conf中修改 修改配置文件之后需要重新生成一些内置配置： 12./preparedocker-compose up -d 登录被refuse多次docker login被refuse 这是因为 Docker 默认不允许非 HTTPS 方式推送镜像。我们可以通过 Docker 配置来取消这个限制，或者配置能够通过 HTTPS 访问的私有仓库。 有两种方式达到效果 方案一首先修改/etc/default/docker 1DOCKER_OPTS=&quot;--insecure-registry 192.168.1.102:8888&quot; 修改/lib/systemd/system/docker.service： 12345# 找到ExecStart=/usr/bin/dockerd -H fd:// # 前面添加EnvironmentFile=-/etc/default/docker，后面追加$DOCKER_OPTSEnvironmentFile=-/etc/default/dockerExecStart=/usr/bin/dockerd -H fd:// $DOCKER_OPTS 重启docker： 1sudo systemctl daemon-reload &amp;&amp; sudo systemctl restart docker 方案二如果是systemd 的系统例如Ubuntu16.04+、Debian 8+、centos 7，可以在/etc/docker/daemon.json 中写入如下内容： 1234&#123; &quot;registry-mirrors&quot;: [&quot;https://xxxxx.mirror.aliyuncs.com&quot;], &quot;insecure-registries&quot;: [&quot;192.168.1.102:8888&quot;]&#125; 然后重启docker： 1sudo systemctl daemon-reload &amp;&amp; sudo systemctl restart docker centos下是这样的： 修改/etc/sysconfig/docker： 123# OPTIONS=&apos;--selinux-enabled --log-driver=journald --signature-verification=false -H&apos;后面追加 --insecure-registry 10.0.11.150:5000OPTIONS=&apos;--selinux-enabled --log-driver=journald --signature-verification=false -H --insecure-registry 10.0.11.150:5000&apos; 重启： 1sudo systemctl restart docker Login and Push1234docker login 192.168.1.102:8888 -u admin -p Harbor12345docker tag ubuntu:latest 192.168.1.102/library/ubuntu:latestdocker push 192.168.1.102/library/ubuntu:latest 注意：使用docker stack deploy时，如果是私有镜像，需要终端登录后加上--with-registry-auth选项。 删除Harbor删除harbor，但保留数据 1docker-compose down -v 删除harbor数据（对应docker-compose.yml里面的数据卷） 12rm -r /data/databaserm -r /data/registry 删除镜像 UI界面操作删除镜像，只是删除元数据，并未删除真实数据，还需要调用registry的garbage-collect进行清理 1234567docker-compose stopdocker run -it --name gc --rm --volumes-from registry vmware/registry:2.6.2-photon garbage-collect --dry-run /etc/registry/config.yml #只是打印过程，并不删除docker run -it --name gc --rm --volumes-from registry vmware/registry:2.6.2-photon garbage-collect /etc/registry/config.ymldocker-compose start 注意：配置文件config.yml挂载在/etc/registry/下. Harbor做Mirror加速器mirror服务器和私有服务器分开部署，因为mirror服务器只能pull，不能push ./prepare之后修改config/registry/config.yml，在config.yml文件的最后追加以下配置： 12proxy: remoteurl: https://vioqnt8w.mirror.aliyuncs.com 这样保证docker pull并不存在于docker harbor中的image时，会从Docker Hub上去pull，并缓存于mirror服务器。 最后修改/etc/docker/daemon.json中的&quot;registry-mirrors&quot;: [&quot;https://xxxxx.mirror.aliyuncs.com&quot;] But，试了一下发现木有效果 Registry Mirrorregistry mirror原理 Docker Hub的镜像数据分为两部分：index数据和registry数据。前者保存了镜像的一些元数据信息，数据量很小；后者保存了镜像的实际数据，数据量比较大。平时我们使用docker pull命令拉取一个镜像时的过程是：先去index获取镜像的一些元数据，然后再去registry获取镜像数据。 所谓registry mirror就是搭建一个registry，然后将docker hub的registry数据缓存到自己本地的registry。整个过程是：当我们使用docker pull去拉镜像的时候，会先从我们本地的registry mirror去获取镜像数据，如果不存在，registry mirror会先从docker hub的registry拉取数据进行缓存，再传给我们。而且整个过程是流式的，registry mirror并不会等全部缓存完再给我们传，而且边缓存边给客户端传。 对于缓存，我们都知道一致性非常重要。registry mirror与docker官方保持一致的方法是：registry mirror只是缓存了docker hub的registry数据，并不缓存index数据。所以我们pull镜像的时候会先连docker hub的index获取镜像的元数据，如果我们registry mirror里面有该镜像的缓存，且数据与从index处获取到的元数据一致，则从registry mirror拉取；如果我们的registry mirror有该镜像的缓存，但数据与index处获取的元数据不一致，或者根本就没有该镜像的缓存，则先从docker hub的registry缓存或者更新数据。 1、拉取镜像 1docker pull registry:latest 2、获取registry的默认配置 1docker run -it --rm --entrypoint cat registry:latest /etc/docker/registry/config.yml &gt; config.yml 内容可能如下： 123456789101112131415161718version: 0.1log: fields: service: registrystorage: cache: blobdescriptor: inmemory filesystem: rootdirectory: /var/lib/registryhttp: addr: :5000 headers: X-Content-Type-Options: [nosniff]health: storagedriver: enabled: true interval: 10s threshold: 3 我们在最后面加上如下配置： 1234proxy: remoteurl: https://registry-1.docker.io username: [username] password: [password] username和password是可选的，如果配置了的话，那registry mirror除了可以缓存所有的公共镜像外，也可以访问这个用户所有的私有镜像。 启动registry容器： Bash 1docker run --restart=always -p 5000:5000 --name v2-mirror -v /data:/var/lib/registry -v $PWD/config.yml:/etc/registry/config.yml registry:latest /etc/registry/config.yml 当然我们也可以使用docker-compose启动： 12345678910111213version: &apos;3&apos;services: registry: image: library/registry:latest container_name: registry-mirror restart: always volumes: - /data:/var/lib/registry - ./config.yml:/etc/registry/config.yml ports: - 5000:5000 command: [&quot;serve&quot;, &quot;/etc/registry/config.yml&quot;] curl验证一下服务是否启动OK： 123456# ybd @ ybd-PC in ~ [17:30:14] $ curl -I http://192.168.6.113:5000HTTP/1.1 200 OKCache-Control: no-cacheDate: Fri, 05 Jan 2018 09:30:27 GMTContent-Type: text/plain; charset=utf-8 最后修改/etc/docker/daemon.json或/etc/default/docker中的registry-mirrors即可 Cluster and Orchestrate ToolsDocker Compose 官方文档：https://docs.docker.com/compose/ release：https://github.com/docker/compose/releases Compose是定义和运行多容器Docker应用程序的工具，使用Compose，您可以使用YAML文件来配置应用程序的服务，然后，使用单个命令创建并启动配置中的所有服务。 Dockerfile 可以让用户管理一个单独的应用容器。使用Docker Compose，不再需要使用shell脚本来启动容器。在配置文件中，所有的容器通过services来定义，然后使用docker-compose脚本来启动，停止和重启应用，和应用中的服务以及所有依赖服务的容器 Install在release页面找到最新版安装，ex： 1sudo curl -L https://github.com/docker/compose/releases/download/1.18.0/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose 变为可执行命令： 1sudo chmod +x /usr/local/bin/docker-compose 检查安装成功： 1docker-compose --version 卸载： 1sudo rm /usr/local/bin/docker-compose Command基本命令： -p 指定项目名称 build 构建项目中的服务容器 –force-rm 删除构建过程中的临时容器 --no-cache 构建过程中不使用 cache --pull 始终通过 pull 来获取更新版本的镜像 docker-compose kill 强制停止服务容器 docker-compose logs 查看容器的输出 调试必备 docker-compose pause 暂停一个服务容器 docker-compose unpause 恢复暂停 docker-compose port 打印某个容器端口所映射的公共端口 docker-compose ps 列出项目中目前的所有容器 -q 只打印容器 id docker-compose pull 拉取服务依赖的镜像 docker-compose restart -t 指定重启前停止容器的超时默认10秒 docker-compose rm 删除所有停止状态的容器先执行 stop docker-compose run 指定服务上执行一个命令 docker-compose start 启动已经存在的服务容器 docker-compose stop 停止已经存在的服务容器 docker-compose up 自动构建、创建服务、启动服务，关联一系列，运行在前台，ctrl c 就都停止运行。如果容器已经存在，将会尝试停止容器，重新创建。如果不希望重新创建，可以 --no-recreate 就只启动处于停止状态的容器，如果只想重新部署某个服务，可以使用 docker-compose up --no-deps -d ，不影响其所依赖的服务 docker-compose up -d 后台启动运行，生产环境必备 docker-compose down 停止并删除容器 Zsh命令补全12mkdir -p ~/.zsh/completioncurl -L https://raw.githubusercontent.com/docker/compose/$(docker-compose version --short)/contrib/completion/zsh/_docker-compose &gt; ~/.zsh/completion/_docker-compose 在.zshrc添加： 注意：(如果是oh-my-zsh，在$ZSH/oh-my-zsh.sh中添加) 1fpath=(~/.zsh/completion $fpath) 执行： 1autoload -Uz compinit &amp;&amp; compinit -i 重载： 1exec $SHELL -l Compose 模板文件默认的模板文件名称为 docker-compose.yml，格式为 YAML 格式。 12345678version: &quot;3&quot;services: webapp: image: examples/web ports: - &quot;80:80&quot; volumes: - &quot;/data&quot; 注意每个服务都必须通过 image 指令指定镜像或 build 指令（需要 Dockerfile）等来自动构建生成镜像。 如果使用 build 指令，在 Dockerfile 中设置的选项(例如：CMD, EXPOSE, VOLUME, ENV 等) 将会自动被获取，无需在 docker-compose.yml 中再次设置。下面分别介绍各个指令的用法。 build指定 Dockerfile 所在文件夹的路径（可以是绝对路径，或者相对 docker-compose.yml 文件的路径）。 Compose 将会利用它自动构建这个镜像，然后使用这个镜像。 12345version: &apos;3&apos;services: webapp: build: ./dir 你也可以使用 context 指令指定 Dockerfile 所在文件夹的路径。 使用 dockerfile 指令指定 Dockerfile 文件名。 使用 arg 指令指定构建镜像时的变量。 123456789version: &apos;3&apos;services: webapp: build: context: ./dir dockerfile: Dockerfile-alternate args: buildno: 1 使用 cache_from 指定构建镜像的缓存 12345build: context: . cache_from: - alpine:latest - corp/web_app:3.14 cap_add, cap_drop指定容器的内核能力（capacity）分配。 例如，让容器拥有所有能力可以指定为： 12cap_add: - ALL 去掉 NET_ADMIN 能力可以指定为： 12cap_drop: - NET_ADMIN command覆盖容器启动后默认执行的命令。 1command: echo &quot;hello world&quot; configs仅用于 Swarm mode，详细内容请查看下面Swarm模式介绍 cgroup_parent指定父 cgroup 组，意味着将继承该组的资源限制。 例如，创建了一个 cgroup 组名称为 cgroups_1。 1cgroup_parent: cgroups_1 container_name指定容器名称。默认将会使用 项目名称_服务名称_序号 这样的格式。 1container_name: docker-web-container 注意: 指定容器名称后，该服务将无法进行扩展（scale），因为 Docker 不允许多个容器具有相同的名称。 deploy仅用于 Swarm mode，这是 V3 才能使用的语法，通过docker-compose up方式启动会忽略这部分。 语法规则： 1234567deploy: replicas: 6 update_config: parallelism: 2 delay: 10s restart_policy: condition: on-failure mode首先 deploy 提供了一个模式选项，它的值有 global 和 replicated 两个，默认是 replicated 模式。 这两个模式的区别是： global：每个集群每个服务实例启动一个容器，就像以前启动 Service 时一样。 replicated：用户可以指定集群中实例的副本数量。 以前这个功能是无法在 Compose 中直接实现的，以前需要用户先使用 docker-compose bundle 命令将 docker-compose.yml 转换为 .dab 文件，然后才能拿到集群部署，而且很多功能用不了。 但是随着这次更新把 stack 加进来了，deploy 也就水到渠成加进了 Compose 功能中。 replicas上面说到可以指定副本数量，其中 replicas 就是用于指定副本数量的选项。 12deploy: replicas: 6 部署服务栈： 1docker stack deploy --compose-file docker-compose.yml placement这是 Docker 1.12 版本时就引入的概念，允许用户限制服务容器，下面是官方的说明： node attribute matches example node.id Node ID node.id==2ivku8v2gvtg4 node.hostname Node hostname node.hostname!=node-2 node.role Node role node.role==manager node.labels user defined node labels node.labels.security==high engine.labels Docker Engine’s labels engine.labels.operatingsystem==ubuntu 14.04 1234567891011version: &apos;3&apos;services: db: image: postgres deploy: placement: constraints: - node.role == manager - engine.labels.operatingsystem == ubuntu 14.04 preferences: - spread: node.labels.zone update_config早在上一个版本中，Swarm 就提供了一个升级回滚的功能。当服务升级出现故障时，超过重试次数则停止升级的功能，这也很方便，避免让错误的应用替代现有正常服务。 这个选项用于告诉 Compose 使用怎样的方式升级，以及升级失败后怎样回滚原来的服务。 parallelism: 服务中多个容器同时更新。 delay: 设置每组容器更新之间的延迟时间。 failure_action: 设置更新失败时的动作，可选值有 continue 与 pause (默认是：pause)。 monitor: 每次任务更新失败后监视故障的持续时间 (ns|us|ms|s|m|h) (默认：0s)。 max_failure_ratio: 更新期间容忍的故障率。 resources看例子： 1234567resources: limits: cpus: &apos;0.001&apos; memory: 50M reservations: cpus: &apos;0.0001&apos; memory: 20M 知道干啥用了吧，这是一个新的语法选项，替代了之前的类似 cpu_shares, cpu_quota, cpuset, mem_limit, memswap_limit 这种选项。统一起来好看点。 restart_policy设置如何重启容器，毕竟有时候容器会意外退出。 condition：设置重启策略的条件，可选值有 none, on-failure 和 any (默认：any)。 delay：在重新启动尝试之间等待多长时间，指定为持续时间（默认值：0）。 max_attempts：设置最大的重启尝试次数，默认是永不放弃，哈哈，感受到一股运维的绝望。 window：在决定重新启动是否成功之前要等待多长时间，默认是立刻判断，有些容器启动时间比较长，指定一个“窗口期”非常重要。 devices指定设备映射关系。 12devices: - &quot;/dev/ttyUSB1:/dev/ttyUSB0&quot; depends_on解决容器的依赖、启动先后的问题。以下例子中会先启动 redis db 再启动 web 1234567891011121314version: &apos;3&apos;services: web: build: . depends_on: - db - redis redis: image: redis db: image: postgres 注意：web 服务不会等待 redis db 「完全启动」之后才启动。 dns自定义 DNS 服务器。可以是一个值，也可以是一个列表。 12345dns: 8.8.8.8dns: - 8.8.8.8 - 114.114.114.114 dns_search配置 DNS 搜索域。可以是一个值，也可以是一个列表。 12345dns_search: example.comdns_search: - domain1.example.com - domain2.example.com tmpfs挂载一个 tmpfs 文件系统到容器。 1234tmpfs: /runtmpfs: - /run - /tmp env_file从文件中获取环境变量，可以为单独的文件路径或列表，默认读当前目录.env。 如果通过 docker-compose -f FILE 方式来指定 Compose 模板文件，则 env_file 中变量的路径会基于模板文件路径。 如果有变量名称与 environment 指令冲突，则按照惯例，以后者为准。 123456env_file: .envenv_file: - ./common.env - ./apps/web.env - /opt/secrets.env 环境变量文件中每一行必须符合格式，支持 # 开头的注释行。 12# common.env: Set development environmentPROG_ENV=development environment设置环境变量。你可以使用数组或字典两种格式。 只给定名称的变量会自动获取运行 Compose 主机上对应变量的值，可以用来防止泄露不必要的数据。 1234567environment: RACK_ENV: development SESSION_SECRET:environment: - RACK_ENV=development - SESSION_SECRET 如果变量名称或者值中用到 true|false，yes|no 等表达 布尔 含义的词汇，最好放到引号里，避免 YAML 自动解析某些内容为对应的布尔语义。这些特定词汇，包括 1y|Y|yes|Yes|YES|n|N|no|No|NO|true|True|TRUE|false|False|FALSE|on|On|ON|off|Off|OFF expose暴露端口，但不映射到宿主机，只被连接的服务访问。 仅可以指定内部端口为参数 123expose: - &quot;3000&quot; - &quot;8000&quot; external_links 注意：不建议使用该指令。 链接到 docker-compose.yml 外部的容器，甚至并非 Compose 管理的外部容器。 1234external_links: - redis_1 - project_db_1:mysql - project_db_1:postgresql extra_hosts类似 Docker 中的 --add-host 参数，指定额外的 host 名称映射信息。 123extra_hosts: - &quot;googledns:8.8.8.8&quot; - &quot;dockerhub:52.1.157.61&quot; 会在启动后的服务容器中 /etc/hosts 文件中添加如下两条条目。 128.8.8.8 googledns52.1.157.61 dockerhub healthcheck通过命令检查容器是否健康运行。 12345healthcheck: test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;-f&quot;, &quot;http://localhost&quot;] interval: 1m30s timeout: 10s retries: 3 image指定为镜像名称或镜像 ID。如果镜像在本地不存在，Compose 将会尝试拉去这个镜像。 123image: ubuntuimage: orchardup/postgresqlimage: a4bc65fd labels为容器添加 Docker 元数据（metadata）信息。例如可以为容器添加辅助说明信息。 1234labels: com.startupteam.description: &quot;webapp for a startup team&quot; com.startupteam.department: &quot;devops department&quot; com.startupteam.release: &quot;rc3 for v1.0&quot; links 注意：不推荐使用该指令。 logging配置日志选项。 1234logging: driver: syslog options: syslog-address: &quot;tcp://192.168.0.42:123&quot; 目前支持三种日志驱动类型。 123driver: &quot;json-file&quot;driver: &quot;syslog&quot;driver: &quot;none&quot; options 配置日志驱动的相关参数。 123options: max-size: &quot;200k&quot; max-file: &quot;10&quot; 更多详情：https://docs.docker.com/engine/admin/logging/overview/ network_mode设置网络模式。使用和 docker run 的 --network 参数一样的值。 12345network_mode: &quot;bridge&quot;network_mode: &quot;host&quot;network_mode: &quot;none&quot;network_mode: &quot;service:[service name]&quot;network_mode: &quot;container:[container name/id]&quot; networks配置容器连接的网络。 1234567891011version: &quot;3&quot;services: some-service: networks: - some-network - other-networknetworks: some-network: other-network: Docker 网络类型，有 bridge overlay，默认为bridge。其中 overlay 网络类型用于 Swarm mode pid跟主机系统共享进程命名空间。打开该选项的容器之间，以及容器和宿主机系统之间可以通过进程 ID 来相互访问和操作。 1pid: &quot;host&quot; ports暴露端口信息。 使用宿主端口：容器端口 (HOST:CONTAINER) 格式，或者仅仅指定容器的端口（宿主将会随机选择端口）都可以。 12345ports: - &quot;3000&quot; - &quot;8000:8000&quot; - &quot;49100:22&quot; - &quot;127.0.0.1:8001:8001&quot; 注意：当使用 HOST:CONTAINER 格式来映射端口时，如果你使用的容器端口小于 60 并且没放到引号里，可能会得到错误结果，因为 YAML 会自动解析 xx:yy 这种数字格式为 60 进制。为避免出现这种问题，建议数字串都采用引号包括起来的字符串格式。 secrets存储敏感数据，例如 mysql 服务密码。 12345678910111213141516version: &quot;3&quot;services:mysql: image: mysql environment: MYSQL_ROOT_PASSWORD_FILE: /run/secrets/db_root_password secrets: - db_root_password - my_other_secretsecrets: my_secret: file: ./my_secret.txt my_other_secret: external: true security_opt指定容器模板标签（label）机制的默认属性（用户、角色、类型、级别等）。例如配置标签的用户名和角色名。 123security_opt: - label:user:USER - label:role:ROLE stop_signal设置另一个信号来停止容器。在默认情况下使用的是 SIGTERM 停止容器。 1stop_signal: SIGUSR1 sysctls配置容器内核参数。 1234567sysctls: net.core.somaxconn: 1024 net.ipv4.tcp_syncookies: 0sysctls: - net.core.somaxconn=1024 - net.ipv4.tcp_syncookies=0 ulimits指定容器的 ulimits 限制值。 例如，指定最大进程数为 65535，指定文件句柄数为 20000（软限制，应用可以随时修改，不能超过硬限制） 和 40000（系统硬限制，只能 root 用户提高）。 12345ulimits: nproc: 65535 nofile: soft: 20000 hard: 40000 volumes数据卷所挂载路径设置。可以设置宿主机路径 （HOST:CONTAINER） 或加上访问模式 （HOST:CONTAINER:ro）。 该指令中路径支持相对路径。 1234volumes: - /var/lib/mysql - cache/:/tmp/cache - ~/configs:/etc/configs/:ro 其它指令此外，还有包括 domainname, entrypoint, hostname, ipc, mac_address, privileged, read_only, shm_size, restart, stdin_open, tty, user, working_dir 等指令，基本跟 docker run 中对应参数的功能一致。 指定服务容器启动后执行的入口文件。 1entrypoint: /code/entrypoint.sh 指定容器中运行应用的用户名。 1user: nginx 指定容器中工作目录。 1working_dir: /code 指定容器中搜索域名、主机名、mac 地址等。 123domainname: your_website.comhostname: testmac_address: 08-00-27-00-0C-0A 允许容器中运行一些特权命令。 1privileged: true 指定容器退出后的重启策略为始终重启。该命令对保持服务始终运行十分有效，在生产环境中推荐配置为 always 或者 unless-stopped。 1restart: always 以只读模式挂载容器的 root 文件系统，意味着不能对容器内容进行修改。 1read_only: true 打开标准输入，可以接受外部输入。 1stdin_open: true 模拟一个伪终端。 1tty: true 读取变量Compose 模板文件支持动态读取主机的系统环境变量和当前目录下的 .env 文件中的变量。 例如，下面的 Compose 文件将从运行它的环境中读取变量 ${MONGO_VERSION} 的值，并写入执行的指令中。 12345version: &quot;3&quot;services:db: image: &quot;mongo:$&#123;MONGO_VERSION&#125;&quot; 如果执行 MONGO_VERSION=3.2 docker-compose up 则会启动一个 mongo:3.2 镜像的容器；如果执行 MONGO_VERSION=2.8 docker-compose up 则会启动一个 mongo:2.8 镜像的容器。 若当前目录存在 .env 文件，执行 docker-compose 命令时将从该文件中读取变量。 在当前目录新建 .env 文件并写入以下内容。 12# 支持 # 号注释MONGO_VERSION=3.6 执行 docker-compose up 则会启动一个 mongo:3.6 镜像的容器。 官方例子： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394version: &quot;3&quot;services: redis: image: redis:alpine ports: - &quot;6379&quot; networks: - frontend deploy: replicas: 2 update_config: parallelism: 2 delay: 10s restart_policy: condition: on-failure db: image: postgres:9.4 volumes: - db-data:/var/lib/postgresql/data networks: - backend deploy: placement: constraints: [node.role == manager] vote: image: dockersamples/examplevotingapp_vote:before ports: - 5000:80 networks: - frontend depends_on: - redis deploy: replicas: 2 update_config: parallelism: 2 restart_policy: condition: on-failure result: image: dockersamples/examplevotingapp_result:before ports: - 5001:80 networks: - backend depends_on: - db deploy: replicas: 1 update_config: parallelism: 2 delay: 10s restart_policy: condition: on-failure worker: image: dockersamples/examplevotingapp_worker networks: - frontend - backend deploy: mode: replicated replicas: 1 labels: [APP=VOTING] restart_policy: condition: on-failure delay: 10s max_attempts: 3 window: 120s placement: constraints: [node.role == manager] visualizer: image: dockersamples/visualizer:stable ports: - &quot;8080:8080&quot; stop_grace_period: 1m30s volumes: - &quot;/var/run/docker.sock:/var/run/docker.sock&quot; deploy: placement: constraints: [node.role == manager]networks: frontend: backend:volumes: db-data:作者：左蓝链接：https://www.jianshu.com/p/748416621013來源：简书著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 理解多compose文件组合默认，compose会读取两个文件，一个docker-compose.yml和一个可选的docker-compose.override.yml文件。通常，docker-compose.yml文件包含你的基本配置，而docker-compose.override.yml，顾名思义，就是包含的现有服务配置的覆盖内容，或完全新的配置。 如果一个服务在这两个文件中都有定义，那么compose将使用添加和覆盖配置中所描述的规则来合并服务 要使用多个override文件或不同名称的override文件，可以使用-f选项来指定文件列表。compose根据在命令行指定的顺序来合并它们。 当使用多个配置文件时，必须确保文件中所有的路径都是相对于base compose文件的(-f 指定的第一个compose文件)。这样要求是因为override文件不需要一个有效的compose文件。override文件可以只包含配置中的一小片段。跟踪一个服务的片段是相对于那个路径的，这是很困难的事，所以一定要保持路径容易理解，所以路径必须定义为相对于base文件的路径。 例如，定义两个配置文件： docker-compose.yml 1234567891011web: image: example/my_web_app:latest links: - db - cachedb: image: postgres:latestcache: image: redis:latest docker-compose.prod.yml 123456789web: ports: - 80:80 environment: PRODUCTION: &apos;true&apos;cache: environment: TTL: &apos;500&apos; 要使用这个生产compose文件部署，运行如下命令： 1docker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d 这将会使用docker-compose.yml和docker-compose.prod.yml来部署这三个服务 Docker Machine Docker Machine 是供给和管理 docker 化主机的工具。有自己的命令行客户端 docker-machine。提供多种环境的 docker 主机，可以用 Docker Machine 在一个或者多个虚拟系统（本地或者远程）上安装 Docker Engine。 Install123curl -L https://github.com/docker/machine/releases/download/v0.13.0/docker-machine-`uname -s`-`uname -m` &gt;/tmp/docker-machine &amp;&amp;chmod +x /tmp/docker-machine &amp;&amp;sudo cp /tmp/docker-machine /usr/local/bin/docker-machine uninstall： 1sudo rm $(which docker-machine) Zsh命令补全12mkdir -p ~/.zsh/completioncurl -L https://raw.githubusercontent.com/docker/machine/master/contrib/completion/zsh/_docker-machine &gt; ~/.zsh/completion/_docker-machine 在~/.zshrc添加： 注意：(如果是oh-my-zsh，在$ZSH/oh-my-zsh.sh中添加) 1fpath=(~/.zsh/completion $fpath) 执行： 12autoload -Uz compinit &amp;&amp; compinit -iexec $SHELL -l Usage确保已经安装了virtualbox： 1sudo apt install virtualbox 创建本地实例： 使用 virtualbox 类型的驱动，创建一台 Docker 主机，命名为 test。 1docker-machine create -d virtualbox test 你也可以在创建时加上如下参数，来配置主机或者主机上的 Docker。 --engine-opt dns=114.114.114.114 配置 Docker 的默认 DNS --engine-registry-mirror https://registry.docker-cn.com 配置 Docker 的仓库镜像 --engine-insecure-registry --virtualbox-memory 2048 配置主机内存 --virtualbox-cpu-count 2 配置主机 CPU 更多参数请使用 docker-machine create --driver virtualbox --help 命令查看。 12345678910111213141516171819202122232425262728293031323334353637$ docker-machine create --driver virtualbox --helpUsage: docker-machine create [OPTIONS] [arg...]Create a machine.Run &apos;docker-machine create --driver name&apos; to include the create flags for that driver in the help text.Options: --driver, -d &quot;none&quot; Driver to create machine with. --engine-env [--engine-env option --engine-env option] Specify environment variables to set in the engine --engine-insecure-registry [--engine-insecure-registry option --engine-insecure-registry option] Specify insecure registries to allow with the created engine --engine-install-url &quot;https://get.docker.com&quot; Custom URL to use for engine installation [$MACHINE_DOCKER_INSTALL_URL] --engine-label [--engine-label option --engine-label option] Specify labels for the created engine --engine-opt [--engine-opt option --engine-opt option] Specify arbitrary flags to include with the created engine in the form flag=value --engine-registry-mirror [--engine-registry-mirror option --engine-registry-mirror option] Specify registry mirrors to use [$ENGINE_REGISTRY_MIRROR] --engine-storage-driver Specify a storage driver to use with the engine --swarm Configure Machine with Swarm --swarm-addr addr to advertise for Swarm (default: detect and use the machine IP) --swarm-discovery Discovery service to use with Swarm --swarm-experimental Enable Swarm experimental features --swarm-host &quot;tcp://0.0.0.0:3376&quot; ip/socket to listen on for Swarm master --swarm-image &quot;swarm:latest&quot; Specify Docker image to use for Swarm [$MACHINE_SWARM_IMAGE] --swarm-master Configure Machine to be a Swarm master --swarm-opt [--swarm-opt option --swarm-opt option] Define arbitrary flags for swarm --swarm-strategy &quot;spread&quot; Define a default scheduling strategy for Swarm --virtualbox-boot2docker-url The URL of the boot2docker image. Defaults to the latest available version [$VIRTUALBOX_BOOT2DOCKER_URL] --virtualbox-cpu-count &quot;1&quot; number of CPUs for the machine (-1 to use the number of CPUs available) [$VIRTUALBOX_CPU_COUNT] --virtualbox-disk-size &quot;20000&quot; Size of disk for host in MB [$VIRTUALBOX_DISK_SIZE] --virtualbox-host-dns-resolver Use the host DNS resolver [$VIRTUALBOX_HOST_DNS_RESOLVER] --virtualbox-dns-proxy Proxy all DNS requests to the host [$VIRTUALBOX_DNS_PROXY] --virtualbox-hostonly-cidr &quot;192.168.99.1/24&quot; Specify the Host Only CIDR [$VIRTUALBOX_HOSTONLY_CIDR] --virtualbox-hostonly-nicpromisc &quot;deny&quot; Specify the Host Only Network Adapter Promiscuous Mode [$VIRTUALBOX_HOSTONLY_NIC_PROMISC] --virtualbox-hostonly-nictype &quot;82540EM&quot; Specify the Host Only Network Adapter Type [$VIRTUALBOX_HOSTONLY_NIC_TYPE] --virtualbox-import-boot2docker-vm The name of a Boot2Docker VM to import --virtualbox-memory &quot;1024&quot; Size of memory for host in MB [$VIRTUALBOX_MEMORY_SIZE] --virtualbox-no-share Disable the mount of your home directory 创建好主机之后，查看主机 1234docker-machine lsNAME ACTIVE DRIVER STATE URL SWARM DOCKER ERRORStest - virtualbox Running tcp://192.168.99.187:2376 v17.10.0-ce 创建主机成功后，可以通过 env 命令来让后续操作对象都是目标主机。 1docker-machine env test 后续根据提示在命令行输入命令之后就可以操作 test 主机。 通过以下命令恢复当前环境： 1docker-machine env -u 也可以通过 SSH 登录到主机。 1docker-machine ssh test 连接到主机之后你就可以在其上使用 Docker 了。 操作命令 active 查看活跃的 Docker 主机 config 输出连接的配置信息 create 创建一个 Docker 主机 env 显示连接到某个主机需要的环境变量 inspect 输出主机更多信息 ip 获取主机地址 kill 停止某个主机 ls 列出所有管理的主机 provision 重新设置一个已存在的主机 regenerate-certs 为某个主机重新生成 TLS 认证信息 restart 重启主机 rm 删除某台主机 ssh SSH 到主机上执行命令 scp 在主机之间复制文件 mount 挂载主机目录到本地 start 启动一个主机 status 查看主机状态 stop 停止一个主机 upgrade 更新主机 Docker 版本为最新 url 获取主机的 URL version 输出 docker-machine 版本信息 help 输出帮助信息 每个命令，又带有不同的参数，可以通过 1$ docker-machine COMMAND --help 来查看具体的用法。 注意：docker-machine 安装的 Docker 在 /etc/systemd/system 目录下多出了一个 Docker 相关的目录：docker.service.d。这个目录中只有一个文件 10-machine.conf，这个配置文件至关重要，因为它会覆盖 Docker 默认安装时的配置文件，从而以 Docker Machine 指定的方式启动 Docker daemon。至此我们有了一个可以被远程访问的 Docker daemon。 加入其他物理主机 https://docs.docker.com/machine/drivers/generic/ 在使用 docker-machine 进行远程安装前我们需要做一些准备工作：1. 在目标主机上创建一个用户并加入sudo 组2. 为该用户设置 sudo 操作不需要输入密码3. 把本地用户的 ssh public key 添加到目标主机上 注意：如果远程物理级已经安装过docker，docker-machine会把远程的docker重置，镜像以及容器都没了… 比如我们要在远程主机上添加一个名为 nick 的用户并加入 sudo 组： 12$ sudo adduser nick$ sudo usermod -a -G sudo nick 然后设置 sudo 操作不需要输入密码： 1$ sudo visudo 把下面一行内容添加到%sudo ALL=(ALL:ALL) ALL之后并保存文件，否则不生效： 12%sudo ALL=(ALL:ALL) ALLnick ALL=(ALL:ALL) NOPASSWD: ALL 最后把本地用户的 ssh public key 添加到目标主机上： 1$ ssh-copy-id -i ~/.ssh/id_rsa.pub nick@xxx.xxx.xxx.xxx 这几步操作的主要目的是获得足够的权限可以远程的操作目标主机。 然后添加machine： 123456789docker-machine create \ --driver generic \ --generic-ip-address=192.168.6.105 \ --generic-ssh-key ~/.ssh/id_rsa \ --generic-ssh-user=dworker \ --engine-registry-mirror https://vioqnt7w.mirror.aliyuncs.com \ --engine-insecure-registry 192.168.6.113:8888 \ qww-machine [machine name] 如果已安装docker： 1docker-machine create -d none --url=tcp://192.168.6.105:2375 vmware_docker01 添加镜像加速1234$ docker-machine ssh default$&gt; sudo sed -i &quot;s|EXTRA_ARGS=&apos;|EXTRA_ARGS=&apos;--registry-mirror=$REGISTRY_MIRROR |g&quot; /var/lib/boot2docker/profile$&gt; exit$ docker-machine restart default Swarm Mode Docker 1.12 Swarm mode 已经内嵌入 Docker 引擎，成为了 docker 子命令 docker swarm。请注意与旧的 Docker Swarm 区分开来。 Swarm mode 内置 kv 存储功能，提供了众多的新特性，比如：具有容错能力的去中心化设计、内置服务发现、负载均衡、路由网格、动态伸缩、滚动更新、安全传输等。使得 Docker 原生的 Swarm 集群具备与 Mesos、Kubernetes 竞争的实力。 功能特点与Docker Engine集成的集群管理使用Docker Engine CLI创建一组Docker引擎，您可以在其中部署应用程序服务。您不需要其他编排软件来创建或管理群集。 节点分散式设计Docker Engine不是在部署时处理节点角色之间的差异，而是在运行时处理角色变化。您可以使用Docker Engine部署两种类型的节点，管理节点和工作节点。这意味着您可以从单个服务器构建整个群集。 声明性服务模型Docker Engine使用声明性方法来定义应用程序堆栈中各种服务的所需状态。例如，您可以描述由具有消息队列服务和数据库后端的Web前端服务组成的应用程序。 可扩容与缩放容器对于每个服务，您可以声明要运行的任务数。当您向上或向下缩放时，swarm管理器通过添加或删除任务来自动适应，以保持所需的任务数量来保证集群的可靠状态。 容器容错状态协调群集管理器节点不断监视群集状态，并协调您表示的期望状态的实际状态之间的任何差异。例如，如果设置一个服务以运行容器的10个副本，并且托管其中两个副本的工作程序计算机崩溃，则管理器将创建两个新副本以替换崩溃的副本。 swarm管理器将新副本分配给正在运行和可用的worker节点上。 多主机网络您可以为服务指定覆盖网络。当swarm管理器初始化或更新应用程序时，它会自动为覆盖网络上的容器分配地址。 服务发现Swarm管理器节点为swarm中的每个服务分配唯一的DNS名称，并负载平衡运行的容器。您可以通过嵌入在swarm中的DNS服务器查询在群中运行的每个容器。 负载平衡您可以将服务的端口公开给外部负载平衡器。在内部，swarm允许您指定如何在节点之间分发服务容器。 缺省安全群中的每个节点强制执行TLS相互验证和加密，以保护其自身与所有其他节点之间的通信。您可以选择使用自签名根证书或来自自定义根CA的证书。 滚动更新在已经运行期间，您可以增量地应用服务更新到节点。 swarm管理器允许您控制将服务部署到不同节点集之间的延迟。如果出现任何问题，您可以将任务回滚到服务的先前版本。 概念节点运行 Docker 的主机可以主动初始化一个 Swarm 集群或者加入一个已存在的 Swarm 集群，这样这个运行 Docker 的主机就成为一个 Swarm 集群的节点 (node) 。 节点分为管理 (manager) 节点和工作 (worker) 节点。 管理节点用于 Swarm 集群的管理，docker swarm 命令基本只能在管理节点执行（节点退出集群命令 docker swarm leave 可以在工作节点执行）。一个 Swarm 集群可以有多个管理节点，但只有一个管理节点可以成为 leader，leader 通过 raft 协议实现。 工作节点是任务执行节点，管理节点将服务 (service) 下发至工作节点执行。管理节点默认也作为工作节点。你也可以通过配置让服务只运行在管理节点。 服务和任务任务 （Task）是 Swarm 中的最小的调度单位，目前来说就是一个单一的容器。 服务 （Services） 是指一组任务的集合，服务定义了任务的属性。服务有两种模式： replicated services 按照一定规则在各个工作节点上运行指定个数的任务。 global services 每个工作节点上运行一个任务 两种模式通过 docker service create 的 --mode 参数指定。 下图解释服务、任务、容器： 服务的任务及调试说明： 服务部署的复制模式和全局模式说明： 开启API端口监听（下面的Portainer需要用到） Swarm是通过监听2375端口进行通信的，所以在使用Swarm进行集群管理之前，需要设置一下2375端口的监听。这里有两种方法，一种是通过修改docker配置文件方式，另一种是通过一个轻量级的代理容器进行监听。 方式一，修改配置文件（推荐）： /etc/default/docker中的DOCKER_OPTS追加配置： 1-H tcp://0.0.0.0:2375 -H unix:///var/run/docker.sock 或者在/etc/docker/daemon.json添加（需要高版本Docker）： 123456&#123; &quot;hosts&quot;: [ &quot;tcp://0.0.0.0:2375&quot;, &quot;unix:///var/run/docker.sock&quot; ]&#125; 方式二，添加代理： 1234567docker run -ti -d -p 2375:2375 \--restart=always \--hostname=$HOSTNAME \--name shipyard-proxy \-v /var/run/docker.sock:/var/run/docker.sock \-e PORT=2375 \shipyard/docker-proxy 创建集群在创建集群前，如果开启了防火墙，请确认三台主机的防火墙能让swarm需求的端口开放，需要打开主机之间的端口，以下端口必须可用。在某些系统上，这些端口默认为打开。2377：TCP端口2377用于集群管理通信7946：TCP和UDP端口7946用于节点之间的通信4789：TCP和UDP端口4789用于覆盖网络流量如果您计划使用加密（–opt加密）创建覆盖网络，则还需要确保协议50（ESP）已打开。 docker swarm命令： 1234567891011121314151617181920212223242526272829303132docker swarm init --advertise-addr 172.18.60.133#恢复docker swarm init --advertise-addr 172.18.60.133 --force-new-cluster#其它节点加入docker swarm join --token \ SWMTKN-1-44gjumnutrh4k9lls54f5hp43kiioxf16iuh7qarjfqjsu7jio-2326b8ikb1xiysm3i7neh9nho 172.18.60.133:2377 #输出可以用来以worker角色加入的tokendocker swarm join-token worker#输出可以用来以manager角色加入的tokendocker swarm join-token manager#manager节点强制脱离docker swarm leave --force#worker节点脱离docker swarm leave#节点从swarm中移除docker node rm XXXXX#worker节点提升为managerdocker node promote ilog2#恢复为workerdocker node demote &lt;NODE&gt;#创建服务docker service create --replicas 3 --name helloworld alpine ping docker.com 节点管理查看集群中的docker信息1docker -H 10.0.11.150:2376 info 列出节点1docker node ls 说明：AVAILABILITY列：显示调度程序是否可以将任务分配给节点： Active 意味着调度程序可以将任务分配给节点。 Pause 意味着调度程序不会将新任务分配给节点，但现有任务仍在运行。 Drain 意味着调度程序不会向节点分配新任务。调度程序关闭所有现有任务并在可用节点上调度它们。 MANAGER STATUS列显示节点是属于manager或者worker 没有值 表示不参与群管理的工作节点。 Leader 意味着该节点是使得群的所有群管理和编排决策的主要管理器节点。 Reachable 意味着节点是管理者节点正在参与Raft共识。如果领导节点不可用，则该节点有资格被选为新领导者。 Unavailable 意味着节点是不能与其他管理器通信的管理器。如果管理器节点不可用，您应该将新的管理器节点加入群集，或者将工作器节点升级为管理器。 查看节点的详细信息您可以在管理器节点上运行docker node inspect来查看单个节点的详细信息。 输出默认为JSON格式，但您可以传递–pretty标志以以可读的yml格式打印结果 12345678910111213141516171819202122232425262728293031323334353637# ybd @ ybd-PC in ~ [9:37:23] $ docker node inspect --pretty ybd-machine1 ID: f917bibevklfp3xjsjoyx2g2tHostname: ybd-machine1Joined at: 2018-01-03 10:00:28.499769713 +0000 utcStatus: State: Ready Availability: Active Address: 192.168.6.113Platform: Operating System: linux Architecture: x86_64Resources: CPUs: 1 Memory: 995.9MiBPlugins: Log: awslogs, fluentd, gcplogs, gelf, journald, json-file, logentries, splunk, syslog Network: bridge, host, macvlan, null, overlay Volume: localEngine Version: 17.12.0-ceEngine Labels: - provider=virtualboxTLS Info: TrustRoot:-----BEGIN CERTIFICATE-----MIIBajCCARCgAwIBAgIUTdhfszkLcL0IC92X4TaOWbQlbZAwCgYIKoZIzj0EAwIwEzERMA8GA1UEAxMIc3dhcm0tY2EwHhcNMTcxMjIyMDg0NzAwWhcNMzcxMjE3MDg0NzAwWjATMREwDwYDVQQDEwhzd2FybS1jYTBZMBMGByqGSM49AgEGCCqGSM49AwEHA0IABEWabJlpAGjNi6x8QWGXnMUFwPe27anM5nHwLX8y05TbgamYvV7Is4CZ1BbUypJ/a9FpSp4FbV/6iYveIwwaHLSjQjBAMA4GA1UdDwEB/wQEAwIBBjAPBgNVHRMBAf8EBTADAQH/MB0GA1UdDgQWBBR1K7f/HuhGDD2gzDeejaH2r8ZxIzAKBggqhkjOPQQDAgNIADBFAiEApL0o/FwwzLrhalYddR+buFHg0Hg3jKh37t00TmMU7SICIAOzYZNcngOkQiY2K2poQqRw+dFU9xOk543G+zDHqX4h-----END CERTIFICATE----- Issuer Subject: MBMxETAPBgNVBAMTCHN3YXJtLWNh Issuer Public Key: MFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAERZpsmWkAaM2LrHxBYZecxQXA97btqczmcfAtfzLTlNuBqZi9XsizgJnUFtTKkn9r0WlKngVtX/qJi94jDBoctA== 更新节点Usage: docker node update [OPTIONS] NODE Options: –availability string Availability of the node (“active”|”pause”|”drain”) –label-add list Add or update a node label (key=value) –label-rm list Remove a node label if exists –role string Role of the node (“worker”|”manager”) 升级或降级节点您可以将工作程序节点提升为manager角色。这在管理器节点不可用或者您希望使管理器脱机以进行维护时很有用。 类似地，您可以将管理器节点降级为worker角色。无论您升级或降级节点，您应该始终在群中维护奇数个管理器节点。要升级一个节点或一组节点，请从管理器节点运行： 12docker node promote [NODE]docker node domote [NODE] 退出docker swarm集群work节点： 1docker swarm leave manager节点： 1docker swarm leave -f 可视化visualizer服务123456docker service create \--name=viz \--publish=8088:8080/tcp \--constraint=node.role==manager \--mount=type=bind,src=/var/run/docker.sock,dst=/var/run/docker.sock \dockersamples/visualizer Service用法12345678910111213141516171819202122232425262728创建服务docker service create \--image nginx \--replicas 2 \nginx 更新服务docker service update \--image nginx:alpine \nginx 删除服务docker service rm nginx 减少服务实例(这比直接删除服务要好)docker service scale nginx=0 增加服务实例docker service scale nginx=5 查看所有服务docker service ls 查看服务的容器状态docker service ps nginx 查看服务的详细信息。docker service inspect nginx 实现零宕机部署也非常简单。这样也可以方便地实现持续部署: 12345678构建新镜像docker build -t hub.docker.com/image . 将新镜像上传到Docker仓库docker push hub.docker.com/image 更新服务的镜像docker service update --image hub.docker.com/image service 更新服务要慎重。 你的容器同时运行在多个主机上。更新服务时，只需要更新Docker镜像。合理的测试和部署流程是保证成功的关键。Swarm非常容易入门。分布式系统通常是非常复杂的。与其他容器集群系统(Mesos, Kubernetes)相比，Swarm的学习曲线最低。 Docker Visual ManagementRancher官方网站 如果是对集群管理并且管理员只限制Docker命令权限的话，建议用这个工具，商店用起来都比较方便， 优点：界面中文化，操作简单易懂,功能强大,容灾机制。 缺点: 不能团队分配权限，容器操作权限太大没法满足需求，部署时相应的Docker 服务也很多，需要逐一去了解容器作用。 Shipyard官方网站 Shipyard是在Docker Swarm的基础上，管理Docker资源，包括容器，镜像，注册表等。 优点： 支持镜像管理、容器管理。 支持控制台命令 容器资源消耗监控 支持集群swarm，可以随意增加节点 支持控制用户管理权限，可以设置某个容器对某个用户只读、管理权限。 有汉化版 缺点 ： 启动容器较多，占用每个节点的一部分资源 部署： 1curl -sSL https://shipyard-project.com/deploy | bash -s 注意：这将在端口2375上暴露Docker Engine。如果此节点可以在安全网络之外访问，建议使用TLS。 支持集群，所以可以添加节点： 1curl -sSL https://shipyard-project.com/deploy | ACTION=node DISCOVERY=etcd://10.0.0.10:4001 bash -s 它会下载并启动7个镜像： 界面： 容器信息： 初体验来说，感觉跟下面的Portainer功能差不多，但是Registry总是添加失败 Portainer官方网站 Portainer是Docker的图形化管理工具，提供状态显示面板、应用模板快速部署、容器镜像网络数据卷的基本操作（包括上传下载镜像，创建容器等操作）、事件日志显示、容器控制台操作、Swarm集群和服务等集中管理和操作、登录用户管理和控制等功能。功能十分全面，基本能满足中小型单位对容器管理的全部需求。 优点 支持容器管理、镜像管理 轻量级，消耗资源少 基于docker api，安全性高，可指定docker api端口，支持TLS证书认证。 支持权限分配 支持集群 缺点 功能不够强大。 容器创建后，无法通过后台增加端口。 没有容灾机制 单机启动： 12345docker run -d -p 9000:9000 \--name portainer \--restart=always \-v /var/run/docker.sock:/var/run/docker.sock \portainer/portainer swarm模式启动： 12345678docker service create \--name portainer \--publish 9000:9000 \--constraint &apos;node.role == manager&apos; \--mount type=bind,src=/var/run/docker.sock,dst=/var/run/docker.sock \--mount type=bind,src=/path/on/host/data,dst=/data \portainer/portainer \-H unix:///var/run/docker.sock 容器管理： 镜像管理： 镜像仓库： Endpoints： 注意：添加Endpoints先要暴露节点的2375端口。 Finally 参考： Docker — 从入门到实践 在生产环境中使用Docker Swarm的一些建议 使用Docker Harbor搭建私有镜像服务器和Mirror服务器 远程连接docker daemon，Docker Remote API]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>Swarm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用 Reactor 进行反应式编程]]></title>
    <url>%2F2017%2Fwith-reactor-response-encode%2F</url>
    <content type="text"><![CDATA[Preface反应式编程（Reactive Programming）这种新的编程范式越来越受到开发人员的欢迎。在 Java 社区中比较流行的是 RxJava 和 RxJava 2。本篇要介绍的是另外一个新的反应式编程库 Reactor。Reactor 框架是 Pivotal 公司（开发 Spring 等技术的公司）开发的，实现了 Reactive Programming 思想，符合 Reactive Streams 规范（Reactive Streams 是由 Netflix、TypeSafe、Pivotal 等公司发起的）的一项技术。其名字有反应堆之意，反映了其背后的强大的性能。反应式编程介绍反应式编程来源于数据流和变化的传播，意味着由底层的执行模型负责通过数据流来自动传播变化。比如求值一个简单的表达式 c=a+b，当 a 或者 b 的值发生变化时，传统的编程范式需要对 a+b 进行重新计算来得到 c 的值。如果使用反应式编程，当 a 或者 b 的值发生变化时，c 的值会自动更新。反应式编程最早由 .NET 平台上的 Reactive Extensions (Rx) 库来实现。后来迁移到 Java 平台之后就产生了著名的 RxJava 库，并产生了很多其他编程语言上的对应实现。在这些实现的基础上产生了后来的反应式流（Reactive Streams）规范。该规范定义了反应式流的相关接口，并将集成到 Java 9 中。在传统的编程范式中，我们一般通过迭代器（Iterator）模式来遍历一个序列。这种遍历方式是由调用者来控制节奏的，采用的是拉的方式。每次由调用者通过 next()方法来获取序列中的下一个值。使用反应式流时采用的则是推的方式，即常见的发布者-订阅者模式。当发布者有新的数据产生时，这些数据会被推送到订阅者来进行处理。在反应式流上可以添加各种不同的操作来对数据进行处理，形成数据处理链。这个以声明式的方式添加的处理链只在订阅者进行订阅操作时才会真正执行。反应式流中第一个重要概念是负压（backpressure）。在基本的消息推送模式中，当消息发布者产生数据的速度过快时，会使得消息订阅者的处理速度无法跟上产生的速度，从而给订阅者造成很大的压力。当压力过大时，有可能造成订阅者本身的奔溃，所产生的级联效应甚至可能造成整个系统的瘫痪。负压的作用在于提供一种从订阅者到生产者的反馈渠道。订阅者可以通过 request()方法来声明其一次所能处理的消息数量，而生产者就只会产生相应数量的消息，直到下一次 request()方法调用。这实际上变成了推拉结合的模式。Reactor 简介前面提到的 RxJava 库是 JVM 上反应式编程的先驱，也是反应式流规范的基础。RxJava 2 在 RxJava 的基础上做了很多的更新。不过 RxJava 库也有其不足的地方。RxJava 产生于反应式流规范之前，虽然可以和反应式流的接口进行转换，但是由于底层实现的原因，使用起来并不是很直观。RxJava 2 在设计和实现时考虑到了与规范的整合，不过为了保持与 RxJava 的兼容性，很多地方在使用时也并不直观。Reactor 则是完全基于反应式流规范设计和实现的库，没有 RxJava 那样的历史包袱，在使用上更加的直观易懂。Reactor 也是 Spring 5 中反应式编程的基础。学习和掌握 Reactor 可以更好地理解 Spring 5 中的相关概念。在 Java 程序中使用 Reactor 库非常的简单，只需要通过 Maven 或 Gradle 来添加对 io.projectreactor:reactor-core 的依赖即可，目前的版本是 3.1.2.RELEASE：1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;io.projectreactor&lt;/groupId&gt; &lt;artifactId&gt;reactor-core&lt;/artifactId&gt; &lt;version&gt;3.1.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; Flux 和 MonoFlux 和 Mono 是 Reactor 中的两个基本概念。Flux 表示的是包含 0 到 N 个元素的异步序列。在该序列中可以包含三种不同类型的消息通知：正常的包含元素的消息、序列结束的消息和序列出错的消息。当消息通知产生时，订阅者中对应的方法 onNext(), onComplete()和 onError()会被调用。Mono 表示的是包含 0 或者 1 个元素的异步序列。该序列中同样可以包含与 Flux 相同的三种类型的消息通知。Flux 和 Mono 之间可以进行转换。对一个 Flux 序列进行计数操作，得到的结果是一个 Mono&lt;Long&gt;对象。把两个 Mono 序列合并在一起，得到的是一个 Flux 对象。 创建 Flux有多种不同的方式可以创建 Flux 序列。 Flux 类的静态方法第一种方式是通过 Flux 类中的静态方法。 just()：可以指定序列中包含的全部元素。创建出来的 Flux 序列在发布这些元素之后会自动结束。 fromArray()，fromIterable()和 fromStream()：可以从一个数组、Iterable 对象或 Stream 对象中创建 Flux 对象。 empty()：创建一个不包含任何元素，只发布结束消息的序列。 error(Throwable error)：创建一个只包含错误消息的序列。 never()：创建一个不包含任何消息通知的序列。 range(int start, int count)：创建包含从 start 起始的 count 个数量的 Integer 对象的序列。 interval(Duration period)和 interval(Duration delay, Duration period)：创建一个包含了从 0 开始递增的 Long 对象的序列。其中包含的元素按照指定的间隔来发布。除了间隔时间之外，还可以指定起始元素发布之前的延迟时间。 代码清单 1 中给出了上述这些方法的使用示例。 清单 1. 通过 Flux 类的静态方法创建 Flux 序列 12345678910111213141516public static void main(String[] args) throws InterruptedException &#123; generateSimpleFlux();&#125;private static void generateSimpleFlux() throws InterruptedException &#123; Flux.just(&quot;Hello&quot;, &quot;World&quot;).subscribe(System.out::println); Integer[] array = &#123;1, 2, 3&#125;; Flux.fromArray(array).subscribe(System.out::println); Flux.fromStream(Stream.of(array)).subscribe(System.out::println); Flux.fromIterable(Arrays.asList(array)).subscribe(System.out::println); Flux.empty().subscribe(System.out::println); Flux.range(1, 10).subscribe(System.out::println); Flux.interval(Duration.ofSeconds(1)).subscribe(System.out::println); // Flux.interval(Duration.of(1, ChronoUnit.SECONDS)).subscribe(System.out::println); TimeUnit.SECONDS.sleep(5);&#125; 上面的这些静态方法适合于简单的序列生成，当序列的生成需要复杂的逻辑时，则应该使用 generate() 或 create() 方法。 generate()方法generate()方法通过同步和逐一的方式来产生 Flux 序列。序列的产生是通过调用所提供的 SynchronousSink 对象的 next()，complete()和 error(Throwable)方法来完成的。逐一生成的含义是在具体的生成逻辑中，next()方法只能最多被调用一次。在有些情况下，序列的生成可能是有状态的，需要用到某些状态对象。此时可以使用 generate()方法的另外一种形式 generate(Callable&lt;S&gt; stateSupplier, BiFunction&lt;S,SynchronousSink&lt;T&gt;,S&gt; generator)，其中 stateSupplier 用来提供初始的状态对象。在进行序列生成时，状态对象会作为 generator 使用的第一个参数传入，可以在对应的逻辑中对该状态对象进行修改以供下一次生成时使用。 在代码清单 2中，第一个序列的生成逻辑中通过 next()方法产生一个简单的值，然后通过 complete()方法来结束该序列。如果不调用 complete()方法，所产生的是一个无限序列。第二个序列的生成逻辑中的状态对象是一个 ArrayList 对象。实际产生的值是一个随机数。产生的随机数被添加到 ArrayList 中。当产生了 10 个数时，通过 complete()方法来结束序列。 清单 2. 使用 generate()方法生成 Flux 序列 123456789101112131415161718private static void fluxGenerate() &#123; Flux.generate(sink -&gt; &#123; sink.next(&quot;Hello&quot;); sink.complete(); &#125;).subscribe(System.out::println); Random random = new Random(); Flux.generate(ArrayList::new, (list, sink) -&gt; &#123; int value = random.nextInt(100); list.add(value); sink.next(value); if (list.size() == 10) &#123; sink.complete(); &#125; return list; &#125;).subscribe(System.out::println); &#125; create()方法create()方法与 generate()方法的不同之处在于所使用的是 FluxSink 对象。FluxSink 支持同步和异步的消息产生，并且可以在一次调用中产生多个元素。在代码清单 3 中，在一次调用中就产生了全部的 10 个元素。 清单 3. 使用 create()方法生成 Flux 序列 123456Flux.create(sink -&gt; &#123; for (int i = 0; i &lt; 10; i++) &#123; sink.next(i); &#125; sink.complete();&#125;).subscribe(System.out::println); 创建 MonoMono 的创建方式与之前介绍的 Flux 比较相似。Mono 类中也包含了一些与 Flux 类中相同的静态方法。这些方法包括 just()，empty()，error()和 never()等。除了这些方法之外，Mono 还有一些独有的静态方法。 fromCallable()、fromCompletionStage()、fromFuture()、fromRunnable()和 fromSupplier()：分别从 Callable、CompletionStage、CompletableFuture、Runnable 和 Supplier 中创建 Mono。 delay(Duration duration)：创建一个 Mono 序列，在指定的延迟时间之后，产生数字 0 作为唯一值。 ignoreElements(Publisher&lt;T&gt; source)：创建一个 Mono 序列，忽略作为源的 Publisher 中的所有元素，只产生结束消息。 justOrEmpty(Optional&lt;? extends T&gt; data)和 justOrEmpty(T data)：从一个 Optional 对象或可能为 null 的对象中创建 Mono。只有 Optional 对象中包含值或对象不为 null 时，Mono 序列才产生对应的元素。 还可以通过 create()方法来使用 MonoSink 来创建 Mono。代码清单 4 中给出了创建 Mono 序列的示例。 清单 4. 创建 Mono 序列 12345678910private static final String HELLO = &quot;Hello&quot;;private static void buildMono() throws InterruptedException &#123; Mono.just(HELLO).subscribe(System.out::println); Mono.empty().subscribe(System.out::println); Mono.fromSupplier(() -&gt; HELLO).subscribe(System.out::println); Mono.justOrEmpty(Optional.of(HELLO)).subscribe(System.out::println); Mono.create(sink -&gt; sink.success(HELLO)).subscribe(System.out::println); Mono.delay(Duration.ofSeconds(1)).subscribe(System.out::println); TimeUnit.SECONDS.sleep(2); &#125; 操作符和 RxJava 一样，Reactor 的强大之处在于可以在反应式流上通过声明式的方式添加多种不同的操作符。下面对其中重要的操作符进行分类介绍。 buffer 和 bufferTimeout这两个操作符的作用是把当前流中的元素收集到集合中，并把集合对象作为流中的新元素。在进行收集时可以指定不同的条件：所包含的元素的最大数量或收集的时间间隔。方法 buffer()仅使用一个条件，而 bufferTimeout()可以同时指定两个条件。指定时间间隔时可以使用 Duration 对象或毫秒数。 除了元素数量和时间间隔之外，还可以通过 bufferUntil 和 bufferWhile 操作符来进行收集。这两个操作符的参数是表示每个集合中的元素所要满足的条件的 Predicate 对象。bufferUntil 会一直收集直到 Predicate 返回为 true。使得 Predicate 返回 true 的那个元素可以选择添加到当前集合或下一个集合中；bufferWhile 则只有当 Predicate 返回 true 时才会收集。一旦值为 false，会立即开始下一次收集。 代码清单 5 给出了 buffer 相关操作符的使用示例。第一行语句输出的是 5 个包含 20 个元素的数组；第二行语句输出的是 2 个包含了 10 个元素的数组；第三行语句输出的是 5 个包含 2 个元素的数组。每当遇到一个偶数就会结束当前的收集；第四行语句输出的是 5 个包含 1 个元素的数组，数组里面包含的只有偶数。 需要注意的是，在代码清单 5 中，首先通过 toStream()方法把 Flux 序列转换成 Java 8 中的 Stream 对象，再通过 forEach()方法来进行输出。这是因为序列的生成是异步的，而转换成 Stream 对象可以保证主线程在序列生成完成之前不会退出，从而可以正确地输出序列中的所有元素。 清单 5. buffer 相关操作符的使用示例 1234Flux.range(1, 100).buffer(20).subscribe(System.out::println);Flux.interval(Duration.ofMillis(100)).buffer(10).take(2).toStream().forEach(System.out::println);Flux.range(1, 10).bufferUntil(i -&gt; i % 2 == 0).subscribe(System.out::println);Flux.range(1, 10).bufferWhile(i -&gt; i % 2 == 0).subscribe(System.out::println); filter对流中包含的元素进行过滤，只留下满足 Predicate 指定条件的元素。代码清单 6 中的语句输出的是 1 到 10 中的所有偶数。 清单 6. filter 操作符使用示例 1Flux.range(1, 10).filter(i -&gt; i % 2 == 0).subscribe(System.out::println); windowwindow 操作符的作用类似于 buffer，所不同的是 window 操作符是把当前流中的元素收集到另外的 Flux 序列中，因此返回值类型是 Flux&lt;Flux&lt;T&gt;&gt;。在代码清单 7 中，两行语句的输出结果分别是 5 个和 2 个 UnicastProcessor 字符。这是因为 window 操作符所产生的流中包含的是 UnicastProcessor 类的对象，而 UnicastProcessor 类的 toString 方法输出的就是 UnicastProcessor 字符。 清单 7. window 操作符使用示例 12Flux.range(1, 100).window(20).subscribe(System.out::println);Flux.intervalMillis(100).windowMillis(1001).take(2).toStream().forEach(System.out::println); zipWithzipWith 操作符把当前流中的元素与另外一个流中的元素按照一对一的方式进行合并。在合并时可以不做任何处理，由此得到的是一个元素类型为 Tuple2 的流；也可以通过一个 BiFunction 函数对合并的元素进行处理，所得到的流的元素类型为该函数的返回值。 在代码清单 8 中，两个流中包含的元素分别是 a，b 和 c，d。第一个 zipWith 操作符没有使用合并函数，因此结果流中的元素类型为 Tuple2；第二个 zipWith 操作通过合并函数把元素类型变为 String。 清单 8. zipWith 操作符使用示例 123456Flux.just(&quot;a&quot;, &quot;b&quot;) .zipWith(Flux.just(&quot;c&quot;, &quot;d&quot;)) .subscribe(System.out::println);Flux.just(&quot;a&quot;, &quot;b&quot;) .zipWith(Flux.just(&quot;c&quot;, &quot;d&quot;), (s1, s2) -&gt; String.format(&quot;%s-%s&quot;, s1, s2)) .subscribe(System.out::println); taketake 系列操作符用来从当前流中提取元素。提取的方式可以有很多种。 take(long n)，take(Duration timespan)和 takeMillis(long timespan)：按照指定的数量或时间间隔来提取。 takeLast(long n)：提取流中的最后 N 个元素。 takeUntil(Predicate&lt;? super T&gt; predicate)：提取元素直到 Predicate 返回 true。 takeWhile(Predicate&lt;? super T&gt; continuePredicate)： 当 Predicate 返回 true 时才进行提取。 takeUntilOther(Publisher&lt;?&gt; other)：提取元素直到另外一个流开始产生元素。 在代码清单 9 中，第一行语句输出的是数字 1 到 10；第二行语句输出的是数字 991 到 1000；第三行语句输出的是数字 1 到 9；第四行语句输出的是数字 1 到 10，使得 Predicate 返回 true 的元素也是包含在内的。 清单 9. take 系列操作符使用示例 1234Flux.range(1, 1000).take(10).subscribe(System.out::println);Flux.range(1, 1000).takeLast(10).subscribe(System.out::println);Flux.range(1, 1000).takeWhile(i -&gt; i &lt; 10).subscribe(System.out::println);Flux.range(1, 1000).takeUntil(i -&gt; i == 10).subscribe(System.out::println); reduce 和 reduceWithreduce 和 reduceWith 操作符对流中包含的所有元素进行累积操作，得到一个包含计算结果的 Mono 序列。累积操作是通过一个 BiFunction 来表示的。在操作时可以指定一个初始值。如果没有初始值，则序列的第一个元素作为初始值。 在代码清单 10 中，第一行语句对流中的元素进行相加操作，结果为 5050；第二行语句同样也是进行相加操作，不过通过一个 Supplier 给出了初始值为 100，所以结果为 5150。 清单 10. reduce 和 reduceWith 操作符使用示例 12Flux.range(1, 100).reduce((x, y) -&gt; x + y).subscribe(System.out::println);Flux.range(1, 100).reduceWith(() -&gt; 100, (x, y) -&gt; x + y).subscribe(System.out::println); merge 和 mergeSequentialmerge 和 mergeSequential 操作符用来把多个流合并成一个 Flux 序列。不同之处在于 merge 按照所有流中元素的实际产生顺序来合并，而 mergeSequential 则按照所有流被订阅的顺序，以流为单位进行合并。 代码清单 11 中分别使用了 merge 和 mergeSequential 操作符。进行合并的流都是每隔 100 毫秒产生一个元素，不过第二个流中的每个元素的产生都比第一个流要延迟 50 毫秒。在使用 merge 的结果流中，来自两个流的元素是按照时间顺序交织在一起；而使用 mergeSequential 的结果流则是首先产生第一个流中的全部元素，再产生第二个流中的全部元素。 清单 11. merge 和 mergeSequential 操作符使用示例 123456Flux.merge(Flux.interval(Duration.ofMillis(100)).take(5), Flux.interval(Duration.ofMillis(50), Duration.ofMillis(100)).take(5)).subscribe(System.out::println);TimeUnit.SECONDS.sleep(2);System.out.println();Flux.mergeSequential(Flux.interval(Duration.ofMillis(100)).take(5), Flux.interval(Duration.ofMillis(50), Duration.ofMillis(100)).take(5)) .toStream() .forEach(System.out::println); flatMap 和 flatMapSequentialflatMap 和 flatMapSequential 操作符把流中的每个元素转换成一个流，再把所有流中的元素进行合并。flatMapSequential 和 flatMap 之间的区别与 mergeSequential 和 merge 之间的区别是一样的。 在代码清单 12 中，流中的元素被转换成每隔 100 毫秒产生的数量不同的流，再进行合并。由于第一个流中包含的元素数量较少，所以在结果流中一开始是两个流的元素交织在一起，然后就只有第二个流中的元素。 清单 12. flatMap 操作符使用示例 1234Flux.just(5, 10) .flatMap(x -&gt; Flux.intervalMillis(x * 10, 100).take(x)) .toStream() .forEach(System.out::println); concatMapconcatMap 操作符的作用也是把流中的每个元素转换成一个流，再把所有流进行合并。与 flatMap 不同的是，concatMap 会根据原始流中的元素顺序依次把转换之后的流进行合并；与 flatMapSequential 不同的是，concatMap 对转换之后的流的订阅是动态进行的，而 flatMapSequential 在合并之前就已经订阅了所有的流。 代码清单 13 与代码清单 12 类似，只不过把 flatMap 换成了 concatMap，结果流中依次包含了第一个流和第二个流中的全部元素。 清单 13. concatMap 操作符使用示例 1234Flux.just(5, 10) .concatMap(x -&gt; Flux.intervalMillis(x * 10, 100).take(x)) .toStream() .forEach(System.out::println); combineLatestcombineLatest 操作符把所有流中的最新产生的元素合并成一个新的元素，作为返回结果流中的元素。只要其中任何一个流中产生了新的元素，合并操作就会被执行一次，结果流中就会产生新的元素。在 代码清单 14 中，流中最新产生的元素会被收集到一个数组中，通过 Arrays.toString 方法来把数组转换成 String。 清单 14. combineLatest 操作符使用示例 12345Flux.combineLatest( Arrays::toString, Flux.intervalMillis(100).take(5), Flux.intervalMillis(50, 100).take(5)).toStream().forEach(System.out::println); 消息处理当需要处理 Flux 或 Mono 中的消息时，如之前的代码清单所示，可以通过 subscribe 方法来添加相应的订阅逻辑。在调用 subscribe 方法时可以指定需要处理的消息类型。可以只处理其中包含的正常消息，也可以同时处理错误消息和完成消息。代码清单 15 中通过 subscribe()方法同时处理了正常消息和错误消息。 清单 15. 通过 subscribe()方法处理正常和错误消息 123Flux.just(1, 2) .concatWith(Mono.error(new IllegalStateException())) .subscribe(System.out::println, System.err::println); 正常的消息处理相对简单。当出现错误时，有多种不同的处理策略。第一种策略是通过 onErrorReturn()方法返回一个默认值。在代码清单 16 中，当出现错误时，流会产生默认值 0. 清单 16. 出现错误时返回默认值 1234Flux.just(1, 2) .concatWith(Mono.error(new IllegalStateException())) .onErrorReturn(0) .subscribe(System.out::println); 第二种策略是通过 onErrorResume()方法来根据不同的异常类型来选择要使用的产生元素的流。在代码清单 18 中，根据异常类型来返回不同的流作为出现错误时的数据来源。因为异常的类型为 IllegalArgumentException，所产生的元素为-1。 清单 18. 出现错误时根据异常类型来选择流 1234567891011Flux.just(1, 2) .concatWith(Mono.error(new IllegalArgumentException())) .onErrorResume(e -&gt; &#123; if (e instanceof IllegalStateException) &#123; return Mono.just(0); &#125; else if (e instanceof IllegalArgumentException) &#123; return Mono.just(-1); &#125; return Mono.empty(); &#125;) .subscribe(System.out::println); 当出现错误时，还可以通过 retry 操作符来进行重试。重试的动作是通过重新订阅序列来实现的。在使用 retry 操作符时可以指定重试的次数。代码清单 19 中指定了重试次数为 1，所输出的结果是 1，2，1，2 和错误信息。 清单 19. 使用 retry 操作符进行重试 1234Flux.just(1, 2) .concatWith(Mono.error(new IllegalStateException())) .retry(1) .subscribe(System.out::println); 调度器前面介绍了反应式流和在其上可以进行的各种操作，通过调度器（Scheduler）可以指定这些操作执行的方式和所在的线程。有下面几种不同的调度器实现。 当前线程，通过 Schedulers.immediate()方法来创建。 单一的可复用的线程，通过 Schedulers.single()方法来创建。 使用弹性的线程池，通过 Schedulers.elastic()方法来创建。线程池中的线程是可以复用的。当所需要时，新的线程会被创建。如果一个线程闲置太长时间，则会被销毁。该调度器适用于 I/O 操作相关的流的处理。 使用对并行操作优化的线程池，通过 Schedulers.parallel()方法来创建。其中的线程数量取决于 CPU 的核的数量。该调度器适用于计算密集型的流的处理。 使用支持任务调度的调度器，通过 Schedulers.timer()方法来创建。 从已有的 ExecutorService 对象中创建调度器，通过 Schedulers.fromExecutorService()方法来创建。 某些操作符默认就已经使用了特定类型的调度器。比如 interval()方法创建的流就使用了由 Schedulers.parallel()创建的调度器。通过 publishOn()和 subscribeOn()方法可以切换执行操作的调度器。其中 publishOn()方法切换的是操作符的执行方式，而 subscribeOn()方法切换的是产生流中元素时的执行方式。 在代码清单 20 中，使用 create()方法创建一个新的 Flux 对象，其中包含唯一的元素是当前线程的名称。接着是两对 publishOn()和 map()方法，其作用是先切换执行时的调度器，再把当前的线程名称作为前缀添加。最后通过 subscribeOn()方法来改变流产生时的执行方式。运行之后的结果是[elastic-2][single-1] parallel-1。最内层的线程名字 parallel-1 来自产生流中元素时使用的 Schedulers.parallel()调度器，中间的线程名称 single-1 来自第一个 map 操作之前的 Schedulers.single()调度器，最外层的线程名字 elastic-2 来自第二个 map 操作之前的 Schedulers.elastic()调度器。 清单 20. 使用调度器切换操作符执行方式 1234567891011Flux.create(sink -&gt; &#123; sink.next(Thread.currentThread().getName()); sink.complete();&#125;).publishOn(Schedulers.single()).map(x -&gt; String.format(&quot;[%s] %s&quot;, Thread.currentThread().getName(), x)).publishOn(Schedulers.elastic()).map(x -&gt; String.format(&quot;[%s] %s&quot;, Thread.currentThread().getName(), x)).subscribeOn(Schedulers.parallel()).toStream().forEach(System.out::println); 测试在对使用 Reactor 的代码进行测试时，需要用到 io.projectreactor.addons:reactor-test 库。 使用 StepVerifier进行测试时的一个典型的场景是对于一个序列，验证其中所包含的元素是否符合预期。StepVerifier 的作用是可以对序列中包含的元素进行逐一验证。在代码清单 21 中，需要验证的流中包含 a 和 b 两个元素。通过 StepVerifier.create()方法对一个流进行包装之后再进行验证。expectNext()方法用来声明测试时所期待的流中的下一个元素的值，而 verifyComplete()方法则验证流是否正常结束。类似的方法还有 verifyError()来验证流由于错误而终止。 清单 21. 使用 StepVerifier 验证流中的元素 1234StepVerifier.create(Flux.just(&quot;a&quot;, &quot;b&quot;)) .expectNext(&quot;a&quot;) .expectNext(&quot;b&quot;) .verifyComplete(); 操作测试时间有些序列的生成是有时间要求的，比如每隔 1 分钟才产生一个新的元素。在进行测试中，不可能花费实际的时间来等待每个元素的生成。此时需要用到 StepVerifier 提供的虚拟时间功能。通过 StepVerifier.withVirtualTime()方法可以创建出使用虚拟时钟的 StepVerifier。通过 thenAwait(Duration)方法可以让虚拟时钟前进。 在代码清单 22 中，需要验证的流中包含两个产生间隔为一天的元素，并且第一个元素的产生延迟是 4 个小时。在通过 StepVerifier.withVirtualTime()方法包装流之后，expectNoEvent()方法用来验证在 4 个小时之内没有任何消息产生，然后验证第一个元素 0 产生；接着 thenAwait()方法来让虚拟时钟前进一天，然后验证第二个元素 1 产生；最后验证流正常结束。 清单 22. 操作测试时间 1234567StepVerifier.withVirtualTime(() -&gt; Flux.interval(Duration.ofHours(4), Duration.ofDays(1)).take(2)) .expectSubscription() .expectNoEvent(Duration.ofHours(4)) .expectNext(0L) .thenAwait(Duration.ofDays(1)) .expectNext(1L) .verifyComplete(); 使用 TestPublisherTestPublisher 的作用在于可以控制流中元素的产生，甚至是违反反应流规范的情况。在代码清单 23 中，通过 create()方法创建一个新的 TestPublisher 对象，然后使用 next()方法来产生元素，使用 complete()方法来结束流。TestPublisher 主要用来测试开发人员自己创建的操作符。 清单 23. 使用 TestPublisher 创建测试所用的流 123456789final TestPublisher&lt;String&gt; testPublisher = TestPublisher.create();testPublisher.next(&quot;a&quot;);testPublisher.next(&quot;b&quot;);testPublisher.complete(); StepVerifier.create(testPublisher) .expectNext(&quot;a&quot;) .expectNext(&quot;b&quot;) .expectComplete(); 启用调试模式当需要获取更多与流相关的执行信息时，可以在程序开始的地方添加代码清单 24 中的代码来启用调试模式。在调试模式启用之后，所有的操作符在执行时都会保存额外的与执行链相关的信息。当出现错误时，这些信息会被作为异常堆栈信息的一部分输出。通过这些信息可以分析出具体是在哪个操作符的执行中出现了问题。 清单 24. 启用调试模式 1Hooks.onOperatorDebug(); 不过当调试模式启用之后，记录这些额外的信息是有代价的。一般只有在出现了错误之后，再考虑启用调试模式。但是当为了找到问题而启用了调试模式之后，之前的错误不一定能很容易重现出来。为了减少可能的开销，可以限制只对特定类型的操作符启用调试模式。 使用检查点另外一种做法是通过 checkpoint 操作符来对特定的流处理链来启用调试模式。代码清单 25 中，在 map 操作符之后添加了一个名为 test 的检查点。当出现错误时，检查点名称会出现在异常堆栈信息中。对于程序中重要或者复杂的流处理链，可以在关键的位置上启用检查点来帮助定位可能存在的问题。 清单 25. 使用 checkpoint 操作符 1Flux.just(1, 0).map(x -&gt; 1 / x).checkpoint(&quot;test&quot;).subscribe(System.out::println); 日志记录在开发和调试中的另外一项实用功能是把流相关的事件记录在日志中。这可以通过添加 log 操作符来实现。在代码清单 26 中，添加了 log 操作符并指定了日志分类的名称。 清单 26. 使用 log 操作符记录事件 1Flux.range(1, 2).log(&quot;YBD&quot;).subscribe(System.out::println); 在实际的运行时，所产生的输出如代码清单 27 所示。 清单 27. log 操作符所产生的日志 1234567816:18:06.381 [main] DEBUG reactor.util.Loggers$LoggerFactory - Using Slf4j logging framework16:18:06.391 [main] INFO YBD - | onSubscribe([Synchronous Fuseable] FluxRange.RangeSubscription)16:18:06.393 [main] INFO YBD - | request(unbounded)16:18:06.393 [main] INFO YBD - | onNext(1)116:18:06.394 [main] INFO YBD - | onNext(2)216:18:06.394 [main] INFO YBD - | onComplete() “冷”与“热”序列之前的代码清单中所创建的都是冷序列。冷序列的含义是不论订阅者在何时订阅该序列，总是能收到序列中产生的全部消息。而与之对应的热序列，则是在持续不断地产生消息，订阅者只能获取到在其订阅之后产生的消息。 在代码清单 28 中，原始的序列中包含 10 个间隔为 1 秒的元素。通过 publish()方法把一个 Flux 对象转换成 ConnectableFlux 对象。方法 autoConnect()的作用是当 ConnectableFlux 对象有一个订阅者时就开始产生消息。代码 source.subscribe()的作用是订阅该 ConnectableFlux 对象，让其开始产生数据。接着当前线程睡眠 5 秒钟，第二个订阅者此时只能获得到该序列中的后 5 个元素，因此所输出的是数字 5 到 9。 清单 28. 热序列 12345678final Flux&lt;Long&gt; source = Flux.interval(Duration.ofSeconds(1)) .take(10) .publish() .autoConnect();source.subscribe();Thread.sleep(5000);source.toStream() .forEach(System.out::println); End反应式编程范式对于习惯了传统编程范式的开发人员来说，既是一个需要进行思维方式转变的挑战，也是一个充满了更多可能的机会。Reactor 作为一个基于反应式流规范的新的 Java 库，可以作为反应式应用的基础。本文对 Reactor 库做了详细的介绍，包括 Flux 和 Mono 序列的创建、常用操作符的使用、调度器、错误处理以及测试和调试技巧等。 参考：https://www.ibm.com/developerworks/cn/java/j-cn-with-reactor-response-encode/index.html Demo：https://github.com/masteranthoneyd/reactor-simple-demo]]></content>
      <categories>
        <category>Programming</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Reactor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring5新特征与WebFlux反应式编程]]></title>
    <url>%2F2017%2Fnew-in-spring-framework-5%2F</url>
    <content type="text"><![CDATA[PrefaceSpring 5 于 2017 年 9 月发布了通用版本 (GA)，它标志着自 2013 年 12 月以来第一个主要 Spring Framework 版本。它提供了一些人们期待已久的改进，还采用了一种全新的编程范例，以反应式宣言中陈述的反应式原则为基础。这个版本是很长时间以来最令人兴奋的 Spring Framework 版本。Spring 5 兼容 Java™8 和 JDK 9，它集成了反应式流，以便提供一种颠覆性方法来实现端点和 Web 应用程序开发。诚然，反应式编程不仅是此版本的主题，还是令许多开发人员激动不已的重大特性。人们对能够针对负载波动进行无缝扩展的灾备和响应式服务的需求在不断增加，Spring 5 很好地满足了这一需求。本文将全面介绍 Spring 5。我将介绍 Java SE 8 和 Java EE 7 API 的基准升级、Spring 5 的新反应式编程模型、HTTP/2 支持，以及 Spring 通过 Kotlin 对函数式编程的全面支持。我还会简要介绍测试和性能增强，最后介绍对 Spring 核心和容器的一般性修订。Spring Framework 5 中的新特性升级到 Java SE 8 和 Java EE 7直到现在，Spring Framework 仍支持一些弃用的 Java 版本，但 Spring 5 已从旧包袱中解放出来。为了充分利用 Java 8 特性，它的代码库已进行了改进，而且该框架要求将 Java 8 作为最低的 JDK 版本。Spring 5 在类路径（和模块路径）上完全兼容 Java 9，而且它通过了 JDK 9 测试套件的测试。对 Java 9 爱好者而言，这是一条好消息，因为在 Java 9 发布后，Spring 能立即使用它。在 API 级别上，Spring 5 兼容 Java EE 8 技术，满足对 Servlet 4.0、Bean Validation 2.0 和全新的 JSON Binding API 的需求。对 Java EE API 的最低要求为 V7，该版本引入了针对 Servlet、JPA 和 Bean Validation API 的次要版本。反应式编程模型Spring 5 最令人兴奋的新特性是它的反应式编程模型。Spring 5 Framework 基于一种反应式基础而构建，而且是完全异步和非阻塞的。只需少量的线程，新的事件循环执行模型就可以垂直扩展。该框架采用反应式流来提供在反应式组件中传播负压的机制。负压是一个确保来自多个生产者的数据不会让使用者不堪重负的概念。Spring WebFlux 是 Spring 5 的反应式核心，它为开发人员提供了两种为 Spring Web 编程而设计的编程模型：一种基于注解的模型和 Functional Web Framework (WebFlux.fn)。基于注解的模型是 Spring WebMVC 的现代替代方案，该模型基于反应式基础而构建，而 Functional Web Framework 是基于@Controller 注解的编程模型的替代方案。这些模型都通过同一种反应式基础来运行，后者调整非阻塞 HTTP 来适应反应式流 API。使用注解进行编程WebMVC 程序员应该对 Spring 5 的基于注解的编程模型非常熟悉。Spring 5 调整了 WebMVC 的 @Controller 编程模型，采用了相同的注解。在清单 1 中，BookController 类提供了两个方法，分别响应针对某个图书列表的 HTTP 请求，以及针对具有给定 id 的图书的 HTTP 请求。请注意 resource 方法返回的对象（Mono 和 Flux）。这些对象是实现反应式流规范中的 Publisher 接口的反应式类型。它们的职责是处理数据流。Mono 对象处理一个仅含 1 个元素的流，而 Flux 表示一个包含 N 个元素的流。清单 1. 反应式控制器123456789101112131415@RestControllerpublic class BookController &#123; @GetMapping(&quot;/book&quot;) Flux&lt;Book&gt; list() &#123; return this.repository.findAll(); &#125; @GetMapping(&quot;/book/&#123;id&#125;&quot;) Mono&lt;Book&gt; findById(@PathVariable String id) &#123; return this.repository.findOne(id); &#125; // Plumbing code omitted for brevity&#125; 这是针对 Spring Web 编程的注解。现在我们使用函数式 Web 框架来解决同一个问题。 函数式编程Spring 5 的新函数式方法将请求委托给处理函数，这些函数接受一个服务器请求实例并返回一种反应式类型。清单 2 演示了这一过程，其中 listBook 和 getBook 方法类似于清单 1 中的功能。 清单 2. 清单 2.BookHandler 函数类1234567891011121314151617public class BookHandler &#123; public Mono&lt;ServerResponse&gt; listBooks(ServerRequest request) &#123; return ServerResponse.ok() .contentType(APPLICATION_JSON) .body(repository.allPeople(), Book.class); &#125; public Mono&lt;ServerResponse&gt; getBook(ServerRequest request) &#123; return repository.getBook(request.pathVariable(&quot;id&quot;)) .then(book -&gt; ServerResponse.ok() .contentType(APPLICATION_JSON) .body(fromObject(book))) .otherwiseIfEmpty(ServerResponse.notFound().build()); &#125; // Plumbing code omitted for brevity&#125; 通过路由函数来匹配 HTTP 请求谓词与媒体类型，将客户端请求路由到处理函数。清单 3 展示了图书资源端点 URI 将调用委托给合适的处理函数： 清单 3. Router 函数123456789BookHandler handler = new BookHandler(); RouterFunction&lt;ServerResponse&gt; personRoute = route( GET(&quot;/books/&#123;id&#125;&quot;) .and(accept(APPLICATION_JSON)), handler::getBook) .andRoute( GET(&quot;/books&quot;) .and(accept(APPLICATION_JSON)), handler::listBooks); 这些示例背后的数据存储库也支持完整的反应式体验，该体验是通过 Spring Data 对反应式 Couchbase、Reactive MongoDB 和 Cassandra 的支持来实现的。 使用 REST 端点执行反应式编程新的编程模型脱离了传统的 Spring WebMVC 模型，引入了一些很不错的新特性。 举例来说，WebFlux 模块为 RestTemplate 提供了一种完全非阻塞、反应式的替代方案，名为 WebClient。清单 4 创建了一个 WebClient，并调用 books 端点来请求一本给定 id 为 1234 的图书。 清单 4. 通过 WebClient 调用 REST 端点123456Mono&lt;Book&gt; book = WebClient.create(&quot;http://localhost:8080&quot;) .get() .url(&quot;/books/&#123;id&#125;&quot;, 1234) .accept(APPLICATION_JSON) .exchange(request) .then(response -&gt; response.bodyToMono(Book.class)); HTTP/2 支持HTTP/2 幕后原理：要了解 HTTP/2 如何提高传输性能，减少延迟，并帮助提高应用程序吞吐量，从而提供经过改进的丰富 Web 体验，请查阅https://www.ibm.com/developerworks/cn/web/wa-http2-under-the-hood/index.html。 Spring Framework 5.0 将提供专门的 HTTP/2 特性 支持，还支持人们期望出现在 JDK 9 中的新 HTTP 客户端。尽管 HTTP/2 的服务器推送功能已通过 Jetty servlet 引擎的 ServerPushFilter 类向 Spring 开发人员公开了很长一段时间，但如果发现 Spring 5 中开箱即用地提供了 HTTP/2 性能增强，Web 优化者们一定会为此欢呼雀跃。 Java EE Servlet 规范预计将于 2017 年第 4 季度发布，Servlet 4.0 支持将在 Spring 5.1 中提供。到那时，HTTP/2 特性 将由 Tomcat 9.0、Jetty 9.3 和 Undertow 1.4 原生提供。 Kotlin 和 Spring WebFlux Kotlin 是一种来自 JetBrains 的面向对象的语言，它支持函数式编程。它的主要优势之一是与 Java 有非常高的互操作性。通过引入对 Kotlin 的专门支持，Spring 在 V5 中全面吸纳了这一优势。它的函数式编程风格与 Spring WebFlux 模块完美匹配，它的新路由 DSL 利用了函数式 Web 框架以及干净且符合语言习惯的代码。可以像清单 5 中这样简单地表达端点路由： 清单 5. Kotlin 的用于定义端点的路由 DSL 12345678910111213@Beanfun apiRouter() = router &#123; (accept(APPLICATION_JSON) and &quot;/api&quot;).nest &#123; &quot;/book&quot;.nest &#123; GET(&quot;/&quot;, bookHandler::findAll) GET(&quot;/&#123;id&#125;&quot;, bookHandler::findOne) &#125; &quot;/video&quot;.nest &#123; GET(&quot;/&quot;, videoHandler::findAll) GET(&quot;/&#123;genre&#125;&quot;, videoHandler::findByGenre) &#125; &#125;&#125; 使用 Kotlin 1.1.4+ 时，还添加了对 Kotlin 的不可变类的支持（通过带默认值的可选参数），以及对完全支持 null 的 API 的支持。 使用 Lambda 表达式注册 bean作为传统 XML 和 JavaConfig 的替代方案，现在可以使用 lambda 表达式注册 Spring bean，使 bean 可以实际注册为提供者。清单 6 使用 lambda 表达式注册了一个 Book bean。 清单 6. 将 Bean 注册为提供者1234GenericApplicationContext context = new GenericApplicationContext();context.registerBean(Book.class, () -&gt; new Book(context.getBean(Author.class)) ); Spring WebMVC 支持最新的 API全新的 WebFlux 模块提供了许多新的、令人兴奋的功能，但 Spring 5 也迎合了愿意继续使用 Spring MVC 的开发人员的需求。Spring 5 中更新了模型-视图-控制器框架，以兼容 WebFlux 和最新版的 Jackson 2.9 和 Protobuf 3.0，甚至包括对新的 Java EE 8 JSON-Binding API 的支持。 除了 HTTP/2 特性 的基础服务器实现之外，Spring WebMVC 还通过 MVC 控制器方法的一个参数来支持 Servlet 4.0 的 PushBuilder。最后，WebMVC 全面支持 Reactor 3.1 的 Flux 和 Mono 对象，以及 RxJava 1.3 和 2.1，它们被视为来自 MVC 控制器方法的返回值。这项支持的最终目的是支持 Spring Data 中的新的反应式 WebClient 和反应式存储库。 使用 JUnit 5 执行条件和并发测试JUnit 和 Spring 5：Spring 5 全面接纳了函数式范例，并支持 JUnit 5 及其新的函数式测试风格。还提供了对 JUnit 4 的向后兼容性，以确保不会破坏旧代码。 Spring 5 的测试套件通过多种方式得到了增强，但最明显的是它对 JUnit 5 的支持。现在可以在您的单元测试中利用 Java 8 中提供的函数式编程特性。清单 7 演示了这一支持： 清单 7.JUnit 5 全面接纳了 Java 8 流和 lambda 表达式1234567@Testvoid givenStreamOfInts_SumShouldBeMoreThanFive() &#123; assertTrue(Stream.of(20, 40, 50) .stream() .mapToInt(i -&gt; i) .sum() &gt; 110, () -&gt; &quot;Total should be more than 100&quot;);&#125; 迁移到 JUnit 5：如果您对升级到 JUnit 5 持观望态度，Steve Perry 的分两部分的深入剖析教程 将说服您冒险尝试。 Spring 5 继承了 JUnit 5 在 Spring TestContext Framework 内实现多个扩展 API 的灵活性。举例而言，开发人员可以使用 JUnit 5 的条件测试执行注解 @EnabledIf 和 @DisabledIf 来自动计算一个 SpEL (Spring Expression Language) 表达式，并适当地启用或禁用测试。借助这些注解，Spring 5 支持以前很难实现的复杂的条件测试方案。Spring TextContext Framework 现在能够并发执行测试。 使用 Spring WebFlux 执行集成测试Spring Test 现在包含一个 WebTestClient，后者支持对 Spring WebFlux 服务器端点执行集成测试。WebTestClient 使用模拟请求和响应来避免耗尽服务器资源，并能直接绑定到 WebFlux 服务器基础架构。 WebTestClient 可绑定到真实的服务器，或者使用控制器或函数。在清单 8 中，WebTestClient 被绑定到 localhost： 清单 8. 绑定到 localhost 的 WebTestClient 1234WebTestClient testClient = WebTestClient .bindToServer() .baseUrl(&quot;http://localhost:8080&quot;) .build(); 清单 9. 将 WebTestClient 绑定到 RouterFunction 1234567891011RouterFunction bookRouter = RouterFunctions.route( RequestPredicates.GET(&quot;/books&quot;), request -&gt; ServerResponse.ok().build()); WebTestClient .bindToRouterFunction(bookRouter) .build().get().uri(&quot;/books&quot;) .exchange() .expectStatus().isOk() .expectBody().isEmpty(); 包清理和弃用Spring 5 中止了对一些过时 API 的支持。遭此厄运的还有 Hibernate 3 和 4，为了支持 Hibernate 5，它们遭到了弃用。另外，对 Portlet、Velocity、JasperReports、XMLBeans、JDO 和 Guava 的支持也已中止。 包级别上的清理工作仍在继续：Spring 5 不再支持 beans.factory.access、jdbc.support.nativejdbc、mock.staticmock（来自 spring-aspects 模块）或 web.view.tiles2M。Tiles 3 现在是 Spring 的最低要求。 对 Spring 核心和容器的一般更新Spring Framework 5 改进了扫描和识别组件的方法，使大型项目的性能得到提升。目前，扫描是在编译时执行的，而且向 META-INF/spring.components 文件中的索引文件添加了组件坐标。该索引是通过一个为项目定义的特定于平台的应用程序构建任务来生成的。 标有来自 javax 包 的注解的组件会添加到索引中，任何带 @Index 注解的类或接口都会添加到索引中。Spring 的传统类路径扫描方式没有删除，而是保留为一种后备选择。有许多针对大型代码库的明显性能优势，而托管许多 Spring 项目的服务器也会缩短启动时间。 Spring 5 还添加了对 @Nullable 的支持，后者可用于指示可选的注入点。使用者现在必须准备接受 null 值。此外，还可以使用此注解来标记可以为 null 的参数、字段和返回值。@Nullable 主要用于 IntelliJ IDEA 等 IDE，但也可用于 Eclipse 和 FindBugs，它使得在编译时处理 null 值变得更方便，而无需在运行时发送 NullPointerExceptions。 Spring Logging 还提升了性能，自带开箱即用的 Commons Logging 桥接器。现在已通过资源抽象支持防御性编程，为 getFile访问提供了 isFile 指示器。 小结Spring 5 的首要特性是新的反应式编程模型，这代表着对提供可无缝扩展、基于 Spring 的响应式服务的重大保障。随着人们对 Spring 5 的采用，开发人员有望看到反应式编程将会成为使用 Java 语言的 Web 和企业应用程序开发的未来发展道路。 未来的 Spring Framework 版本将继续反映这一承诺，因为 Spring Security、Spring Data 和 Spring Integration 有望采用反应式编程的特征和优势。 总之，Spring 5 代表着一次大受 Spring 开发人员欢迎的范例转变，同时也为其他框架指出了一条发展之路。 使用 Spring 5 的 WebFlux 开发反应式 Web 应用 WebFlux 简介WebFlux 模块的名称是 spring-webflux，名称中的 Flux 来源于 Reactor 中的类 Flux。该模块中包含了对反应式 HTTP、服务器推送事件和 WebSocket 的客户端和服务器端的支持。对于开发人员来说，比较重要的是服务器端的开发，这也是本文的重点。在服务器端，WebFlux 支持两种不同的编程模型：第一种是 Spring MVC 中使用的基于 Java 注解的方式；第二种是基于 Java 8 的 lambda 表达式的函数式编程模型。这两种编程模型只是在代码编写方式上存在不同。它们运行在同样的反应式底层架构之上，因此在运行时是相同的。WebFlux 需要底层提供运行时的支持，WebFlux 可以运行在支持 Servlet 3.1 非阻塞 IO API 的 Servlet 容器上，或是其他异步运行时环境，如 Netty 和 Undertow。 最方便的创建 WebFlux 应用的方式是使用 Spring Boot 提供的应用模板。直接访问 Spring Initializ 网站（http://start.spring.io/ ），选择创建一个 Maven 或 Gradle 项目。Spring Boot 的版本选择 2.0.0 M2（或更高）。在添加的依赖中，选择 Reactive Web。最后输入应用所在的分组和名称，点击进行下载即可。需要注意的是，只有在选择了 Spring Boot 2.0.0 M2 之后，依赖中才可以选择 Reactive Web。下载完成之后可以导入到 IDE 中进行编辑。 本文从三个方面对 WebFlux 进行介绍。首先是使用经典的基于 Java 注解的编程模型来进行开发，其次是使用 WebFlux 新增的函数式编程模型来进行开发，最后介绍 WebFlux 应用的测试。通过这样循序渐进的方式让读者了解 WebFlux 应用开发的细节。 Java 注解编程模型基于 Java 注解的编程模型，对于使用过 Spring MVC 的开发人员来说是再熟悉不过的。在 WebFlux 应用中使用同样的模式，容易理解和上手。我们先从最经典的 Hello World 的示例开始说明。代码清单 1 中的 BasicController 是 REST API 的控制器，通过@RestController 注解来声明。在 BasicController 中声明了一个 URI 为/hello_world 的映射。其对应的方法 sayHelloWorld()的返回值是 Mono&lt;String&gt;类型，其中包含的字符串&quot;Hello World&quot;会作为 HTTP 的响应内容。 清单 1. Hello World 示例1234567@RestControllerpublic class BasicController &#123; @GetMapping(&quot;/hello_world&quot;) public Mono&lt;String&gt; sayHelloWorld() &#123; return Mono.just(&quot;Hello World&quot;); &#125;&#125; 从代码清单 1 中可以看到，使用 WebFlux 与 Spring MVC 的不同在于，WebFlux 所使用的类型是与反应式编程相关的 Flux 和 Mono 等，而不是简单的对象。对于简单的 Hello World 示例来说，这两者之间并没有什么太大的差别。对于复杂的应用来说，反应式编程和负压的优势会体现出来，可以带来整体的性能的提升。 REST API简单的 Hello World 示例并不足以说明 WebFlux 的用法。在下面的小节中，本文将介绍其他具体的实例。先从 REST API 开始说起。REST API 在 Web 服务器端应用中占据了很大的一部分。我们通过一个具体的实例来说明如何使用 WebFlux 来开发 REST API。 该 REST API 用来对用户数据进行基本的 CRUD 操作。作为领域对象的 User 类中包含了 id、name 和 email 等三个基本的属性。为了对 User 类进行操作，我们需要提供服务类 UserService，如代码清单 2 所示。类 UserService 使用一个 Map 来保存所有用户的信息，并不是一个持久化的实现。这对于示例应用来说已经足够了。类 UserService 中的方法都以 Flux 或 Mono 对象作为返回值，这也是 WebFlux 应用的特征。在方法 getById()中，如果找不到 ID 对应的 User 对象，会返回一个包含了 ResourceNotFoundException 异常通知的 Mono 对象。方法 getById()和 createOrUpdate()都可以接受 String 或 Flux 类型的参数。Flux 类型的参数表示的是有多个对象需要处理。这里使用 doOnNext()来对其中的每个对象进行处理。 清单 2. UserService 123456789101112131415161718192021222324252627282930@Serviceclass UserService &#123; private final Map&lt;String, User&gt; data = new ConcurrentHashMap&lt;&gt;(); Flux&lt;User&gt; list() &#123; return Flux.fromIterable(this.data.values()); &#125; Flux&lt;User&gt; getById(final Flux&lt;String&gt; ids) &#123; return ids.flatMap(id -&gt; Mono.justOrEmpty(this.data.get(id))); &#125; Mono&lt;User&gt; getById(final String id) &#123; return Mono.justOrEmpty(this.data.get(id)) .switchIfEmpty(Mono.error(new ResourceNotFoundException())); &#125; Flux&lt;User&gt; createOrUpdate(final Flux&lt;User&gt; users) &#123; return users.doOnNext(user -&gt; this.data.put(user.getId(), user)); &#125; Mono&lt;User&gt; createOrUpdate(final User user) &#123; this.data.put(user.getId(), user); return Mono.just(user); &#125; Mono&lt;User&gt; delete(final String id) &#123; return Mono.justOrEmpty(this.data.remove(id)); &#125;&#125; 代码清单 3 中的类 UserController 是具体的 Spring MVC 控制器类。它使用类 UserService 来完成具体的功能。类 UserController 中使用了注解@ExceptionHandler 来添加了 ResourceNotFoundException 异常的处理方法，并返回 404 错误。类 UserController 中的方法都很简单，只是简单地代理给 UserService 中的对应方法。 清单 3. UserController 123456789101112131415161718192021222324252627282930313233343536373839404142@RestController@RequestMapping(&quot;/user&quot;)public class UserController &#123; private final UserService userService; @Autowired public UserController(final UserService userService) &#123; this.userService = userService; &#125; @ResponseStatus(value = HttpStatus.NOT_FOUND, reason = &quot;Resource not found&quot;) @ExceptionHandler(ResourceNotFoundException.class) public void notFound() &#123; &#125; @GetMapping(&quot;&quot;) public Flux&lt;User&gt; list() &#123; return this.userService.list(); &#125; @GetMapping(&quot;/&#123;id&#125;&quot;) public Mono&lt;User&gt;getById(@PathVariable(&quot;id&quot;) final String id) &#123; return this.userService.getById(id); &#125; @PostMapping(&quot;&quot;) public Flux&lt;User&gt; create(@RequestBody final Flux&lt;User&gt; users) &#123; return this.userService.createOrUpdate(users); &#125; @PutMapping(&quot;/&#123;id&#125;&quot;) public Mono&lt;User&gt; update(@PathVariable(&quot;id&quot;) final String id, @RequestBody final User user) &#123; Objects.requireNonNull(user); user.setId(id); return this.userService.createOrUpdate(user); &#125; @DeleteMapping(&quot;/&#123;id&#125;&quot;) public Mono&lt;User&gt; delete(@PathVariable(&quot;id&quot;) final String id) &#123; return this.userService.delete(id); &#125;&#125; 服务器推送事件服务器推送事件（Server-Sent Events，SSE）允许服务器端不断地推送数据到客户端。相对于 WebSocket 而言，服务器推送事件只支持服务器端到客户端的单向数据传递。虽然功能较弱，但优势在于 SSE 在已有的 HTTP 协议上使用简单易懂的文本格式来表示传输的数据。作为 W3C 的推荐规范，SSE 在浏览器端的支持也比较广泛，除了 IE 之外的其他浏览器都提供了支持。在 IE 上也可以使用 polyfill 库来提供支持。在服务器端来说，SSE 是一个不断产生新数据的流，非常适合于用反应式流来表示。在 WebFlux 中创建 SSE 的服务器端是非常简单的。只需要返回的对象的类型是 Flux&lt;ServerSentEvent&gt;，就会被自动按照 SSE 规范要求的格式来发送响应。 代码清单 4 中的 SseController 是一个使用 SSE 的控制器的示例。其中的方法 randomNumbers()表示的是每隔一秒产生一个随机数的 SSE 端点。我们可以使用类 ServerSentEvent.Builder 来创建 ServerSentEvent 对象。这里我们指定了事件名称 random，以及每个事件的标识符和数据。事件的标识符是一个递增的整数，而数据则是产生的随机数。 清单 4. 服务器推送事件示例 1234567891011121314@RestController@RequestMapping(&quot;/sse&quot;)public class SseController &#123; @GetMapping(&quot;/randomNumbers&quot;) public Flux&lt;ServerSentEvent&lt;Integer&gt;&gt; randomNumbers() &#123; return Flux.interval(Duration.ofSeconds(1)) .map(seq -&gt; Tuples.of(seq, ThreadLocalRandom.current().nextInt())) .map(data -&gt; ServerSentEvent.&lt;Integer&gt;builder() .event(&quot;random&quot;) .id(Long.toString(data.getT1())) .data(data.getT2()) .build()); &#125;&#125; 在测试 SSE 时，我们只需要使用 curl 来访问即可。代码清单 5 给出了调用 curl http://localhost:8080/sse/randomNumbers 的结果。 清单 5. SSE 服务器端发送的响应 1234567891011id:0event:randomdata:751025203 id:1event:randomdata:-1591883873 id:2event:randomdata:-1899224227 WebSocketWebSocket 支持客户端与服务器端的双向通讯。当客户端与服务器端之间的交互方式比较复杂时，可以使用 WebSocket。WebSocket 在主流的浏览器上都得到了支持。WebFlux 也对创建 WebSocket 服务器端提供了支持。在服务器端，我们需要实现接口 org.springframework.web.reactive.socket.WebSocketHandler 来处理 WebSocket 通讯。接口 WebSocketHandler 的方法 handle 的参数是接口 WebSocketSession 的对象，可以用来获取客户端信息、接送消息和发送消息。代码清单 6 中的 EchoHandler 对于每个接收的消息，会发送一个添加了”ECHO -&gt; “前缀的响应消息。WebSocketSession 的 receive 方法的返回值是一个 Flux&lt;WebSocketMessage&gt;对象，表示的是接收到的消息流。而 send 方法的参数是一个 Publisher&lt;WebSocketMessage&gt;对象，表示要发送的消息流。在 handle 方法，使用 map 操作对 receive 方法得到的 Flux&lt;WebSocketMessage&gt;中包含的消息继续处理，然后直接由 send 方法来发送。 清单 6. WebSocket 的 EchoHandler 示例123456789@Componentpublic class EchoHandler implements WebSocketHandler &#123; @Override public Mono&lt;Void&gt; handle(final WebSocketSession session) &#123; return session.send( session.receive() .map(msg -&gt; session.textMessage(&quot;ECHO -&gt; &quot; + msg.getPayloadAsText()))); &#125;&#125; 在创建了 WebSocket 的处理器 EchoHandler 之后，下一步需要把它注册到 WebFlux 中。我们首先需要创建一个类 WebSocketHandlerAdapter 的对象，该对象负责把 WebSocketHandler 关联到 WebFlux 中。代码清单 7 中给出了相应的 Spring 配置。其中的 HandlerMapping 类型的 bean 把 EchoHandler 映射到路径 /echo。 清单 7. 注册 EchoHandler 1234567891011121314151617181920@Configurationpublic class WebSocketConfiguration &#123; @Autowired @Bean public HandlerMapping webSocketMapping(final EchoHandler echoHandler) &#123; final Map&lt;String, WebSocketHandler&gt; map = new HashMap&lt;&gt;(1); map.put(&quot;/echo&quot;, echoHandler); final SimpleUrlHandlerMapping mapping = new SimpleUrlHandlerMapping(); mapping.setOrder(Ordered.HIGHEST_PRECEDENCE); mapping.setUrlMap(map); return mapping; &#125; @Bean public WebSocketHandlerAdapter handlerAdapter() &#123; return new WebSocketHandlerAdapter(); &#125;&#125; 运行应用之后，可以使用工具来测试该 WebSocket 服务。打开工具页面 https://www.websocket.org/echo.html，然后连接到 ws://localhost:8080/echo，可以发送消息并查看服务器端返回的结果。 函数式编程模型在上节中介绍了基于 Java 注解的编程模型，WebFlux 还支持基于 lambda 表达式的函数式编程模型。与基于 Java 注解的编程模型相比，函数式编程模型的抽象层次更低，代码编写更灵活，可以满足一些对动态性要求更高的场景。不过在编写时的代码复杂度也较高，学习曲线也较陡。开发人员可以根据实际的需要来选择合适的编程模型。目前 Spring Boot 不支持在一个应用中同时使用两种不同的编程模式。 为了说明函数式编程模型的用法，我们使用 Spring Initializ 来创建一个新的 WebFlux 项目。在函数式编程模型中，每个请求是由一个函数来处理的， 通过接口 org.springframework.web.reactive.function.server.HandlerFunction 来表示。HandlerFunction 是一个函数式接口，其中只有一个方法 Mono&lt;T extends ServerResponse&gt; handle(ServerRequest request)，因此可以用 labmda 表达式来实现该接口。接口 ServerRequest 表示的是一个 HTTP 请求。通过该接口可以获取到请求的相关信息，如请求路径、HTTP 头、查询参数和请求内容等。方法 handle 的返回值是一个 Mono&lt;T extends ServerResponse&gt;对象。接口 ServerResponse 用来表示 HTTP 响应。ServerResponse 中包含了很多静态方法来创建不同 HTTP 状态码的响应对象。本节中通过一个简单的计算器来展示函数式编程模型的用法。代码清单 8 中给出了处理不同请求的类 CalculatorHandler，其中包含的方法 add、subtract、multiply 和 divide 都是接口 HandlerFunction 的实现。这些方法分别对应加、减、乘、除四种运算。每种运算都是从 HTTP 请求中获取到两个作为操作数的整数，再把运算的结果返回。 清单 8. 处理请求的类 CalculatorHandler 123456789101112131415161718192021222324252627282930313233343536373839@Componentpublic class CalculatorHandler &#123; public Mono&lt;ServerResponse&gt; add(final ServerRequest request) &#123; return calculate(request, (v1, v2) -&gt; v1 + v2); &#125; public Mono&lt;ServerResponse&gt; subtract(final ServerRequest request) &#123; return calculate(request, (v1, v2) -&gt; v1 - v2); &#125; public Mono&lt;ServerResponse&gt; multiply(final ServerRequest request) &#123; return calculate(request, (v1, v2) -&gt; v1 * v2); &#125; public Mono&lt;ServerResponse&gt; divide(final ServerRequest request) &#123; return calculate(request, (v1, v2) -&gt; v1 / v2); &#125; private Mono&lt;ServerResponse&gt; calculate(final ServerRequest request, final BiFunction&lt;Integer, Integer, Integer&gt; calculateFunc) &#123; final Tuple2&lt;Integer, Integer&gt; operands = extractOperands(request); return ServerResponse .ok() .body(Mono.just(calculateFunc.apply(operands.getT1(), operands.getT2())), Integer.class); &#125; private Tuple2&lt;Integer, Integer&gt; extractOperands(final ServerRequest request) &#123; return Tuples.of(parseOperand(request, &quot;v1&quot;), parseOperand(request, &quot;v2&quot;)); &#125; private int parseOperand(final ServerRequest request, final String param) &#123; try &#123; return Integer.parseInt(request.queryParam(param).orElse(&quot;0&quot;)); &#125; catch (final NumberFormatException e) &#123; return 0; &#125; &#125;&#125; 在创建了处理请求的 HandlerFunction 之后，下一步是为这些 HandlerFunction 提供路由信息，也就是这些 HandlerFunction 被调用的条件。这是通过函数式接口 org.springframework.web.reactive.function.server.RouterFunction 来完成的。接口 RouterFunction 的方法 Mono&lt;HandlerFunction&lt;T extends ServerResponse&gt;&gt; route(ServerRequest request)对每个 ServerRequest，都返回对应的 0 个或 1 个 HandlerFunction 对象，以 Mono&lt;HandlerFunction&gt;来表示。当找到对应的 HandlerFunction 时，该 HandlerFunction 被调用来处理该 ServerRequest，并把得到的 ServerResponse 返回。在使用 WebFlux 的 Spring Boot 应用中，只需要创建 RouterFunction 类型的 bean，就会被自动注册来处理请求并调用相应的 HandlerFunction。 代码清单 9 给了示例相关的配置类 Config。方法 RouterFunctions.route 用来根据 Predicate 是否匹配来确定 HandlerFunction 是否被应用。RequestPredicates 中包含了很多静态方法来创建常用的基于不同匹配规则的 Predicate。如 RequestPredicates.path 用来根据 HTTP 请求的路径来进行匹配。此处我们检查请求的路径是/calculator。在清单 9 中，我们首先使用 ServerRequest 的 queryParam 方法来获取到查询参数 operator 的值，然后通过反射 API 在类 CalculatorHandler 中找到与查询参数 operator 的值名称相同的方法来确定要调用的 HandlerFunction 的实现，最后调用查找到的方法来处理该请求。如果找不到查询参数 operator 或是 operator 的值不在识别的列表中，服务器端返回 400 错误；如果反射 API 的方法调用中出现错误，服务器端返回 500 错误。 清单 9. 注册 RouterFunction 123456789101112131415@Configurationpublic class Config &#123; @Bean @Autowired public RouterFunction&lt;ServerResponse&gt;routerFunction(final CalculatorHandler calculatorHandler) &#123; return RouterFunctions.route(RequestPredicates.path(&quot;/calculator&quot;), request -&gt; request.queryParam(&quot;operator&quot;).map(operator -&gt; Mono.justOrEmpty(ReflectionUtils.findMethod(CalculatorHandler.class, operator, ServerRequest.class)) .flatMap(method -&gt; (Mono&lt;ServerResponse&gt;) ReflectionUtils.invokeMethod(method, calculatorHandler, request)) .switchIfEmpty(ServerResponse.badRequest().build()) .onErrorResume(ex -&gt; ServerResponse.status(HttpStatus.INTERNAL_SERVER_ERROR).build())) .orElse(ServerResponse.badRequest().build())); &#125;&#125; 客户端除了服务器端实现之外，WebFlux 也提供了反应式客户端，可以访问 HTTP、SSE 和 WebSocket 服务器端。 HTTP对于 HTTP 和 SSE，可以使用 WebFlux 模块中的类 org.springframework.web.reactive.function.client.WebClient。代码清单 10 中的 RESTClient 用来访问前面小节中创建的 REST API。首先使用 WebClient.create 方法来创建一个新的 WebClient 对象，然后使用方法 post 来创建一个 POST 请求，并使用方法 body 来设置 POST 请求的内容。方法 exchange 的作用是发送请求并得到以 Mono&lt;ServerResponse&gt;表示的 HTTP 响应。最后对得到的响应进行处理并输出结果。ServerResponse 的 bodyToMono 方法把响应内容转换成类 User 的对象，最终得到的结果是 Mono&lt;User&gt;对象。调用 createdUser.block 方法的作用是等待请求完成并得到所产生的类 User 的对象。 清单 10. 使用 WebClient 访问 REST API 123456789101112131415public class RESTClient &#123; public static void main(final String[] args) &#123; final User user = new User(); user.setName(&quot;Test&quot;); user.setEmail(&quot;test@example.org&quot;); final WebClient client = WebClient.create(&quot;http://localhost:8080/user&quot;); final Monol&lt;User&gt; createdUser = client.post() .uri(&quot;&quot;) .accept(MediaType.APPLICATION_JSON) .body(Mono.just(user), User.class) .exchange() .flatMap(response -&gt; response.bodyToMono(User.class)); System.out.println(createdUser.block()); &#125;&#125; SSEWebClient 还可以用同样的方式来访问 SSE 服务，如代码清单 11 所示。这里我们访问的是在之前的小节中创建的生成随机数的 SSE 服务。使用 WebClient 访问 SSE 在发送请求部分与访问 REST API 是相同的，所不同的地方在于对 HTTP 响应的处理。由于 SSE 服务的响应是一个消息流，我们需要使用 flatMapMany 把 Mono&lt;ServerResponse&gt;转换成一个 Flux&lt;ServerSentEvent&gt;对象，这是通过方法 BodyExtractors.toFlux 来完成的，其中的参数 new ParameterizedTypeReference&lt;ServerSentEvent&lt;String&gt;&gt;() {}表明了响应消息流中的内容是 ServerSentEvent 对象。由于 SSE 服务器会不断地发送消息，这里我们只是通过 buffer 方法来获取前 10 条消息并输出。 清单 11. 使用 WebClient 访问 SSE 服务 12345678910111213141516public class SSEClient &#123; public static void main(final String[] args) &#123; final WebClient client = WebClient.create(); client.get() .uri(&quot;http://localhost:8080/sse/randomNumbers&quot;) .accept(MediaType.TEXT_EVENT_STREAM) .exchange() .flatMapMany(response -&gt; response.body(BodyExtractors.toFlux(new ParameterizedTypeReference&lt;ServerSentEvent&lt;String&gt;&gt;() &#123; &#125;))) .filter(sse -&gt; Objects.nonNull(sse.data())) .map(ServerSentEvent::data) .buffer(10) .doOnNext(System.out::println) .blockFirst(); &#125;&#125; WebSocket访问 WebSocket 不能使用 WebClient，而应该使用专门的 WebSocketClient 客户端。Spring Boot 的 WebFlux 模板中默认使用的是 Reactor Netty 库。Reactor Netty 库提供了 WebSocketClient 的实现。在代码清单 12 中，我们访问的是上面小节中创建的 WebSocket 服务。WebSocketClient 的 execute 方法与 WebSocket 服务器建立连接，并执行给定的 WebSocketHandler 对象。该 WebSocketHandler 对象与代码清单 6 中的作用是一样的，只不过它是工作于客户端，而不是服务器端。在 WebSocketHandler 的实现中，首先通过 WebSocketSession 的 send 方法来发送字符串 Hello 到服务器端，然后通过 receive 方法来等待服务器端的响应并输出。方法 take(1)的作用是表明客户端只获取服务器端发送的第一条消息。 清单 12. 使用 WebSocketClient 访问 WebSocket 1234567891011public class WSClient &#123; public static void main(final String[] args) &#123; final WebSocketClient client = new ReactorNettyWebSocketClient(); client.execute(URI.create(&quot;ws://localhost:8080/echo&quot;), session -&gt; session.send(Flux.just(session.textMessage(&quot;Hello&quot;))) .thenMany(session.receive().take(1).map(WebSocketMessage::getPayloadAsText)) .doOnNext(System.out::println) .then()) .block(Duration.ofMillis(5000)); &#125;&#125; 测试在 spring-test 模块中也添加了对 WebFlux 的支持。通过类 org.springframework.test.web.reactive.server.WebTestClient 可以测试 WebFlux 服务器。进行测试时既可以通过 mock 的方式来进行，也可以对实际运行的服务器进行集成测试。代码清单 13 通过一个集成测试来测试 UserController 中的创建用户的功能。方法 WebTestClient.bindToServer 绑定到一个运行的服务器并设置了基础 URL。发送 HTTP 请求的方式与代码清单 10 相同，不同的是 exchange 方法的返回值是 ResponseSpec 对象，其中包含了 expectStatus 和 expectBody 等方法来验证 HTTP 响应的状态码和内容。方法 jsonPath 可以根据 JSON 对象中的路径来进行验证。 清单 13. 测试 UserController 12345678910111213141516public class UserControllerTest &#123; private final WebTestClient client = WebTestClient.bindToServer().baseUrl(&quot;http://localhost:8080&quot;).build(); @Test public void testCreateUser() throws Exception &#123; final User user = new User(); user.setName(&quot;Test&quot;); user.setEmail(&quot;test@example.org&quot;); client.post().uri(&quot;/user&quot;) .contentType(MediaType.APPLICATION_JSON) .body(Mono.just(user), User.class) .exchange() .expectStatus().isOk() .expectBody().jsonPath(&quot;name&quot;).isEqualTo(&quot;Test&quot;); &#125;&#125; 小结反应式编程范式为开发高性能 Web 应用带来了新的机会和挑战。Spring 5 中的 WebFlux 模块可以作为开发反应式 Web 应用的基础。由于 Spring 框架的流行，WebFlux 会成为开发 Web 应用的重要趋势之一。本文对 Spring 5 中的 WebFlux 模块进行了详细的介绍，包括如何用 WebFlux 开发 HTTP、SSE 和 WebSocket 服务器端应用，以及作为客户端来访问 HTTP、SSE 和 WebSocket 服务。对于 WebFlux 的基于 Java 注解和函数式编程等两种模型都进行了介绍。最后介绍了如何测试 WebFlux 应用。 End 原文链接: https://www.ibm.com/developerworks/cn/java/spring5-webflux-reactive/index.html https://www.ibm.com/developerworks/cn/java/j-whats-new-in-spring-framework-5-theedom/index.html]]></content>
      <categories>
        <category>Programming</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring5</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式原则与UML类图]]></title>
    <url>%2F2017%2Fdesign-pattern-uml-and-six-principle%2F</url>
    <content type="text"><![CDATA[Preface设计模式，总的来说，就是前人踩过无数的坑总结出来的软件设计经验。在学习设计模式之前，有必要了解它的一些规则以及建模。UML(Unified Modeling Language)又称统一建模语言或标准建模语言，是始于1997年一个OMG(Object Management Group)标准，它是一个支持模型化和软件系统开发的图形化语言，为软件开发的所有阶段提供模型化和可视化支持，包括由需求分析到规格，到构造和配置。Design Pattern在软件工程中，设计模式（design pattern）是对软件设计中普遍存在（反复出现）的各种问题，所提出的解决方案。这个术语是由埃里希·伽玛（Erich Gamma）等人在1990年代从建筑设计领域引入到计算机科学的。设计模式并不直接用来完成代码的编写，而是描述在各种不同情况下，要怎么解决问题的一种方案。面向对象设计模式通常以类别或对象)来描述其中的关系和相互作用，但不涉及用来完成应用程序的特定类别或对象。设计模式能使不稳定依赖于相对稳定、具体依赖于相对抽象，避免会引起麻烦的紧耦合，以增强软件设计面对并适应变化的能力。 ——来自维基百科六大原则。单一职责原则单一职责原则（Single Responsibility Principle,SRP）：就一个类而言，应该仅有一个引起它变化的原因。即一个类应该只负责一个功能领域中的相应职责。单一职责原则是实现高内聚、低耦合的指导方针，它是最简单但又最难运用的原则，需要设计人员发现类的不同职责并将其分离，而发现类的多重职责需要设计人员具有较强的分析设计能力和相关实践经验。开闭原则开闭原则（Open-Closed Principle,OCP）： 是指软件实体（类、模块、函数等等）应该可以扩展，但是不可修改。即软件实体应该尽量在不修改原有代码的情况下进行扩展。为了满足开闭原则，需要对系统进行抽象化设计，抽象化是开闭原则的关键。里氏替换原则里氏替换原则（Liskov Substitution Principle,LSP）：所有引用父类的地方必须能够透明的使用子类的对象。即子类型必须能够替换掉它们的父类型。里氏替换原则告诉我们，在软件中将一个基类对象替换成它的子类对象，程序将不会产生任何错误和异常，反过来则不成立，如果一个软件实体使用的是一个子类对象的话，那么它不一定能够使用基类对象。因此在程序中尽量使用基类类型来对对象进行定义，而在运行时再确定其子类类型，用子类对象来替换父类对象。同时，里氏代换原则是实现开闭原则的重要方式之一。依赖倒置原则依赖倒置原则（Dependency Inversion Principle,DIP）：抽象不应该依赖细节，细节应该依赖于抽象。即应该针对接口编程，而不是针对实现编程。在大多数情况下，我们会同时使用开闭原则、里氏代换原则和依赖倒转原则，开闭原则是目标，里氏代换原则是基础，依赖倒转原则是手段。接口隔离原则接口隔离原则（Interface Segregation Principle,ISP）：使用专门的接口，而不使用单一的总接口，即客户端不应该依赖那些它不需要的接口。根据接口隔离原则，当一个接口太大时，我们需要将它分割成一些更细小的接口，使用该接口的客户端仅需知道与之相关的方法即可。每一个接口应该承担一种相对独立的角色，不干不该干的事，该干的事都要干。迪米特法则迪米特法则（Law of Demeter,LoD）：一个软件实体应当尽可能少地与其它实体发生相互作用。迪米特法则又称为最少知识原则（LeastKnowledge Principle,LIP）。如果一个系统符合迪米特法则，那么当其中某一个模块发生修改时，就会尽量少地影响其他模块，扩展会相对容易，这是对软件实体之间通信的限制，迪米特法则要求限制软件实体之间通信的宽度和深度。迪米特法则可降低系统的耦合度，使类与类之间保持松散的耦合关系。三大类型创建型(Creational)单例模式(Singleton)：保证一个类仅有一个实例，并提供一个访问它的全局访问点。工厂方法(Factory Method)：定义一个创建对象的接口，让其子类自己决定实例化哪一个工厂类，工厂模式使其创建过程延迟到子类进行。抽象工厂(Abstract Factory)：提供一个创建一系列相关或相互依赖对象的接口，而无需指定它们具体的类。建造者模式(Builder)：将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。原型模式(Prototype)：用原型实例指定创建对象的种类，并且通过拷贝这些原型来创建新的对象。结构型(Structural)适配器模式(Adapter)：适配器模式把一个类的接口变换成客户端所期待的另一种接口，从而使原本因接口不匹配而无法在一起工作的两个类能够在一起工作。装饰模式(Decrator)：装饰模式是在不必改变原类文件和使用继承的情况下，动态的扩展一个对象的功能。它是通过创建一个包装对象，也就是装饰来包裹真实的对象。代理模式(Proxy)：为其他对象提供一种代理以控制对这个对象的访问 ；外观模式(Facade)：为子系统中的一组接口提供一个一致的界面，外观模式定义了一个高层接口，这个接口使得这一子系统更加容易使用。桥接模式(Bridge)：将抽象部分与实现部分分离，使它们都可以独立的变化。组合模式(Composite)：允许你将对象组合成树形结构来表现”整体-部分”层次结构。 组合能让客户以一致的方法处理个别对象以及组合对象。享元模式(Flyweight)：运用共享技术有效地支持大量细粒度的对象。行为型(Behavioral)策略模式(Strategy)：定义一组算法，将每个算法都封装起来，并且使他们之间可以互换。模板方法(Template Method)：一个操作中算法的框架，而将一些步骤延迟到子类中，使得子类可以不改变算法的结构即可重定义该算法中的某些特定步骤。观察者模式(Observer)：定义对象间的一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。迭代器模式(Iterator)：提供一种方法顺序访问一个聚合对象中各个元素, 而又无须暴露该对象的内部表示；职责链模式(Chain of Responsibility)：避免请求发送者与接收者耦合在一起，让多个对象都有可能接收请求，将这些对象连接成一条链，并且沿着这条链传递请求，直到有对象处理它为止。命令模式(Command)：将一个请求封装为一个对象，从而使你可以用不同的请求对客户进行参数化，对请求排队和记录请求日志，以及支持可撤销的操作；备忘录模式(Memento)：在不破坏封装性的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态。这样就可以将该对象恢复到原先保存的状态。状态模式(State)：允许对象在内部状态改变时改变它的行为, 对象看起来好像修改了它的类。访问者模式(Visitor)：表示一个作用于其对象结构中的各元素的操作，它使你可以在不改变各元素类的前提下定义作用于这些元素的新操作。中介者模式(Mediator)：用一个中介对象来封装一系列的对象交互，中介者使各对象不需要显示地相互引用。从而使其耦合松散，而且可以独立地改变它们之间的交互。解释器模式(Interpreter)：给定一个语言，定义它的文法表示，并定义一个解释器，这个解释器使用该标识来解释语言中的句子。四大阶段 1、没学之前，什么是设计模式，老听别人说设计模式，感觉好高大上，那它到底是什么鬼。这时我们设计的代码复用性很差、难以维护。 2、学了几个模式后，感觉很简单，于是到处想着要用自己学过的模式，这样就会造成滥用。最后感觉还不如不用。 3、学完全部模式时，感觉很多模式太相似了，无法很清晰的知道各模式之间的区别、联系，这时一脸懵逼，脑子一团乱麻。在使用时，分不清要使用那种模式。 4、模式已熟记于心，已忘其形，深知其意，达到无剑胜有剑的境界，恭喜你，万剑归宗已练成！！！UMLUML中有九种建模的图标，即：用例图、类图、对象图、顺序图、协作图、状态图、活动图、组件图、配置图Class Diagram在这主要学习一下类图 Class diagram 。通过显示出系统的类以及这些类之间的关系来表示系统。类图是静态的———它们显示出什么可以产生影响但不会告诉你什么时候产生影响。UML类的符号是一个被划分成三块的方框：类名，属性，和操作。抽象类的名字，是斜体的。类之间的关系是连接线。类与类的关系泛化：表示类与类之间的继承关系、接口与接口之间的继承关系；实现：表示类对接口的实现；依赖：当类与类之间有使用关系时就属于依赖关系，不同于关联关系，依赖不具有“拥有关系”，而是一种“相识关系”，只在某个特定地方（比如某个方法体内）才有关系。关联：表示类与类或类与接口之间的依赖关系，表现为“拥有关系”，具体到代码可以用实例变量来表示；聚合：属于是关联的特殊情况，体现部分-整体关系，是一种弱拥有关系，整体和部分可以有不一样的生命周期，是一种弱关联；组合：属于是关联的特殊情况，也体现了体现部分-整体关系，是一种强“拥有关系”，整体与部分有相同的生命周期，是一种强关联。StarUMLStarUML…就是一个画UML的很炫酷的工具=.=显示interface在staruml中，interface默认是以一个圆圈显示的(尴尬了)…，但好在可以设置成想要的样子。添加一个圆圈（interface）之后，右键或选择菜单栏中的Format选择Stereotype Display -&gt; Label，这样矩形就显示出来了同样是Format，然后把Suppress Operations取消掉，这样操作就可以显示出来了GliffyGliffy是一个在线绘图工具，支持Chrome插件，非常强大。]]></content>
      <categories>
        <category>Programming</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Design Pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu 常用命令]]></title>
    <url>%2F2017%2Fnote-of-linux-command%2F</url>
    <content type="text"><![CDATA[Preface=.= 这里只记录一些个人比较常用到的Ubuntu命令那些太基本以及太高深的就……SSH相关安装SSH12sudo apt install sshsudo apt install openssh-server 查看启动成功：ps -e|grep ssh，如果看到sshd那代表成功了，如果没有，执行： 1sudo/etc/init.d/ssh start ssh的配置文件位于/etc/ssh/sshd_config，修改后需要重启ssh： 1sudo /etc/init.d/sshresart 保持长连接只需要在ssh命令后加上发送心跳即可：1ssh -o ServerAliveInterval=30 root@123.456.88 -p 2333 生成SSH密钥和公钥打开终端，使用下面的ssh-keygen来生成RSA密钥和公钥。-t表示type，就是说要生成RSA加密的钥匙：1ssh-keygen -t rsa -C "your_email@youremail.com" RSA也是默认的加密类型，所以你也可以只输入ssh-keygen，默认的RSA长度是2048位，如果你非常注重安全，那么可以指定4096位的长度：1ssh-keygen -b 4096 -t rsa -C "your_email@youremail.com" 生成SSH Key的过程中会要求你指定一个文件来保存密钥，按Enter键使用默认的文件就行了，然后需要输入一个密码来加密你的SSH Key，密码至少要20位长度，SSH密钥会保存在home目录下的.ssh/id_rsa文件中，SSH公钥保存在.ssh/id_rsa.pub文件中。1234567891011121314151617181920Generating public/private rsa key pair.Enter file in which to save the key (/home/matrix/.ssh/id_rsa): #按Enter键Enter passphrase (empty for no passphrase): #输入一个密码Enter same passphrase again: #再次输入密码Your identification has been saved in /home/matrix/.ssh/id_rsa.Your public key has been saved in /home/matrix/.ssh/id_rsa.pub.The key fingerprint is:e1:dc:ab:ae:b6:19:b0:19:74:d5:fe:57:3f:32:b4:d0 matrix@vividThe key&apos;s randomart image is:+---[RSA 4096]----+| .. || . . || . . .. . || . . o o.. E .|| o S ..o ...|| = ..+...|| o . . .o .|| .o . || .++o |+-----------------+ 文件传输姿势：12345# 传输单个文件scp -P &lt;端口&gt; &lt;源文件&gt; &lt;目标文件&gt;# 传输文件夹scp -P &lt;端口&gt; -r &lt;源文件夹&gt; &lt;目标文件夹&gt; 注意-P要在前面例如把本地的file复制到远程服务器：1scp -P 2333 /home/ybd/file root@123.456.78:/root/file 免密码登录远程服务器姿势一使用上述scp把公钥上传到服务器，然后：1cat id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys 姿势二可以使用ssh-copy-id命令来完成：1ssh-copy-id &lt;用户名&gt;@&lt;服务器ip&gt; -p &lt;端口&gt; 输入远程用户的密码后，SSH公钥就会自动上传了，SSH公钥保存在远程Linux服务器的.ssh/authorized_keys文件中。 别名alias简化命令只需要在当前用户目录加上别名命令，但博主用的是zsh，所有配置在.zshrc而不是.bashrc12echo "alias vps='ssh -o ServerAliveInterval=30 root@172.104.65.190 -p 2333'" &gt;&gt; ~/.zshrcsource ~/.zshrc 然后直接输入vps就可以登陆远程服务器了。 切换用户使用su命令切换用户，ex：1su - ybd 这样就切换到了ybd用户su -就是su -l(l为login的意思)，l可以省略，所以一般写成su -…..(坑爹)如果不加用户名，默认是 su root切换root用户。注意：su 和 su -的区别 前者是直接切换，还保留了当前位置以及变量 而后者不单单切换了用户，而且还切换到了用户目录，并且之前用户的环境变量没有了！ 因为这个原因，写Dockerfile困扰了好一段时间…囧 还有su也可以使用某个用户的身份执行一些命令，ex：1234# 执行单个命令su - $&#123;USER_NAME&#125; -c &quot;npm install -g hexo-cli&quot;# 执行shell脚本su - $&#123;USER_NAME&#125; -s /bin/bash shell.sh 执行完之后还是保持当前用户。可以通过exit退出当前用户。 ufw防火墙安装Ubuntu自带ufw，没有可以直接安装： 1sudo get install ufw 查看端口是否开启1telnet 192.168.1.103 80 设置默认规则大多数系统只需要打开少量的端口接受传入连接，并且关闭所有剩余的端口。 从一个简单的规则基础开始，ufw default命令可以用于设置对传入和传出连接的默认响应动作。 要拒绝所有传入并允许所有传出连接，那么运行： 12sudo ufw default allow outgoingsudo ufw default deny incoming 查看本地的端口开启情况1sudo ufw status 打开80端口1sudo ufw allow 80 允许从一个 IP 地址连接1sudo ufw allow from 123.45.67.89 允许特定子网的连接1sudo ufw allow from 123.45.67.89/24 允许特定 IP/ 端口的组合1sudo ufw allow from 123.45.67.89 to any port 22 proto tcp 防火墙开启/禁用1234# 开启sudo ufw enable# 禁用sudo ufw disable 防火墙重启：1sudo ufw reload 用户与用户组相关添加用户useradd ex：创建ybd用户并且加入ybd用户组并且创建用户目录： 123useradd -g ybd -m ybd# 或者user add -m -U ybd 修改密码1passwd ybd 修改用户usermod 添加用户组groupadd 修改用户组 ex:将test组的名子改成test21groupmod -n test2 test 删除组test21groupdel test2 查看组查看当前登录用户所在的组：1groups 查看用户test所在组：1groups test 查看所有组：1cat /etc/group 修改用户名 usermod不允许你改变正在线上的使用者帐号名称。当usermod用来改变userID，必须确认这名user没在电脑上执行任何程序，否则会报“usermod: user xxx is currently logged in”错误。因此必须root用户登录或者其他用户登录然后切换到root身份，而不能在当前用户下切换至root进行修改。 1、以root身份登录 2、usermod -l hadoop seed该命令相当于做了两件事： 将/etc/passwd下的用户名栏从seed修改为hadoop，其他部分不变 将/etc/shadow下的用户名栏从seed修改为hadoop，其他部分不变 3、usermod -c hadoop hadoop 相当于将/etc/passwd下的注解栏修改为hadoop，其他部分不变 4、groupmod -n hadoop seed 将原来的用户组seed修改为hadoop，只修改组名，组标识号不变，相当于修改了文件/etc/group和/etc/gshadow 5、usermod -md /home/hadoop hadoop相当于做了两件事： 将~下的登入目录栏修改为/home/hadoop，其他部分不变 将原来的用户目录/home/seed修改为新的用户目录/home/hadoop 递归下载抓取整个网站内容1wget -r -p -k -np &lt;URL&gt; 参数说明：-r： 递归下载-p： 下载所有用于显示 HTML 页面的图片之类的元素-k： 在转换文件 X 前先将它备份为 X.orig-np： 不追溯至父目录 跟踪日志输出1234tail -f &lt;log&gt;# 输出最后1000行tail -1000 &lt;log&gt; 统计文件夹大小1du -hs `ls -al |awk &apos;&#123;print $9&#125;&apos;` 上面命令可以统计文件夹中所有的文件夹和文件的大小，并且包括隐藏目录。缺点是连上级目录也会统计。 如果不需要列出上级目录，则把ls命令的-a换成-A，就不会列出点文件了。1du -hs `ls -Al |awk &apos;&#123;print $9&#125;&apos;` 如果不需要列出文件，只需文件夹，则在ls中增加-d参数即可123du -hs `ls -Adl |awk &apos;&#123;print $9&#125;&apos;`或du -hs `ls -Al |grep ^d|awk &apos;&#123;print $9&#125;&apos;` 压缩和解压缩打包但是不压缩(tar)：tar -cf &lt;压缩包文件名&gt; &lt;要打包的目录&gt;打包并压缩(tar.gz)：tar -zcf &lt;压缩包文件名&gt; &lt;要打包的目录&gt; 解压缩tar文件：tar -xvf &lt;压缩包文件&gt;解压缩tar.gz文件：tar -zxvf &lt;压缩包文件&gt; 目录操作命令在Windows系统中，有C、D、E等众多的盘符，每个盘符就是一个根目录。在Linux、Unix、MacOS等系统的文件系统中，只有一个根目录，那就是root，以一个斜杠代表（/）。 切换目录：cd该命令和Windows中没有太大的区别，都表示改变当前的工作目录。1cd &lt;目标目录&gt; 显示当前目录：pwd显示当前目录的路径，返回字符串。在Windows使用cd不带参数的方式代替。该命令同样也没有参数。 遍历目录：ls显示当前目录中的内容，常用的命令有：12以列表显示当前目录所有的目录和文件ls -l 在Linux、Unix、MacOS等系统中，隐藏文件均是点（.）开头的，下面命令以列表显示当前目录所有的目录和文件，包括隐藏的目录和文件。1ls -al 显示所有的目录，包括隐藏的目录，但是不包括文件1ls -adl 复制：cpcp是copy的简称，用于复制文件和目录。复制的时候，源路径和目录路径可以是一个文件，也可以是一个目录。1cp &lt;源路径&gt; &lt;目标路径&gt; 移动：mvmv是移动(move)的简称，用于移动文件和目录。1mv &lt;源路径&gt; &lt;目标路径&gt; 删除：rmrm命令可以用于删除目录和文件，但是通过rm删除目录的话，必须加上rm -rf &lt;目录名称&gt;。删除文件直接就是rm &lt;文件名&gt; 注意：在Linux或者Unix系统中，通过rm或者文件管理器删除文件将会从文件系统的目录结构上解除链接(unlink).然而如果文件是被打开的（有一个进程正在使用），那么进程将仍然可以读取该文件，磁盘空间也一直被占用。可以通过lsof命令查看文件是否被打开。详见 列出打开的文件。 删除目录：rmdir删除目录的时候，必须确保目录是空的，否则无法删除。命令格式：rm &lt;目录&gt;。 管理员权限打开文件夹1sudo nautilus 查找相关 以下转载于http://blog.csdn.net/wzzfeitian/article/details/40985549 find命令find &lt; path &gt; &lt; expression &gt; &lt; cmd &gt; path： 所要搜索的目录及其所有子目录。默认为当前目录。 expression： 所要搜索的文件的特征。 cmd： 对搜索结果进行特定的处理。 如果什么参数也不加，find默认搜索当前目录及其子目录，并且不过滤任何结果（也就是返回所有文件），将它们全都显示在屏幕上。 find命令常用选项及实例-name 按照文件名查找文件。12find /dir -name filename 在/dir目录及其子目录下面查找名字为filename的文件find . -name &quot;*.c&quot; 在当前目录及其子目录（用“.”表示）中查找任何扩展名为“c”的文件 -perm 按照文件权限来查找文件。1find . -perm 755 –print 在当前目录下查找文件权限位为755的文件，即文件属主可以读、写、执行，其他用户可以读、执行的文件 -prune 使用这一选项可以使find命令不在当前指定的目录中查找，如果同时使用-depth选项，那么-prune将被find命令忽略。 12find /apps -path &quot;/apps/bin&quot; -prune -o –print 在/apps目录下查找文件，但不希望在/apps/bin目录下查找find /usr/sam -path &quot;/usr/sam/dir1&quot; -prune -o –print 在/usr/sam目录下查找不在dir1子目录之内的所有文件 -depth：在查找文件时，首先查找当前目录中的文件，然后再在其子目录中查找。 1find / -name &quot;CON.FILE&quot; -depth –print 它将首先匹配所有的文件然后再进入子目录中查找 -user 按照文件属主来查找文件。 1find ~ -user sam –print 在$HOME目录中查找文件属主为sam的文件 -group 按照文件所属的组来查找文件。 1find /apps -group gem –print 在/apps目录下查找属于gem用户组的文件 -mtime -n +n 按照文件的更改时间来查找文件， -n表示文件更改时间距现在n天以内，+n表示文件更改时间距现在n天以前。 12find / -mtime -5 –print 在系统根目录下查找更改时间在5日以内的文件find /var/adm -mtime +3 –print 在/var/adm目录下查找更改时间在3日以前的文件 -nogroup 查找无有效所属组的文件，即该文件所属的组在/etc/groups中不存在。 1find / –nogroup -print -nouser 查找无有效属主的文件，即该文件的属主在/etc/passwd中不存在。 1find /home -nouser –print -newer file1 ! file2 查找更改时间比文件file1新但比文件file2旧的文件。 -type 查找某一类型的文件， 诸如： b - 块设备文件。 d - 目录。 c - 字符设备文件。 p - 管道文件。 l - 符号链接文件。 f - 普通文件。123find /etc -type d –print 在/etc目录下查找所有的目录find . ! -type d –print 在当前目录下查找除目录以外的所有类型的文件find /etc -type l –print 在/etc目录下查找所有的符号链接文件 -size n[c] 查找文件长度为n块的文件，带有c时表示文件长度以字节计。123find . -size +1000000c –print 在当前目录下查找文件长度大于1 M字节的文件find /home/apache -size 100c –print 在/home/apache目录下查找文件长度恰好为100字节的文件find . -size +10 –print 在当前目录下查找长度超过10块的文件（一块等于512字节） -mount 在查找文件时不跨越文件系统mount点。 find . -name “*.XC” -mount –print 从当前目录开始查找位于本文件系统中文件名以XC结尾的文件（不进入其他文件系统） -follow 如果find命令遇到符号链接文件，就跟踪至链接所指向的文件 -exec find命令对匹配的文件执行该参数所给出的shell命令。相应命令的形式为command {} \，注意{}和\;之间的空格 12345678$ find ./ -size 0 -exec rm &#123;&#125; \; 删除文件大小为零的文件$ rm -i `find ./ -size 0` $ find ./ -size 0 | xargs rm -f &amp;为了用ls -l命令列出所匹配到的文件，可以把ls -l命令放在find命令的-exec选项中：$ find . -type f -exec ls -l &#123;&#125; \;在/logs目录中查找更改时间在5日以前的文件并删除它们：find /logs -type f -mtime +5 -exec rm &#123;&#125; \; -ok，和-exec的作用相同，只不过以一种更为安全的模式来执行该参数所给出的shell命令，在执行每一个命令之前，都会给出提示，让用户来确定是否执行。 1find . -name &quot;*.conf&quot; -mtime +5 -ok rm &#123;&#125; \; 在当前目录中查找所有文件名以.LOG结尾、更改时间在5日以上的文件，并删除它们，只不过在删除之前先给出提示 说明： 如果你要寻找一个档案的话，那么使用 find 会是一个不错的主意。不过，由于 find 在寻找数据的时候相当的耗硬盘，所以没事情不要使用 find 啦！有更棒的指令可以取代呦，那就是 whereis 与 locate 咯~ 一些常用命令123456789101112131415161718192021221. find . -type f -exec ls -l &#123;&#125; \;查找当前路径下的所有普通文件，并把它们列出来。2. find logs -type f -mtime +5 -exec rm &#123;&#125; \;删除logs目录下更新时间为5日以上的文件。3.find . -name &quot;*.log&quot; -mtime +5 -ok rm &#123;&#125; \;删除当前路径下以。log结尾的五日以上的文件，删除之前要确认。4. find ~ -type f -perm 4755 -print查找$HOME目录下suid位被设置，文件属性为755的文件打印出来。说明： find在有点系统中会一次性得到将匹配到的文件都传给exec，但是有的系统对exec的命令长度做限制，就会报：”参数列太长“，这就需要使用xargs。xargs是部分取传来的文件。5. find / -type f -print |xargs filexargs测试文件分类6. find . -name &quot;core*&quot; -print|xargs echo &quot; &quot;&gt;/tmp/core.log将core文件信息查询结果报存到core。log日志。7. find / -type f -print | xargs chmod o -w8. find . -name * -print |xargs grep &quot;DBO&quot; grep命令1grep [选项] pattern [文件名] 命令中的选项为： -? 同时显示匹配行上下的？行，如：grep -2 pattern filename 同时显示匹配行的上下2行。 -b，—byte-offset 打印匹配行前面打印该行所在的块号码。 -c,—count 只打印匹配的行数，不显示匹配的内容。 -f File，—file=File 从文件中提取模板。空文件中包含0个模板，所以什么都不匹配。 -h，—no-filename 当搜索多个文件时，不显示匹配文件名前缀。 -i，—ignore-case 忽略大小写差别。 -q，—quiet 取消显示，只返回退出状态。0则表示找到了匹配的行。 -l，—files-with-matches 打印匹配模板的文件清单。 -L，—files-without-match 打印不匹配模板的文件清单。 -n，—line-number 在匹配的行前面打印行号。 -s，—silent 不显示关于不存在或者无法读取文件的错误信息。 -v，—revert-match 反检索，只显示不匹配的行。 -w，—word-regexp 如果被\&lt;和&gt;引用，就把表达式做为一个单词搜索。 -V，—version 显示软件版本信息。 123456789101112ls -l | grep &apos;^a&apos; 通过管道过滤ls -l输出的内容，只显示以a开头的行。grep &apos;test&apos; d* 显示所有以d开头的文件中包含test的行。grep &apos;test&apos; aa bb cc 显示在aa，bb，cc文件中匹配test的行。grep &apos;[a-z]&apos; aa 显示所有包含每个字符串至少有5个连续小写字符的字符串的行。grep &apos;w(es)t.*&apos; aa 如果west被匹配，则es就被存储到内存中，并标记为1，然后搜索任意个字符(.*)，这些字符后面紧跟着另外一个es()，找到就显示该行。如果用egrep或grep -E，就不用&quot;&quot;号进行转义，直接写成&apos;w(es)t.*&apos;就可以了。grep -i pattern files ：不区分大小写地搜索。默认情况区分大小写grep -l pattern files ：只列出匹配的文件名，grep -L pattern files ：列出不匹配的文件名，grep -w pattern files ：只匹配整个单词，而不是字符串的一部分(如匹配‘magic’，而不是‘magical’)，grep -C number pattern files ：匹配的上下文分别显示[number]行，grep pattern1 | pattern2 files ：显示匹配 pattern1 或 pattern2 的行，grep pattern1 files | grep pattern2 ：显示既匹配 pattern1 又匹配 pattern2 的行。 pattern为所要匹配的字符串，可使用下列模式1234567. 匹配任意一个字符* 匹配0 个或多个*前的字符^ 匹配行开头$ 匹配行结尾[] 匹配[ ]中的任意一个字符，[]中可用 - 表示范围，例如[a-z]表示字母a 至z 中的任意一个\ 转意字符 xargs命令【xargs定位参数位置 | xargs控制参数位置 | 如何定位控制xargs参数位置】背景：管道 + xargs用于把上游输出转换为下游参数输入。例如 ls *.bak | xargs rm -f 问题：xargs默认把输入作为参数放到命令的最后，但是很多命令需要自己定位参数的位置，比如拷贝命令cp {上游结果} destFolder 解决方法：xargs 使用大写字母i 定义参数指示符 -I &lt;指示符&gt;，然后用这个参数指示符定位参数插入的位置, 例如： 1ls *.bak | xargs -I % cp % /tmp/test 注释：这里使用%作为指示符，第一个%可以理解为声明，第二个%可以理解为调用。你也可以用其他字符，比如 ls *.bak | xargs -I {} cp {} /tmp/test 简介之所以能用到xargs这个命令，关键是由于很多命令不支持|管道来传递参数，而日常工作中有有这个必要，所以就有了xargs命令，例如： 12find /sbin -perm +700 | ls -l 这个命令是错误的find /sbin -perm +700 | xargs ls -l 这样才是正确的 xargs 可以读入 stdin 的资料，并且以空白字元或断行字元作为分辨，将 stdin 的资料分隔成为 arguments 。 因为是以空白字元作为分隔，所以，如果有一些档名或者是其他意义的名词内含有空白字元的时候， xargs 可能就会误判了～选项解释-0 当sdtin含有特殊字元时候，将其当成一般字符，像/ ‘ 空格等 123root@localhost:~/test#echo &quot;//&quot;|xargs echoroot@localhost:~/test#echo &quot;//&quot;|xargs -0 echo/ -a file 从文件中读入作为sdtin 123root@localhost:~/test#cat test#!/bin/shecho &quot;hello world/n&quot;root@localhost:~/test#xargs -a test echo#!/bin/sh echo hello world/nroot@localhost:~/test# -e flag ，注意有的时候可能会是-E，flag必须是一个以空格分隔的标志，当xargs分析到含有flag这个标志的时候就停止。 1234root@localhost:~/test#cat txt/bin tao shou kunroot@localhost:~/test#cat txt|xargs -E &apos;shou&apos; echo/bin tao -p 当每次执行一个argument的时候询问一次用户。 12root@localhost:~/test#cat txt|xargs -p echoecho /bin tao shou kun ff ?...y/bin tao shou kun ff -n num 后面加次数，表示命令在执行的时候一次用的argument的个数，默认是用所有的 1234567root@localhost:~/test#cat txt|xargs -n1 echo/bintaoshoukunroot@localhost:~/test3#cat txt|xargs echo/bin tao shou ku -t 表示先打印命令，然后再执行。 12root@localhost:~/test#cat txt|xargs -t echoecho /bin tao shou kun/bin tao shou kun -i 或者是-I，这得看linux支持了，将xargs的每项名称，一般是一行一行赋值给{}，可以用{}代替。 1$ ls | xargs -t -i mv &#123;&#125; &#123;&#125;.bak -r no-run-if-empty 当xargs的输入为空的时候则停止xargs，不用再去执行了。 12root@localhost:~/test#echo &quot;&quot;|xargs -t -r mvroot@localhost:~/test# -s num 命令行的最大字符数，指的是xargs后面那个命令的最大命令行字符数 1234567root@localhost:~/test#cat test |xargs -i -x -s 14 echo &quot;&#123;&#125;&quot;exp1exp5filexargs: argument line too longlinux-2root@localhost:~/test# -L num Use at most max-lines nonblank input lines per command line.-s是含有空格的。 -l 同-L -d delim 分隔符，默认的xargs分隔符是回车，argument的分隔符是空格，这里修改的是xargs的分隔符 123456789101112131415161718192021root@localhost:~/test#cat txt |xargs -i -p echo &#123;&#125;echo /bin tao shou kun ?...yroot@localhost:~/test#cat txt |xargs -i -p -d &quot; &quot; echo &#123;&#125;echo /bin ?...yecho tao ?.../binyecho shou ?...tao再如：root@localhost:~/test#cat test |xargs -i -p -d &quot; &quot; echo &#123;&#125;echo exp1exp5filelinux-2ngis_posttaotesttxtxen-3?...yroot@localhost:~/test#cat test |xargs -i -p echo &#123;&#125;echo exp1 ?...yecho exp5 ?...exp1yecho file ?...exp5y -x exit的意思，主要是配合-s使用。 -P 修改最大的进程数，默认是1，为0时候为as many as it can 其他查找命令1. locate命令locate命令其实是“find -name”的另一种写法，但是要比后者快得多，原因在于它不搜索具体目录，而是搜索一个数据库（/var/lib/locatedb），这个数据库中含有本地所有文件信息。Linux系统自动创建这个数据库，并且每天自动更新一次，所以使用locate命令查不到最新变动过的文件。为了避免这种情况，可以在使用locate之前，先使用updatedb命令，手动更新数据库。 locate命令的使用实例： 1234$ locate /etc/sh搜索etc目录下所有以sh开头的文件。$ locate -i ~/m搜索用户主目录下，所有以m开头的文件，并且忽略大小写。 2. whereis命令whereis命令只能用于程序名的搜索，而且只搜索二进制文件（参数-b）、man说明文件（参数-m）和源代码文件（参数-s）。如果省略参数，则返回所有信息。 whereis命令的使用实例： 12$ whereis grepgrep: /bin/grep /usr/share/man/man1p/grep.1p.gz /usr/share/man/man1/grep.1.gz 3. which命令which命令的作用是，在PATH变量指定的路径中，搜索某个系统命令的位置，并且返回第一个搜索结果。也就是说，使用which命令，就可以看到某个系统命令是否存在，以及执行的到底是哪一个位置的命令。 which命令的使用实例： 12$ which grep/bin/grep 查看磁盘空间1df -hl 显示格式为： 123文件系统 容量 已用 可用 已用% 挂载点 Filesystem Size Used Avail Use% Mounted on df -hl 查看磁盘剩余空间 df -h 查看每个根路径的分区大小 du -sh [目录名] 返回该目录的大小 du -sm [文件夹] 返回该文件夹总M数 查看内存使用情况free： 1234root@localhost:~# free -h total used free shared buff/cache availableMem: 989M 121M 87M 7.0M 781M 662MSwap: 255M 14M 241M Extend使用systemd设置开机启动 ubuntu从16.04开始不再使用initd管理系统，改用systemd 为了像以前一样，在/etc/rc.local中设置开机启动程序，需要以下几步： 1、systemd默认读取/etc/systemd/system下的配置文件，该目录下的文件会链接/lib/systemd/system/下的文件。一般系统安装完/lib/systemd/system/下会有rc-local.service文件，即我们需要的配置文件。 链接过来： 1ln -fs /lib/systemd/system/rc-local.service /etc/systemd/system/rc-local.service 12cd /etc/systemd/system/vim rc-local.service rc-local.service内容： 123456789101112131415161718192021222324# This file is part of systemd.## systemd is free software; you can redistribute it and/or modify it# under the terms of the GNU Lesser General Public License as published by# the Free Software Foundation; either version 2.1 of the License, or# (at your option) any later version.# This unit gets pulled automatically into multi-user.target by# systemd-rc-local-generator if /etc/rc.local is executable.[Unit]Description=/etc/rc.local CompatibilityConditionFileIsExecutable=/etc/rc.localAfter=network.target[Service]Type=forkingExecStart=/etc/rc.local startTimeoutSec=0RemainAfterExit=yesGuessMainPID=no[Install]WantedBy=multi-user.targetAlias=rc-local.service 2、创建/etc/rc.local文件 1touch /etc/rc.local 3、赋可执行权限 1chmod 755 /etc/rc.local 4、编辑rc.local，添加需要开机启动的任务 123#!/bin/bashecho &quot;test test &quot; &gt; /var/test_boot_up.log 5、执行reboot重启系统验证OK。 最后，说一下/etc/systemd/system/下的配置文件（XXXX.service）,其中有三个配置项，[Unit] / [Service] / [Install] [Unit] 区块：启动顺序与依赖关系。 [Service] 区块：启动行为,如何启动，启动类型。 [Install] 区块，定义如何安装这个配置文件，即怎样做到开机启动。 apt-get update无法下载 出现类似情况，可以找到/etc/apt/sources.list.d目录，删除对应的.list文件即可]]></content>
      <categories>
        <category>OperatingSystem</category>
        <category>Ubuntu</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker入坑笔记]]></title>
    <url>%2F2017%2Fdocker-learning%2F</url>
    <content type="text"><![CDATA[PrefaceDocker是什么？下面是官方的一段说明：Docker is the world’s leading software containerization platform.恩，很niubility，引领世界软件容器化的平台…本篇主要记录Docker的基础学习（安装、简单使用）Containerization VS Virtualization了解Docker之前，我们有必要了解一下容器化容器相当于轻量级的虚拟机，但隔离性不如虚拟机。StoryLong long ago…Dev: “帮我构建几台跟生产环境一样的测试服务器”Ops: “给我一个星期时间”Dev: “明天用…”Ops: “开发的这群傻叉新给的发布包又把系统CPU搞到100%了，应用又夯住了，都是些什么水平的人啊…”Dev: “运维的这帮傻鸟技术太差，维护的是些什么稀烂的系统，在我这跑得好好的，上他们那应用就挂…”Ops: “这是开发的锅…”Dev: “这是运维的盘…”Q：线上线下环境不一致，线上JDK1.8.01,线下JDK1.8.02，数据库版本不统一等环境问题单机安装和配置MySQL、Memcatched、MongoDB、Hadoop、GlusterFS、RabbitMQ、Node.js、Nginx已经够复杂，集群更不用说最终引发的问题就是，我们的服务方是用户，受害方也是用户…各司其职的同时也在两者之间形成了一面无形的墙，阻碍了开发和运维之间的沟通和协作，而Docker、DevOps的出现就是为了击碎这堵无形之墙。Docker核心理念：Build，Ship，and Run Any App，Anywhere(Java的核心理念：Write once, run anywhere)Docker是GO语言编写的容器化的一种实现，是一个分布式应用构建、迁移和运行的开放平台，它允许开发或运维人员将应用和运行应用所依赖的文件打包到一个标准化的单元（容器）中运行。其他的容器实现有OpenVZ，Pouch(Ali出品)等。服务器好比运输码头：拥有场地和各种设备（服务器硬件资源）服务器容器化好比作码头上的仓库：拥有独立的空间堆放各种货物或集装箱(仓库之间完全独立，独立的应用系统和操作系统）实现的核心技术: lcx、cgroup、namespaces…（Linux内核级别隔离技术）注意点: 不能乱玩…遵循单一职责，无状态。Docker实现DevOps的优势优势一:开发、测试和生产环境的统一化和标准化。镜像作为标准的交付件，可在开发、测试和生产环境上以容器来运行，最终实现三套环境上的应用以及运行所依赖内容的完全一致。优势二:解决底层基础环境的异构问题。基础环境的多元化造成了从Dev到Ops过程中的阻力，而使用Docker Engine可无视基础环境的类型。不同的物理设备，不同的虚拟化类型，不同云计算平台，只要是运行了Docker Engine的环境，最终的应用都会以容器为基础来提供服务。优势三:易于构建、迁移和部署。Dockerfile实现镜像构建的标准化和可复用，镜像本身的分层机制也提高了镜像构建的效率。使用Registry可以将构建好的镜像迁移到任意环境，而且环境的部署仅需要将静态只读的镜像转换为动态可运行的容器即可。优势四:轻量和高效。和需要封装操作系统的虚拟机相比，容器仅需要封装应用和应用需要的依赖文件，实现轻量的应用运行环境，且拥有比虚拟机更高的硬件资源利用率。优势五:工具链的标准化和快速部署。将实现DevOps所需的多种工具或软件进行Docker化后，可在任意环境实现一条或多条工具链的快速部署。适合敏捷开发、持续交付核心概念以下是Docker的三个基本概念。Image(镜像)官方而言，Docker 镜像是一个特殊的文件系统，除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的一些配置参数（如匿名卷、环境变量、用户等）。镜像不包含任何动态数据，其内容在构建之后也不会被改变。对博主而言，它相当于就是个Java Class(类)=.=但它的存储结构类似Git，一层一层地网上盖，删除一个文件并不会真的删除，只是在那个文件上面做了一个标记为已删除。在最终容器运行的时候，虽然不会看到这个文件，但是实际上该文件会一直跟随镜像。因此，在构建镜像的时候，需要额外小心，每一层尽量只包含该层需要添加的东西，任何额外的东西应该在该层构建结束前清理掉。Container(容器)通俗来说，如果镜像是类，那么容器就是这个类的实例了，镜像是静态的定义，容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等。容器也有其特性，例如存储，不指定数据卷(Volume)的话，容器消亡数据也就跟着没了…跟多特性请自行百度~Repository(仓库)仓库没啥好说的了，以 Ubuntu 镜像 为例，ubuntu 是仓库的名字，其内包含有不同的版本标签，如，14.04, 16.04。我们可以通过 ubuntu:14.04，或者 ubuntu:16.04 来具体指定所需哪个版本的镜像。如果忽略了标签，比如 ubuntu，那将视为 ubuntu:latest安装这里以Ubuntu为例（当然是因为博主用的是Ubuntu= =），版本的话Docker目前支持的Ubuntu版本最低为12.04LTS,但从稳定性上考虑,推荐使用14.04LTS或更高的版本。使用脚本自动安装在测试或开发环境中 Docker 官方为了简化安装流程，提供了一套便捷的安装脚本，Ubuntu 系统上可以使用这套脚本安装：12curl -fsSL get.docker.com -o get-docker.shsudo sh get-docker.sh --mirror Aliyun 执行这个命令后，脚本就会自动的将一切准备工作做好，并且把 Docker 安装在系统中 使用 APT 镜像源 安装123456sudo apt-get updatesudo apt-get install \ apt-transport-https \ ca-certificates \ curl \ software-properties-common 鉴于国内网络问题，强烈建议使用国内源 国内源12345curl -fsSL https://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add -sudo add-apt-repository \ &quot;deb [arch=amd64] https://mirrors.aliyun.com/docker-ce/linux/ubuntu \ $(lsb_release -cs) \ stable&quot; 以上命令会添加 稳定 版本的 Docker CE APT 镜像源，如果需要最新版本的 Docker CE 请将 stable 改为 edge 或者 test 。从 Docker 17.06 开始，edge test 版本的 APT 镜像源也会包含稳定版本的 Docker 官方源12345curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -sudo add-apt-repository \ &quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu \ $(lsb_release -cs) \ stable&quot; 安装 Docker CE12sudo apt-get updatesudo apt-get install docker-ce 启动 Docker CE12sudo systemctl enable dockersudo systemctl start docker 建立 docker 用户组默认情况下，docker 命令会使用 Unix socket 与 Docker 引擎通讯。而只有 root 用户和 docker 组的用户才可以访问 Docker 引擎的 Unix socket。出于安全考虑，一般 Linux 系统上不会直接使用 root 用户。因此，更好地做法是将需要使用 docker 的用户加入 docker 用户组。建立 docker 组(貌似执行了自动安装脚本会自动建一个docker的用户组)：1sudo groupadd docker 将当前用户加入 docker 组：1sudo usermod -aG docker $USER 加入docker 组之后要重启才能生效哦… Mirror Acceleration没有代理的话国内访问Docker Hub的速度实在感人，但Docker官方和国内很多云服务商都提供了加速器服务： Docker 官方提供的中国registry mirror 阿里云加速器 DaoCloud 加速器 灵雀云加速器 如阿里，注册并申请后会得到加速域名如https://vioqnt8w.mirror.aliyuncs.com，然后正如官方说的一样，通过修改daemon配置文件/etc/docker/daemon.json来使用加速器：12345678sudo mkdir -p /etc/dockersudo tee /etc/docker/daemon.json &lt;&lt;-&apos;EOF&apos;&#123; &quot;registry-mirrors&quot;: [&quot;https://vioqnt8w.mirror.aliyuncs.com&quot;]&#125;EOFsudo systemctl daemon-reloadsudo systemctl restart docker 查看生效： 1sudo docker info|grep &quot;Registry Mirrors&quot; -A 1 输出如下： 12Registry Mirrors: https://vioqnt8w.mirror.aliyuncs.com/ 镜像的相关操作获取Docker Hub 上有大量的高质量的镜像可以用，我们可以通过以下的方式获取镜像：1docker pull [选项] [Docker Registry地址]&lt;仓库名&gt;:&lt;标签&gt; 选项可以通过docker pull --help查看。eg，从Docker Hub下载REPOSITORY为java的所有镜像：1docker pull -a java 列出使用docker images [OPTIONS] [REPOSITORY[:TAG]]列出已下载的镜像列表包含了仓库名、标签、镜像 ID、创建时间以及所占用的空间 OPTIONS说明：123456-a :列出本地所有的镜像（含中间映像层，默认情况下，过滤掉中间映像层）；--digests :显示镜像的摘要信息；-f :显示满足条件的镜像；--format :指定返回值的模板文件；--no-trunc :显示完整的镜像信息；-q :只显示镜像ID。 eg:12# 看到在 mongo:3.2 之后建立的镜像,想查看某个位置之前的镜像也可以，只需要把 since 换成 before 即可docker images -f since=mongo:3.2 虚悬镜像(dangling image)举个例子：原来为 mongo:3.2，随着官方镜像维护，发布了新版本后，重新 docker pull mongo:3.2 时，mongo:3.2 这个镜像名被转移到了新下载的镜像身上，而旧的镜像上的这个名称则被取消，从而成为了 &lt;none&gt;。除了 docker pull 可能导致这种情况，docker build 也同样可以导致这种现象。由于新旧镜像同名，旧镜像名称被取消，从而出现仓库名、标签均为 &lt;none&gt; 的镜像。这类无标签镜像也被称为 虚悬镜像(dangling image) ，可以用下面的命令专门显示这类镜像：1docker images -f dangling=true 一般来说，虚悬镜像已经失去了存在的价值，是可以随意删除的，可以用下面的命令删除：1docker rmi $(docker images -q -f dangling=true) Commit从容器创建一个新的镜像:1docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]] OPTIONS说明：1234-a :提交的镜像作者；-c :使用Dockerfile指令来创建镜像；-m :提交时的说明文字；-p :在commit时，将容器暂停。 eg:1docker commit -a &quot;ybd&quot; -m &quot;my apache&quot; a404c6c174a2 mymysql:v1 当我们修改了镜像文件提交时候，可以使用docker diff [OPTIONS] CONTAINER查看修改了什么东西。一般地，不推荐使用commit来构建镜像，之前也提过，镜像是特殊的文件系统，改了东西之后原来的基础之上叠加，使之变得越来越臃肿。此外，使用 docker commit 意味着所有对镜像的操作都是黑箱操作，生成的镜像也被称为黑箱镜像，换句话说，就是除了制作镜像的人知道执行过什么命令、怎么生成的镜像，别人根本无从得知。一般我们会使用Dockerfile定制镜像。 删除删除镜像可以使用：1docker rmi [OPTIONS] IMAGE [IMAGE...] OPTIONS说明：12-f :强制删除；--no-prune :不移除该镜像的过程镜像，默认移除； 一般会组合使用： 12345docker rmi $(docker images -q -f dangling=true)docker rmi $(docker images -q redis)docker rmi $(docker images -q -f before=mongo:3.2) 查看元数据docker inspect : 获取容器/镜像的元数据。 1docker inspect [OPTIONS] CONTAINER|IMAGE [CONTAINER|IMAGE...] OPTIONS说明： 123-f :指定返回值的模板文件。-s :显示总的文件大小。--type :为指定类型返回JSON。 实例 获取镜像mysql:5.6的元信息。 1234567891011121314151617181920212223~: docker inspect mysql:5.6[ &#123; &quot;Id&quot;: &quot;sha256:2c0964ec182ae9a045f866bbc2553087f6e42bfc16074a74fb820af235f070ec&quot;, &quot;RepoTags&quot;: [ &quot;mysql:5.6&quot; ], &quot;RepoDigests&quot;: [], &quot;Parent&quot;: &quot;&quot;, &quot;Comment&quot;: &quot;&quot;, &quot;Created&quot;: &quot;2016-05-24T04:01:41.168371815Z&quot;, &quot;Container&quot;: &quot;e0924bc460ff97787f34610115e9363e6363b30b8efa406e28eb495ab199ca54&quot;, &quot;ContainerConfig&quot;: &#123; &quot;Hostname&quot;: &quot;b0cf605c7757&quot;, &quot;Domainname&quot;: &quot;&quot;, &quot;User&quot;: &quot;&quot;, &quot;AttachStdin&quot;: false, &quot;AttachStdout&quot;: false, &quot;AttachStderr&quot;: false, &quot;ExposedPorts&quot;: &#123; &quot;3306/tcp&quot;: &#123;&#125; &#125;,... 获取正在运行的容器mymysql的 IP。 12~: docker inspect -f &apos;&apos; mymysql172.17.0.3 查看容器内部IP： 12docker inspect --format=&apos;&#123;\&#123;.NetworkSettings.IPAddress&#125;&#125;&apos; CONTAINER（注：由于代码块解析的问题，上面NetworkSettings前面的 \ 去掉） 标签docker tag： 1docker tag IMAGE/CONTAINER TAG ex： 1234将同一IMAGE_ID的所有tag，合并为一个新的# docker tag 195eb2565349 ybd/ubuntu:rm_test新建一个tag，保留旧的那条记录# docker tag Registry/Repos:Tag New_Registry/New_Repos:New_Tag 保存镜像到归档文件docker save : 将指定镜像保存成 tar 归档文件。 1docker save [OPTIONS] IMAGE [IMAGE...] OPTIONS说明： 1-o :输出到的文件。 实例 将镜像runoob/ubuntu:v3 生成my_ubuntu_v3.tar文档 runoob@runoob:~$ docker save -o my_ubuntu_v3.tar runoob/ubuntu:v3 导入镜像Importdocker import : 从归档文件中创建镜像。 1docker import [OPTIONS] file|URL|- [REPOSITORY[:TAG]] OPTIONS说明： 123-c :应用docker 指令创建镜像；-m :提交时的说明文字； 例如： 1docker import ubuntu.tar ybd/ubuntu:v1 LoadUsage: docker load [OPTIONS] Load an image from a tar archive or STDIN Options: 123-i, --input string Read from tar archive file, instead of STDIN-q, --quiet Suppress the load output 区别 首先，docker import可以重新指定镜像的名字，docker load不可以 其次，我们发现导出后的版本会比原来的版本稍微小一些。那是因为导出后，会丢失历史和元数据。执行下面的命令就知道了：显示镜像的所有层(layer)docker images --tree执行命令，显示下面的内容。正你看到的，导出后再导入(exported-imported)的镜像会丢失所有的历史，而保存后再加载（saveed-loaded）的镜像没有丢失历史和层(layer)。这意味着使用导出后再导入的方式，你将无法回滚到之前的层(layer)，同时，使用保存后再加载的方式持久化整个镜像，就可以做到层回滚（可以执行docker tag 来回滚之前的层）。 容器的相关操作开启docker run ：创建一个新的容器并运行一个命令 docker create ：创建一个新的容器但不启动它12docker run [OPTIONS] IMAGE [COMMAND] [ARG...]docker create [OPTIONS] IMAGE [COMMAND] [ARG...] docker run OPTIONS说明：123456789101112131415161718192021222324252627282930313233-a stdin: 指定标准输入输出内容类型，可选 STDIN/STDOUT/STDERR 三项；-d: 后台运行容器，并返回容器ID；-i: 以交互模式运行容器，通常与 -t 同时使用；-t: 为容器重新分配一个伪输入终端，通常与 -i 同时使用；-v: 挂载数据卷--name=&quot;nginx-lb&quot;: 为容器指定一个名称；--restart=always: docker启动容器也跟着启动--dns 8.8.8.8: 指定容器使用的DNS服务器，默认和宿主一致；--dns-search example.com: 指定容器DNS搜索域名，默认和宿主一致；-h &quot;mars&quot;: 指定容器的hostname；-e username=&quot;ritchie&quot;: 设置环境变量；--env-file=[]: 从指定文件读入环境变量；--cpuset=&quot;0-2&quot; or --cpuset=&quot;0,1,2&quot;: 绑定容器到指定CPU运行；-m :设置容器使用内存最大值；--net=&quot;bridge&quot;: 指定容器的网络连接类型，支持 bridge/host/none/container: 四种类型；--link=[]: 添加链接到另一个容器；--expose=[]: 开放一个端口或一组端口； &lt;b&gt;实例&lt;/b&gt; 例如，启动一个 bash 终端，允许用户进行交互：1docker run -t -i ubuntu:14.04 /bin/bash 当利用 docker run 来创建容器时，Docker 在后台运行的标准操作包括： 检查本地是否存在指定的镜像，不存在就从公有仓库下载 利用镜像创建并启动一个容器 分配一个文件系统，并在只读的镜像层外面挂载一层可读写层 从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去 从地址池配置一个 ip 地址给容器 执行用户指定的应用程序 执行完毕后容器被终止 启动一个es并指明healthcheck相关策略： 1234567docker run --rm -d \ --name=elasticsearch \ --health-cmd=&quot;curl --silent --fail localhost:9200/_cluster/health || exit 1&quot; \ --health-interval=5s \ --health-retries=12 \ --health-timeout=2s \ elasticsearch:5.5 暂停docker pause :暂停容器中所有的进程。 docker unpause :恢复容器中所有的进程。 123docker pause [OPTIONS] CONTAINER [CONTAINER...]docker unpause [OPTIONS] CONTAINER [CONTAINER...] 实例 暂停数据库容器db01提供服务。 1docker pause db01 恢复数据库容器db01提供服务。 1docker unpause db01 停止docker stop :停止一个运行中的容器：1docker stop [OPTIONS] CONTAINER [CONTAINER...] 杀掉容器docker kill :杀掉一个运行中的容器。 1docker kill [OPTIONS] CONTAINER [CONTAINER...] OPTIONS说明： 1-s :向容器发送一个信号 实例 杀掉运行中的容器mynginx 1docker kill -s KILL mynginx 进入容器使用docker exec ：1docker exec [OPTIONS] CONTAINER COMMAND [ARG...] OPTIONS说明：12345-d :分离模式: 在后台运行-i :即使没有附加也保持STDIN 打开-t :分配一个伪终端 例如进入ubuntu容器交互式模式：1docker exec -it ubuntu /bin/sh 或者使用docker attach： 1docker attach --sig-proxy=false CONTAINER attach是可以带上--sig-proxy=false来确保CTRL-D或CTRL-C不会关闭容器。 导出容器导出容器快照1docker export [OPTIONS] CONTAINER 例如：1docker export 7691a814370e &gt; ubuntu.tar 删除1docker rm [OPTIONS] CONTAINER [CONTAINER...] OPTIONS说明：12345-f :通过SIGKILL信号强制删除一个运行中的容器-l :移除容器间的网络连接，而非容器本身-v :-v 删除与容器关联的卷 删除所有容器：1docker rm $(docker ps -a -q) 但这并不会删除运行中的容器 列出容器1docker ps [OPTIONS] OPTIONS说明：123456789101112131415-a :显示所有的容器，包括未运行的。-f, --filter :根据条件过滤显示的内容。--format :指定返回值的模板文件。-l :显示最近创建的容器。-n :列出最近创建的n个容器。--no-trunc :不截断输出。-q :静默模式，只显示容器编号。-s :显示总的文件大小。 例如列出最近创建的5个容器信息：1docker ps -n 5 列出所有创建的容器ID：1docker ps -a -q 下面是docker官方的filter参数： Filter Description id Container’s ID name Container’s name label An arbitrary string representing either a key or a key-value pair. Expressed as &lt;key&gt; or &lt;key&gt;=&lt;value&gt; exited An integer representing the container’s exit code. Only useful with --all. status One of created, restarting, running, removing, paused, exited, or dead ancestor Filters containers which share a given image as an ancestor. Expressed as &lt;image-name&gt;[:&lt;tag&gt;], &lt;image id&gt;, or &lt;image@digest&gt; before or since Filters containers created before or after a given container ID or name volume Filters running containers which have mounted a given volume or bind mount. network Filters running containers connected to a given network. publish or expose Filters containers which publish or expose a given port. Expressed as &lt;port&gt;[/&lt;proto&gt;] or &lt;startport-endport&gt;/[&lt;proto&gt;] health Filters containers based on their healthcheck status. One of starting, healthy, unhealthy or none. isolation Windows daemon only. One of default, process, or hyperv. is-task Filters containers that are a “task” for a service. Boolean option (true or false) ex 列出所有状态为退出的容器： 1docker ps -q --filter status=exited 查看日志1docker logs [OPTIONS] CONTAINER OPTIONS说明： 1234567-f : 跟踪日志输出--since :显示某个开始时间的所有日志-t : 显示时间戳--tail :仅列出最新N条容器日志 数据拷贝docker cp :用于容器与主机之间的数据拷贝。 123docker cp [OPTIONS] CONTAINER:SRC_PATH DEST_PATH|-docker cp [OPTIONS] SRC_PATH|- CONTAINER:DEST_PATH OPTIONS说明： 1-L :保持源目标中的链接 实例 将主机/www/runoob目录拷贝到容器96f7f14e99ab的/www目录下。 1docker cp /www/runoob 96f7f14e99ab:/www/ 将主机/www/runoob目录拷贝到容器96f7f14e99ab中，目录重命名为www。 1docker cp /www/runoob 96f7f14e99ab:/www 将容器96f7f14e99ab的/www目录拷贝到主机的/tmp目录中。 1docker cp 96f7f14e99ab:/www /tmp/ Volume的相关操作Usage: docker volume COMMAND Command Description docker volume create Create a volume docker volume inspect Display detailed information on one or more volumes docker volume ls List volumes docker volume prune Remove all unused volumes docker volume rm Remove one or more volumes ex 删除所有悬浮的volume： 1docker volume rm $(docker volume ls -q -f dangling=true) 选择 -v 还是 -–mount 参数Docker 新用户应该选择 --mount 参数，经验丰富的 Docker 使用者对 -v 或者 --volume 已经很熟悉了，但是推荐使用 --mount 参数。 使用 --mount 标记可以指定挂载一个本地主机的目录到容器中去。 12345$ docker run -d -P \--name web \--mount type=bind,source=/src/webapp,target=/opt/webapp \training/webapp \python app.py 上面的命令加载主机的 /src/webapp 目录到容器的 /opt/webapp目录。这个功能在进行测试的时候十分方便，比如用户可以放置一些程序到本地目录中，来查看容器是否正常工作。本地目录的路径必须是绝对路径，以前使用 -v 参数时如果本地目录不存在 Docker 会自动为你创建一个文件夹，现在使用 --mount 参数时如果本地目录不存在，Docker 会报错。 Docker 挂载主机目录的默认权限是 读写，用户也可以通过增加 readonly 指定为 只读。 12345docker run -d -P \--name web \--mount type=bind,source=/src/webapp,target=/opt/webapp,readonly \training/webapp \python app.py Network的相关操作基本命令： 123456docker network createdocker network connectdocker network lsdocker network rmdocker network disconnectdocker network inspect 下面先创建一个新的 Docker 网络。 1docker network create -d bridge my-net -d 参数指定 Docker 网络类型，有 bridge overlay。其中 overlay 网络类型用于 Swarm mode 容器链接网络： 1docker run -it --rm --name busybox1 --network my-net busybox sh 创建一个Swarm mode网络： 1234567docker network create \--driver overlay \--opt encrypted \--attachable \--subnet 10.0.9.0/24 \--gateway 10.0.9.99 \my-network Dockerfile 详解 制作一个镜像可以使用docker commit和定制Dockerfile，但推荐的是写Dockerfile。 因为docker commit是一个暗箱操作，除了制作镜像的人知道执行过什么命令、怎么生成的镜像，别人根本无从得知，而且会加入一些没用的操作导致镜像臃肿。 Build Images首先在当前空目录创建一个Dockerfile：123456789101112131415161718192021222324FROM ubuntu:latestENV BLOG_PATH /root/blogENV NODE_VERSION 6MAINTAINER yangbingdong &lt;yangbingdong1994@gmail.com&gt;RUN \ apt-get update -y &amp;&amp; \ apt-get install -y git curl libpng-dev &amp;&amp; \ curl -sL https://deb.nodesource.com/setup_$NODE_VERSION.x | bash - &amp;&amp; \ apt-get install -y nodejs &amp;&amp; \ apt-get clean &amp;&amp; \ apt-get autoclean &amp;&amp; \ rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/* &amp;&amp; \ npm install -g hexo-cliWORKDIR $BLOG_PATHVOLUME [&quot;$BLOG_PATH&quot;, &quot;/root/.ssh&quot;]EXPOSE 4000CMD [&apos;/bin/bash&apos;] 然后在当前目录打开终端：1docker build -t &lt;repo-name&gt;/&lt;image-name&gt;:&lt;tag&gt; . 其中&lt;repo-name&gt;表示仓库名，与远程仓库（如docker hub）名字要一致，&lt;tag&gt;表示标签，不给默认latest，都是可选项，例如可以写成这样：1docker build -t &lt;image-name&gt; . 看到Successfully built就表示构建成功了 注意docker build 命令最后有一个 .表示构建的上下文，镜像构建需要把上下文的东西上传到Docker引擎去构建。 Dockerfile 指令From 指定基础镜像所谓定制镜像，那一定是以一个镜像为基础，在其上进行定制。而 FROM 就是指定基础镜像，因此一个 Dockerfile 中 FROM 是必备的指令，并且必须是第一条指令。 在 Docker Hub上有非常多的高质量的官方镜像， 有可以直接拿来使用的服务类的镜像，如 nginx、redis、mongo、mysql、httpd、php、tomcat 等； 也有一些方便开发、构建、运行各种语言应用的镜像，如 node、openjdk、python、ruby、golang 等。 可以在其中寻找一个最符合我们最终目标的镜像为基础镜像进行定制。 如果没有找到对应服务的镜像，官方镜像中还提供了一些更为基础的操作系统镜像，如 ubuntu、debian、centos、fedora、alpine 等，这些操作系统的软件库为我们提供了更广阔的扩展空间。 除了选择现有镜像为基础镜像外，Docker 还存在一个特殊的镜像，名为 scratch。这个镜像是虚拟的概念，并不实际存在，它表示一个空白的镜像。 RUN 执行命令RUN 指令是用来执行命令行命令的。由于命令行的强大能力，RUN 指令在定制镜像时是最常用的指令之一。其格式有两种： shell 格式：RUN &lt;命令&gt;，就像直接在命令行中输入的命令一样。刚才写的 Dockrfile 中的 RUN 指令就是这种格式。 1RUN echo &apos;&lt;h1&gt;Hello, Docker!&lt;/h1&gt;&apos; &gt; /usr/share/nginx/html/index.html exec 格式：RUN [&quot;可执行文件&quot;, &quot;参数1&quot;, &quot;参数2&quot;]，这更像是函数调用中的格式。 注意： RUN命令尽量精简，也就是像上面一样一个RUN（使用$$ \），如果分开写很多个RUN会导致镜像铺了很多层从而臃肿。 RUN最后记住清理掉没用的垃圾，很多人初学 Docker 制作出了很臃肿的镜像的原因之一，就是忘记了每一层构建的最后一定要清理掉无关文件。 COPY 复制文件格式： COPY &lt;源路径&gt;... &lt;目标路径&gt; COPY [&quot;&lt;源路径1&gt;&quot;,... &quot;&lt;目标路径&gt;&quot;] 和 RUN 指令一样，也有两种格式，一种类似于命令行，一种类似于函数调用。 COPY 指令将从构建上下文目录中 &lt;源路径&gt; 的文件/目录复制到新的一层的镜像内的 &lt;目标路径&gt; 位置。比如：1COPY package.json /usr/src/app/ ADD 更高级的复制文件ADD 指令和 COPY 的格式和性质基本一致。但是在 COPY 基础上增加了一些功能。 比如 &lt;源路径&gt; 可以是一个 URL，这种情况下，Docker 引擎会试图去下载这个链接的文件放到 &lt;目标路径&gt; 去。下载后的文件权限自动设置为 600，如果这并不是想要的权限，那么还需要增加额外的一层 RUN进行权限调整，另外，如果下载的是个压缩包，需要解压缩，也一样还需要额外的一层 RUN 指令进行解压缩。所以不如直接使用 RUN 指令，然后使用 wget 或者 curl 工具下载，处理权限、解压缩、然后清理无用文件更合理。因此，这个功能其实并不实用，而且不推荐使用。 如果 &lt;源路径&gt; 为一个 tar 压缩文件的话，压缩格式为 gzip, bzip2 以及 xz 的情况下，ADD 指令将会自动解压缩这个压缩文件到 &lt;目标路径&gt; 去。 在某些情况下，这个自动解压缩的功能非常有用，比如官方镜像 ubuntu 中： 123FROM scratchADD ubuntu-xenial-core-cloudimg-amd64-root.tar.gz /... 但在某些情况下，如果我们真的是希望复制个压缩文件进去，而不解压缩，这时就不可以使用 ADD 命令了。 在 Docker 官方的最佳实践文档中要求，尽可能的使用 COPY，因为 COPY 的语义很明确，就是复制文件而已，而 ADD 则包含了更复杂的功能，其行为也不一定很清晰。最适合使用 ADD 的场合，就是所提及的需要自动解压缩的场合。 另外需要注意的是，ADD 指令会令镜像构建缓存失效，从而可能会令镜像构建变得比较缓慢。 因此在 COPY 和 ADD 指令中选择的时候，可以遵循这样的原则，所有的文件复制均使用 COPY 指令，仅在需要自动解压缩的场合使用 ADD。 CMD 容器启动命令CMD 指令就是用于指定默认的容器主进程的启动命令的。 CMD 指令的格式和 RUN 相似，也是两种格式： shell 格式：CMD &lt;命令&gt; exec 格式：CMD [&quot;可执行文件&quot;, &quot;参数1&quot;, &quot;参数2&quot;...] 参数列表格式：CMD [&quot;参数1&quot;, &quot;参数2&quot;...]。在指定了 ENTRYPOINT 指令后，用 CMD 指定具体的参数。 在运行时可以指定新的命令来替代镜像设置中的这个默认命令，比如，ubuntu 镜像默认的 CMD 是 /bin/bash，如果我们直接 docker run -it ubuntu 的话，会直接进入 bash。我们也可以在运行时指定运行别的命令，如 docker run -it ubuntu cat /etc/os-release。这就是用 cat /etc/os-release 命令替换了默认的 /bin/bash 命令了，输出了系统版本信息。 在指令格式上，一般推荐使用 exec 格式，这类格式在解析时会被解析为 JSON 数组，因此一定要使用双引号 &quot;，而不要使用单引号。 如果使用 shell 格式的话，实际的命令会被包装为 sh -c 的参数的形式进行执行。比如：1CMD echo $HOME 在实际执行中，会将其变更为：1CMD [ &quot;sh&quot;, &quot;-c&quot;, &quot;echo $HOME&quot; ] 所以如果使用shell格式会导致容器莫名退出，因为实际上执行的事sh命令，而sh命令执行完时候容器也就没有存在的意义。 ENTRYPOINT 入口点ENTRYPOINT 的格式和 RUN 指令格式一样，分为 exec 格式和 shell 格式。 ENTRYPOINT 的目的和 CMD 一样，都是在指定容器启动程序及参数。ENTRYPOINT 在运行时也可以替代，不过比 CMD 要略显繁琐，需要通过 docker run 的参数 --entrypoint 来指定。 当指定了 ENTRYPOINT 后，CMD 的含义就发生了改变，不再是直接的运行其命令，而是将 CMD 的内容作为参数传给 ENTRYPOINT 指令，换句话说实际执行时，将变为： 1&lt;ENTRYPOINT&gt; &quot;&lt;CMD&gt;&quot; 这个指令非常有用，例如可以把命令后面的参数传进来或启动容器前准备一些环境然后执行启动命令（通过脚本exec &quot;$@&quot;）。 ENV 设置环境变量格式有两种： ENV &lt;key&gt; &lt;value&gt; ENV &lt;key1&gt;=&lt;value1&gt; &lt;key2&gt;=&lt;value2&gt;... 这个指令很简单，就是设置环境变量而已，无论是后面的其它指令，如 RUN，还是运行时的应用，都可以直接使用这里定义的环境变量。 ex： 1234ENV NODE_VERSION 6...RUN curl -sL https://deb.nodesource.com/setup_$NODE_VERSION.x | bash - &amp;&amp; \... ARG 构建参数格式：ARG &lt;参数名&gt;[=&lt;默认值&gt;] 构建参数和 ENV 的效果一样，都是设置环境变量。所不同的是，ARG 所设置的构建环境的环境变量，在将来容器运行时是不会存在这些环境变量的。但是不要因此就使用 ARG 保存密码之类的信息，因为 docker history 还是可以看到所有值的。 Dockerfile 中的 ARG 指令是定义参数名称，以及定义其默认值。该默认值可以在构建命令 docker build 中用 --build-arg &lt;参数名&gt;=&lt;值&gt; 来覆盖。 在 1.13 之前的版本，要求 --build-arg 中的参数名，必须在 Dockerfile 中用 ARG 定义过了，换句话说，就是 --build-arg 指定的参数，必须在 Dockerfile 中使用了。如果对应参数没有被使用，则会报错退出构建。从 1.13 开始，这种严格的限制被放开，不再报错退出，而是显示警告信息，并继续构建。这对于使用 CI 系统，用同样的构建流程构建不同的 Dockerfile 的时候比较有帮助，避免构建命令必须根据每个 Dockerfile 的内容修改。 VOLUME 定义匿名卷格式为： VOLUME [&quot;&lt;路径1&gt;&quot;, &quot;&lt;路径2&gt;&quot;...] VOLUME &lt;路径&gt; 之前我们说过，容器运行时应该尽量保持容器存储层不发生写操作，对于数据库类需要保存动态数据的应用，其数据库文件应该保存于卷(volume)中，后面的章节我们会进一步介绍 Docker 卷的概念。为了防止运行时用户忘记将动态文件所保存目录挂载为卷，在 Dockerfile 中，我们可以事先指定某些目录挂载为匿名卷，这样在运行时如果用户不指定挂载，其应用也可以正常运行，不会向容器存储层写入大量数据。1VOLUME /data 这里的 /data 目录就会在运行时自动挂载为匿名卷，任何向 /data 中写入的信息都不会记录进容器存储层，从而保证了容器存储层的无状态化。当然，运行时可以覆盖这个挂载设置。比如：1docker run -d -v mydata:/data xxxx 在这行命令中，就使用了 mydata 这个命名卷挂载到了 /data 这个位置，替代了 Dockerfile 中定义的匿名卷的挂载配置。 EXPOSE 声明端口格式为 EXPOSE &lt;端口1&gt; [&lt;端口2&gt;...]。EXPOSE 指令是声明运行时容器提供服务端口，这只是一个声明，在运行时并不会因为这个声明应用就会开启这个端口的服务。在 Dockerfile 中写入这样的声明有两个好处，一个是帮助镜像使用者理解这个镜像服务的守护端口，以方便配置映射；另一个用处则是在运行时使用随机端口映射时，也就是 docker run -P时，会自动随机映射 EXPOSE 的端口。 此外，在早期 Docker 版本中还有一个特殊的用处。以前所有容器都运行于默认桥接网络中，因此所有容器互相之间都可以直接访问，这样存在一定的安全性问题。于是有了一个 Docker 引擎参数 --icc=false，当指定该参数后，容器间将默认无法互访，除非互相间使用了 --links 参数的容器才可以互通，并且只有镜像中 EXPOSE 所声明的端口才可以被访问。这个 --icc=false 的用法，在引入了 docker network后已经基本不用了，通过自定义网络可以很轻松的实现容器间的互联与隔离。 要将 EXPOSE 和在运行时使用 -p &lt;宿主端口&gt;:&lt;容器端口&gt; 区分开来。-p，是映射宿主端口和容器端口，换句话说，就是将容器的对应端口服务公开给外界访问，而 EXPOSE 仅仅是声明容器打算使用什么端口而已，并不会自动在宿主进行端口映射。 WORKDIR 指定工作目录格式为 WORKDIR &lt;工作目录路径&gt;。使用 WORKDIR 指令可以来指定工作目录（或者称为当前目录），以后各层的当前目录就被改为指定的目录，如该目录不存在，WORKDIR 会帮你建立目录。 之前提到一些初学者常犯的错误是把 Dockerfile 等同于 Shell 脚本来书写，这种错误的理解还可能会导致出现下面这样的错误：12RUN cd /appRUN echo &quot;hello&quot; &gt; world.txt 如果将这个 Dockerfile 进行构建镜像运行后，会发现找不到 /app/world.txt 文件，或者其内容不是 hello。原因其实很简单，在 Shell 中，连续两行是同一个进程执行环境，因此前一个命令修改的内存状态，会直接影响后一个命令；而在 Dockerfile 中，这两行 RUN 命令的执行环境根本不同，是两个完全不同的容器。这就是对 Dokerfile 构建分层存储的概念不了解所导致的错误。 之前说过每一个 RUN 都是启动一个容器、执行命令、然后提交存储层文件变更。第一层 RUN cd /app 的执行仅仅是当前进程的工作目录变更，一个内存上的变化而已，其结果不会造成任何文件变更。而到第二层的时候，启动的是一个全新的容器，跟第一层的容器更完全没关系，自然不可能继承前一层构建过程中的内存变化。 因此如果需要改变以后各层的工作目录的位置，那么应该使用 WORKDIR 指令。 USER 指定当前用户格式：USER &lt;用户名&gt; USER 指令和 WORKDIR 相似，都是改变环境状态并影响以后的层。WORKDIR 是改变工作目录，USER则是改变之后层的执行 RUN, CMD 以及 ENTRYPOINT 这类命令的身份。 当然，和 WORKDIR 一样，USER 只是帮助你切换到指定用户而已，这个用户必须是事先建立好的，否则无法切换。 123RUN groupadd -r redis &amp;&amp; useradd -r -g redis redisUSER redisRUN [ &quot;redis-server&quot; ] HEALTHCHECK 健康检查格式： HEALTHCHECK [选项] CMD &lt;命令&gt;：设置检查容器健康状况的命令 HEALTHCHECK NONE：如果基础镜像有健康检查指令，使用这行可以屏蔽掉其健康检查指令 HEALTHCHECK 支持下列选项： --interval=&lt;间隔&gt;：两次健康检查的间隔，默认为 30 秒； --timeout=&lt;间隔&gt;：健康检查命令运行超时时间，如果超过这个时间，本次健康检查就被视为失败，默认 30 秒； --retries=&lt;次数&gt;：当连续失败指定次数后，则将容器状态视为 unhealthy，默认 3 次。 --start-period=&lt;间隔&gt;: 应用的启动的初始化时间，在启动过程中的健康检查失效不会计入，默认 0 秒； (从17.05)引入 在 HEALTHCHECK [选项] CMD 后面的命令，格式和 ENTRYPOINT 一样，分为 shell 格式，和 exec 格式。命令的返回值决定了该次健康检查的成功与否： 0：成功； 1：失败； 2：保留值，不要使用 容器启动之后，初始状态会为 starting (启动中)。Docker Engine会等待 interval 时间，开始执行健康检查命令，并周期性执行。如果单次检查返回值非0或者运行需要比指定 timeout 时间还长，则本次检查被认为失败。如果健康检查连续失败超过了 retries 重试次数，状态就会变为 unhealthy (不健康)。 注： 一旦有一次健康检查成功，Docker会将容器置回 healthy (健康)状态 当容器的健康状态发生变化时，Docker Engine会发出一个 health_status 事件。 假设我们有个镜像是个最简单的 Web 服务，我们希望增加健康检查来判断其 Web 服务是否在正常工作，我们可以用 curl来帮助判断，其 Dockerfile 的 HEALTHCHECK 可以这么写： 1234FROM elasticsearch:5.5HEALTHCHECK --interval=5s --timeout=2s --retries=12 \ CMD curl --silent --fail localhost:9200/_cluster/health || exit 1 踩坑 Dockerfile里也需要注意权限问题（nodejs7版本以上不能正常安装hexo，需要创建用户并制定权限去安装） 在docker容器里如果是root用户对挂载的文件进行了操作，那么实际上挂载文件的权限也变成了root的 使用attach进入容器，退出的时候容器也跟着退出了。。。囧 每一个RUN是一个新的shell su -之前在启动脚本加了-，导致环境变量以及工作目录都变了 Hexo Dockerfile12345678910111213141516171819202122232425262728293031323334353637FROM ubuntu:16.04MAINTAINER yangbingdong &lt;yangbingdong1994@gmail.com&gt;USER rootENV NODE_VERSION 8.9.4ENV NODE_DIR /opt/nodejsENV HOXO_DIR /root/hexoRUN apt-get update &amp;&amp; \ apt-get install -y git curl &amp;&amp; \ mkdir $&#123;NODE_DIR&#125; &amp;&amp; \ curl -L https://nodejs.org/dist/v$&#123;NODE_VERSION&#125;/node-v$&#123;NODE_VERSION&#125;-linux-x64.tar.gz | tar xvzf - -C $&#123;NODE_DIR&#125; --strip-components=1 ENV PATH $PATH:$&#123;NODE_DIR&#125;/binRUN npm install -g hexo-cliENV PATH $PATH:$&#123;NODE_DIR&#125;/binRUN cd /root &amp;&amp; \ hexo init hexo &amp;&amp; \ cd hexo &amp;&amp; \ git clone https://github.com/iissnan/hexo-theme-next themes/next &amp;&amp; \ npm install &amp;&amp; \ apt-get clean &amp;&amp; \ apt-get autoremove -y &amp;&amp; \ rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/*VOLUME [&quot;/root/hexo/source/_posts&quot;] WORKDIR /root/hexoCOPY docker-entrypoint.sh /docker-entrypoint.shENTRYPOINT [&quot;/docker-entrypoint.sh&quot;] docker-entrypoint.sh: 1234#!/bin/shset -ehexo clean &amp;&amp; hexo serverexec &quot;$@&quot; 修改Docker默认镜像，容器存放位置方法一、软链接默认情况下Docker的存放位置为：/var/lib/docker可以通过下面命令查看具体位置： 1sudo docker info | grep &quot;Docker Root Dir&quot; 解决这个问题，最直接的方法当然是挂载分区到这个目录，但是我的数据盘还有其他东西，这肯定不好管理，所以采用修改镜像和容器的存放路径的方式达到目的。 这个方法里将通过软连接来实现。 首先停掉Docker服务： 123systemctl restart docker或者service docker stop 然后移动整个/var/lib/docker目录到目的路径： 12mv /var/lib/docker /root/data/dockerln -s /root/data/docker /var/lib/docker 这时候启动Docker时发现存储目录依旧是/var/lib/docker，但是实际上是存储在数据盘的，你可以在数据盘上看到容量变化。 方法二、修改镜像和容器的存放路径指定镜像和容器存放路径的参数是--graph=/var/lib/docker，我们只需要修改配置文件指定启动参数即可。 Docker 的配置文件可以设置大部分的后台进程参数，在各个操作系统中的存放位置不一致，在 Ubuntu 中的位置是：/etc/default/docker，在 CentOS 中的位置是：/etc/sysconfig/docker。 如果是 CentOS 则添加下面这行： 1OPTIONS=--graph=&quot;/root/data/docker&quot; --selinux-enabled -H fd:// 如果是 Ubuntu 则添加下面这行（因为 Ubuntu 默认没开启 selinux）： 123OPTIONS=--graph=&quot;/root/data/docker&quot; -H fd://# 或者DOCKER_OPTS=&quot;-g /root/data/docker&quot; 最后重新启动，Docker 的路径就改成 /root/data/docker 了。 定期清理容器日志 参考：https://zhuanlan.zhihu.com/p/29051214 通过logrotate服务实现日志定期清理和回卷logrotate是个十分有用的工具，它可以自动对日志进行截断（或轮循）、压缩以及删除旧的日志文件。例如，你可以设置logrotate，让/var/log/foo日志文件每30天轮循，并删除超过6个月的日志。配置完后，logrotate的运作完全自动化，不必进行任何进一步的人为干预。 https://github.com/blacklabelops/logrotate 通过修改dockerd参数进行回卷和清理在/etc/docker/daemon.json中添加log-driver以及log-opts参数： 12345678&#123; &quot;registry-mirrors&quot;: [&quot;https://vioqnt8w.mirror.aliyuncs.com&quot;], &quot;insecure-registries&quot;: [&quot;192.168.6.113:8888&quot;], &quot;log-driver&quot;:&quot;json-file&quot;, &quot;log-opts&quot;:&#123; &quot;max-size&quot; :&quot;10m&quot;,&quot;max-file&quot;:&quot;3&quot; &#125;&#125; 参数说明： 设置单个容器日志超过10M则进行回卷，回卷的副本数超过3个就进行清理。 重启docker 1sudo systemctl daemon-reload &amp;&amp; sudo systemctl restart docker 数据卷备份与恢复数据卷备份12345docker run --rm \ --volumes-from &lt;ContainerName&gt; \ -v $(pwd):/backup \ busybox \ tar cvf /backup/backup.tar /data --rm: 执行完命令之后移除容器 --volumes-from &lt;Container&gt;: 连接要备份数据的容器 -v $(pwd):/backup: 挂载当前路径到容器 busybox 容器，数据将会备份到此路径 busybox: 非常小的镜像 tar cvf /backup/backup.tar /data: 将 /data 路径下的文件打包到 backup.tar 数据卷恢复1、新建容器 1docker run -v /data --name &lt;ContainerName&gt; &lt;Image&gt; 2、恢复数据 12345docker run --rm \ --volumes-from &lt;ContainerName&gt; \ -v $(pwd):/backup \ busybox \ tar xvf /backup/backup.tar 注意：其中的路径 /data 仅为示例，具体需要备份的文件路径请结合自身需求。 使用Github自动构建Docker 一开始玩Docker总是用别人的镜像确实很爽歪歪…But，如果要定制个性化的Image那就必须要自己写Dockerfile了，但是每一次修改完Dockerfile，都要经过几个步骤：Built -&gt; Push -&gt; Delete invalid images对于程序猿而言做重复的事情是很恐怖的，所以博主选择Github自动构建Docker Image~ 创建用于自动构建的仓库在Github上面创建一个项目并把Dockerfile以及上下文需要用到的文件放到里面。 链接仓库服务首先需要绑定一个仓库服务（Github）： 1、登录Docker Hub；2、选择 Profile &gt; Settings &gt; Linked Accounts &amp; Services；3、选择需要连接的仓库服务（目前只支持Github和BitBucket）；4、这时候需要授权，点击授权就可以了。 创建一个自动构建自动构建需要创建对应的仓库类型自动构建仓库也可以使用docker push把已有的镜像上传上去1、选择Create &gt; Create Automated Build；2、选择Github；3、接下来会列出User/Organizations的所有项目，从中选择你需要的构建的项目（包含Dockerfile）；4、可以选择Click here to customize自定义路径；5、最后点击创建就可以了。 集成到Github用过Github自动构建当然需要Github的支持啦，这里只需要在Github里面点两下就配置完成，很方便：在Add Service里面找到Docker并添加 构建设置勾选自动构建系统会默认帮我们勾上自动构建选项：这时候，当我们的Dockerfile有变动会自动触发构建：还在构建过程中我们可以点击Cancel取消构建过程。 添加新的构建Docker hub默认选择master分支作为latest版本，我们可以根据自己的标签或分支构建不同的版本： （点击箭头位置会出现例子）这样，当我们创建一个标签如1.0.2并push上去的时候会自动触发构建～ Git标签相关请看：Git标签管理 远程触发构建当然我们也可以远程触发构建，同样在Build Setting页面:然后例子已经说的很清楚了 参考：https://docs.docker.com/docker-hub/builds/ 使用代理构建镜像有时候，我们构建镜像需要在镜像内安装一些软件，因为构建时采用的是bridge模式，对于一些资源比较稀缺或需要科学上网才能安装的软件慢得简直无法忍受。对此，我们可以在构建时设置构建参数（--build-arg）从而达到代理安装的目的。或者也可以用官方的Docker Hub自动构建，或者将Dockerfile上传到VPS进行构建=.=…但感觉没必要。 例如像下面Dockerfile： 123456789FROM XXXXXXMAINTAINER ybd &lt;yangbingdong1994@gmail.com&gt; ARG HTTP_PROXYENV http_proxy=$&#123;HTTP_PROXY&#125; https_proxy=$&#123;HTTP_PROXY&#125;RUN apk update &amp;&amp; \ apk add --no-cache &amp;&amp; \ apk add curl bash tree tzdata .....ENV http_proxy=ENV https_proxy= 然后构建： 1docker build --build-arg HTTP_PROXY=192.168.6.113:8118 -t yangbingdong/oraclejdk8 . 192.168.6.113:8118是从Sock5转换过来的http代理 注意：镜像内软件安装完成时候需要将代理置空，所以上面示例最后两行后面的值是空的，否则接下来容器内发生的网络访问都会走代理… Self Usage Docker Or Compose以下是个人使用的一些容器运行命令或者docker-compose.yml，不定时更新 Mysql运行实例： 1234567891011121314MYSQL_DATA=$&#123;HOME&#125;/data/docker/mysql/data &amp;&amp; \MYSQL_PORT=3306 &amp;&amp; \MYSQL_VERSION=latest &amp;&amp; \docker run --name=mysql \--restart=always \-p $&#123;MYSQL_PORT&#125;:3306 \-v $&#123;MYSQL_DATA&#125;:/var/lib/mysql \-e MYSQL_ROOT_PASSWORD=root \-d \mysql:$&#123;MYSQL_VERSION:-latest&#125; \--character-set-server=utf8mb4 \--collation-server=utf8mb4_unicode_ci \--sql-mode=STRICT_TRANS_TABLES,NO_ENGINE_SUBSTITUTION \--lower-case-table-names=1 链接Mysql服务端需要安装终端客户端： 1sudo apt install mysql-client 链接： 12mysql -h 127.0.0.1 -P 3306 -u root -p// 然后需要输入密码 Redis运行实例： 123456789101112REDIS_DATA=$&#123;HOME&#125;/data/docker/redis/data &amp;&amp; \REDIS_CONF=$&#123;HOME&#125;/data/docker/redis/redis.conf &amp;&amp; \REDIS_PORT=6379 &amp;&amp; \REDIS_VERSION=latest &amp;&amp; \docker run -p $&#123;REDIS_PORT&#125;:6379 \--restart=always \-v $&#123;REDIS_DATA&#125;:/usr/local/etc/redis/redis.conf \-v $&#123;REDIS_DATA&#125;:/data \--name redis \-d \redis:$&#123;REDIS_VERSION:-latest&#125; \redis-server /usr/local/etc/redis/redis.conf --appendonly yes 链接Redis服务端需要安装终端客户端： 1sudo apt install redis-tools 链接： 1redis-cli Portainer功能：管理容器与swarm集群 单机版： 12345docker run -d -p 9000:9000 \--name portainer \--restart=always \-v /var/run/docker.sock:/var/run/docker.sock \portainer/portainer:&#123;PORTAINER_VERSION:-latest&#125; 集群版： 123456789PORTAINER_DATA=$&#123;HOME&#125;/data/docker/portainer/datadocker service create \--name portainer \--publish 9000:9000 \--constraint &apos;node.role == manager&apos; \--mount type=bind,src=/var/run/docker.sock,dst=/var/run/docker.sock \--mount type=bind,src=$&#123;PORTAINER_DATA&#125;,dst=/data \portainer/portainer:&#123;PORTAINER_VERSION:-latest&#125; \-H unix:///var/run/docker.sock Visualizer123456docker service create \--name=viz \--publish=8088:8080/tcp \--constraint=node.role==manager \--mount=type=bind,src=/var/run/docker.sock,dst=/var/run/docker.sock \dockersamples/visualizer Nexus3创建Volume ： 1docker volume create --name nexus-data 运行实例： 12345678NEXUS_PORT=8090 &amp;&amp; \NEXUS_VERSION=3.6.2 &amp;&amp; \docker run --restart=always \-d \-p $&#123;NEXUS_PORT&#125;:8081 \--name nexus \-v nexus-data:/nexus-data \sonatype/nexus3:$&#123;NEXUS_VERSION&#125; 查看启动日志： 1docker logs nexus 备份： 123456789BAK_CONTAINER=ubuntu:latest &amp;&amp; \VOLUME=nexus-data &amp;&amp; \BAK_PATH=$&#123;PWD&#125; &amp;&amp; \BAK_ARCHIVE_NAME=nexus-data &amp;&amp; \docker run --rm \-v $&#123;BAK_PATH&#125;:/backup \-v $&#123;VOLUME&#125;:/backup-data \$&#123;BAK_CONTAINER&#125; \tar zcvf /backup/$&#123;BAK_ARCHIVE_NAME&#125;.tar.gz /backup-data 还原： 先要创建还原的Volume： 1docker volume create --name nexus-data1 然后： 12345678910BAK_CONTAINER=ubuntu:latest &amp;&amp; \RESTORE_VOLUME=nexus-data1 &amp;&amp; \BAK_PATH=$&#123;PWD&#125; &amp;&amp; \BAK_ARCHIVE_NAME=nexus-data &amp;&amp; \docker volume create --name $&#123;RESTORE_VOLUME&#125; &amp;&amp; \docker run --rm \-v $&#123;RESTORE_VOLUME&#125;:/restore \-v $&#123;BAK_PATH&#125;:/backup \ubuntu:latest \tar zxvf /backup/$&#123;BAK_ARCHIVE_NAME&#125;.tar.gz -C /restore --strip-components=1 Shadowsocks服务端： 12345678SS_PASSWORD=123456 &amp;&amp; \SS_PORT=22 &amp;&amp; \docker run -dt \--name ssserver \--restart=always \-p $&#123;SS_PORT&#125;:6443 \mritd/shadowsocks:latest \-m &quot;ss-server&quot; -s &quot;-s 0.0.0.0 -p 6443 -m aes-256-cfb -k $&#123;PASSWORD&#125; --fast-open&quot; 客户端： 123456789SS_IP=127.0.0.1 &amp;&amp; \SS_PORT=22 &amp;&amp; \SS_PASSWORD=123456 &amp;&amp; \docker run -d \--name ssclient \--restart=always \-p 1080:1080 \mritd/shadowsocks:latest \-m &quot;ss-local&quot; -s &quot;-s $&#123;SS_IP&#125; -p $&#123;SS_PORT&#125; -b 0.0.0.0 -l 1080 -m aes-256-cfb -k $&#123;SS_PASSWORD&#125; --fast-open&quot; 加速需要开启BBR Ngrok（服务端）运行实例： 123456NGROK_DATA=/root/docker/ngrok/data &amp;&amp; \NGROK_PORT=9000 &amp;&amp; \docker run -idt --name ngrok-server \-p $&#123;NGROK_PORT&#125;:80 -p 4432:443 -p 4443:4443 \-v $&#123;NGROK_DATA&#125;:/myfiles \-e DOMAIN=&apos;ngrok.yangbingdong.com&apos; hteen/ngrok /bin/sh /server.sh 详情：Docker搭建Ngrok Zookeeper集群docker-compose.yml: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576version: &apos;3.4&apos;services: zoo1: image: zookeeper:latest hostname: zoo1 environment: ZOO_MY_ID: 1 ZOO_SERVERS: server.1=0.0.0.0:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888 ports: - &quot;2181:2181&quot; deploy: mode: replicated replicas: 1 restart_policy: condition: on-failure delay: 5s max_attempts: 3 placement: constraints: - node.hostname == ybd-PC networks: zoo-net: aliases: - zookeeper1 zoo2: image: zookeeper:latest hostname: zoo2 environment: ZOO_MY_ID: 2 ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=0.0.0.0:2888:3888 server.3=zoo3:2888:3888 ports: - &quot;2182:2181&quot; deploy: mode: replicated replicas: 1 restart_policy: condition: on-failure delay: 5s max_attempts: 3 placement: constraints: - node.hostname == qww-PC networks: zoo-net: aliases: - zookeeper2 zoo3: image: zookeeper:latest hostname: zoo3 environment: ZOO_MY_ID: 3 ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=0.0.0.0:2888:3888 ports: - &quot;2183:2181&quot; deploy: mode: replicated replicas: 1 restart_policy: condition: on-failure delay: 5s max_attempts: 3 placement: constraints: - node.hostname == qww-PC networks: zoo-net: aliases: - zookeeper3# docker network create -d=overlay --attachable zoo-netnetworks: zoo-net: external: name: zoo-net Kafka集群docker-compose.yml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677version: &apos;3.4&apos;services: kafka1: image: wurstmeister/kafka:1.0.0 ports: - &quot;9092:9092&quot; environment: KAFKA_BROKER_ID: 1 KAFKA_ADVERTISED_PORT: 9092 KAFKA_ZOOKEEPER_CONNECT: zookeeper1:2181,zookeeper2:2181,zookeeper3:2181 deploy: mode: replicated replicas: 1 restart_policy: condition: on-failure delay: 5s max_attempts: 3 placement: constraints: - node.hostname == ybd-PC networks: zoo-net: aliases: - kafka1 kafka2: image: wurstmeister/kafka:1.0.0 ports: - &quot;9093:9092&quot; environment: KAFKA_BROKER_ID: 2 KAFKA_ADVERTISED_PORT: 9093 KAFKA_ZOOKEEPER_CONNECT: zookeeper1:2181,zookeeper2:2181,zookeeper3:2181 deploy: mode: replicated replicas: 1 restart_policy: condition: on-failure delay: 5s max_attempts: 3 placement: constraints: - node.hostname == qww-PC networks: zoo-net: aliases: - kafka2 kafka3: image: wurstmeister/kafka:1.0.0 ports: - &quot;9094:9092&quot; environment: KAFKA_BROKER_ID: 3 KAFKA_ADVERTISED_PORT: 9094 KAFKA_ZOOKEEPER_CONNECT: zookeeper1:2181,zookeeper2:2181,zookeeper3:2181 deploy: mode: replicated replicas: 1 restart_policy: condition: on-failure delay: 5s max_attempts: 3 placement: constraints: - node.hostname == qww-PC networks: zoo-net: aliases: - kafka3# docker network create -d=overlay --attachable zoo-netnetworks: zoo-net: external: name: zoo-net 参考：http://www.blockchain4u.info/docker/2017/07/28/kafka-cluster-with-docker Kafka Managerdocker-compose.yml: 1234567891011121314151617181920212223242526272829version: &apos;3.4&apos;services: kafka-manager: image: sheepkiller/kafka-manager environment: ZK_HOSTS: zookeeper1:2181,zookeeper2:2181,zookeeper3:2181 APPLICATION_SECRET: letmein ports: - &quot;9100:9000&quot; deploy: mode: replicated replicas: 1 restart_policy: condition: on-failure delay: 5s max_attempts: 3 placement: constraints: - node.hostname == ybd-PC networks: zoo-net: aliases: - kafka-manager# docker network create -d=overlay --attachable zoo-netnetworks: zoo-net: external: name: zoo-net Logrotate功能：日志清理 单机运行： 123456789docker run -d \--name logrotate \--restart always \-v /var/lib/docker/containers:/var/lib/docker/containers \-v /var/log/docker:/var/log/docker \-e &quot;LOGS_DIRECTORIES=/var/lib/docker/containers /var/log/docker&quot; \-e &quot;LOGROTATE_SIZE=10M&quot; \-e &quot;LOGROTATE_INTERVAL=weekly&quot; \blacklabelops/logrotate:1.2 docker-compose.yml: 1234567891011121314151617version: &apos;3.4&apos;services: kafka-manager: image: blacklabelops/logrotate:1.2 volumes: - /var/lib/docker/containers:/var/lib/docker/containers environment: LOGS_DIRECTORIES: /var/lib/docker/containers LOGROTATE_INTERVAL: weekly LOGROTATE_SIZE: 20M TZ: Asia/Shanghai deploy: mode: global restart_policy: condition: on-failure delay: 5s max_attempts: 3 ShowDoc功能：API与数据字典管理 docker-compose.yml: 12345678910version: &apos;3.4&apos;services: showdoc: image: yangbingdong/showdoc:1.0 volumes: - /home/ybd/data/docker/showdoc/data:/var/www/html ports: - &quot;4999:80&quot; restart: always 其中要把 ShowDoc 整个项目根目录所有文件拷贝到 data 里面，确保里面文件可执行 chmod -R 777 data 访问 localhost:4999/install 进行设置后把data里面的 install 目录删除防止再次安装。 Last 参考：Docker — 从入门到实践Docker命令大全Docker命令官方文档]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java8 Noob Tutorial]]></title>
    <url>%2F2017%2Fjava-8-tutorial%2F</url>
    <content type="text"><![CDATA[Preface“Java is still not dead—and people are starting to figure that out.”Java 8是自Java 5（2004年）发布以来Java语言最大的一次版本升级，Java 8带来了很多的新特性，包括Lambda 表达式、方法引用、流(Stream API)、默认方法、Optional、组合式异步编程、新的时间 API，等等各个方面。利用这些特征，我们可以写出如同清泉般的简洁代码= =…Default Methods for InterfacesJava 8 允许我们使用default关键字，为接口声明添加非抽象的方法实现。这个特性又被称为扩展方法。下面是我们的第一个例子：1234567interface Formula &#123; double calculate(int a); default double sqrt(int a) &#123; return Math.sqrt(a); &#125;&#125; 在接口Formula中，除了抽象方法caculate以外，还定义了一个默认方法sqrt.Formula的实现类只需要实现抽象方法caculate就可以了。默认方法sqrt可以直接使用。123456789Formula formula = new Formula() &#123; @Override public double calculate(int a) &#123; return sqrt(a * 100); &#125;&#125;;formula.calculate(100); // 100.0formula.sqrt(16); // 4.0 那么这个新特征有啥用呢？我们往往会碰到这样一个情况我们定义的接口根据不同的场景定义了几个不同的实现类，那么如果需要这几个实现类调用的方法都得到同一个结果或者只有一个实现类需要这个接口方法，那么我们需要去重写每个实现了这个接口的类，而这大大增加了我们的实现需求的负担。 正是为了解决Java接口中只能定义抽象方法的问题。Java8新增加了默认方法的特性。默认方法可以被继承接口重写成抽象方法或者重新定义成默认方法。除了默认方法，接口里还可以声明静态方法，并且可以实现。例子如下： 123456private interface DefaulableFactory &#123; // Interfaces now allow static methods static Defaulable create( Supplier&lt; Defaulable &gt; supplier ) &#123; return supplier.get(); &#125;&#125; Conflict因为一个类可以实现多个接口，所以当一个类实现了多个接口，而这些接口中存在两个或两个以上方法签名相同的默认方法时就会产生冲突，java8定义如下三条原则来解决冲突： 类或父类中显式声明的方法，其优先级高于所有的默认方法； 如果1规则失效，则选择与当前类距离最近的具有具体实现的默认方法； 如果2规则也失效，则需要显式指定接口。 Lambda Expressions先来看一段代码： 123456789public interface ActionListener &#123; void actionPerformed(ActionEvent e);&#125;button.addActionListener(new ActionListener) &#123; public void actionPerformed(ActionEvent e) &#123; ui.dazzle(e.getModifiers()); &#125;&#125; 匿名类型最大的问题就在于其冗余的语法。有人戏称匿名类型导致了“高度问题”（height problem）：比如前面ActionListener的例子里的五行代码中仅有一行在做实际工作。Lambda表达式（又被成为“闭包”或“匿名方法”）是简洁地表示可传递的匿名函数的一种方式，它提供了轻量级的语法，从而解决了匿名内部类带来的“高度问题”。 重点留意这四个关键词：匿名、函数、传递、简洁Lambda的三个部分： 参数列表 箭头 Lambda 主体 Lambda的基本语法大概就是下面这样子的了： (parameters) -&gt; expression (parameters) -&gt; { statements; } 来看个例子：1234567List&lt;String&gt; names = Arrays.asList("D", "B", "C", "A");Collections.sort(names, new Comparator&lt;String&gt;() &#123; @Override public int compare(String a, String b) &#123; return b.compareTo(a); &#125;&#125;); 使用Lambda来表示：1234567Collections.sort(names, (String a, String b) -&gt; &#123; return b.compareTo(a);&#125;);或者是Collections.sort(names, (String a, String b) -&gt; b.compareTo(a));亦或是Collections.sort(names, (a, b) -&gt; b.compareTo(a)); 在IDEA里面，对于可以写成Lambda表达式的，按下Alt+Enter 它会智能地提示转换 Lexiacal Scope访问局部变量 可以直接在Lambda表达式中访问外层的局部变量，但是和匿名对象不同的是，Lambda表达式的局部变量可以不用声明为final，不过局部变量必须不可被后面的代码修改（即隐性的具有final的语义）。eg：下面代码无法编译1234int num = 1; Converter&lt;Integer, String&gt; s = (param) -&gt; String.valueOf(param + num); num = 5; 在Lambda表达式中试图修改局部变量是不允许的！ 在 Lambda 表达式当中被引用的变量的值不可以被更改。 在 Lambda 表达式当中不允许声明一个与局部变量同名的参数或者局部变量。 ​访问对象字段与静态变量和局部变量不同的是，Lambda内部对于实例的字段（即：成员变量）以及静态变量是即可读又可写。 不能访问接口的默认方法Lambda表达式中是无法访问到默认方法的。 补充：Lambda表达式对值封闭，对变量开放的原文是：lambda expressions close over values, not variables，在这里增加一个例子以说明这个特性： 12345int sum = 0;list.forEach(e -&gt; &#123; sum += e.size(); &#125;); // Illegal, close over valuesList&lt;Integer&gt; aList = new List&lt;&gt;();list.forEach(e -&gt; &#123; aList.add(e); &#125;); // Legal, open over variables 匿名内部类的简写？Lambda表达式通过invokedynamic指令实现，书写Lambda表达式不会产生新的类。如果有如下代码，编译之后只有一个class文件： 1234567public class MainLambda &#123; public static void main(String[] args) &#123; new Thread( () -&gt; System.out.println(&quot;Lambda Thread run()&quot;) ).start();; &#125;&#125; 编译之后的结果： 通过javap反编译命名，我们更能看出Lambda表达式内部表示的不同： 12345678910111213141516171819// javap -c -p MainLambda.classpublic class MainLambda &#123; ... public static void main(java.lang.String[]); Code: 0: new #2 // class java/lang/Thread 3: dup 4: invokedynamic #3, 0 // InvokeDynamic #0:run:()Ljava/lang/Runnable; /*使用invokedynamic指令调用*/ 9: invokespecial #4 // Method java/lang/Thread.&quot;&lt;init&gt;&quot;:(Ljava/lang/Runnable;)V 12: invokevirtual #5 // Method java/lang/Thread.start:()V 15: return private static void lambda$main$0(); /*Lambda表达式被封装成主类的私有方法*/ Code: 0: getstatic #6 // Field java/lang/System.out:Ljava/io/PrintStream; 3: ldc #7 // String Lambda Thread run() 5: invokevirtual #8 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 8: return&#125; 反编译之后我们发现Lambda表达式被封装成了主类的一个私有方法，并通过invokedynamic指令进行调用。 Lambda表达式中的this既然Lambda表达式不是内部类的简写，那么Lambda内部的this引用也就跟内部类对象没什么关系了。在Lambda表达式中this的意义跟在表达式外部完全一样。 eg： 12345678910111213141516public class Test2 &#123; public static void main(String[] args) &#123; Test2 test = new Test2(); test.method(); &#125; @Override public String toString() &#123; return "Lambda"; &#125; public void method() &#123; Runnable runnable = () -&gt; &#123; System.out.println(this.toString()); &#125;; new Thread(runnable).start(); &#125; &#125; 显示结果：Lambda Functional Interfaces任意只包含一个抽象方法的接口，我们都可以用来做成Lambda表达式。为了让你定义的接口满足要求，你应当在接口前加上@FunctionalInterface 标注。编译器会注意到这个标注，如果你的接口中定义了第二个抽象方法的话，编译器会抛出异常。eg:12345678@FunctionalInterfaceinterface Converter&lt;F, T&gt; &#123; T convert(F from);&#125; Converter&lt;String, Integer&gt; converter = (from) -&gt; Integer.valueOf(from);Integer converted = converter.convert("123");System.out.println(converted); // 123 注意，如果你不写@FunctionalInterface 标注，程序也是正确的。下面是Java SE 7中已经存在的函数式接口：· java.lang.Runnable· java.util.concurrent.Callable· java.security.PrivilegedAction· java.util.Comparator· java.io.FileFilter· java.beans.PropertyChangeListener 除此之外，Java SE 8中增加了一个新的包：java.util.function，它里面包含了常用的函数式接口，例如：· Predicate&lt;T&gt;——接收T对象并返回boolean· Consumer&lt;T&gt;——接收T对象，不返回值· Function&lt;T, R&gt;——接收T对象，返回R对象· Supplier&lt;T&gt;——提供T对象（例如工厂），不接收值· UnaryOperator&lt;T&gt;——接收T对象，返回T对象· BinaryOperator&lt;T&gt;——接收两个T对象，返回T对象 除了上面的这些基本的函数式接口，我们还提供了一些针对原始类型（Primitive type）的特化（Specialization）函数式接口，例如IntSupplier和LongBinaryOperator。（我们只为int、long和double提供了特化函数式接口，如果需要使用其它原始类型则需要进行类型转换）同样的我们也提供了一些针对多个参数的函数式接口，例如BiFunction&lt;T, U, R&gt;，它接收T对象和U对象，返回R对象。 Method and Constructor ReferencesLambda表达式允许我们定义一个匿名方法，并允许我们以函数式接口的方式使用它。我们也希望能够在已有的方法上实现同样的特性。方法引用和Lambda表达式拥有相同的特性（例如，它们都需要一个目标类型，并需要被转化为函数式接口的实例），不过我们并不需要为方法引用提供方法体，我们可以直接通过方法名称引用已有方法。 方法引用就是替代那些转发参数的 Lambda 表达式的语法糖。方法引用有很多种，它们的语法如下：· 静态方法引用：ClassName::methodName· 实际上的实例方法引用：instanceReference::methodName· 超类上的实例方法引用：super::methodName· 类型上的实例方法引用：ClassName::methodName· 构造方法引用：Class::new· 数组构造方法引用：TypeName[]::new 对于静态方法引用，我们需要在类名和方法名之间加入::分隔符，例如Integer::sum。结合Lambda可以使我们的代码更加简洁：1234List&lt;String&gt; strings = Arrays.asList("a", "b");strings.stream().map(String::toUpperCase).forEach(System.out::println);List&lt;Character&gt; chars = Arrays.asList('a', 'b'); System.out.println(chars.stream().map(String::valueOf).collect(Collectors.joining(","))); OptionalNullPointException可以说是所有Java程序员都遇到过的一个异常，虽然Java从设计之初就力图让程序员脱离指针的苦海，但是指针确实是实际存在的，而java设计者也只能是让指针在Java语言中变得更加简单、易用，而不能完全的将其剔除，所以才有了我们日常所见到的关键字null。 空指针异常是一个运行时异常，对于这一类异常，如果没有明确的处理策略，那么最佳实践在于让程序早点挂掉，但是很多场景下，不是开发人员没有具体的处理策略，而是根本没有意识到空指针异常的存在。当异常真的发生的时候，处理策略也很简单，在存在异常的地方添加一个if语句判定即可，但是这样的应对策略会让我们的程序出现越来越多的null判定，我们知道一个良好的程序设计，应该让代码中尽量少出现null关键字，而Java8所提供的Optional类则在减少NullPointException的同时，也提升了代码的美观度。但首先我们需要明确的是，它并 不是对null关键字的一种替代，而是对于null判定提供了一种更加优雅的实现，从而避免NullPointException。 java.util.Optional&lt;T&gt; 对可能缺失的值建模,引入的目的并非是要消除每一个 null 引用，而是帮助你更好地设计出普适的 API。 创建 Optional 对象,三个静态工厂方法： Optional.empty：创建空的 Optional 对象 Optional.of：依据非空值创建 Optional 对象，若传空值会抛 NPE Optianal.ofNullable：创建 Optional 对象，允许传空值 Optional API： isPresent(): 变量存在返回true get(): 返回封装的变量值，或者抛出 NoSuchElementException orElse(T other): 提供默认值 orElseGet(Supplier&lt;? extends T&gt; other): orElse 方法的延迟调用版 orElseThrow(Supplier&lt;&gt; extends X&gt; exceptionSupplier): 类似 get，但可以定制希望抛出的异常类型 ifPresent(Consumer&lt;? super T&gt;): 变量存在时可以执行一个方法 filter(Predicate&lt;? super T&gt; predicate): 过滤 map(Function&lt;? super T, ? extends U&gt; mapper): 转换 flatMap(Function&lt;? super T, Optional&lt;U&gt;&gt; mapper): 转换成Optional 值得注意的是：Optional是一个final类，未实现任何接口，所以当我们在利用该类包装定义类的属性的时候，如果我们定义的类有序列化的需求，那么因为Optional没有实现Serializable接口，这个时候执行序列化操作就会有问题：12345678public class User implements Serializable&#123; /** 用户编号 */ private long id; private String name; private int age; private Optional&lt;Long&gt; phone; // 不能序列化 private Optional&lt;String&gt; email; // 不能序列化 不过我们可以采用如下替换策略：12345private long phone;public Optional&lt;Long&gt; getPhone() &#123; return Optional.ofNullable(this.phone);&#125; Optional 类设计的初衷仅仅是要支持能返回 Optional 对象的方法，没有考虑将它作为类的字段使用… 另外，在Java9中对Optional添加了三个新的方法： public Optional&lt;T&gt; or(Supplier&lt;? extends Optional&lt;? extends T&gt;&gt; supplier)or 方法的作用是，如果一个 Optional 包含值，则返回自己；否则返回由参数 supplier 获得的 Optional public void ifPresentOrElse(Consumer&lt;? super T&gt; action, Runnable emptyAction)ifPresentOrElse 方法的用途是，如果一个 Optional 包含值，则对其包含的值调用函数 action，即 action.accept(value)，这与 ifPresent 一致；与 ifPresent 方法的区别在于，ifPresentOrElse 还有第二个参数 emptyAction —— 如果 Optional 不包含值，那么 ifPresentOrElse 便会调用 emptyAction，即 emptyAction.run() public Stream&lt;T&gt; stream()stream 方法的作用就是将 Optional 转为一个 Stream，如果该 Optional 中包含值，那么就返回包含这个值的 Stream；否则返回一个空的 Stream（Stream.empty()）。 举个例子，在 Java8，我们会写下面的代码： 12345678// 此处 getUserById 返回的是 Optional&lt;User&gt;public List&lt;User&gt; getUsers(Collection&lt;Integer&gt; userIds) &#123; return userIds.stream() .map(this::getUserById) // 获得 Stream&lt;Optional&lt;User&gt;&gt; .filter(Optional::isPresent)// 去掉不包含值的 Optional .map(Optional::get) .collect(Collectors.toList());&#125; 而有了 Optional.stream()，我们就可以将其简化为： 123456public List&lt;User&gt; getUsers(Collection&lt;Integer&gt; userIds) &#123; return userIds.stream() .map(this::getUserById) // 获得 Stream&lt;Optional&lt;User&gt;&gt; .flatMap(Optional::stream) // Stream 的 flatMap 方法将多个流合成一个流 .collect(Collectors.toList());&#125; Streams 流是什么先来一段代码： 12345Arrays.asList("a1", "a2", "b1", "c2", "c1").stream() .filter(s -&gt; s.startsWith("c")) .map(String::toUpperCase) .sorted() .forEach(System.out::println); 流是Java SE 8类库中新增的关键抽象，它被定义于java.util.stream（这个包里有若干流类型：Stream&lt;T&gt;代表对象引用流，此外还有一系列特化（specialization）流，比如IntStream代表整形数字流）。每个流代表一个值序列，流提供一系列常用的聚集操作，使得我们可以便捷的在它上面进行各种运算。集合类库也提供了便捷的方式使我们可以以操作流的方式使用集合、数组以及其它数据结构。流的操作可以被组合成流水线（Pipeline）。 引入的原因： 声明性方式处理数据集合 透明地并行处理，提高性能 流 的定义：从支持数据处理操作的源生成的元素序列两个重要特点： 流水线 内部迭代 流与集合： 集合与流的差异就在于什么时候进行计算 集合是内存中的数据结构，包含数据结构中目前所有的值 流的元素则是按需计算/生成 另一个关键区别在于遍历数据的方式 集合使用 Collection 接口，需要用户去做迭代，称为外部迭代 流的 Streams 库使用内部迭代 流的使用： 一个数据源（如集合）来执行一个查询； 一个中间操作链，形成一条流的流水线； 一个终端操作，执行流水线，并能生成结果。 流的流水线背后的理念类似于构建器模式。常见的中间操作有filter,map,limit,sorted,distinct；常见的终端操作有 forEach,count,collect。 流的操作类型分为两种： Intermediate：一个流可以后面跟随零个或多个 intermediate 操作。其目的主要是打开流，做出某种程度的数据映射/过滤，然后返回一个新的流，交给下一个操作使用。这类操作都是惰性化的（lazy），就是说，仅仅调用到这类方法，并没有真正开始流的遍历。 Terminal：一个流只能有一个 terminal 操作，当这个操作执行后，流就被使用“光”了，无法再被操作。所以这必定是流的最后一个操作。Terminal 操作的执行，才会真正开始流的遍历，并且会生成一个结果，或者一个 side effect。 流的使用构建流 由值创建流：Stream.of、Stream.empty、IntStream.range 由集合创建流：Collection.stream、Collection.parallelStream 由数组创建流：Arrays.stream(数组变量) 由文件生成流：Files.lines、Files.walk 由BufferedReader创建流：java.io.BufferedReader.lines 由函数生成流：创建无限流， 迭代： Stream.iterate（接受一个种子值，和一个UnaryOperator） 生成：Stream.generate（接收一个Supplier接口） 使用流Intermediate（中间操作）： 筛选: 谓词筛选：filter 筛选互异的元素：distinct 忽略头几个元素：skip 截短至指定长度：limit 排序：sorted 偷瞄（输出）：peek 平行化：parallel 串行化：sequential 映射: 对流中每个元素应用函数：map 流的扁平化：flatMap 转为原始流：mapToInt、mapToInt、mapToInt 从原始流转为普通流：boxed 数值范围： range:[起始值，结束值) rangeClosed:[起始值，结束值] Terminal（终结操作） 查找和匹配: 检查谓词是否至少匹配一个元素：anyMatch 检查谓词是否匹配所有元素：allMatch/noneMatch 查找元素：findAny 查找第一个元素：findFirst 归约（折叠）：reduce(初值，结合操作) 元素求和：count、sum 最大值和最小值：min、 max 遍历：forEach、 forEachOrdered anyMatch,allMatch,noneMatch 都用到了短路；distinct,sorted是有状态且无界的，skip,limit,reduce是有状态且有界的。原始类型流特化：IntStream,DoubleStream,LongStream，避免暗含的装箱成本。 映射到数值流：mapToInt,mapToDouble,mapToLong 转换回流对象：boxed 默认值：OptionalInt,OptionalDouble,OptionalLong 用流收集数据对流调用 collect 方法将对流中的元素触发归约操作（由 Collector 来参数化）。Collectors 实用类提供了许多静态工厂方法，用来创建常见收集器的实例，主要提供三大功能： 将流元素归约和汇总为一个值 元素分组 元素分区 归约和汇总(Collectors 类中的工厂方法)： 统计个数：Collectors.counting 查找流中最大值和最小值：Collectors.maxBy,Collectors.minBy 汇总：Collectors.summingInt,Collectors.averagingInt,summarizingInt/IntSummaryStatistics。还有对应的 long 和 double 类型的函数 连接字符串：joining 广义的归约汇总：Collectors.reducing(起始值，映射方法，二元结合)/Collectors.reducing(二元结合)。Collectors.reducing 工厂方法是所有上述特殊情况的一般化。 collect vs. reduce，两者都是 Stream 接口的方法，区别在于： 语意问题 reduce 方法旨在把两个值结合起来生成一个新值，是不可变的归约； collect 方法设计就是要改变容器，从而累积要输出的结果 实际问题 以错误的语义使用 reduce 会导致归约过程不能并行工作 分组和分区 分组：Collectors.groupingBy 多级分组 按子数组收集数据: maxBy 把收集器的结果转换为另一种结果 collectingAndThen 与 groupingBy 联合使用的其他收集器例子：summingInt,mapping 分区：Collectors.partitioningBy是分组的特殊情况，由一个谓词作为分类函数(分区函数)，返回一个Map，只有两个Boolean类型的key。 Ex1:使用collect()生成Collection前面已经提到通过collect()方法将Stream转换成容器的方法，这里再汇总一下。将Stream转换成List或Set是比较常见的操作，所以Collectors工具已经为我们提供了对应的收集器，通过如下代码即可完成： 1234// 将Stream转换成List或SetStream&lt;String&gt; stream = Stream.of(&quot;I&quot;, &quot;love&quot;, &quot;you&quot;, &quot;too&quot;);List&lt;String&gt; list = stream.collect(Collectors.toList()); // (1)Set&lt;String&gt; set = stream.collect(Collectors.toSet()); // (2) 上述代码能够满足大部分需求，但由于返回结果是接口类型，我们并不知道类库实际选择的容器类型是什么，有时候我们可能会想要人为指定容器的实际类型，这个需求可通过Collectors.toCollection(Supplier&lt;C&gt; collectionFactory)方法完成。 123// 使用toCollection()指定规约容器的类型ArrayList&lt;String&gt; arrayList = stream.collect(Collectors.toCollection(ArrayList::new));// (3)HashSet&lt;String&gt; hashSet = stream.collect(Collectors.toCollection(HashSet::new));// (4) 上述代码(3)处指定规约结果是ArrayList，而(4)处指定规约结果为HashSet。一切如你所愿。 Ex2:使用collect()生成Map前面已经说过Stream背后依赖于某种数据源，数据源可以是数组、容器等，但不能是Map。反过来从Stream生成Map是可以的，但我们要想清楚Map的key和value分别代表什么，根本原因是我们要想清楚要干什么。通常在三种情况下collect()的结果会是Map： 使用Collectors.toMap()生成的收集器，用户需要指定如何生成Map的key和value。 使用Collectors.partitioningBy()生成的收集器，对元素进行二分区操作时用到。 使用Collectors.groupingBy()生成的收集器，对元素做group操作时用到。 情况1：使用toMap()生成的收集器，这种情况是最直接的，前面例子中已提到，这是和Collectors.toCollection()并列的方法。如下代码展示将学生列表转换成由&lt;学生，GPA&gt;组成的Map。非常直观，无需多言。 1234// 使用toMap()统计学生GPAMap&lt;Student, Double&gt; studentToGPA = students.stream().collect(Collectors.toMap(Functions.identity(),// 如何生成key student -&gt; computeGPA(student)));// 如何生成value 情况2：使用partitioningBy()生成的收集器，这种情况适用于将Stream中的元素依据某个二值逻辑（满足条件，或不满足）分成互补相交的两部分，比如男女性别、成绩及格与否等。下列代码展示将学生分成成绩及格或不及格的两部分。 123// Partition students into passing and failingMap&lt;Boolean, List&lt;Student&gt;&gt; passingFailing = students.stream() .collect(Collectors.partitioningBy(s -&gt; s.getGrade() &gt;= PASS_THRESHOLD)); 情况3：使用groupingBy()生成的收集器，这是比较灵活的一种情况。跟SQL中的group by语句类似，这里的groupingBy()也是按照某个属性对数据进行分组，属性相同的元素会被对应到Map的同一个key上。下列代码展示将员工按照部门进行分组： 123// Group employees by departmentMap&lt;Department, List&lt;Employee&gt;&gt; byDept = employees.stream() .collect(Collectors.groupingBy(Employee::getDepartment)); 以上只是分组的最基本用法，有些时候仅仅分组是不够的。在SQL中使用group by是为了协助其他查询，比如1. 先将员工按照部门分组，2. 然后统计每个部门员工的人数。Java类库设计者也考虑到了这种情况，增强版的groupingBy()能够满足这种需求。增强版的groupingBy()允许我们对元素分组之后再执行某种运算，比如求和、计数、平均值、类型转换等。这种先将元素分组的收集器叫做上游收集器，之后执行其他运算的收集器叫做下游收集器(downstream Collector)。 1234// 使用下游收集器统计每个部门的人数Map&lt;Department, Integer&gt; totalByDept = employees.stream() .collect(Collectors.groupingBy(Employee::getDepartment, Collectors.counting()));// 下游收集器 上面代码的逻辑是不是越看越像SQL？高度非结构化。还有更狠的，下游收集器还可以包含更下游的收集器，这绝不是为了炫技而增加的把戏，而是实际场景需要。考虑将员工按照部门分组的场景，如果我们想得到每个员工的名字（字符串），而不是一个个Employee对象，可通过如下方式做到： 12345// 按照部门对员工分布组，并只保留员工的名字Map&lt;Department, List&lt;String&gt;&gt; byDept = employees.stream() .collect(Collectors.groupingBy(Employee::getDepartment, Collectors.mapping(Employee::getName,// 下游收集器 Collectors.toList())));// 更下游的收集器 Notice And Optimization 流不可被复用 一般先filter、limit、skip操作后再进行sorted、peek、map等操作以达到short-circuiting 目的 Stream操作分类 中间操作(Intermediate operations) 无状态(Stateless) unordered() filter() map() mapToInt() mapToLong() mapToDouble() flatMap() flatMapToInt() flatMapToLong() flatMapToDouble() peek() 有状态(Stateful) distinct() sorted() sorted() limit() skip() 结束操作(Terminal operations) 非短路操作 forEach() forEachOrdered() toArray() reduce() collect() max() min() count() 短路操作(short-circuiting) anyMatch() allMatch() noneMatch() findFirst() findAny() Stream上的所有操作分为两类：中间操作和结束操作，中间操作只是一种标记，只有结束操作才会触发实际计算。中间操作又可以分为无状态的(Stateless)和有状态的(Stateful)，无状态中间操作是指元素的处理不受前面元素的影响，而有状态的中间操作必须等到所有元素处理之后才知道最终结果，比如排序是有状态操作，在读取所有元素之前并不能确定排序结果；结束操作又可以分为短路操作和非短路操作，短路操作是指不用处理全部元素就可以返回结果，比如找到第一个满足条件的元素。之所以要进行如此精细的划分，是因为底层对每一种情况的处理方式不同。 AnnotationsJava 8中的注解是可重复的。首先，我们定义一个包装注解，它包括了一个实际注解的数组:12345678@interface Hints &#123; Hint[] value();&#125;@Repeatable(Hints.class)@interface Hint &#123; String value();&#125; 只要在前面加上注解名：@Repeatable，Java 8 允许我们对同一类型使用多重注解变体1：使用注解容器（老方法）12@Hints(&#123;@Hint(&quot;hint1&quot;), @Hint(&quot;hint2&quot;)&#125;)class Person &#123;&#125; 变体2：使用可重复注解（新方法）123@Hint(&quot;hint1&quot;)@Hint(&quot;hint2&quot;)class Person &#123;&#125; 使用变体2，Java编译器能够在内部自动对@Hint进行设置。这对于通过反射来读取注解信息来说，是非常重要的。12345678Hint hint = Person.class.getAnnotation(Hint.class);System.out.println(hint); // nullHints hints1 = Person.class.getAnnotation(Hints.class);System.out.println(hints1.value().length); // 2Hint[] hints2 = Person.class.getAnnotationsByType(Hint.class);System.out.println(hints2.length); // 2 尽管我们绝对不会在Person类上声明@Hints注解，但是它的信息仍然可以通过getAnnotation(Hints.class)来读取。并且，getAnnotationsByType方法会更方便，因为它赋予了所有@Hints注解标注的方法直接的访问权限。12@Target(&#123;ElementType.TYPE_PARAMETER, ElementType.TYPE_USE&#125;)@interface MyAnnotation &#123;&#125; Other ExtendLambda表达式遇上检测型异常先来看一段代码： 12345678long count = Files.walk(Paths.get(&quot;/home/test&quot;)) // 获得项目目录下的所有目录及文件 .filter(file -&gt; !Files.isDirectory(file)) // 筛选出文件 .filter(file -&gt; file.toString().endsWith(&quot;.java&quot;)) // 筛选出 java 文件 .flatMap(file -&gt; Files.lines(file)) // 按行获得文件中的文本 .filter(line -&gt; !line.trim().isEmpty()) // 过滤掉空行 .count();System.out.println(&quot;代码行数：&quot; + count); Files.walk(Path) 在 JDK1.8 时添加，深度优先遍历一个 Path （目录），返回这个目录下所有的 Path（目录和文件），通过 Stream&lt;Path&gt; 返回； Files.lines(Path) 也是在 JDK1.8 时添加，功能是返回指定 Path （文件）中所有的行，通过 Stream&lt;String&gt; 返回。 然后，编译不过 —— 因为 Files.lines(Path) 会抛出 IOException，如果要编译通过，得这样写： 123456789101112131415long count = Files.walk(Paths.get(&quot;/home/test&quot;)) // 获得项目目录下的所有文件 .filter(file -&gt; !Files.isDirectory(file)) // 筛选出文件 .filter(file -&gt; file.toString().endsWith(&quot;.java&quot;)) // 筛选出 java 文件 .flatMap(file -&gt; &#123; try &#123; return Files.lines(file); &#125; catch (IOException ex) &#123; ex.printStackTrace(System.err); return Stream.empty(); // 抛出异常时返回一个空的 Stream &#125; &#125;) // 按行获得文件中的文本 .filter(line -&gt; !line.trim().isEmpty()) // 过滤掉空行 .count();System.out.println(&quot;代码行数：&quot; + count); 对于有强迫症的程序员来说这简直是噩梦，one-liner expression 的 Lambda需要绝对的简介明了。 这里有两种做法，比较偷懒的就是每个会抛出异常的地方我们独自捕获处理，这样带来的问题就是不够通用，每个异常方法都要捕获一次： 12345678910111213141516171819public static void main(String[] args) throws Exception &#123; long count = Files.walk(Paths.get(&quot;/home/test&quot;)) // 获得项目目录下的所有文件 .filter(file -&gt; !Files.isDirectory(file)) // 筛选出文件 .filter(file -&gt; file.toString().endsWith(&quot;.java&quot;)) // 筛选出 java 文件 .flatMap(file -&gt; getLines(file)) // 按行获得文件中的文本 .filter(line -&gt; !line.trim().isEmpty()) // 过滤掉空行 .count(); System.out.println(&quot;代码行数：&quot; + count);&#125;private static Stream&lt;String&gt; getLines(Path file) &#123; try &#123; return Files.lines(file); &#125; catch (IOException ex) &#123; ex.printStackTrace(System.err); return Stream.empty(); &#125;&#125; 这种解决方法下，我们需要处理受检异常 —— 即在程序抛出异常的时候，我们需要告诉程序怎么去做（getLines 方法中抛出异常时我们输出了异常，并返回一个空的 Stream） 上面方式当然是不可取的啦，我们选择更偷懒的方式，将会抛出异常的函数进行包装，使其不抛出受检异常。 如果一个 FunctionInterface 的方法会抛出受检异常（比如 Exception），那么该 FunctionInterface 便可以作为会抛出受检异常的 Lambda 的目标类型。我们定义如下一个 FunctionInterface： 1234@FunctionalInterface public interface UncheckedFunction&lt;T, R&gt; &#123; R apply(T t) throws Exception; &#125; 那么该 FunctionInterface 便可以作为类似于 file -&gt; File.lines(file) 这类会抛出受检异常的 Lambda 的目标类型，此时 Lambda 中并不需要捕获异常（因为目标类型的 apply 方法已经将异常抛出了）—— 之所以原来的 Lambda 需要捕获异常，就是因为在流式操作 flatMap 中使用的 java.util.function 包下的 Function&lt;T, R&gt; 没有抛出异常： 那我们如何使用 UncheckedFunction 到流式操作的 Lambda 中呢？首先我们定义一个 Trier 类，它的 tryFunction 方法提供将 UncheckedFunction 包装为 Function 的功能： 1234567891011121314151617181920public class Trier &#123; private static final Logger LOGGER = LoggerFactory.getLogger(Trier.class); public static &lt;T, R&gt; Function&lt;T, R&gt; tryFunction(UncheckedFunction&lt;T, R&gt; function) &#123; requireNonNull(function); return t -&gt; &#123; try &#123; return function.apply(t); &#125; catch (Exception e) &#123; throw logAndThrow(e); &#125; &#125;; &#125; @FunctionalInterface public static interface UncheckedFunction&lt;T, R&gt; &#123; R apply(T t) throws Exception; &#125;&#125; 然后在原先的代码中，我们使用 Trier.tryFunction 方法来对会抛出受检异常的 Lambda 进行包装： 12345678910long count = Files.walk(Paths.get(&quot;/home/test&quot;)) // 获得项目目录下的所有文件 .filter(file -&gt; !Files.isDirectory(file)) // 筛选出文件 .filter(file -&gt; file.toString().endsWith(&quot;.java&quot;)) // 筛选出 java 文件 .flatMap(Trier.tryFunction(file -&gt; Files.lines(file))) // 将 会抛出受检异常的 Lambda 包装为 抛出非受检异常的 Lambda .filter(line -&gt; !line.trim().isEmpty()) // 过滤掉空行 .count();System.out.println(&quot;代码行数：&quot; + count); 指定默认值的包装方法，即如果抛出异常，那么就返回默认值： 123456789101112131415public static &lt;T, R&gt; Function&lt;T, R&gt; tryFunction(UncheckedFunction&lt;T, R&gt; function, R defaultValue) &#123; requireNonNull(function); return t -&gt; &#123; try &#123; return function.apply(t); &#125; catch (Exception e) &#123; return logAndReturn(e, defaultValue); &#125; &#125;; &#125; private static &lt;R&gt; R logAndReturn(Exception e, R defaultValue) &#123; LOGGER.error(&quot;Trier catch an exception: &quot; + getFullStackTrace(e) + &quot;\n And return default value: &quot; + defaultValue); return defaultValue; &#125; 比如我们前面的例子，如果 file -&gt; Files.lines(file) 抛出异常了，说明在访问 file 类的时候出了问题，我们可以就假设这个文件的行数为 0 ，那么默认值就是个空的 Stream&lt;String&gt;： 12345678910long count = Files.walk(Paths.get(&quot;/home/test&quot;)) // 获得项目目录下的所有文件 .filter(file -&gt; !Files.isDirectory(file)) // 筛选出文件 .filter(file -&gt; file.toString().endsWith(&quot;.java&quot;)) // 筛选出 java 文件 .flatMap(Trier.tryFunction(file -&gt; Files.lines(file), Stream.empty())) .filter(line -&gt; !line.trim().isEmpty()) // 过滤掉空行 .count();System.out.println(&quot;代码行数：&quot; + count); 如此类推，我们可以创建UncheckedConsumer、UncheckedSupplier等： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115public class Trier &#123; private static final Logger LOGGER = LoggerFactory.getLogger(Trier.class); public static &lt;T, R&gt; Function&lt;T, R&gt; tryFunction(UncheckedFunction&lt;T, R&gt; function) &#123; requireNonNull(function); return t -&gt; &#123; try &#123; return function.apply(t); &#125; catch (Exception e) &#123; throw logAndThrow(e); &#125; &#125;; &#125; public static &lt;T, R&gt; Function&lt;T, R&gt; tryFunction(UncheckedFunction&lt;T, R&gt; function, R defaultValue) &#123; requireNonNull(function); return t -&gt; &#123; try &#123; return function.apply(t); &#125; catch (Exception e) &#123; return logAndReturn(e, defaultValue); &#125; &#125;; &#125; public static &lt;T&gt; Supplier&lt;T&gt; trySupplier(UncheckedSupplier&lt;T&gt; supplier) &#123; requireNonNull(supplier); return () -&gt; &#123; try &#123; return supplier.get(); &#125; catch (Exception e) &#123; throw logAndThrow(e); &#125; &#125;; &#125; public static &lt;T&gt; Supplier&lt;T&gt; trySupplier(UncheckedSupplier&lt;T&gt; supplier, T defaultValue) &#123; requireNonNull(supplier); return () -&gt; &#123; try &#123; return supplier.get(); &#125; catch (Exception e) &#123; return logAndReturn(e, defaultValue); &#125; &#125;; &#125; public static &lt;T&gt; Consumer&lt;T&gt; tryConsumer(UncheckedConsumer&lt;T&gt; consumer) &#123; requireNonNull(consumer); return t -&gt; &#123; try &#123; consumer.accept(t); &#125; catch (Exception e) &#123; throw logAndThrow(e); &#125; &#125;; &#125; public static &lt;T&gt; Predicate&lt;T&gt; tryPredicate(UncheckedPredicate&lt;T&gt; predicate) &#123; requireNonNull(predicate); return t -&gt; &#123; try &#123; return predicate.test(t); &#125; catch (Exception e) &#123; throw logAndThrow(e); &#125; &#125;; &#125; public static &lt;T&gt; Predicate&lt;T&gt; tryPredicate(UncheckedPredicate&lt;T&gt; predicate, boolean defaultValue) &#123; requireNonNull(predicate); return t -&gt; &#123; try &#123; return predicate.test(t); &#125; catch (Exception e) &#123; return logAndReturn(e, defaultValue); &#125; &#125;; &#125; private static void log(Exception e) &#123; LOGGER.error(&quot;Trier catch an exception: &quot; + getFullStackTrace(e)); &#125; private static &lt;R&gt; R logAndReturn(Exception e, R defaultValue) &#123; LOGGER.error(&quot;Trier catch an exception: &quot; + getFullStackTrace(e) + &quot;\n And return default value: &quot; + defaultValue); return defaultValue; &#125; private static RuntimeException logAndThrow(Exception e) &#123; log(e); throw new RuntimeException(e); &#125; @FunctionalInterface public interface UncheckedFunction&lt;T, R&gt; &#123; R apply(T t) throws Exception; &#125; @FunctionalInterface public interface UncheckedSupplier&lt;T&gt; &#123; T get() throws Exception; &#125; @FunctionalInterface public interface UncheckedConsumer&lt;T&gt; &#123; void accept(T t) throws Exception; &#125; @FunctionalInterface public interface UncheckedPredicate&lt;T&gt; &#123; boolean test(T t) throws Exception; &#125;&#125; Java8 对字符串连接的改进有时候，我们会有一种需求就是将若干个字符串用某个链接符衔接起来，例如有一个 List，将其格式化为 元素1, 元素2, 元素3, … 元素N 的字符串形式。 以前我们的一般做法就是使用StringBuilder： 123456789101112131415161718public static String formatList(List&lt;String&gt; list, String delimiter) &#123; StringBuilder result = new StringBuilder(); for (String str : list) &#123; result.append(str).append(delimiter); &#125; // 删除末尾多余的 delimiter result.delete(result.length() - delimiter.length(), result.length()); return result.toString();&#125;public static void main(String[] args) throws Exception &#123; List&lt;String&gt; list = Arrays.asList(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;, &quot;e&quot;, &quot;f&quot;, &quot;g&quot;); System.out.println(&quot;使用 StringBuilder：&quot;); String format = formatList(list, &quot;,&quot;); System.out.println(format);&#125; 运行结果： 12使用 StringBuilder：a,b,c,d,e,f,g JDK1.8 时，添加了一个新的用于字符串连接的类，专门用于这种需要 分隔符 的场合，它就是 StringJoiner。StringJoiner 在构造时可以指定一个分隔符（delimiter），然后每连接一个元素它便会加上一个 delimiter，使用 StringJoiner 改写 formatList： 123456789101112131415public static String formatList(List&lt;String&gt; list, String delimiter) &#123; StringJoiner result = new StringJoiner(delimiter); for (String str : list) &#123; result.add(str); &#125; return result.toString();&#125;public static void main(String[] args) throws Exception &#123; List&lt;String&gt; list = Arrays.asList(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;, &quot;e&quot;, &quot;f&quot;, &quot;g&quot;); System.out.println(&quot;使用 StringJoiner：&quot;); String format = formatList(list, &quot;,&quot;); System.out.println(format);&#125; 结果与上面一样。 或者使用String.join: 123public static String formatList(List&lt;String&gt; list, String delimiter) &#123; return String.join(delimiter, list);&#125; 它的底层也是调用StringJoiner： 但是我们看到了 String.join 方法的不足 —— 它不能指定前缀和后缀 —— 比如我们如果想要直接将 List&lt;String&gt; 格式化为 { 元素1, 元素2, 元素3, … 元素N } 呢？（此时前缀为 &quot;{ &quot;，后缀为 &quot; }&quot;） 查看 StringJoiner 的构造方法，发现 StringJoiner 除了指定 分隔符 的构造方法，还有一个可以指定 分隔符、前缀和后缀 的构造方法： 修改 formatList： 1234567891011121314151617public static String formatList( List&lt;String&gt; list, String delimiter, String prefix, String suffix) &#123; StringJoiner result = new StringJoiner(delimiter, prefix, suffix); for (String str : list) &#123; result.add(str); &#125; return result.toString();&#125;public static void main(String[] args) throws Exception &#123; List&lt;String&gt; list = Arrays.asList(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;, &quot;e&quot;, &quot;f&quot;, &quot;g&quot;); System.out.println(&quot;使用 StringJoiner，带前缀和后缀：&quot;); String format = formatList(list, &quot;, &quot;, &quot;&#123; &quot;, &quot; &#125;&quot;); System.out.println(format);&#125; 运行结果： 12使用 StringJoiner，带前缀和后缀：&#123; a, b, c, d, e, f, g &#125; 事实上，Java8 对于字符串集合的连接操作提供了一个专门的流式 API，即 Collectors.joining 函数： 无参的 joining() 方法，即不存在连接符（底层实现为 StringBuilder）； joining(CharSequence delimiter) 方法，即分隔符为 delimiter（底层实现为 StringJoiner）； joining(CharSequence delimiter, CharSequence prefix, CharSequence suffix)方法，即分隔符为 delimiter，前缀为 prefix，后缀为 suffix（底层实现为 StringJoiner）。 那怎么使用呢？ 我们直接使用三个参数的 Collectors.joining 方法改写 formatList： 12345678910111213public static String formatList( List&lt;String&gt; list, String delimiter, String prefix, String suffix) &#123; return list.stream().collect(Collectors.joining(delimiter, prefix, suffix));&#125;public static void main(String[] args) throws Exception &#123; List&lt;String&gt; list = Arrays.asList(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;, &quot;e&quot;, &quot;f&quot;, &quot;g&quot;); System.out.println(&quot;使用 Collectors.joining：&quot;); String format = formatList(list, &quot;, &quot;, &quot;&#123; &quot;, &quot; &#125;&quot;); System.out.println(format);&#125; 运行结果同上。 Java8 中 Map 接口的新方法假如现在我们存在这样的需求：给定一个 List&lt;String&gt;，统计每个元素出现的所有位置。 比如，给定 list：[&quot;a&quot;, &quot;b&quot;, &quot;b&quot;, &quot;c&quot;, &quot;c&quot;, &quot;c&quot;, &quot;d&quot;, &quot;d&quot;, &quot;d&quot;, &quot;f&quot;, &quot;f&quot;, &quot;g&quot;] ，那么应该返回： 123456a : [0]b : [1, 2]c : [3, 4, 5]d : [6, 7, 8]f : [9, 10]g : [11] 很明显，我们很适合使用 Map 来完成这件事情： 12345678910111213141516171819202122232425public static Map&lt;String, List&lt;Integer&gt;&gt; getElementPositions(List&lt;String&gt; list) &#123; Map&lt;String, List&lt;Integer&gt;&gt; positionsMap = new HashMap&lt;&gt;(); for (int i = 0; i &lt; list.size(); i++) &#123; String str = list.get(i); List&lt;Integer&gt; positions = positionsMap.get(str); if (positions == null) &#123; // 如果 positionsMap 还不存在 str 这个键及其对应的 List&lt;Integer&gt; positions = new ArrayList&lt;&gt;(1); positionsMap.put(str, positions); // 将 str 及其对应的 positions 放入 positionsMap &#125; positions.add(i); // 将索引加入 str 相关联的 List&lt;Integer&gt; 中 &#125; return positionsMap;&#125;public static void main(String[] args) throws Exception &#123; List&lt;String&gt; list = Arrays.asList(&quot;a&quot;, &quot;b&quot;, &quot;b&quot;, &quot;c&quot;, &quot;c&quot;, &quot;c&quot;, &quot;d&quot;, &quot;d&quot;, &quot;d&quot;, &quot;f&quot;, &quot;f&quot;, &quot;g&quot;); System.out.println(&quot;使用 Java8 之前的 API：&quot;); Map&lt;String, List&lt;Integer&gt;&gt; elementPositions = getElementPositions(list); System.out.println(elementPositions);&#125; 运行结果： 12使用 Java8 之前的 API：&#123;a=[0], b=[1, 2], c=[3, 4, 5], d=[6, 7, 8], f=[9, 10], g=[11]&#125; 在Java8之后，Map添加了一下新的方法签名： 查看源码发现computeIfAbsent很符合上面需求： 我们可以改造成这样子： 1234567891011121314151617public static Map&lt;String, List&lt;Integer&gt;&gt; getElementPositions(List&lt;String&gt; list) &#123; Map&lt;String, List&lt;Integer&gt;&gt; positionsMap = new HashMap&lt;&gt;(); for (int i = 0; i &lt; list.size(); i++) &#123; positionsMap.computeIfAbsent(list.get(i), k -&gt; new ArrayList&lt;&gt;(1)).add(i); &#125; return positionsMap;&#125;public static void main(String[] args) throws Exception &#123; List&lt;String&gt; list = Arrays.asList(&quot;a&quot;, &quot;b&quot;, &quot;b&quot;, &quot;c&quot;, &quot;c&quot;, &quot;c&quot;, &quot;d&quot;, &quot;d&quot;, &quot;d&quot;, &quot;f&quot;, &quot;f&quot;, &quot;g&quot;); System.out.println(&quot;使用 computeIfAbsent：&quot;); Map&lt;String, List&lt;Integer&gt;&gt; elementPositions = getElementPositions(list); System.out.println(elementPositions);&#125; 效果一样，但是代码优雅整洁了很多。 当 forEach 需要索引上面的例子通过Java8新增的Map方法可以很优雅地实现一些需求： 1234567public static Map&lt;String, List&lt;Integer&gt;&gt; getElementPositions(List&lt;String&gt; list) &#123; Map&lt;String, List&lt;Integer&gt;&gt; positionsMap = new HashMap&lt;&gt;(); for (int i = 0; i &lt; list.size(); i++) &#123; positionsMap.computeIfAbsent(list.get(i), k -&gt; new ArrayList&lt;&gt;(1)).add(i); &#125; return positionsMap;&#125; 但是方法里面的for循环似乎让这个方法不太优雅了，Java8中Iterable提供的foreach并不带索引的： 我们可以自己写一个： 1234567891011 public static &lt;E&gt; void forEach( Iterable&lt;? extends E&gt; elements, BiConsumer&lt;Integer, ? super E&gt; action) &#123; Objects.requireNonNull(elements); Objects.requireNonNull(action); int index = 0; for (E element : elements) &#123; action.accept(index++, element); &#125; &#125;&#125; 然后改造getElementPositions方法： 123456789public static Map&lt;String, List&lt;Integer&gt;&gt; getElementPositions(List&lt;String&gt; list) &#123; Map&lt;String, List&lt;Integer&gt;&gt; positionsMap = new HashMap&lt;&gt;(); Iterables.forEach(list, (index, str) -&gt; &#123; positionsMap.computeIfAbsent(str, k -&gt; new ArrayList&lt;&gt;(1)).add(index); &#125;); return positionsMap;&#125; Summary关于java8的介绍与使用网上有太多太多了，如java8最佳技巧等等… 更加深入理解函数式编程请参考Java Functional Programming Internals 参考Java8简明教程CarpenterLeehttp://winterbe.com/posts/2014/03/16/java-8-tutorial/http://brianway.github.io/2017/03/29/javase-java8/#%E6%B5%81stream-apihttp://ifeve.com/java-8-features-tutorial/https://segmentfault.com/a/1190000007832130]]></content>
      <categories>
        <category>Programming</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VPS自搭建Ngrok内网穿透服务]]></title>
    <url>%2F2017%2Fself-hosted-build-ngrok-server%2F</url>
    <content type="text"><![CDATA[前言Ngrok可以干嘛？我们经常会有 “把本机开发中的 web 项目给朋友看一下” 或 “测试一下支付宝、微信的支付功能” 这种临时需求，为此专门购买个域名然后在 VPS或云主机 上部署一遍就有点太浪费了。那么这时候，Ngrok就是个很好的东西，它可以实现我们的这种需求。而且 Ngrok 官网本身还提供了公共服务，只需要注册一个帐号，运行它的客户端，就可以快速把内网映射出去。不过这么好的服务，没多久就被墙了~幸好Ngrok是开源的，那么我们可以自己搭建一个Ngrok！域名泛解析因为内网穿透需要用到多级域名，这里，博主的这个域名是在Namesilo购买的，然后转到DNSPod解析：如图所示，我搞买的域名是yangbingdong.com,将ngrok.yangbingdong.com通过A记录解析导VPS的ip地址，再将*.ngrok.yangbingdong.com通过CNAME解析导ngrok.yangbingdong.com，完成泛解析。服务端安装安装GO环境这里博主选择通过下载最新版解压安装。123456789apt-get updateapt-get -y install build-essential mercurial gitwget https://storage.googleapis.com/golang/go1.8.1.linux-amd64.tar.gztar -C /usr/local -xzf go1.8.1.linux-amd64.tar.gzmkdir $HOME/goecho 'export GOROOT=/usr/local/go' &gt;&gt; /etc/profile.d/go.shecho 'export GOPATH=$HOME/go' &gt;&gt; /etc/profile.d/go.shecho 'export PATH=$PATH:$GOROOT/bin:$GOPATH/bin' &gt;&gt; /etc/profile.d/go.shsource /etc/profile.d/go.sh 安装Ngrok123cd /usr/local/src/git clone https://github.com/tutumcloud/ngrok.git ngrokexport GOPATH=/usr/local/src/ngrok/ 生成自签名SSL证书，ngrok为ssl加密连接：12345678910111213cd ngrokNGROK_DOMAIN="ngrok.yangbingdong.com"openssl genrsa -out rootCA.key 2048openssl req -x509 -new -nodes -key rootCA.key -subj "/CN=$NGROK_DOMAIN" -days 5000 -out rootCA.pemopenssl genrsa -out device.key 2048openssl req -new -key device.key -subj "/CN=$NGROK_DOMAIN" -out device.csropenssl x509 -req -in device.csr -CA rootCA.pem -CAkey rootCA.key -CAcreateserial -out device.crt -days 5000cp rootCA.pem assets/client/tls/ngrokroot.crtcp device.crt assets/server/tls/snakeoil.crt cp device.key assets/server/tls/snakeoil.keyGOOS=linux GOARCH=amd64make cleanmake release-server release-client 注意：上面的ngrok.yangbingdong.com换成自己的域名。 如果是32位系统,GOARCH=386; 如果是64为系统，GOARCH=amd64 如果要编译linux,GOOS=linux;如果要编译window,GOOS=windows 启动server1cd /usr/local/src/ngrok/bin &amp;&amp; ./ngrokd -domain="ngrok.yangbingdong.com" -httpAddr=":8002" -httpsAddr=":8003" -tunnelAddr=":4000" ngrok.yangbingdong.com换成自己的域名。其他端口可自己配置。顺利的话，可以正常编译，在bin下面可以看到「ngrokd」和「ngrok」，其中「ngrokd」是服务端执行程序，「ngrok」是客户端执行程序 后台运行：1cd /usr/local/src/ngrok/bin &amp;&amp; nohup ./ngrokd -domain="ngrok.yangbingdong.com" -httpAddr=":8002" -httpsAddr=":8003" -tunnelAddr=":4000" &gt; /dev/null 2&gt;&amp;1 &amp; 123456apt-get install screenscreen -S 任意名字（例如：keepngork）然后运行ngrok启动命令最后按快捷键ctrl+A+D既可以保持ngrok后台运行 设置开机启动12345vim /etc/init.d/ngrok_start:cd /usr/local/src/ngrok/bin./ngrokd -domain="ngrok.yangbingdong.com" -httpAddr=":8002" -httpsAddr=":8003" -tunnelAddr=":4000"chmod 755 /etc/init.d/ngrok_start 客户端使用下载客户端1scp -P 26850 root@12.34.56.78:/usr/local/src/ngrok/bin/ngrok ~/ 将12.34.56.78换成自己的VPS ip。 启动客户端写一个简单的配置文件，随意命名如 ngrok.cfg：12server_addr: ngrok.yangbingdong.com:4000trust_host_root_certs: false 然后启动：1./ngrok -subdomain ybd -config=ngrok.cfg 8080 其中ybd是自定义的域名前缀，ngrok.cfg是上面创建的配置文件，8080是本地需要映射到外网的端口。没有意外的话访问ybd.ngrok.yangbingdong.com:8002就会映射到本机的8080端口了。 控制台： 就是上图的Web Interface，通过这个界面可以看到远端转发过来的 http 详情，包括完整的 request/response 信息，相当于附带了一个抓包工具。 另外，Ngrok支持多种协议，启动的时候可以指定通过-proto指定协议，例如： http协议： 1./ngrok -subdomain ybd -config=ngrok.cfg -proto=http 8080 tcp协议： 1./ngrok -subdomain ybd -config=ngrok.cfg -proto=tcp 8080 应该会看到： 12345678ngrok (Ctrl+C to quit)Tunnel Status onlineVersion 1.7/1.7Forwarding tcp://ybd.ngrok.yangbingdong.com:8002-&gt; 127.0.0.1:8080Web Interface 127.0.0.1:4040# Conn 0Avg Conn Time 0.00ms Nginx添加server虽然可以访问，但是带着端口就让人不舒服，80端口又被Nginx占用，那么可以用过Nginx反向代理Ngrok。Nginx的配置一般在/etc/nginx/conf.d或者/usr/local/nginx/conf.d里面：12345678910111213141516171819202122#ngrok.yangbingdong.com.confupstream ngrok &#123; server 127.0.0.1:8002; keepalive 64;&#125;server &#123; listen 80; server_name *.ngrok.yangbingdong.com; access_log /var/log/nginx/ngrok_access.log; proxy_set_header &quot;Host&quot; $host:8002; location / &#123; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Host $host:8002; proxy_pass_header Server; proxy_redirect off; proxy_pass http://ngrok; &#125; access_log off; log_not_found off;&#125; 重启Nginx：1nginx -s reload 维护脚本在网上看到的某大神写的维护脚本： 1234567wget https://gist.githubusercontent.com/IvanChou/1be8b15b1b41bf0ce2e9d939866bbfec/raw/1a2445599fe7fd706505a6e103a9dc60b4d3a0ed/ngrokd -O ngrokd##修改 脚本中的配置vi ngrokdchomd +x ngrokdsudo mv ngrokd /etc/init.d/ngrokd 常见错误在ngrok目录下执行如下命令，编译ngrokd12345678910111213$ make release-server出现如下错误：GOOS=&quot;&quot; GOARCH=&quot;&quot; go get github.com/jteeuwen/go-bindata/go-bindatabin/go-bindata -nomemcopy -pkg=assets -tags=release \ -debug=false \ -o=src/ngrok/client/assets/assets_release.go \ assets/client/…make: bin/go-bindata: Command not foundmake: *** [client-assets] Error 127go-bindata被安装到了$GOBIN下了，go编译器找不到了。修正方法是将$GOBIN/go-bindata拷贝到当前ngrok/bin下。$cp /home/ubuntu/.bin/go14/bin/go-bindata ./bin 遇到的问题：source与./写了一个Ngrok的安装脚本，然后chmod +x ngrok-installation.sh赋权，再./ngrok-installation.sh执行。但是遇到了一个奇怪的问题：在脚本里面设置了环境变量并source让其生效，然而出现的结果是由于没有加载到环境变量导致找不到命令，百思不得解，Google了一把，发现了原因： source命令与shell scripts的区别是：我们在test.sh设置了AA环境变量，它只在fork出来的这个子shell中生效，子shell只能继承父shell的环境变量，而不能修改父shell的环境变量，所以test.sh结束后，父进程的环境就覆盖回去。source在当前bash环境下执行命令，而scripts是启动一个子shell来执行命令。这样如果把设置环境变量（或alias等等）的命令写进scripts中，就只会影响子shell,无法改变当前的BASH,所以通过文件（命令列）设置环境变量时，要用source 命令。 然后直接source ngrok-installation.sh，安装成功！ Docker搭建Ngrok 安装Docker请看这里 构建镜像123git clone https://github.com/hteen/docker-ngrok.gitcd docker-ngrokdocker build -t hteen/ngrok . 运行镜像1234docker run -idt --name ngrok-server \-p 8082:80 -p 4432:443 -p 4443:4443 \-v /root/docker/ngrok/data:/myfiles \-e DOMAIN=&apos;ngrok.yangbingdong.com&apos; hteen/ngrok /bin/sh /server.sh -p: 80端口为http端口，433端口为https端口，4443端口为tunnel端口 -v: 生成的各种配置文件和客户端都在里面 -e: 泛化的域名 稍等片刻，会在挂在的目录（/root/docker/ngrok/data）下面生成对应的配置文件以及客户端 1234bin/ngrokd 服务端bin/ngrok linux客户端bin/darwin_amd64/ngrok osx客户端bin/windows_amd64/ngrok.exe windows客户端 Nginx Conf12345678910111213141516171819202122server &#123; listen 80; server_name *.ngrok.yangbingdong.com; location / &#123; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://172.17.0.1:8082; &#125; &#125; server &#123; listen 443; server_name *.ngrok.yangbingdong.com; location / &#123; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://172.17.0.1:4432; &#125; &#125; 172.17.0.1为内网ip 注意：大概每个星期会产生100M的日志文件。查年docker日志文件位置docker inspect &lt;id&gt; | grep LogPath查看大小ls -lh /var/lib/docker/containers/&lt;id&gt;/&lt;id&gt;-json.log]]></content>
      <categories>
        <category>VPS</category>
      </categories>
      <tags>
        <tag>VPS</tag>
        <tag>Ngrok</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NGINX初学指南(安装与简单配置)]]></title>
    <url>%2F2017%2Fnginx-noob-guide%2F</url>
    <content type="text"><![CDATA[前言走上了VPS这条不归路，就意味着需要会维护以及运营自己的服务器。那么这一章记录一下学习Nginx的一些东西…本文绝大部分内容来自NGINX 网站的官方手册：https://www.nginx.com/resources/admin-guide/installing-nginx-open-source/http://nginx.org/en/docs/beginners_guide.html安装NGINX部分主干版本VS稳定版本NGINX 有两个有效版本：主干版本。这个版本中包含了最新的功能和 BUG 修复，并且总是最新的版本。这个版本很可靠，但是也包含了一些实验性质的模块和一定数量的新 BUG。稳定版本。这个版本没有最新的功能，但是包含了关键 BUG 的修复。在生产服务器中推荐使用稳定版本。预编译包VS源码编译NGINX 的主干版本和稳定版本都可以以下两种方式安装：预编译包安装。这是一种快捷的安装方式。预编译包中含有几乎所有 NGINX 官方模块并且适用于大多数主流的操作系统。通过源码编译安装。这种方式更加灵活：你可以添加包括第三方模块在内的特殊模块以及最新的安全补丁。通过源码编译和安装通过源码编译 NGINX 带给你更多的灵活性：你可以添加包括第三方模块在内的特殊模块以及最新的安全补丁。先安装一些编译依赖：1apt-get update &amp;&amp; apt-get install -y build-essential libtool 安装 NGINX 依赖1、PCRC 库：被 NGINX Core 和 Rewrite 模块需求，并且提供正则表达式支持：1cd /usr/local/src &amp;&amp; wget ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/pcre-8.40.tar.gz &amp;&amp; tar -zxf pcre-8.40.tar.gz &amp;&amp; cd pcre-8.40 &amp;&amp; ./configure &amp;&amp; make &amp;&amp; make install 2、zlib 库：为了头部压缩被 NGINX Gzip 模块需求：1cd /usr/local/src &amp;&amp; wget http://zlib.net/zlib-1.2.11.tar.gz &amp;&amp; tar -zxf zlib-1.2.11.tar.gz &amp;&amp; cd zlib-1.2.11 &amp;&amp; ./configure &amp;&amp; make &amp;&amp; make install 3、OpenSSL 库：被 NGINX SSL 模块需求用以支持 HTTPS 协议： 这里博主并不选择源码安装=.=，而是通过apt安装： 12apt-get upgradeapt-get install -y libssl-dev openssl 下载源码NGINX 同时提供了稳定版本和主干版本的源码文件。源码文件可以从 NGINX Open Source 下载页面下载：Redirect Download Page下载并解压最新的主干版本源码文件，在命令行中输入下面的命令：1cd /usr/local/src &amp;&amp; wget http://nginx.org/download/nginx-1.12.0.tar.gz &amp;&amp; tar -zxvf nginx-1.12.0.tar.gz &amp;&amp; cd nginx-1.12.0 配置构建选项配置选项要使用 ./configure 脚本来设置各种 NGINX 的参数，其中包括源码和配置文件路径、编译器选项，连接处理方法以及模块列表。脚本最终创建了用于编译代码和安装 NGINX 的 Makefile 文件。例如：1./configure --sbin-path=/usr/local/nginx/nginx --conf-path=/usr/local/nginx/nginx.conf --pid-path=/usr/local/nginx/nginx.pid --with-pcre=../pcre-8.40 --with-zlib=../zlib-1.2.11 --with-http_ssl_module --with-stream --with-http_stub_status_module 配置 NGINX 路径配置脚本允许你设置 NGINX 二进制文件和配置文件的路径以及依赖库 （PCRC 或 SSL）的路径，以便静态链接到 NGINX 二进制文件中。 –prefix=path：定义保存 NGINX 文件的目录。目录也将被用于所有通过 ./configure 设置的相对路径和 nginx.conf 配置文件的路径。默认这个路径被设置为 /usr/local/nginx。 –sbin-path=path：设置 NGINX 可执行文件的名称。这个名称仅在安装期间使用。该文件默认的被命名为 prefix/sbin/nginx。 –conf-path=path：设置 NGINX 配置文件名称。该文件默认的被命名为 prefix/conf/nginx.conf。 注意：无论这个选项是什么，你都可以在命令行中通过 -c 选项来指定使用不同的配置文件启动 NGINX。 –pid-path=path：设置存储主进程的进程 id 的 nginx.pid 文件名。在安装以后，文件名的路径总是可以在 nginx.conf 文件中被修改，通过使用 pid 指令。默认该文件被命名为 prefix/logs/nginx.pid –error-log-path=path：设置主要的错误，警告和诊断文件的名字。安装之后，文件名总是可以在 nginx.conf 文件中使用 error_log 指令修改。该文件默认被命名为 prefix/logs/access.log。 –user=name：设置凭据将被用于 NGINX worker 进程的非特权用户的名称。在安装后，这个名称可以通过使用 user 指令在 nginx.conf 文件中修改。默认的名字是 nobody。 –group=name：设置凭据将被用于 NGINX worker 进程的用户组名。在安装以后，这个名称可以通过使用 user 指令在 nginx.conf 文件中修改。默认地，用户组名被设置为非特权用户的名字。 –with-pcre=path：设置 PCRE 库的源码的路径。这个库在 location 指令和 ngx_http_rewrite_module 模块中被用于支持正则表达式。 –with-pcre-jit：使用 “just-in-time compilation” 支持（pcre_jit 指令）来构建 PCRE 库。 –with-zlib=path：设置 zlib 库的源码的路径。这个库被用于 ngx_http_gzip_module 模块中。 配置 NGINX GCC 选项在配置脚本中你也可以指定编译器关联选项：–with-cc-opt=parameters：设置添加到 CFLAGS 变量中的附加参数。在 FreeBSD 系统下，当使用系统 PCRE 库的时候，–with-cc-opt=-I/usr/local/include 必须被指定。 如果被select支持的文件数量需要增加，那么也可以像这下面这样指定：–with-cc-opt=-D/FD_SETSIZE=2048。 –with-ld-opt=parameters：设置将用于链接时的附加参数。当在 FreeBSD 下使用系统 PCRE 库时，–with-cc-opt=-L/usr/local/lib 必须被指定。 指定 NGINX 连接处理方法在配置脚本中，你可以重新定义基于事件的轮询方法。查看 Connection Processing Methods 了解更多内容。–with-select_module,–without-select_module：启用或禁用构建允许 NGINX 使用 select 方法工作的模块。如果平台没有明确支持想 kqueue,epoll,/dev/poll这样更加合适的方法，该模块将被自动构建。 –with-poll_module,–without-poll-module：启用或禁用构建允许 NGINX 使用 poll() 方法工作的模块。如果该平台没有明确支持像 kqueue,epoll,/dev/poll 这样更加更是的方法，该模块将被自动构建。 NGINX 模块模块的 NGINX 常量。模块的设置就如其他构建选项一样被配置在 ./configure 脚本中。有一些模块被自动构建——他们不需要在配置脚本中指定。然而，一些默认的模块可以被排除在 NGINX 二进制文件之外，通过在配置脚本中使用 -without- 配置选项。模块默认不包含第三方模块，必须在配置脚本中使用其他的构建选项明确指定才行。这些模块可以被链接到 NGINX 二进制文件，以静态的方式在每次启动 NGINX 被加载，或者如果他们在配置文件中被指定则以动态的方式被加载。 默认的模块构建如果你不需要一个默认的构建模块，你可以通过使用 –without- 前缀的模块名来禁用它：1./configure --sbin-path=/usr/local/nginx/nginx --conf-path=/usr/local/nginx/nginx.conf --pid-path=/usr/local/nginx/nginx.pid --with-http_ssl_module --with-stream --with-pcre=../pcre-8.40 --with-zlib=../zlib-1.2.11 --without-http_empty_gif_module 模块名称 描述 http_charset_module 向 Content-Type 响应 header 域添加指定的字符集，能够覆盖数据从一种编码到另外一种。 http_gzip_module 使用 gzip 方法压缩响应，有助于将传输的数据减少至少一半。 http_ssi_module 通过它在响应中处理 SSI (Server Side Includes) 命令。 http_userid_module 为客户端鉴定设置 cookies 适配。 http_access_module 限制对特定客户端地址的访问 http_auth_basic_module 通过使用 HTTP Basic Authentication 协议验证用户名和密码来限制访问资源。 http_autoindex_module 处理以斜线（/）结束的请求并产生一个目录列表。 http_geo_module 创建依赖客户端 IP 地址值的变量。 http_map_module 创建依赖其他变量值的变量。 http_split_clients_module 创建适配 AB 测试的变量，也被称为分隔测试。 http_referer_module 如果请求的 header 域中的 Referer 使用了无效值，阻止其访问站点。 http_rewrite_module 使用正则表达式改变请求的 URI 并重定向。有条件的选择。需要 PCRE 库支持。 http_proxy_module 传递请求到其他服务器。 http_fastcgi_module 传递请求到 FastCGI 服务器。 http_uwsgi_module 传递请求到 uwsgi 服务器。 http_scgi_module 传递请求到 SCGI 服务器。 http_memcached_module 从 memcached 服务器中获取响应。 http_limit_conn_module 限制每个定义的 key 的连接数量，特别是来自单一 IP 地址的连接数量。 http_limit_req_module 限制每个定义的 key 的请求处理率，特别是来自单一 IP 地址的处理率。 http_empty_gif_module 发出单像素透明 GIF。 http_browser_module 创建依赖请求 header 域中的 “User-Agent” 值的变量。 http_upstream_hash_module 开启 hash 负载均衡方法。 http_upstream_ip_hash_module 开启 IP hash 负载均衡方法。 http_upstream_least_conn_module 开启 least_conn 负载均衡方法。 http_upstream_keepalive_module 开启持续连接。 http_upstream_zone_module 开启共享内存区。 非默认构建的模块一些 NGINX 模块不是默认构建的。你需要通过添加到 ./configure 命令去手动启用他们。mail,stream,geoip,image_filter,perl和xslt 模块可以被动态编译。查看 Dynamic Modules 来了解更多内容。 例如，./configure 命令包含了这些模块：1./configure --sbin-path=/usr/local/nginx/nginx --conf-path=/usr/local/nginx/nginx.conf --pid-path=/usr/local/nginx/nginx.pid --with-pcre=../pcre-8.40 --with-zlib=../zlib-1.2.11 --with-http_ssl_module --with-stream --with-mail 选项 说明 –with-threads 允许 NGINX 使用线程池。查看详情： Thread Pools in NGINX Boost Performance 9x! –with-file-aio 启用异步 I/O。 –with-ipv6 启用 IPv6 支持。 –with-http_ssl_module 提供 HTTPS 支持。需要 SSL 库，如 OpenSSL。配置参考： ngx_http_ssl_module –with-http_v2_module 提供 HTTP/2 支持。配置参考：ngx_http_v2_module，更多信息：HTTP/2 Module in NGINX –with-http_realip_module 修改客户端地址为在指定 header 域中的发送地址。参考配置：ngx_http_realip_module –with-http_addition_module 在响应的前后添加文本。配置参考：ngx_http_addition_module –with-http_xslt_module 或 –with-http_xslt_module=dynamic 使用一种或多种 XSLT 样式表来转换 XML 响应。该模块需要 Libxml2 和 XSLT 库。配置参考：ngx_http_xslt_module –with-http_image_filter_module 或 –with-http_image_filter_module=dynamic 将图片在 JPEG、GIF 和 PNG 中转换格式。该模块需要 LibGD 库。配置参考：ngx_http_image_filter_module –with-http_geoip_module 或 –with-http_geoip_module=dynamic 允许创建依赖客户端 IP 地址值的变量。该模块使用了 MaxMind GeoIP 数据库。配置参考：ngx_http_geoip_module –with-http_sub_module 通过使用其他的字符串替换指定字符串修改响应。配置参考：ngx_http_sub_module –with-http_dav_module 用于通过 WebDAV 协议的文件管理自动化。配置参考：ngx_http_dav_module –with-http_flv_module 为 Flash Video (FLV) 文件提供伪流服务器端支持。配置参考：ngx http_flv_module –with-mp4_module 为 MP4 文件提供伪流服务器端支持。配置参考：ngx_http_mp4_module –with-http_gunzip_module 使用 Content-Encoding 解压响应：gzip 用于不支持 zip 编码方法的客户端。配置参考：ngx_http_gunzip_module –with-http_gzip_static_module 允许发送使用 *.gz 文件扩展名而不是常规的预压缩文件。配置参考：ngx_http_gzip_static_module –with-http_auth_request_module 基于子请求实施客户端授权。配置参考：http_auth_request_module –with-http_random_index_module 处理使用斜杠 (/) 结尾的请求，并且从一个目录取出一个随机文件来作为首页。配置参考：ngx_http_random_index_module –with-http_secure_link_module 用于插件被请求链接的授权，保护资源不被未授权访问或者限制链接的生命周期。配置参考：ngx_http_secure_link_module –with-http_slice_module 允许将请求分隔为子请求，每个请求返回确定的响应范围。提供更多大型文件的有效缓存。查看 ngx_http_slice_module 相关的指令列表。配置参考：ngx_http_slice_module –with-http_degradation_module 当内存超出默认值的时候，允许返回错误信息 –with-http_stub_status_module 提供访问基本状态信息。配置参考： ngx_http_stub__status_module。注意 NGINX Plus 用户不需要这个模块，因为已经为他们提供了扩展状态的面板。 –with-http_perl_module 或 –with-http_perl_module=dynamic 用于在 Perl 中实现位置和变量句柄，并且将 Perl 调用插入到 SSI 中。需要 PERL 库。配置参考： ngx_http_perl_module 。该模块也可以被动态编译。 –with-mail 或 –with-mail=dynamic 启用邮件代理功能。配置参考：ngx_mail_core_module 。该模块也可以被动态编译。 –with-mail_ssl_module 为使用 SSL/TLS 协议工作的邮件代理服务器提供支持。需要想 OpenSSL 这样的 SSL 库。配置参考： ngx_mail_ssl_module –with-stream 或 –with-stream=dynamic 开启 TCP 代理功能。配置参考： ngx_stream_code_module 。该模块可以被动态编译。 –with-google_perftools_module 允许使用 Google Performance 工具库。 –with-cpp_test_module 或 –with-debug 开启调试日志。 第三方模块你可以使用你自己的模块或者第三方模块扩展 NGINX 的功能通过编译 NGINX 源码。一些第三方模块被列举在 https://nginx.com/resources/wiki/modules/ 页面中。使用第三方模块的你将要承担稳定性无法保证的风险。 静态链接模块被构建在 NGINX 源码中的大多数模块是被静态链接的：他们在编译的时候被构建在 NGINX 源码中，然后被静态的了链接到 NGINX 二进制文件中。这些模块只能在 NGINX 重新编译之后才能禁用。要使用静态链接的第三方模块去编译 NGINX 源码，在配置脚本中要指定 –add-module=option 并且输入模块的路径：1$ ./configure ... --add-module=/usr/build/nginx-rtmp-module 动态链接模块NGINX 模块也可以被编译为一个共享对象（.so 文件），然后在运行时动态的加载到 NGINX 中。这样提供了更多的灵活性，作为模块可以在任何时候被加载或反加载通过在 NGINX 配置文件中使用 **load_module* 指令指定。注意：这种模块必须支持动态链接。要使用动态加载第三方模块编译 NGINX 源码，在配置脚本中要指定 –add-dynamic-module=配置选项和模块的路径。1$ ./configure ... --add-dynamic-module=/path/to/module 动态模块的结果文件 .so 在编译结束后在 prefix/modules/ 目录中被找到，prefix 是保存服务器文件的目录，如：/usr/local/nginx/modules。要想加载动态模块，在 NGINX 安装完成后使用 local_module 指令。查看 Introducing Dynamic Modules in NGINX 1.9.11 和 Extending NGINX 来了解更多内容。 完成安装12./configure --prefix=/usr/local/nginx --with-pcre=../pcre-8.40 --with-zlib=../zlib-1.2.11 --with-http_stub_status_module --with-http_ssl_modulemake &amp;&amp; make install 到此NGINX已经安装完成，但是，此时直接敲nginx可能会显示没有找到命令，因为还没有配置环境变量：1234touch /etc/profile.d/nginx.shecho "PATH=$PATH:/usr/local/nginx/sbin" &gt;&gt; /etc/profile.d/nginx.shecho "export PATH" &gt;&gt; /etc/profile.d/nginx.shsource /etc/profile.d/nginx.sh 完成！查看NGINX:1nginx -v 预编译包安装 博主用的就是这种方式，简单粗暴！当然上面的方式也是过，但毕竟只是个业余的，手动一个个模块配置上去的话，小白表示搞不定。 添加源12echo "deb http://nginx.org/packages/ubuntu/ trusty nginx" &gt;&gt; /etc/apt/sources.listecho "deb-src http://nginx.org/packages/ubuntu/ trusty nginx" &gt;&gt; /etc/apt/sources.list 更新并导入升级Key完成安装1wget http://nginx.org/keys/nginx_signing.key &amp;&amp; apt-key add nginx_signing.key &amp;&amp; apt-get update &amp;&amp; apt-get upgrade &amp;&amp; apt-get install openssl nginx 查看1nginx -V NGINX初学启动，停止和重新加载配置1nginx -s stop|quit|reload|reopen 也可以是这样：1kill -s QUIT 1888 #1888是nginx的PID 要获取全部正在运行中的 nginx 进程列表，可以使用 ps 工具，就像下面这样：1ps -ax | grep nginx 如果要了解更多的有关信号发送的信息，请查看控制nginx。 配置文件的结构nginx 由被配置文件指定的指令控制的模块组成。指令被分为简单指令和块指令。简单指令有名称和参数组成，通过空格来分隔开，以 ; 号来结束。块指令拥有和简单指令一样的结构，但是不用 ; 结束而是使用一组被 {} 环绕的额外指令。如果一个块指令在其内部包含了其他指令，则被称为上下文（context），比如：events,http,server 和location。 被放置在配置文件中却不在任何上下文中的指令被认为是在主上下文之内的。events 和 http 指令就属于主上下文， server 在 http 之内，location 在 server 之内。 单行之中在 # 号之后的剩余内容被认为是注释。 静态内容服务一个重要的 web 服务器任务就是提供文件（比如图片或者静态 HTML 页面）。你将会实现一个例子，依赖于 request 请求，文件将被从不同的本地目录（/data/www 和 /data/images）中提供。这需要编辑配置文件并在 http 块之内使用两个 location 块来设置一个 server 块。 首先，创建 /data/www 目录并且将一个名为 index.html 文件放进去，然后在创建一个 /data/images 目录并放置一些图片在里面。 接下来，打开配置文件。默认的配置文件已经包含了一些 server 块的例子，通常都被注释掉了。那么现在，注释掉全部块并且编写一个新的 server块吧： 1234http &#123; server &#123; &#125;&#125; 通常地，配置文件可能包含了一些 server 块，通过监听端口和服务器名字来区分。一旦 nginx 决定哪个服务处理请求，将会试着添加以下 location 块到 server 块中： 123location / &#123; root /data/www;&#125; 这个 location 块说明了 / 前缀和请求中的 URI 进行比较。对于匹配的请求，URI 将会被添加到被 root 指令说明的路径中去，就是到 /data/www 中，形成一个在本地文件系统中的请求文件路径。如果有多个匹配了 location 的块，nginx 会选择前缀最长的那个。上面的那个 location 块是最短的前缀，长度只有 1，所以只有其他 location 块匹配都失败了，这个块才会被使用。 接下来，添加第二个 location 块： 123location /images/ &#123; root /data;&#125; 这将匹配以 /images/ 开始的请求（location / 也会匹配这个请求，但他的前缀最短）。 最终 server 块的配置看起来是像下面这样的： 123456789server &#123; location / &#123; root /data/www ; &#125; location /iamges/ &#123; root /data; &#125;&#125; 配置一个监听标准 80 端口并且可在本机访问的服务器的工作就是这样了。在响应使用以 /images/ 为开头的 URI 的请求中，服务器会从 /data/images 目录中中发送文件。例如，在响应 http://localhost/images/example.png 的请求中，nginx 会发送 /data/images/exmaple.png 文件。如果这个文件不存在，nginx 会发送一个 404 错误的响应。URI 不以 /images/ 开头的请求将被映射到 /data/www 目录中。例如，在响应 http://localhost/some/example.html 的请求中，nginx 将发送 /data/www/some/example.html 文件。 要想应用新的配置，请启动 nginx（如果还没启动的话）或者发送 reload 信号到 nginx 主进程，通过执行如下命令： 1nginx -s reload 本例中，有些不会像期望中的那样工作，你可以在 access.log 和 error.log 文件中尝试找到原因，这些文件的位置在 /usr/local/nginx/logs 或 /var/log/nginx 中。 设置一个简单的代理服务器nginx 的一个频繁的用法是被设置作为代理服务器，这意味着接收请求的服务器，通过他们到被代理的服务器，再通过他们取回相应，并且通过他们发送给客户端。 下面我们来配置一个基本的代理服务器，来为本地图片请求提供服务并将其他请求转到被代理的服务器上。本例中，两个服务器将被定义在一个 nginx 实例中。 首先，通过增加一个 server 块到 nginx 配置文件的方式定义被代理的服务，配置内容如下： 1234567server &#123; listen 8080; root /data/up1; location / &#123; &#125;&#125; 这是一个监听 8080 端口并且映射全部请求到本地 /data/up1 目录的简单服务器。创建这个目录并放一个 index.html 在里面。注意， root 指令被放置在 server 上下文中，这样的 root 指令被用在当 location 块被选中提供服务的时候。 接下来，使用上一节的服务器配置并修改为一个代理服务器的配置。在第一 location 块中，放入使用由协议，名字以及被代理服务器的端口描述的参数的 proxy_pass 指令（在我们的例子中，就是 http://localhost:8080）： 12345678server &#123; localtion / &#123; proxy_pass http://localhost:8080; &#125; localtion /images/ &#123; root /data; &#125;&#125; 我们将修改第二个 location 块，它当前使用 /images/ 前缀来映射请求到 /data/images/ 下的文件，我们现在想要让他匹配一些典型的图片类型扩展名的请求。修改后的 localtion 块看起来像这样的： 123localtion ~ \.(gif|jpg|png)$ &#123; root /data/images;&#125; 参数是匹配了全部以 .gif .jpg .png 结尾的 URI 的正则表达式。一个正则表达式应被 ~ 开始。这样，相关的请求就会被映射到 /data/images/ 目录中了。 当 nginx 选取一个 localtion 块来为请求提供服务的时候，首先要检查 location 指令说明的前缀，记住最长前缀的 location，然后再检查正则表达式。如果匹配了一个正则表达式，nginx 挑出这个 localtion，否则，它就会挑选之前被记录的。 代理服务器的配置结果看起来将会是下面这样： 12345678server&#123; location / &#123; proxy_pass http://localhost:8080/; &#125; localtion ~ \.(gif|jpg|png)$ &#123; root /data/images; &#125;&#125; 这个服务器将过滤以 .gif .jpg .png 结尾的请求，并映射他们到 /data/images 目录（通过添加 URI 到 root 指令的参数），还会传递其他请求到被之前配置的被代理服务器上。 要应用新配置，要像前面章节提到的发送 reload 信号给 nginx。 这里有更多的可能更加有用的配置代理连接的指令。 最后 参考：Installing NGINX Open SourceNginx 初学者指南 顺便写了个安装脚本：源码版预编译版 人生在于折腾，这几天玩VPS有很大的收获，学会了一些以前不会的命令、写脚本、穿墙、Nginx等等，坚持折腾！PS：链接换成加粗斜体，一个一个地找好累，于是又学会了正则表达式：\[[\w\s]*\]\(https?://[a-z\.\?/_=0-9\s#&amp;-]*\)，一键替换～]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>VPS</tag>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Access Blocked Sites(科学上网):VPS自搭建ShadowSocks与加速]]></title>
    <url>%2F2017%2Fuse-vps-cross-wall-by-shadowsocks-under-ubuntu%2F</url>
    <content type="text"><![CDATA[前言最近在玩VPS，作为没有Google就活不下去的开发人员，穿墙已是日常= =…使用别人的VPN或者Sock5代理显然是不安全的，个人信息随时被截获，那么拥有一台自己VPS也是必需的，价格也可以很便宜（绝对不是在打广告）ShadowSocks介绍什么是ShadowSocks(影梭)ShadowSocks 是由clowwindy所开发的一个开源 Socks5 代理。如其官网所言 ，它是 “A secure socks5 proxy, designed to protect your Internet traffic” （一个安全的 Socks5 代理）。其作用，亦如该项目主页的 wiki（中文版） 中所说，“A fast tunnel proxy that helps you bypass firewalls” （一个可穿透防火墙的快速代理）。不过，在中国，由于GFW[1]的存在，更多的网友用它来进行科学上网。This is a story…long long ago…我们的互联网通讯是这样的：when evil comes然后有一天，GFW[1] 就出现了，他像一个收过路费的强盗一样夹在了在用户和服务之间，每当用户需要获取信息，都经过了 GFW，GFW将它不喜欢的内容统统过滤掉，于是客户当触发 GFW 的过滤规则的时候，就会收到 Connection Reset 这样的响应内容，而无法接收到正常的内容：ssh tunnel聪明的人们想到了利用境外服务器代理的方法来绕过 GFW 的过滤，其中包含了各种HTTP代理服务、Socks服务、VPN服务… 其中以 ssh tunnel 的方法比较有代表性：1) 首先用户和境外服务器基于 ssh 建立起一条加密的通道2-3) 用户通过建立起的隧道进行代理，通过 ssh server 向真实的服务发起请求4-5) 服务通过 ssh server，再通过创建好的隧道返回给用户由于 ssh 本身就是基于 RSA 加密技术，所以 GFW 无法从数据传输的过程中的加密数据内容进行关键词分析，避免了被重置链接的问题，但由于创建隧道和数据传输的过程中，ssh 本身的特征是明显的，所以 GFW 一度通过分析连接的特征进行干扰，导致 ssh存在被定向进行干扰的问题。shadowsocks于是 clowwindy 同学分享并开源了他的解决方案。简单理解的话，shadowsocks 是将原来 ssh 创建的 Socks5 协议拆开成 server 端和 client 端，所以下面这个原理图基本上和利用 ssh tunnel 大致类似。1、6) 客户端发出的请求基于 Socks5 协议跟 ss-local 端进行通讯，由于这个 ss-local 一般是本机或路由器或局域网的其他机器，不经过 GFW，所以解决了上面被 GFW 通过特征分析进行干扰的问题2、5) ss-local 和 ss-server 两端通过多种可选的加密方法进行通讯，经过 GFW 的时候是常规的TCP包，没有明显的特征码而且 GFW 也无法对通讯数据进行解密3、4) ss-server 将收到的加密数据进行解密，还原原来的请求，再发送到用户需要访问的服务，获取响应原路返回VPS选择BandwagonHOSTBandwagonHOST俗称搬瓦工，隶属于美国IT7旗下的VPS服务品牌，VPS采用OpenVZ架构，主要针对低端VPS市场。具体节点的选择，可以在浏览器中输入以下IP进行实际测试（测试地址由www.banwagong.com提供）：美国洛杉矶 US West Coast-Los Angeles：104.224.162.217美国佛罗里达 US West Coast-Florida：104.224.141.127欧洲 荷兰 EU-Netherlands：104.224.145.203美国 凤凰城 US, Arizona ：45.62.112.117一般而言，中国用户使用洛杉矶和凤凰城的机房会有较好的网络体验。注：搬瓦工已被墙，需要翻墙访问。搬瓦工从15年6月26日起支持支付宝付款。Digital OceanDigitalOcean是一家位于美国的云主机服务商，总部位于纽约，成立于2012年，VPS 核心架构采用KVM架构。由于价格低廉，高性能配置、灵活布置的优势，近些年来发展迅猛。该公司拥有多个数据中心，分布在：New York( Equinix 和 Telx 机房), San Francisco ( Telx ), Singapore ( Equinix ), Amsterdam ( TelecityGroup ), Germany ( Frankfurt ). 其私有数据网络供应商是Level3, NTT, nLayer, Tinet, Cogent, 和Telia。一般而言，建议非电信用户可以采用新加坡节点，速度非常给力。电信用户不建议采用此VPS，速度比较一般，更推荐 Vultr 和 Linode 的日本机房。VultrVultr 是一家成立于2014年的VPS提供商。根据域名所有者资料，母公司是2005年成立于新泽西州的 ClanServers Hosting LLC 公司，他们家的游戏服务器托管在全球6个国家的14个数据中心，选择非常多。 Vultr 家的服务器采用的 E3 的 CPU ，清一色的 Intel 的 SSD 硬盘，VPS采用KVM架构。 Vultr 的计费按照使用计费（自行选择配置、可以按月或按小时计费），用多少算多少，可以随时取消，另外可以自己上传镜像安装需要的操作系统也是一大亮点。现在已经成为 Digital Ocean 的有力竞争对手。Vultr的服务器托管在全球14个数据中心，即时开通使用。大陆访问日本机房速度不错，延迟低、带宽足。LinodeLinode 是VPS 服务商中的大哥，高富帅般的存在。价格相对较高，但是性能，稳定性等各方面也非常给力。 VPS 采用 Xen 架构，不过最近的周年庆开始升级到 KVM 架构，VPS 性能进一步提升。推荐给对连接速度和网络延迟有极致追求的用户。Linode只能使用信用卡支付，官方会随机手工抽查，被抽查到的话需要上传信用卡正反面照片以及可能还需要身份证正反面照片，只要材料真实齐全，审核速度很快，一般一个小时之内就可以全部搞定。账户成功激活以后，就可以安心使用了。SSH无密码登录VPS参考 免密码登录远程服务器ShadowSocks服务端安装这里博主选择的VPS的操作系统是Ubuntu14.04,因为16.04不明原因安装失败。另外，搬瓦工可以一键安装Shadowsocks和OpenVPN（只支持CentOS），但处于爱折腾，手动安装。安装123apt-get updateapt-get install python-pippip install shadowsocks 修改配置文件1vi /etc/shadowsocks.json 添加以下内容：12345678910&#123; "server":"my_server_ip", "server_port":8388, "local_address": "127.0.0.1", "local_port":1080, "password":"mypassword", "timeout":300, "method":"aes-256-cfb", "fast_open": false&#125; name info server 服务器 IP (IPv4/IPv6)，注意这也将是服务端监听的 IP 地址 server_port 服务器端口 local_port 本地端端口 password 用来加密的密码 timeout 超时时间（秒） method 加密方法，可选择 “bf-cfb”, “aes-256-cfb”, “des-cfb”, “rc4″, 等等。默认是一种不安全的加密，推荐用 “aes-256-cfb” 只需要把 my_server_ip换成你VPS的IP，并且把 mypassword 换成你自己的密码，注意：这个密码不是你登录VPS的密码，是你一会从ShadowSocks客户端登录的时候用的密码.server_port默认8388也行，你修改也行，这个端口是ShadowSocks客户端登录时用的端口号，如果你修改了，最好改成1024至65536之间的一个数字，并且自己一定要记住。其它的都默认就好。 启动服务下面就可以开始启动ShadowSocks服务端了。ShadowSocks服务端自身就已经支持后台运行了，所以，通过下面的命令启动之后，只要你的VPS不关机不重启，ShadowSocks服务端就会一直在后台运行。1ssserver -c /etc/shadowsocks.json -d start 看到started没有，这就表示你的ShadowSocks服务端就已经启动了。此时就可以关掉你的终端，然后打开你的ShadowSocks客户端进行连接了。 最后一步，将ShadowSocks加入开机启动。很简单，只需在/etc/rc.local加一句话就成。通过如下命令打开rc.local文件1vi /etc/rc.local 在exit 0的上一行添加以下内容：1/usr/bin/python /usr/local/bin/ssserver -c /etc/shadowsocks.json -d start 粘贴完成后，和上面编辑配置文件一样，选按键盘左上角的“ESC”键，然后输入”:wq”，保存退出。这样，开机就会自动启动ShadowSocks了。不信，你可以试一下。 或者一键安装…一键安装脚本 ShadowSocks客户端安装安装与启动Ubuntu使用ShadowSocks客户端有两种方式：1、安装ShadowSocks命令行程序，配置命令。2、安装ShadowSocks GUI图形界面程序，配置。 博主推荐第一种，配置好后基本不用管。但使用的前提是你的服务端已经搭建好或者你有别人提供的SS 服务，下面我们来看怎么在Ubuntu上使用ShadowSocks 方法一安装用PIP安装很简单：123sudo apt-get updatesudo apt-get install python-pipsudo apt-get install python-setuptools m2crypto 接着安装ShadowSocks：1pip install shadowsocks 如果是ubuntu16.04 直接 (16.04 里可以直接用apt 而不用 apt-get 这是一项改进。sudo apt install shadowsocks当然你在安装时候肯定有提示需要安装一些依赖比如python-setuptools m2crypto ，依照提示安装然后再安装就好。也可以网上搜索有很多教程的。 启动安装好后，在本地我们要用到sslocal ，终端输入sslocal –help 可以查看帮助，像这样通过帮助提示我们知道各个参数怎么配置，比如 sslocal -c 后面加上我们的json配置文件，或者像下面这样直接命令参数写上运行。比如1sslocal -s 11.22.33.44 -p 50003 -k &quot;123456&quot; -l 1080 -t 600 -m aes-256-cfb -s表示服务IP, -p指的是服务端的端口，-l是本地端口默认是1080, -k 是密码（要加””）, -t超时默认300,-m是加密方法默认aes-256-cfb。 为了方便我推荐直接用sslcoal -c 配置文件路径 这样的方式，简单好用。我们可以在/home/ybd/ 下新建个文件shadowsocks.json (ybd是我在我电脑上的用户名，这里路径你自己看你的)。内容是这样：12345678&#123;"server":"11.22.33.44","server_port":8388,"local_port":1080,"password":"123456","timeout":600,"method":"aes-256-cfb"&#125; server： 你服务端的IPservier_port： 你服务端的端口local_port： 本地端口，一般默认1080passwd： ss服务端设置的密码timeout： 超时设置 和服务端一样method： 加密方法 和服务端一样确定上面的配置文件没有问题，然后我们就可以在终端输入 sslocal -c /home/ybd/shadowsocks.json 回车运行。如果没有问题的话，下面会是这样… 如果你选择这一种请跳过第二种。你可以去系统的代理设置按照说明设置代理，但一般是全局的，然而我们访问baidu,taobao等着些网站如果用代理就有点绕了，而且还会浪费服务器流量。我们最好配置我们的浏览器让它可以自动切换，该用代理用代理该直接连接自动直接连接。所以请看配置浏览器。 方法二安装GUI 图形界面程序，然后按照提示配置相对应的参数。安装教程地址：ShadowSocks-qt5 安装指南 在ubuntu上可以这样，通过PPA源安装，仅支持Ubuntu 14.04或更高版本。123sudo add-apt-repository ppa:hzwhuang/ss-qt5sudo apt-get updatesudo apt-get install shadowsocks-qt5 由于是图形界面，配置和windows基本没啥差别就不赘述了。经过上面的配置，你只是启动了sslocal 但是要上网你还需要配置下浏览器到指定到代理端口比如1080才可以正式上网。 开机后台自动运行ss客户端如果你选择了第二种可以不管这个如果你上面可以代理上网了可以进行这一步，之前让你不要关掉终端，因为关掉终端的时候代理就随着关闭了，之后你每次开机或者关掉终端之后，下次你再想用代理就要重新在终端输入这样的命令 sslocal -c /home/ybd/shadowsocks.json ，挺麻烦是不？ 我们现在可以在你的Ubuntu上安装一个叫做supervisor的程序来管理你的sslocal启动。1sudo apt-get install supervisor 安装好后我们直接在/etc/supervisor/conf.d/下新建个文件比如ss.conf然后加入下面内容：1234567[program:shadowsocks]command=sslocal -c /home/ybd/shadowsocks.jsonautostart=trueautorestart=trueuser=rootlog_stderr=truelogfile=/var/log/shadowsocks.log command =这里json文件的路径根据你的文件路径来填写。确认无误后记得保存。sslocal 和ssserver这两个命令是被存在 /usr/bin/下面的，我们要拷贝一份命令文件到/bin12sudo cp /usr/bin/sslocal /bin sudo cp /usr/bin/ssserver /bin 现在关掉你之前运行sslocal命令的终端，再打开终端输入sudo service supervisor restart 然后去打开浏览器看看可不可以继续代理上网。你也可以用ps -ef|grep sslocal命令查看sslocal是否在运行。 这个时候我们需要在/etc下编辑一个叫rc.local的文件 ，让supervisor开机启动。1sudo gedit /etc/rc.local 在这个配置文件的exit 0前面一行加上 service supervisor start 保存。看你是否配置成功你可以在现在关机重启之后直接打开浏览器看是否代理成功。 还有一种方法就是：1sudo systemctl enable supervisor 然后重启即可 番外篇：服务端一键安装番外篇一：搬瓦工一键安装搬瓦工早就知道广大使用者的阴谋意图，所以特意提供了一键无脑安装Shadowsocks。注意：目前只支持CentOS。进入KiwiVM后，在左边的选项栏的最下面：点击Install之后会出现如下界面代表安装成功：点GO Back可看到相关信息了 番外篇二：一键安装脚本这个就不多说了，直接贴上网址：Shadowsocks 一键安装脚本（四合一） 更多脚本请看：https://github.com/iMeiji/shadowsocks_install 基于Docker安装安装Docker详细教程不在本篇范围内，请看Docker入门笔记以下是最简单快捷高效的安装方式： 12curl -fsSL get.docker.com -o get-docker.shsh get-docker.sh 就是这么粗暴的两条命令=.=这里可能会有个小问题，如果VPS使用的IPv6可能会导致apt update失败，解决办法是把上面下载的get-docker.sh里面所有的apt-get update改为apt-get Acquire::ForceIPv4=true update。 拉取镜像Showdowsocks镜像：https://hub.docker.com/r/mritd/shadowsocks/根据需要选择自己喜欢的Tag 1docker pull mritd/shadowsocks:latest 启动示例1docker run -dt --name ss -p 6443:6443 mritd/shadowsocks -s &quot;-s 0.0.0.0 -p 6443 -m aes-256-cfb -k test123 --fast-open&quot; 说明： -m : 参数后指定一个 shadowsocks 命令，如 ss-local，不写默认为 ss-server；该参数用于 shadowsocks 在客户端和服务端工作模式间切换，可选项如下: ss-local、ss-manager、ss-nat、ss-redir、ss-server、ss-tunnel -s : 参数后指定一个 shadowsocks-libev 的参数字符串，所有参数将被拼接到 ss-server 后 -x : 指定该参数后才会开启 kcptun 支持，否则将默认禁用 kcptun -e : 参数后指定一个 kcptun 命令，如 kcpclient，不写默认为 kcpserver；该参数用于 kcptun 在客户端和服务端工作模式间切换，可选项如下: kcpserver、kcpclient -k : 参数后指定一个 kcptun 的参数字符串，所有参数将被拼接到 kcptun 后 Shadowsocks ServerWith Kcptun 1docker run -dt --name ssserver --restart=always -p 6443:6443 -p 6500:6500/udp mritd/shadowsocks:latest -m &quot;ss-server&quot; -s &quot;-s 0.0.0.0 -p 6443 -m aes-256-cfb -k 123456 --fast-open&quot; -x -e &quot;kcpserver&quot; -k &quot;-t 127.0.0.1:6443 -l :6500 -mode fast2&quot; Without Kcptun 1docker run -dt --name ssserver --restart=always -p 6443:6443 mritd/shadowsocks:latest -m &quot;ss-server&quot; -s &quot;-s 0.0.0.0 -p 6443 -m aes-256-cfb -k 123456 --fast-open&quot; ss命令说明： -s : 监听服务ip，为服务器本地 -p : 端口 -m : 加密算法 -k : 密码 --fast-open : 开启TCP fast-open kcptun命令自行度娘=.= Shadowsocks ClientWith Kcptun 1docker run -dt --name ssclient --restart=always -p 1080:1080 -p 6500:6500/udp mritd/shadowsocks:latest -m &quot;ss-local&quot; -s &quot;-s 127.0.0.1 -p 6500 -b 0.0.0.0 -l 1080 -m aes-256-cfb -k 123456 --fast-open&quot; -x -e &quot;kcpclient&quot; -k &quot;-r server-ip:6500 -l :6500 -mode fast2&quot; Without Kcptun 1docker run -dt --name ssclient --restart=always -p 1080:1080 mritd/shadowsocks:latest -m &quot;ss-local&quot; -s &quot;-s server-ip -p 6443 -b 0.0.0.0 -l 1080 -m aes-256-cfb -k 123456 --fast-open&quot; 注意：如果使用了With Kcptun，ss的监听ip填本地 127.0.0.1，server-ip填服务器ip。 Test测试了一下，在开启了BBR情况下，without kcptun更快。对于一般情况（没有开启BBR或其他加速），with kcptun速度有所提升。 使用ShadowSocks代理实现科学上网毕竟Shadowsocks是sock5代理，不能接受http协议，所以我们需要把sock5转化成http流量。 方式一：配置浏览器代理假如你上面任选一种方式已经开始运行sslocal了，火狐那个代理插件老是订阅不了gfwlist所以配置自动模式的话不好使。这里用的是chrome，你可以在Ubuntu软件中心下载得到。 安装插件我们需要给chrome安装SwitchyOmega插件，但是没有代理之前是不能从谷歌商店安装这个插件的，但是我们可以从Github上直接下载最新版https://github.com/FelisCatus/SwitchyOmega/releases/（这个是chrome的）然后浏览器地址打开chrome://extensions/，将下载的插件托进去安装。 设置代理地址安装好插件会自动跳到设置选项，有提示你可以跳过。左边新建情景模式-选择代理服务器-比如命名为shadowProxy（叫什么无所谓）其他默认之后创建，之后在代理协议选择SOCKS5，地址为127.0.0.1,端口默认1080 。然后保存即应用选项。 设置自动切换接着点击自动切换 ( Auto switch）上面的不用管，在按照规则列表匹配请求后面选择刚才新建的SS，默认情景模式选择直接连接。点击应用选项保存。再往下规则列表设置选择AutoProxy 然后将这个地址填进去，点击下面的立即更新情景模式，会有提示更新成功！ 点击浏览器右上角的SwitchyOmega图标，下面选择自动切换，然后打开google.com试试，其他的就不在这贴图了。 方式二：GenPAC全局代理如果不想每个浏览器都要设置代理，可以通过GenPAC实现全局代理。 安装pip：123sudo apt-get install python-pip python-dev build-essential sudo pip install --upgrade pip sudo pip install --upgrade virtualenv GenPAC：12sudo pip install genpacsudo pip install --upgrade genpac 设置全局代理1、进入终端，Ctrl+Alt+T，cd到你希望生成文件存放的位置。例如：1cd /home/ybd/Data/application/shadowsocks 2、执行下面的语句：1sudo genpac --proxy="SOCKS5 127.0.0.1:1080" --gfwlist-proxy="SOCKS5 127.0.0.1:1080" -o autoproxy.pac --gfwlist-url="https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt" 注意：上面语句中127.0.0.1:1080应按照自己的情况填写。如果出现下面这种报错：1fetch gfwlist fail. online: https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt local: None 那么换成执行下面的语句：1sudo genpac --proxy="SOCKS5 127.0.0.1:1080" -o autoproxy.pac --gfwlist-url="https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt" 如果出现base64 decoding fail .，安装其他版本：123sudo pip install https://github.com/JinnLynn/genpac/archive/master.zipsudo pip install --upgrade https://github.com/JinnLynn/genpac/archive/master.zipsudo pip uninstall genpac 3、全局代理系统设置 –&gt; 网络 –&gt; 网络代理“方法”选择“自动”“配置URL”填写：file:///home/ybd/Data/application/shadowsocks/autoproxy.pac点击“应用到整个系统”，接下来可以愉悦的跨过墙了～ 方式三：通过proxychains安装proxychains：1sudo apt install proxychains 配置proxychains：编辑/etc/proxychains.conf，最下面有一行socks4 127.0.0.1 9050，把这一行注释掉，添加一行socks5 127.0.0.1 1080测试：1proxychains curl www.google.com 使用：用命令行启动软件，在前面加上proxychains，如：1proxychains firefox 使用shadowsocks+proxychains代理打开新的Firefox实现浏览器翻墙。也可以通过输入proxychains bash建立一个新的shell，基于这个shell运行的所有命令都将使用代理。 方式四：PrivoxyPrivoxy是一款带过滤功能的代理服务器，针对HTTP、HTTPS协议。通过Privoxy的过滤功能，用户可以保护隐私、对网页内容进行过滤、管理cookies，以及拦阻各种广告等。Privoxy可以用作单机，也可以应用到多用户的网络。 1sudo apt install privoxy 安装好后进行配置，Privoxy的配置文件在/etc/privoxy/config，这个配置文件中注释很多。 找到4.1. listen-address这一节，确认监听的端口号。 找到5.2. forward-socks4, forward-socks4a, forward-socks5 and forward-socks5t这一节，加上如下配置，注意最后的点号。 重启一下Privoxy 1sudo /etc/init.d/privoxy restart 终端体验： 12export http_proxy=&quot;127.0.0.1:8118&quot; &amp;&amp; export https_proxy=&quot;127.0.0.1:8118&quot;wget http://www.google.com 在/etc/profile的末尾添加如下两句。 12export http_proxy=&quot;127.0.0.1:8118&quot;export https_proxy=&quot;127.0.0.1:8118&quot; ShadowSocks优化开启TCP Fast Open这个需要服务器和客户端都是Linux 3.7+的内核在服务端和客户端的/etc/sysctl.conf都加上：12# turn on TCP Fast Open on both client and server sidenet.ipv4.tcp_fastopen = 3 然后把vi /etc/shadowsocks.json配置文件中&quot;fast_open&quot;: false改为&quot;fast_open&quot;: true 使用特殊端口GFW会通过某些手段来减轻数据过滤的负荷，例如特殊的端口如ssh，ssh默认端口给ss用了那么久必须修改我们登录服务器的端口。修改SSH配置文件：1vi /etc/ssh/sshd_config 找到#port 22，将前面的#去掉，然后修改端口 port 2333（自己设定）。然后重启SSH：1service ssh restart 跟多详情请见：https://github.com/iMeiji/shadowsocks_install/wiki/shadowsocks-optimize 黑科技加速系列FinalSpeed91yun发布的finalspeed一键安装包锐速替代品双边加速FinalSpeed客户端下载及教程 ，Openvz福音 锐速锐速破解版linux一键自动安装包 Google BBR一键安装最新内核并开启 BBR 脚本 更换Linode内核谷歌开发的TCP加速“外挂”，目前已集成到最新的Linux内核。博主用的Linode不能直接命令更换内核，需要到管理后台设置： 安装123wget --no-check-certificate https://github.com/teddysun/across/raw/master/bbr.sh &amp;&amp; \chmod +x bbr.sh &amp;&amp; \./bbr.sh KcptunKcptun 服务端一键安装脚本 VPS防DDOS攻击 公司刚买了一个Linode VPS 2TB流量的，不到几天就被DDOS攻击，直到余额被扣完停机。。。 吓得我马上谷歌了一些防御措施 开启UFW防火墙1234ufw enableufw allow sshufw allow [shadowsocks_port]ufw allow from [remote_ip] DDOS deflateDDOS deflate是一款免费的用来防御和减轻DDOS攻击的脚本。它通过netstat监测跟踪创建大量网络连接的IP地址，在检测到某个结点超过预设的限制时，该程序会通过APF或IPTABLES禁止或阻挡这些IP。 123wget http://www.moerats.com/usr/down/DDOS/deflate.sh &amp;&amp; \chmod +x deflate.sh &amp;&amp; \./deflate.sh 配置文件/usr/local/ddos/ddos.conf 123456789101112131415161718192021222324252627282930313233343536##### Paths of the script and other filesPROGDIR=”/usr/local/ddos”PROG=”/usr/local/ddos/ddos.sh”IGNORE_IP_LIST=”/usr/local/ddos/ignore.ip.list” # 白名单.如有反向代理,注意添加本机地址和本机外网IP地址,防止提供反向代理的主机被判定为攻击.CRON=”/etc/cron.d/ddos.cron”APF=”/etc/apf/apf”IPT=”/sbin/iptables”##### frequency in minutes for running the script##### Caution: Every time this setting is changed, run the script with cron##### option so that the new frequency takes effectFREQ=1##### How many connections define a bad IP? Indicate that below. # 单IP发起连接数阀值,不建议设置太低.NO_OF_CONNECTIONS=150##### APF_BAN=1 (Make sure your APF version is atleast 0.96)##### APF_BAN=0 (Uses iptables for banning ips instead of APF) #一般情况下你是使用iptables来做防火墙,所以这里你需要将 APF_BAN的值改为0.APF_BAN=1##### KILL=0 (Bad IPs are’nt banned, good for interactive execution of script)##### KILL=1 (Recommended setting)KILL=1 #是否屏蔽IP，默认即可##### An email is sent to the following address when an IP is banned. # 当单IP发起的连接数超过阀值后,将发邮件给指定的收件人.##### Blank would suppress sending of mailsEMAIL_TO=”root” # 这里是邮箱，可以把root替换成你的邮箱##### Number of seconds the banned ip should remain in blacklist. # 设置被挡IP多少秒后移出黑名单.BAN_PERIOD=600 将上述配置文件修改完成后，使用命令启动即可 1ddos -d Ubuntu中可能会报错： 1234root@localhost:~# ddos -d/usr/local/sbin/ddos: 13: [: /usr/local/ddos/ddos.conf: unexpected operatorDDoS-Deflate version 0.6Copyright (C) 2005, Zaf &lt;zaf@vsnl.com&gt; 因为启动大多数为 bash 脚本，而 Ubuntu 的默认环境为 dash，所以需要使用 dpkg-reconfigure dash，选择 NO，切换为 bash 运行脚本： 1dpkg-reconfigure dash Denyhosts防暴力攻击这个方法比较省时省力。denyhosts 是 Python 语言写的一个程序，它会分析 sshd 的日志文件，当发现重复的失败登录时就会记录 IP 到 /etc/hosts.deny 文件，从而达到自动屏 IP 的功能：1apt-get install denyhosts 1.防火长城（英语：Great Firewall( of China)，常用简称：GFW，中文也称中国国家防火墙，中国大陆民众俗称防火墙等），是对中华人民共和国政府在其互联网边界审查系统（包括相关行政审查系统）的统称。此系统起步于1998年，其英文名称得自于2002年5月17日Charles R. Smith所写的一篇关于中国网络审查的文章《The Great Firewall of China》，取與Great Wall（长城）相谐的效果，简写为Great Firewall，缩写GFW。隨着使用的拓广，中文「墙」和英文「GFW」有时也被用作动词，网友所說的「被墙」即指被防火长城所屏蔽，「翻墙」也被引申为浏览国外网站、香港等特区网站的行为。 ↩]]></content>
      <categories>
        <category>VPS</category>
      </categories>
      <tags>
        <tag>VPS</tag>
        <tag>ShadowSocks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java基本数据类型传递与引用传递的那点事]]></title>
    <url>%2F2017%2Fjava-call-by-value%2F</url>
    <content type="text"><![CDATA[前言今天在逛博客的时候看到了有意思的东西，下面代码会输出什么？123456789public static void change(String s) &#123; s = "123"; &#125; public static void main(String args[]) &#123; String s = "abc"; change(s); System.out.println(s); &#125; 结果是abc。为什么？经过一番查找与理解，又学习到了… 捋一捋术语Java的值传递和引用传递在面试中一般都会都被涉及到，今天我们就来聊聊这个问题，首先我们必须认识到这个问题一般是相对函数而言的，也就是java中的方法参数，那么我们先来回顾一下在程序设计语言中有关参数传递给方法（或函数）的两个专业术语： 按值调用（call by value） 按引用调用（call by reference）所谓的按值调用表示方法接收的是调用着提供的值，而按引用调用则表示方法接收的是调用者提供的变量地址(如果是C语言的话来说就是指针啦，当然java并没有指针的概念)。这里我们需要注意的是一个方法可以修改传递引用所对应的变量值，而不能修改传递值调用所对应的变量值，这句话相当重要，这是按值调用与引用调用的根本区别。 基本数据类型的传递前面说过java中并不存在引用调用，这点是没错的，因为java程序设计语言确实是采用了按值调用，即call by value。也就是说方法得到的是所有参数值的一个拷贝，方法并不能修改传递给它的任何参数变量的内容。下面来看一个例子：12345678910111213public class CallByValue &#123; private static int x=10; public static void updateValue(int value)&#123; value = 3 * value; &#125; public static void main(String[] args) &#123; System.out.println("调用前x的值："+x); updateValue(x); System.out.println("调用后x的值："+x); &#125; 运行程序，结果如下：12调用前x的值：10调用后x的值：10 可以看到x的值并没有变化，接下来我们一起来看一下具体的执行过程： 分析：1）value被初始化为x值的一个拷贝（也就是10）2）value被乘以3后等于30，但注意此时x的值仍为10！3）这个方法结束后，参数变量value不再使用，被回收。结论：当传递方法参数类型为基本数据类型（数字以及布尔值）时，一个方法是不可能修改一个基本数据类型的参数。 引用数据类型的传递当然java中除了基本数据类型还有引用数据类型，也就是对象引用，那么对于这种数据类型又是怎么样的情况呢？还是一样先来看一个例子：声明一个User对象类型：1234567891011121314151617181920public class User &#123; private String name; private int age; public User(String name, int age) &#123; this.name=name; this.age=age; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; &#125; 执行类如下：1234567891011121314public class CallByValue &#123; private static User user=null; public static void updateUser(User student)&#123; student.setName("Lishen"); student.setAge(18); &#125; public static void main(String[] args) &#123; user = new User("zhangsan",26); System.out.println("调用前user的值："+user.toString()); updateUser(user); System.out.println("调用后user的值："+user.toString()); &#125; 运行结果如下：12调用前user的值：User [name=zhangsan, age=26]调用后user的值：User [name=Lishen, age=18] 很显然，User的值被改变了，也就是说方法参数类型如果是引用类型的话，引用类型对应的值将会被修改，下面我们来分析一下这个过程： 过程分析：1）student变量被初始化为user值的拷贝，这里是一个对象的引用。2）调用student变量的set方法作用在这个引用对象上，user和student同时引用的User对象内部值被修改。3）方法结束后，student变量不再使用，被释放，而user还是没有变，依然指向User对象。结论：当传递方法参数类型为引用数据类型时，一个方法将修改一个引用数据类型的参数所指向对象的值。 再来举个例子虽然到这里两个数据类型的传递都分析完了，也明白的基本数据类型的传递和引用数据类型的传递区别，前者将不会修改原数据的值，而后者将会修改引用所指向对象的值。可通过上面的实例我们可能就会觉得java同时拥有按值调用和按引用调用啊，可惜的是这样的理解是有误导性的，虽然上面引用传递表面上体现了按引用调用现象，但是java中确实只有按值调用而没有按引用调用。到这里估计不少人都蒙逼了，下面我们通过一个反例来说明（回忆一下开头我们所说明的按值调用与按引用调用的根本区别）。12345678910111213141516171819202122232425public class CallByValue &#123; private static User user=null; private static User stu=null; /** * 交换两个对象 * @param x * @param y */ public static void swap(User x,User y)&#123; User temp =x; x=y; y=temp; &#125; public static void main(String[] args) &#123; user = new User("user",26); stu = new User("stu",18); System.out.println("调用前user的值："+user.toString()); System.out.println("调用前stu的值："+stu.toString()); swap(user,stu); System.out.println("调用后user的值："+user.toString()); System.out.println("调用后stu的值："+stu.toString()); &#125; 我们通过一个swap函数来交换两个变量user和stu的值，在前面我们说过，如果是按引用调用那么一个方法可以修改传递引用所对应的变量值，也就是说如果java是按引用调用的话，那么swap方法将能够实现数据的交换，而实际运行结果是：1234调用前user的值：User [name=user, age=26]调用前stu的值：User [name=stu, age=18]调用后user的值：User [name=user, age=26]调用后stu的值：User [name=stu, age=18] 我们发现user和stu的值并没有发生变化，也就是方法并没有改变存储在变量user和stu中的对象引用。swap方法的参数x和y被初始化为两个对象引用的拷贝，这个方法交换的是这两个拷贝的值而已，最终，所做的事都是白费力气罢了。在方法结束后x，y将被丢弃，而原来的变量user和stu仍然引用这个方法调用之前所引用的对象。这个过程也充分说明了java程序设计语言对对象采用的不是引用调用，实际上是对象引用进行的是值传递，当然在这里我们可以简单理解为这就是按值调用和引用调用的区别，而且必须明白即使java函数在传递引用数据类型时，也只是拷贝了引用的值罢了，之所以能修改引用数据是因为它们同时指向了一个对象，但这仍然是按值调用而不是引用调用。总结： 一个方法不能修改一个基本数据类型的参数（数值型和布尔型） 一个方法可以修改一个引用所指向的对象状态，但这仍然是按值调用而非引用调用 上面两种传递都进行了值拷贝的过程 最后 参考http://blog.csdn.net/javazejian/article/details/51192130http://blog.csdn.net/seu_calvin/article/details/70089977]]></content>
      <categories>
        <category>Programming</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Java basics</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu下使用IntelliJ IDEA的正确姿势]]></title>
    <url>%2F2017%2Fnote-of-learning-idea-under-ubuntu%2F</url>
    <content type="text"><![CDATA[Preface公司里的大牛们用的IDE基本都是IDEA近墨者黑，早就听闻IntelliJ IDEA这个大名，只不过当初比较菜鸟还不会用(…虽然现在也还是个菜鸟=.=)，再不用就要被OUT了此篇把在Ubuntu下使用IDEA的学习经验记录下来(网上还是比较少资料解决Ubuntu下IDEA的问题Orz)，以便老了记性不好可以看一看…Install博主采用Toolbox App 方式安装。这样的好处是我们不用关心更新问题，每次有新版本它都会提示，我们是需要点一下Install就可以了，不需要关心升级后的配置。还有一个好处是可以管理其他的IntelliJ软件（虽然博主只用他们的IDEA = =）…安装的时候注意配置安装路径：License注册码可以自己读娘，或者使用授权服务器博主用的是基于docker的授权服务器：12docker pull ilanyu/golang-reverseproxydocker run -d -p 6666:8888 ilanyu/golang-reverseproxy 也可以自己搭建一个基于docker的服务 = = https://github.com/masteranthoneyd/docker-jetlicense 部署到VPS上，nginx反向代理： 12345678910111213server &#123; listen 80; server_name 域名; location / &#123; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Host $http_host; proxy_set_header X-NginX-Proxy true; proxy_pass http://127.0.0.1:端口/; proxy_redirect off; &#125;&#125; 重启nginx： 1nginx -s reload Personal Setting博主的常用配置：一般会选择打开项目时最外层的窗口打开setting，对全局生效。 文件修改后，设置左边目录出现颜色变化 如果只有一行方法的代码默认要展开，去掉这个勾 修改字体和字号Ubuntu下默认的字体还是让人看了有点不爽，而且使用Ubuntu默认的字体工具栏可能会出现乱码。下面三个地方，分别是窗口字体，代码字体和控制台字体： 修改VM参数通过Toolbox可以简单地设置VM参数，博主16G内存的主机的VM参数设置为123-Xms512m-Xmx1500m-XX:ReservedCodeCacheSize=500m 设置代码不区分大小写 优化导包IDEA默认检测到有5个相同包就会自动import *，其实没必要，需要哪个就import哪个。 设置不自动打开上一次最后关闭的项目 Postfix Completion这个本来就是默认开启的 可生成SreializableID在 setting&gt;Editor&gt;Inspections&gt;Java&gt;Serializtion Issues&gt;:钩上之后在需要生成的类上Alt+Enter就会出现了。 关闭代码拖拽功能一不小心手抖就改了代码…禁用！ 显示内存使用情况点击内存信息展示的那个条可以进行部分的内存回收 优化 Java 注释 优化方法链在Java8中特别是使用Stream API，ex：1list.stream().filter(func).distinct().skip(num).limit(num).map(func).peek(func).collect(func); 写成一行太长了！！勾上这个选项idea将自动帮我们优化： 会变成这样 1234list = list.stream() .filter(func) .distinct() ..... 多线程自动编译 Keyboard shortcuts JetBrains官方快捷键手册： https://resources.jetbrains.com/storage/products/intellij-idea/docs/IntelliJIDEA_ReferenceCard.pdf 个人感觉Ubuntu下使用IDEA最大的一个不爽就是快捷键了，想屎的感觉有木有，各种没反应，原来是快捷键冲突，本来想改成Eclipse的风格，但想了想好像不太合适。快捷键风格可以在setting -&gt; Keymap 里面这是，博主使用安装时候idea默认配置的Default for XWin。先来大致分各类（纯属个人看法= =）： 导航（一般都可以在Navigate里面找到） Keyboard shortcut Declaration Ctrl+N 查找Java类 Ctrl+Shift+N 查找非Java文件 Ctrl+Shift+Alt+N 查找类中的方法或变量 Double Shift 查找所有 Ctrl+Alt+Left/Right 跳到光标的上/下一个位置 F2/Shift+F2 光标移动到下/上一个错误 Ctrl+Shift+Backspace 跳到上一个编辑处 Ctrl+Alt+B 跳到实现类/方法 Ctrl+U 跳到父类/方法 Alt+Up/Down 光标移动到上/下一个方法 Ctrl+F12 搜索当前文件方法 Ctrl+H/Ctrl+Shift+H 显示类/方法层级 F11/Shift+F11 当前行设置书签/显示所有书签 Ctrl+Shift+Backspace 跳到上一个编辑处 Ctrl+G 跳到指定行 查找/替换（一般在Edit的find里面） Keyboard shortcut Declaration Ctrl+F 文件内查找 Ctrl+R 文件内替换 F3/Shift+F3 查找下/上一个 Ctrl+Shift+F 目录内查找 Ctrl+Shift+R 目录内替换 Ctrl+F7 查找当前文件中的使用处 Alt+F7 查找被使用处 Ctrl+Alt+F7 显示被使用处 编辑 Keyboard shortcut Declaration Ctrl+D/Ctrl+Y 重复代码,未选择代码时重复当前行/删除当前行 Ctrl+Shift+Enter 补全语句 Ctrl+P 显示方法参数 Ctrl+Q 显示注释文档 Alt+Insert 生成代码,生成 Getter、Setter、构造器等 Ctrl+O/Ctrl+I 重写父类方法/实现接口方法 Ctrl+W 选择代码块,连续按会增加选择外层的代码块 Ctrl+Shift+W 与“Ctrl+W”相反,减少选择代码块 Ctrl+Alt+L 格式化代码 Ctrl+Alt+O 优化 Imports Ctrl+Shift+J 合并多行为一行 Ctrl+Shift+U 对选中内容进行大小写切换 Ctrl+Shift+]/[ 选中到代码块的开始/结束 Ctrl+Delete/Ctrl+Backspace 删除从光标所在位置到单词结束/开头处 Ctrl+F4 关闭当前编辑页 Alt+J/Ctrl+Alt+Shift+J 匹配下一个/全部与当前选中相同的代码 Alt+Shift+J “Alt+J”的反选 Alt+Shift+Insert,然后Shift+Up/Down 同时编辑多行(退出此Column模式也是“Alt+Shift+Insert”) 调试 Keyboard shortcut Declaration F8/F7 单步调试,不进入函数内部/进入函数内部 Shift+F8 跳出函数 Alt+F9 运行到断点 Alt+F8 执行表达式查看结果 F9 继续执行,进入下一个断点或执行完程序 Ctrl+Shift+F8 查看断点 重构 Keyboard shortcut Declaration F6 移动类 Alt+Delete 安全删除,删除前会提示调用处 Shift+F6 重命名 Ctrl+F6 重构方法参数、Exception 等 Ctrl+Alt+M 提取为新方法 Ctrl+Alt+V 提取为新变量 Ctrl+Alt+F 提取为对象新属性 Ctrl+Alt+C 提取为新静态常量 Ctrl+Alt+P 提取为方法参数 Ctrl+Shift+Alt+P 提取为函数式参数 Ctrl+Alt+Shift+T 重构一切 Plugin简洁代码风格Lombok1.首先在IDEA里面安装使用lombok编写简略风格代码的插件，打开IDEA的Settings面板，并选择Plugins选项，然后点击 “Browse repositories..”在输入框输入”lombok”，得到搜索结果，选择第二个，点击安装，然后安装提示重启IDEA，安装成功; 还需要在IDEA中开启支持： 2.在自己的项目里添加lombok的编译支持(maven项目),在pom文件里面添加如下indenpence 12345&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.18&lt;/version&gt;&lt;/dependency&gt; 3.然后就可以尽情在自己项目里面编写简略风格的Java代码咯12345678910111213141516171819202122232425package com.lombok;import lombok.Data;import lombok.EqualsAndHashCode;import java.util.List;@Data@EqualsAndHashCode(callSuper = false)public class Student &#123; String name; int sex; Integer age; String address; List&lt;String&gt; books;&#125;//使用Student类对象Student student = new Student();student.setName(name);student.setAge(age);student.setAddress(address);student.setBooks(Arrays.asList(books)); 4.常用注解 @Getter and @Setter：生成getter / setter方法，默认生成的方法是public的，如果要修改方法修饰符可以设置AccessLevel的值，例如：@Getter(access = AccessLevel.PROTECTED) @ToString：生成toString()方法，可以这样设置不包含哪些字段@ToString(exclude = &quot;id&quot;) / @ToString(exclude = {&quot;id&quot;,&quot;name&quot;})，如果继承的有父类的话，可以设置callSuper 让其调用父类的toString()方法，例如：@ToString(callSuper = true) @NoArgsConstructor, @RequiredArgsConstructor, @AllArgsConstructor：@NoArgsConstructor生成一个无参构造方法。当类中有final字段没有被初始化时，编译器会报错，此时可用@NoArgsConstructor(force = true)，然后就会为没有初始化的final字段设置默认值 0 / false / null。对于具有约束的字段（例如@NonNull字段），不会生成检查或分配，因此请注意，正确初始化这些字段之前，这些约束无效。@RequiredArgsConstructor会生成构造方法（可能带参数也可能不带参数），如果带参数，这参数只能是以final修饰的未经初始化的字段，或者是以@NonNull注解的未经初始化的字段@RequiredArgsConstructor(staticName = &quot;of&quot;)会生成一个of()的静态方法，并把构造方法设置为私有。@AllArgsConstructor 生成一个全参数的构造方法。 @Data：@Data 包含了@ToString，@EqualsAndHashCode，@Getter / @Setter和@RequiredArgsConstructor的功能。 @Accessors：主要用于控制生成的getter和setter，此注解有三个参数：fluent boolean值，默认为false。此字段主要为控制生成的getter和setter方法前面是否带get/set；chain boolean值，默认false。如果设置为true，setter返回的是此对象，方便链式调用方法prefix 设置前缀 例如：@Accessors(prefix = &quot;abc&quot;) private String abcAge 当生成get/set方法时，会把此前缀去掉。 @Synchronized：给方法加上同步锁。 @Builder：@Builder注释为你的类生成复杂的构建器API： 1Person.builder().name(&quot;Adam Savage&quot;).city(&quot;San Francisco&quot;).job(&quot;Mythbusters&quot;).job(&quot;Unchained Reaction&quot;).build(); @NonNull：如其名，不能为空，否则抛出NullPointException Log类： 1234567891011121314@CommonsLogCreates private static final org.apache.commons.logging.Log log = org.apache.commons.logging.LogFactory.getLog(LogExample.class);@JBossLogCreates private static final org.jboss.logging.Logger log = org.jboss.logging.Logger.getLogger(LogExample.class);@LogCreates private static final java.util.logging.Logger log = java.util.logging.Logger.getLogger(LogExample.class.getName());@Log4jCreates private static final org.apache.log4j.Logger log = org.apache.log4j.Logger.getLogger(LogExample.class);@Log4j2Creates private static final org.apache.logging.log4j.Logger log = org.apache.logging.log4j.LogManager.getLogger(LogExample.class);@Slf4jCreates private static final org.slf4j.Logger log = org.slf4j.LoggerFactory.getLogger(LogExample.class);@XSlf4jCreates private static final org.slf4j.ext.XLogger log = org.slf4j.ext.XLoggerFactory.getXLogger(LogExample.class); Lombok的功能不仅如此，更详细请看features Docker Integration可以通过IDEA链接Docker API，前提是开启了Docker API GsonFormat复制一段JSON格式字符串 Ali规约插件 P3C插件地址：https://github.com/alibaba/p3c文档：https://github.com/alibaba/p3c/blob/master/idea-plugin/README_cn.md FindBugs装完之后右键最下面会多出一个FindBugs的选项 热部署插件JRebel安装与激活 每次修改java文件都需要重启tomcat，很痛苦有木有？ 推荐给大家一个很好用的热部署插件，JRebel，目前是最好的，在使用过程中应该90%的编辑操作都是可以reload的，爽歪歪，节约我们大量的开发时间，提高开发效率。 安装两种方式安装： 方式一下载安装，前往JRebe官网下载地址，选择对应IDE的版本下载，然后安装（下面照搬官网说的…）：1、Open File &gt; Settings (Preferences on macOS). Select Plugins.2、Press Install plugin from disk…3、Browse to the downloaded archive and press OK. Complete the installation. 方式二直接安装：1、Open File &gt; Settings. Select Plugins.2、Press Browse Repositories.3、Find JRebel. Press Install plugin.4、Next → Activation 激活先戳进官网，使用Facebook或Twitter注册登录，之后就可以免费申请激活码了： 打开 Help &gt; JRebel &gt; Activation，将申请的激活码复制进去，稍等片刻完成激活。 工程配置打开 view &gt; tool window &gt; Jrebel，在弹出框中勾选你要热部署的项目：在tomcat配置中勾选图示选项：deployment 要选择后缀为explored的工程。 启动点击 JRebel图标，启动项目 Stackoverflow看名字就知道这个是干嘛的啦，在plugin repostories直接搜索stackoverflow就找得到 重启后随便选中内容右键就可以看到 Nyan progress bar这个是彩虹版的进度条… Background Image Plus这是一个设置背景图的插件 activate-power-mode 或 Power mode ||这个抖动的窗口老年人实在受不了… Markdown Navigator支持md编写下载Markdown Navigator下载地址： https://plugins.jetbrains.com/plugin/7896-markdown-navigator下载下来的应该是一个zip文件 解压解压后进入lib文件，找到idea-multimarkdown.jar： 打开jar包找到 com.vladsch.idea.multimarkdown.license.LicenseAgent.java IDEA创建项目在IDEA里创建一个Java项目，且目录必须为com.vladsch.idea.multimarkdown.license,要不然编译出来的package属性就变了哦把上面找到的LicenseAgent.java扔进去 恩，接着一大波红色的波浪错误出现啦，先别紧张，咱们把依赖包加上去就OK了： 上图的两个依赖分别是解压Markdown Navigator插件里边的lib包和IDEA文件夹里边的lib包 修改铺垫做完了，开始改源码了。修改 com.vladsch.idea.multimarkdown.license.LicenseAgent.java 文件的内容如下： getLicenseExpires() 整个方法体干掉不要了(删除方法体)，只留返回值改为 return &quot;Never Expires&quot;; getLicenseCode() 最后一行返回值 return false 改为 return true，对你没有看错，只改最后一行代码; isValidLicense() 删除方法体，只留返回值，返回值改为 return true; isValidActivation() 删除方法体，只留返回值，返回值改为 return true; getLicenseType() 删除方法体，只留返回值，返回值改为 return &quot;License&quot; 或 return &quot;license&quot;; getLicenseExpiringIn() 删除方法体，只留返回值，返回值改为 return 36000;(单位是天) isActivationExpired() 删除方法体，只留返回值，返回值改为 return false. 改完后右键java文件compile编译一下得到class文件 替换用上面得到的LicenseAgent.class文件替换掉idea-multimarkdown.jar/com/vladsch/idea/multimarkdown/license里面的文件LicenseAgent.class文件： 安装替换完成后把解压的插件包重新打包成zip文件 打开Setting找到Pligins： 之后重启IDEA，搞定~虽然有很多功能齐全的md编辑器，但是用IDEA配置和编写Hexo，还要打开别的编辑器那就太不方便了，还是用浑然天成的插件吧。改了源码后插件上面的工具栏貌似没有效果了… Enso它可以将测试名转化成一个句子，一目了然地显示测试的内容。这意味着当你在注视任何类的时候， Enso 都会展示其说明文档。 VM Options可以通过ToolBox或IDEA选项里面设置 优化参数： 12345678910111213141516-Xms512m-Xmx2g-XX:ReservedCodeCacheSize=480m-XX:+UseG1GC-XX:-UseParNewGC-XX:-UseConcMarkSweepGC-XX:SoftRefLRUPolicyMSPerMB=200-XX:MaxMetaspaceSize=512m-ea-server-Dsun.io.useCanonCaches=false-Djava.net.preferIPv4Stack=true-XX:+HeapDumpOnOutOfMemoryError-XX:-OmitStackTraceInFastThrow-Dsun.awt.keepWorkingSetOnMinimize=true-Dide.no.platform.update=true 部分参数说明： -Xms512m: 初始时内存大小，至少为Xmx的二分之一 -Xmx2g: 最大内存大小，若总内存小于2GB，至少为总内存的四分之一；若总内存大于2GB，设为1-4GB -XX:+UseG1GC -XX:-UseParNewGC -XX:-UseConcMarkSweepGC: 设置使用G1垃圾收集器 -server: JVM以server的方式运行，启动速度慢，运行速度快 -Dsun.awt.keepWorkingSetOnMinimize=true: 让IDEA最小化后阻止JVM对其进行修剪 Conflict of keyboard shortcuts快捷键有冲突，创建脚本并执行：12345#!/bin/bash gsettings set org.gnome.desktop.wm.keybindings toggle-shaded "[]" gsettings set org.gnome.settings-daemon.plugins.media-keys screensaver "[]"gsettings set org.gnome.desktop.wm.keybindings switch-to-workspace-left "[]" gsettings set org.gnome.desktop.wm.keybindings begin-move "[]" 如果是习惯Windows下的快捷键，那么可以禁用TTY（IDEA Ctrl+Alt+F1-6冲突）： 1234567FILE_NAME=/usr/share/X11/xorg.conf.d/50-novtswitch.conf &amp;&amp;\sudo touch $&#123;FILE_NAME&#125; &amp;&amp; \sudo tee $&#123;FILE_NAME&#125; &lt;&lt; EOF Section &quot;ServerFlags&quot;Option &quot;DontVTSwitch&quot; &quot;true&quot;EndSectionEOF 目前发现的快捷键冲突：1、Ctrl+Alt+方向，直接到系统设置里面改： 2、安装了搜狗之后，按Ctrl+Alt+B会启动虚拟键盘，所以在输入法里面打开Fcitx设置，在附加组件里面，点击高级，再把虚拟键盘的选项去掉：然后注销或重启电脑。 3、Ctrl+Alt+S，这个在键盘设置里面找了很久，原来这玩意在输入法设置里面，点开输入法全局配置，把显示高级选项钩上，就会看到很多快捷键，我都把它们干掉了。 Finally IDEA真的智能到没朋友…如果喜欢IDEA这款软件，并且有经济能力的，请付费购买~]]></content>
      <categories>
        <category>IDE</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>IDE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM知识杂汇]]></title>
    <url>%2F2017%2Fjvm-knowledge-collect-01%2F</url>
    <content type="text"><![CDATA[前言想要深刻地理解Java，那么就要深入地理解底层——JVM(Java Virtual Machine | Java虚拟机)。JVM（Java Virtual Machine）Java 虚拟机是整个 java 平台的基石，是 java 系统实现硬件无关与操作系统无关的关键部分，是保障用户机器免于恶意代码损害的屏障。Java开发人员不需要了解JVM是如何工作的，但是，了解 JVM 有助于我们更好的开（通）发（过） java（公司） 程（面）序（试）博主经过一番查阅，找到了自认为写的好的一些文章，并记录总结，方便不定时的看。希望每次看都会有新的领悟，不断提高自己。Java虚拟机架构什么是JVM要想说明白什么 JVM 就不得不提另外两个概念，JRE 和 JDK，初学者总是把这几个概念搞混。JVM，JRE，JDK 都是 Java 语言的支柱，他们分工协作。但不同的是 JDK 和 JRE 是真实存在的，而 JVM 是一个抽象的概念，并不真实存在。JDKJDK(Java Development Kit) 是 Java 语言的软件开发工具包（SDK）。JDK 物理存在，是 programming tools、JRE 和 JVM 的一个集合。JREJRE（Java Runtime Environment）Java 运行时环境，JRE 物理存在，主要由Java API 和 JVM 组成，提供了用于执行 Java 应用程序最低要求的环境。JVM（Java Virtual Machine）JVM(Java Virtual Machine) 是一种软件实现，执行像物理机程序的机器（即电脑）。本来，Java被设计基于从物理机器分离实现WORA（ 写一次，随处运行 ）的虚拟机上运行，虽然这个目标已经几乎被遗忘。JVM 并不是专为 Java 所实现的运行时，实际上只要有其他编程语言的编译器能生成正确 Java bytecode 文件，则这个语言也能实现在JVM上运行。因此，JVM 通过执行 Java bytecode 可以使 java 代码在不改变的情况下运行在各种硬件之上。JVM实现了Java语言最重要的特征：即平台无关性。平台无关性原理：编译后的 Java程序（.class文件）由JVM执行。JVM屏蔽了与具体平台相关的信息，使程序可以在多种平台上不加修改地运行。Java虚拟机在执行字节码时，把字节码解释成具体平台上的机器指令执行。因此实现Java平台无关性。JVM结构图JVM = 类加载器 classloader+ 执行引擎 executionengine + 运行时数据区域 runtime data area首先Java源代码文件被Java编译器编译为字节码文件，然后JVM中的类加载器加载完毕之后，交由JVM执行引擎执行。在整个程序执行过程中，JVM中的运行时数据区（内存）会用来存储程序执行期间需要用到的数据和相关信息。因此，在Java中我们常常说到的内存管理就是针对这段空间进行管理（如何分配和回收内存空间）。ClassLoaderClassLoader把硬盘上的class文件加载到JVM中的运行时数据区域，但是它不负责这个类文件能否执行，而这个是执行引擎负责的。执行引擎作用：执行字节码，或者执行本地方法。Runtime DataAreaJVM运行时数据区 (JVM RuntimeArea)其实就是指 JVM在运行期间，其对JVM内存空间的划分和分配。JVM在运行时将数据划分为了以下几个区域来存储。程序员写的所有程序都被加载到运行时数据区域中。（图注：JDK1.7已经把常量池转移到堆里面了！）PC寄存器（The pc Register）（1）每一个Java线程都有一个PC寄存器，用以记录当前执行到哪个指令。（2）用于存储每个线程下一步将执行的JVM指令，如该方法是Java方法，则记录的是正在执行的虚拟机字节码地址，如该方法为native的，则计数器值为空。（3）此内存区域是唯一一个在JVM中没有规定任何OutOfMemoryError情况的区域。JVM栈（Java Virtual Machine Stacks）（1）JVM栈是线程私有的，并且生命周期与线程相同。并且当线程运行完毕后，相应内存也就被自动回收。（2）栈里面存放的元素叫栈帧，每个函数从调用到执行结束，其实是对应一个栈帧的入栈和出栈。（栈帧好像很复杂的样子，其实它很简单！）它里面具体存放的是执行的函数的一些数据，如局部变量、操作数栈（执行引擎计算时需要），方法出口等等。（3）这个区域可能有两种异常：如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError异常（如：将一个函数反复递归自己，最终会出现这种异常）。如果JVM栈可以动态扩展（大部分JVM是可以的），当扩展时无法申请到足够内存则抛出OutOfMemoryError异常。下面来实现一个栈溢出：12345678910111213141516171819202122package org.antd.test;public class StackOverFlowMock &#123; int num; public int getNum() &#123; return num; &#125; public void stackOver()&#123; num++; stackOver(); &#125; public static void main(String[] args) &#123; StackOverFlowMock stackOverFlowTest = new StackOverFlowMock(); try &#123; stackOverFlowTest.stackOver(); &#125; catch (Throwable t) &#123; System.out.println("迭代深度："+stackOverFlowTest.getNum()); t.printStackTrace(); &#125; &#125;&#125; 输出为：12345678迭代深度：17781java.lang.StackOverflowError at org.antd.test.StackOverFlowMock.stackOver(StackOverFlowMock.java:10) at org.antd.test.StackOverFlowMock.stackOver(StackOverFlowMock.java:10) at org.antd.test.StackOverFlowMock.stackOver(StackOverFlowMock.java:10) at org.antd.test.StackOverFlowMock.stackOver(StackOverFlowMock.java:10) at org.antd.test.StackOverFlowMock.stackOver(StackOverFlowMock.java:10) at org.antd.test.StackOverFlowMock.stackOver(StackOverFlowMock.java:10) 本地方法栈（Native Method Stacks）（1）本地方法栈与虚拟机栈所发挥的作用很相似，他们的区别在于虚拟机栈为执行Java代码方法服务，而本地方法栈是为Native方法服务。（2）和JVM栈一样，这个区域也会抛出StackOverflowError和OutOfMemoryError异常。 方法区（Method Area）（1）在方法区中，存储了每个类的信息、静态变量等。如，当程序中通过getName、isInterface等方法来获取信息时，这些数据来源于方法区。（2）方法区域是全局共享的，比如每个线程都可以访问同一个类的静态变量。（3）由于使用反射机制的原因，虚拟机很难推测哪个类信息不再使用，因此这块区域的回收很难！另外，对这块区域主要是针对常量池回收，值得注意的是JDK1.7已经把常量池转移到堆里面了。（4）同样，当方法区无法满足内存分配需求时，会抛出OutOfMemoryError。下面演示一下造成方法区内的OOM场景。执行之前，可以把虚拟机的参数-XXpermSize和-XX：MaxPermSize限制方法区大小。那么实现一下OOM：1234567891011121314151617public class HeapOomMock &#123; public static void main(String[] args) &#123; List&lt;byte[]&gt; list = new ArrayList&lt;byte[]&gt;(); int i = 0; boolean flag = true; while (flag) &#123; try &#123; i++; list.add(new byte[1024 * 1024]);// 每次增加一个1M大小的数组对象 &#125; catch (Throwable e) &#123; flag = false; System.out.println("count=" + i);// 记录运行的次数 e.printStackTrace(); &#125; &#125; &#125;&#125; 控制台输出：123count=3422java.lang.OutOfMemoryError: Java heap space at org.antd.test.HeapOomMock.main(HeapOomMock.java:14) 运行时常量池（Runtime Constant Pool）（1）存放类中固定的常量信息、方法引用信息等，其空间从方法区域（JDK1.7后为堆空间）中分配。（2）Class文件中除了有类的版本、字段、方法、接口等描述等信息外，还有就是常量表(constant_pool table)，用于存放编译期已可知的常量，这部分内容将在类加载后进入方法区（永久代）存放。但是Java语言并不要求常量一定只有编译期预置入Class的常量表的内容才能进入方法区常量池，运行期间也可将新内容放入常量池（最典型的String.intern()方法）。（3）当常量池无法在申请到内存时会抛出OutOfMemoryError异常。再来一段代码展示以下：123456//不断将字符串添加到常量池，最终导致内存不足抛出方法区的OOM List&lt;String&gt; list =new ArrayList&lt;String&gt;(); int i =0; while(true)&#123; list.add(String.valueOf(i).intern()); &#125; String的intern函数的作用就不多赘述了，在这篇博文了解String类的intern()方法有所介绍。关于JDK1.6和JDK1.7之后常量池位置的变化对该函数的影响，也在链接文中阐述了。 Java堆（1）Java堆是JVM所管理的最大的一块内存。它是被所有线程共享的一块内存区域，在虚拟机启动时创建。（2）几乎所有的实例对象都是在这块区域中存放。（JIT编译器貌似不是这样的）。（3）Java堆是垃圾搜集管理的主要战场。所有Java堆可以细分为：新生代和老年代。再细致分就是把新生代分为：Eden空间、FromSurvivor空间、To Survivor空间。（4）根据Java虚拟机规范的规定，Java堆可以处于物理上不连续的内存空间中，只要逻辑上是连续的即可，就像我们的磁盘空间一样。如果在堆中没有内存完成实例分配，并且堆也无法再扩展时，将会抛出OutOfMemoryError异常。 堆和栈的区别这是一个非常常见的面试题，主要从以下几个方面来回答。 各司其职最主要的区别就是栈内存用来存储局部变量和方法调用。而堆内存用来存储Java中的对象。无论是成员变量、局部变量还是类变量，它们指向的对象都存储在堆内存中。 空间大小栈的内存要远远小于堆内存，如果你使用递归的话，那么你的栈很快就会充满并产生StackOverFlowError。 独有还是共享栈内存归属于线程的私有内存，每个线程都会有一个栈内存，其存储的变量只能在其所属线程中可见。而堆内存中的对象对所有线程可见，可以被所有线程访问。 异常错误如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError异常。如果JVM栈可以动态扩展（大部分JVM是可以的），当扩展时无法申请到足够内存则抛出OutOfMemoryError异常。而堆内存没有可用的空间存储生成的对象，JVM会抛出java.lang.OutOfMemoryError。 以上便是关于JVM架构的相关知识。 通过String类的intern()了解内存建模与常量池引言什么都先不说，先看下面这个引入的例子：123String str1 = new String("SEU")+ new String("Calvin"); System.out.println(str1.intern() == str1);System.out.println(str1 == "SEUCalvin"); JDK版本1.8，输出结果为：12truetrue 再将上面的例子加上一行代码：1234String str2 = "SEUCalvin";//新加的一行代码，其余不变 String str1 = new String("SEU")+ new String("Calvin"); System.out.println(str1.intern() == str1);System.out.println(str1 == "SEUCalvin"); 再运行，结果为：12false false 是不是感觉莫名其妙，新定义的str2好像和str1没有半毛钱的关系，怎么会影响到有关str1的输出结果呢？其实这都是intern()方法搞的鬼！看完这篇文章，你就会明白。在JVM架构一文中也有介绍，在JVM运行时数据区中的方法区有一个常量池，但是发现在JDK1.6以后常量池被放置在了堆空间，因此常量池位置的不同影响到了String的intern()方法的表现。深入了解后发现还是值得写下来记录一下的。为了确保文章的实时更新，实时修改可能出错的地方，请确保这篇是原文，而不是无脑转载来的“原创文”，原文链接为：http://blog.csdn.net/seu_calvin/article/details/52291082。 为什么要介绍intern()方法intern()方法设计的初衷，就是重用String对象，以节省内存消耗。这么说可能有点抽象，那么就用例子来证明。1234567891011121314151617181920static final int MAX = 100000; static final String[] arr = new String[MAX]; public static void main(String[] args) throws Exception &#123; //为长度为10的Integer数组随机赋值 Integer[] sample = new Integer[10]; Random random = new Random(1000); for (int i = 0; i &lt; sample.length; i++) &#123; sample[i] = random.nextInt(); &#125; //记录程序开始时间 long t = System.currentTimeMillis(); //使用/不使用intern方法为10万个String赋值，值来自于Integer数组的10个数 for (int i = 0; i &lt; MAX; i++) &#123; arr[i] = new String(String.valueOf(sample[i % sample.length])); //arr[i] = new String(String.valueOf(sample[i % sample.length])).intern(); &#125; System.out.println((System.currentTimeMillis() - t) + "ms"); System.gc(); &#125; 这个例子也比较简单，就是为了证明使用intern()比不使用intern()消耗的内存更少。先定义一个长度为10的Integer数组，并随机为其赋值，在通过for循环为长度为10万的String对象依次赋值，这些值都来自于Integer数组。两种情况分别运行，可通过Window&gt;Preferences&gt;Java&gt;InstalledJREs设置JVM启动参数为-agentlib:hprof=heap=dump,format=b，将程序运行完后的hprof置于工程目录下。再通过MAT插件查看该hprof文件。两次实验结果如下：从运行结果来看，不使用intern()的情况下，程序生成了101762个String对象，而使用了intern()方法时，程序仅生成了1772个String对象。自然也证明了intern()节省内存的结论。细心的同学会发现使用了intern()方法后程序运行时间有所增加。这是因为程序中每次都是用了new String后又进行intern()操作的耗时时间，但是不使用intern()占用内存空间导致GC的时间是要远远大于这点时间的。 深入认识intern()方法JDK1.7后，常量池被放入到堆空间中，这导致intern()函数的功能不同，具体怎么个不同法，且看看下面代码，这个例子是网上流传较广的一个例子，分析图也是直接粘贴过来的，这里自己的理解去解释这个例子：123456789String s = new String("1"); s.intern();String s2 = "1"; System.out.println(s == s2); String s3 = new String("1") + new String("1"); s3.intern(); String s4 = "11"; System.out.println(s3 == s4); 输出结果为：12JDK1.6以及以下：false false JDK1.7以及以上：false true 再分别调整上面代码2.3行、7.8行的顺序：123456789String s = new String("1"); String s2 = "1"; s.intern(); System.out.println(s == s2); String s3 = new String("1") + new String("1"); String s4 = "11"; s3.intern(); System.out.println(s3 == s4); 输出结果为：12JDK1.6以及以下：false false JDK1.7以及以上：false false 下面依据上面代码对intern()方法进行分析 JDK1.6在JDK1.6中所有的输出结果都是 false，因为JDK1.6以及以前版本中，常量池是放在 Perm 区（属于方法区）中的，熟悉JVM的话应该知道这是和堆区完全分开的。使用引号声明的字符串都是会直接在字符串常量池中生成的，而 new 出来的 String 对象是放在堆空间中的。所以两者的内存地址肯定是不相同的，即使调用了intern()方法也是不影响的。如果不清楚String类的“==”和equals()的区别可以查看这篇博文Java面试——从Java堆、栈角度比较equals和==的区别。intern()方法在JDK1.6中的作用是：比如String s=new String(&quot;SEU_Calvin&quot;)，再调用s.intern()，此时返回值还是字符串&quot;SEU_Calvin&quot;，表面上看起来好像这个方法没什么用处。但实际上，在JDK1.6中它做了个小动作：检查字符串池里是否存在&quot;SEU_Calvin&quot;这么一个字符串，如果存在，就返回池里的字符串；如果不存在，该方法会把&quot;SEU_Calvin&quot;添加到字符串池中，然后再返回它的引用。然而在JDK1.7中却不是这样的，后面会讨论。 JDK1.7针对JDK1.7以及以上的版本，我们将上面两段代码分开讨论。先看第一段代码的情况：123456789String s = new String("1"); s.intern(); String s2 = "1"; System.out.println(s == s2); String s3 = new String("1") + new String("1"); s3.intern(); String s4 = "11"; System.out.println(s3 == s4); String s = newString(&quot;1&quot;)，生成了常量池中的“1” 和堆空间中的字符串对象。s.intern()，这一行的作用是s对象去常量池中寻找后发现”1”已经存在于常量池中了。String s2 = &quot;1&quot;，这行代码是生成一个s2的引用指向常量池中的“1”对象。结果就是 s 和 s2 的引用地址明显不同。因此返回了false。 String s3 = new String(&quot;1&quot;) + newString(&quot;1&quot;)，这行代码在字符串常量池中生成“1” ，并在堆空间中生成s3引用指向的对象（内容为”11”）。注意此时常量池中是没有 “11”对象的。s3.intern()，这一行代码，是将 s3中的“11”字符串放入 String 常量池中，此时常量池中不存在“11”字符串，JDK1.6的做法是直接在常量池中生成一个 “11” 的对象。但是在JDK1.7中，常量池中不需要再存储一份对象了，可以直接存储堆中的引用。这份引用直接指向 s3 引用的对象，也就是说s3.intern() == s3会返回true。String s4 = &quot;11&quot;， 这一行代码会直接去常量池中创建，但是发现已经有这个对象了，此时也就是指向 s3 引用对象的一个引用。因此s3 == s4返回了true。 下面继续分析第二段代码：再把第二段代码贴一下便于查看：123456789String s = new String("1"); String s2 = "1"; s.intern(); System.out.println(s == s2); String s3 = new String("1") + new String("1"); String s4 = "11"; s3.intern(); System.out.println(s3 == s4); String s = newString(&quot;1&quot;)，生成了常量池中的“1” 和堆空间中的字符串对象。String s2 = &quot;1&quot;，这行代码是生成一个s2的引用指向常量池中的“1”对象，但是发现已经存在了，那么就直接指向了它。s.intern()，这一行在这里就没什么实际作用了。因为”1”已经存在了。结果就是 s 和 s2 的引用地址明显不同。因此返回了false。 String s3 = new String(&quot;1&quot;) + newString(&quot;1&quot;)，这行代码在字符串常量池中生成“1” ，并在堆空间中生成s3引用指向的对象（内容为”11”）。注意此时常量池中是没有 “11”对象的。String s4 = &quot;11&quot;， 这一行代码会直接去生成常量池中的”11”。s3.intern()，这一行在这里就没什么实际作用了。因为”11”已经存在了。结果就是 s3 和 s4 的引用地址明显不同。因此返回了false。为了确保文章的实时更新，实时修改可能出错的地方，请确保这篇是原文，而不是无脑转载来的“原创文”，原文链接为：http://blog.csdn.net/seu_calvin/article/details/52291082。 总结终于要做Ending了。现在再来看一下开篇给的引入例子，是不是就很清晰了呢。123String str1 = new String("SEU") + new String("Calvin"); System.out.println(str1.intern() == str1); System.out.println(str1 == "SEUCalvin"); str1.intern()==str1就是上面例子中的情况，str1.intern()发现常量池中不存在“SEUCalvin”，因此指向了str1。&quot;SEUCalvin&quot;在常量池中创建时，也就直接指向了str1了。两个都返回true就理所当然啦。那么第二段代码呢：1234String str2 = "SEUCalvin";//新加的一行代码，其余不变 String str1 = new String("SEU")+ new String("Calvin"); System.out.println(str1.intern() == str1); System.out.println(str1 == "SEUCalvin"); 也很简单啦，str2先在常量池中创建了“SEUCalvin”，那么str1.intern()当然就直接指向了str2，你可以去验证它们两个是返回的true。后面的&quot;SEUCalvin&quot;也一样指向str2。所以谁都不搭理在堆空间中的str1了，所以都返回了false。好了，本篇对intern的作用以及在JDK1.6和1.7中的实现原理的介绍就到此为止了。希望能给你带来帮助。 内存管理和垃圾回收何为GCJava与C语言相比的一个优势是，可以通过自己的JVM自动分配和回收内存空间。垃圾回收机制是由垃圾搜集器Garbage Collection来实现的，GC是后台一个低优先级的守护进程。在内存中低到一定限度时才会自动运行，因此垃圾回收的时间是不确定的。 为何要这样设计：因为GC也要消耗CPU等资源，如果GC执行过于频繁会对Java的程序的执行产生较大的影响，因此实行不定期的GC。 与GC有关的是：JVM运行时数据区中的堆（对象实例会存储在这里）和 gabagecollector方法。垃圾回收GC只能回收通过new关键字申请的内存（在堆上），但是堆上的内存并不完全是通过new申请分配的。还有一些本地方法，这些内存如果不手动释放，就会导致内存泄露，所以需要在finalize中用本地方法(nativemethod)如free操作等，再使用gc方法。1System.gc(); 何为垃圾Java中那些不可达的对象就会变成垃圾。对象之间的引用可以抽象成树形结构，通过树根（GC Roots）作为起点，从这些树根往下搜索，搜索走过的链称为引用链。当一个对象到GC Roots没有任何引用链相连时，则证明这个对象为可回收的对象。可以作为GC Roots的主要有以下几种：（1）栈帧中的本地变量表所引用的对象。（2）方法区中类静态属性和常量引用的对象。（3）本地方法栈中JNI（Native方法）引用的对象。123456//垃圾产生的情况举例： //1.改变对象的引用，如置为null或者指向其他对象 Object obj1 = new Object(); Object obj2 = new Object(); obj1 = obj2; //obj1成为垃圾 obj1 = obj2 = null ; //obj2成为垃圾 12345//2.引用类型 //第2句在内存不足的情况下会将String对象判定为可回收对象，第3句无论什么情况下String对象都会被判定为可回收对象 String str = new String("hello"); SoftReference&lt;String&gt; sr = new SoftReference&lt;String&gt;(new String("java")); WeakReference&lt;String&gt; wr = new WeakReference&lt;String&gt;(new String("world")); 12345//3.循环每执行完一次，生成的Object对象都会成为可回收的对象 for(int i=0;i&lt;10;i++) &#123; Object obj = new Object(); System.out.println(obj.getClass()); &#125; 1234567//4.类嵌套 class A&#123; A a; &#125; A x = new A();//分配了一个空间 x.a = new A();//又分配了一个空间 x = null;//产生两个垃圾 1234567891011//5.线程中的垃圾 calss A implements Runnable&#123; void run()&#123; //.... &#125; &#125; //main A x = new A(); x.start(); x=null; //线程执行完成后x对象才被认定为垃圾 四种引用类型强引用1Object obj = new Object(); 这里的obj引用便是一个强引用，强引用不会被GC回收。即使抛出OutOfMemoryError错误，使程序异常终止。 软引用如果内存空间足够，垃圾回收器就不会回收它，如果内存空间不足了，就会回收这些对象的内存。软引用可用来实现内存敏感的高速缓存。软引用可以和一个引用队列（ReferenceQueue）联合使用，如果软引用所引用的对象被垃圾回收，Java虚拟机就会把这个软引用加入到与之关联的引用队列中。 弱引用弱引用与软引用的区别在于：垃圾回收器一旦发现了弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。不过由于垃圾回收器是一个优先级很低的线程，因此不一定会很快发现那些弱引用的对象。弱引用可以和一个引用队列（ReferenceQueue）联合使用，如果弱引用所引用的对象被垃圾回收，Java虚拟机就会把这个弱引用加入到与之关联的引用队列中。 虚引用虚引用与软引用和弱引用的一个区别在于：虚引用必须和引用队列（ReferenceQueue）联合使用。当垃圾回收器发现一个对象有虚引用时，就会把这个虚引用对象加入到与之关联的引用队列中。此时该对象并没有被GC回收。而是要等到引用队列被真正的处理后才会被回收。程序可以通过判断引用队列中是否已经加入了虚引用，来了解被引用的对象是否将要被垃圾回收。（由于Object.finalize()方法的不安全性、低效性，常常使用虚引用完成对象回收前的资源释放工作。）这里特别需要注意：当JVM将虚引用插入到引用队列的时候，虚引用执行的对象内存还是存在的。但是PhantomReference并没有暴露API返回对象。所以如果想做清理工作，需要继承PhantomReference类，以便访问它指向的对象。如NIO直接内存的自动回收，就使用到了sun.misc.Cleaner。 典型的垃圾回收算法在确定了哪些垃圾可以被回收后，垃圾搜集器要做的事情就是开始进行垃圾回收，但是这里面涉及到一个问题是：如何高效地进行垃圾回收。下面讨论几种常见的垃圾搜集算法。 Mark-Sweep（标记-清除）算法标记-清除算法分为两个阶段：标记阶段和清除阶段。标记阶段的任务是标记出所有需要被回收的对象，清除阶段就是回收被标记的对象所占用的空间。标记-清除算法实现起来比较容易，但是有一个比较严重的问题就是容易产生内存碎片，碎片太多可能会导致后续过程中需要为大对象分配空间时无法找到足够的空间而提前触发GC。 Copying（复制）算法Copying算法将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把第一块内存上的空间一次清理掉，这样就不容易出现内存碎片的问题，并且运行高效。但是该算法导致能够使用的内存缩减到原来的一半。而且，该算法的效率跟存活对象的数目多少有很大的关系，如果存活对象很多，那么Copying算法的效率将会大大降低。（这也是为什么后面提到的新生代采用Copying算法） Mark-Compact（标记-整理）算法为了解决Copying算法的缺陷，充分利用内存空间，提出了Mark-Compact算法。该算法标记阶段标记出所有需要被回收的对象，但是在完成标记之后不是直接清理可回收对象，而是将存活的对象都移向一端，然后清理掉端边界以外的所有内存（只留下存活对象）。 以上三种算法对比它们的共同点主要有以下两点：1、三个算法都基于根搜索算法去判断一个对象是否应该被回收，而支撑根搜索算法可以正常工作的理论依据，就是语法中变量作用域的相关内容。因此，要想防止内存泄露，最根本的办法就是掌握好变量作用域，而不应该使用前面内存管理杂谈一章中所提到的C/C++式内存管理方式。2、在GC线程开启时，或者说GC过程开始时，它们都要暂停应用程序（stop the world）。它们的区别按照下面几点来给各位展示。（&gt;表示前者要优于后者，=表示两者效果一样）效率：复制算法&gt;标记-整理算法&gt;标记-清除算法（此处的效率只是简单的对比时间复杂度，实际情况不一定如此）。内存整齐度：复制算法=标记-整理算法&gt;标记-清除算法。内存利用率：标记-整理算法=标记-清除算法&gt;复制算法。可以看到标记-清除算法是比较落后的算法了，但是后两种算法却是在此基础上建立的，俗话说“吃水不忘挖井人”，因此各位也莫要忘记了标记-清除这一算法前辈。而且，在某些时候，标记-清除也会有用武之地。 到此我们已经将三个算法了解清楚了，可以看出，效率上来说，复制算法是当之无愧的老大，但是却浪费了太多内存，而为了尽量兼顾上面所提到的三个指标，标记-整理算法相对来说更平滑一些，但效率上依然不尽如人意，它比复制算法多了一个标记的阶段，又比标记-清除多了一个整理内存的过程。难道就没有一种最优算法吗？当然是没有的，这个世界是公平的，任何东西都有两面性，试想一下，你怎么可能找到一个又漂亮又勤快又有钱又通情达理，性格又合适，家境也合适，身高长相等等等等都合适的女人？就算你找到了，至少有一点这个女人也肯定不满足，那就是她不会爱上你。你是不是想说你比博主强太多了，那博主只想对你说，高富帅是不会爬在电脑前看技术文章的，0.0。但是古人就是给力，古人说了，找媳妇不一定要找最好的，而是要找最合适的，听完这句话，瞬间感觉世界美好了许多。算法也是一样的，没有最好的算法，只有最合适的算法。既然这三种算法都各有缺陷，高人们自然不会容许这种情况发生。因此，高人们提出可以根据对象的不同特性，使用不同的算法处理，类似于萝卜白菜各有所爱的原理。于是奇迹发生了，高人们终于找到了GC算法中的神级算法—–分代搜集算法。 Generational Collection（分代搜集）算法分代搜集算法是针对对象的不同特性，而使用适合的算法，这里面并没有实际上的新算法产生。与其说分代搜集算法是第四个算法，不如说它是对前三个算法的实际应用。分代搜集算法是目前大部分JVM的垃圾搜集器采用的算法。它的核心思想是将堆区划分为老年代（Tenured Generation）和新生代（Young Generation），老年代的特点是每次垃圾搜集时只有少量对象需要被回收，而新生代的特点是每次垃圾回收时都有大量的对象需要被回收，那么就可以在不同代的采取不同的最适合的搜集算法。 目前大部分垃圾搜集器对于新生代都采取Copying算法，因为新生代中每次垃圾回收都要回收大部分对象，也就是说需要复制的操作次数较少，该算法效率在新生代也较高。但是实际中并不是按照1：1的比例来划分新生代的空间的，一般来说是将新生代划分为一块较大的Eden空间和两块较小的Survivor空间，每次使用Eden空间和其中的一块Survivor空间，当进行回收时，将还存活的对象复制到另一块Survivor空间中，然后清理掉Eden和A空间。在进行了第一次GC之后，使用的便是Eden space和B空间了，下次GC时会将存活对象复制到A空间，如此反复循环。 当对象在Survivor区躲过一次GC的话，其对象年龄便会加1，默认情况下，对象年龄达到15时，就会移动到老年代中。一般来说，大对象会被直接分配到老年代，所谓的大对象是指需要大量连续存储空间的对象，最常见的一种大对象就是大数组，比如：byte[] data = new byte[4*1024*1024]。当然分配的规则并不是百分之百固定的，这要取决于当前使用的是哪种垃圾搜集器组合和JVM的相关参数。这些搬运工作都是GC完成的，GC不仅负责在Heap中搬运实例，同时负责回收存储空间。最后，因为每次回收都只回收少量对象，所以老年代一般使用的是标记整理算法。 注意，在方法区中有一个永久代（Permanet Generation），它用来存储class类、常量、方法描述等。对永久代的回收主要回收两部分内容：废弃常量和无用的类。有关查看垃圾回收信息的JVM常见配置方式：1-XX:+PrintGCDetails 最后介绍一下有关堆的JVM常见配置方式：1234567-Xss //选置栈内存的大小 -Xms: //初始堆大小 -Xmx: //最大堆大小 -XX:NewSize=n: //设置年轻代大小 -XX:NewRatio=n: //设置年轻代和年老代的比值。比如设置为3，表示年轻代与年老代比值为1：3 -XX:SurvivorRatio=n: //年轻代中Eden区与两个Survivor区的比值。注意Survivor区有两个。比如设置为3，表示Eden：Survivor=3：2，一个Survivor区占整个年轻代的1/5。 -XX:MaxPermSize=n: //设置持久代大小 典型的垃圾回收器垃圾搜集算法是内存回收的理论基础，而垃圾搜集器就是内存回收的具体实现。下面介绍一下HotSpot（JDK 7)虚拟机提供的几种垃圾搜集器，用户可以根据自己的需求组合出各个年代使用的搜集器。 Serial&amp;Serial OldSerial和Serial Old搜集器是最基本最古老的搜集器，是一个单线程搜集器，并且在它进行垃圾搜集时，必须暂停所有用户线程。Serial搜集器是针对新生代的搜集器，采用的是Copying算法，Serial Old搜集器是针对老年代的搜集器，采用的是Mark-Compact算法。它的优点是实现简单高效，但是缺点是会给用户带来停顿。 ParNewParNew搜集器是Serial搜集器的多线程版本，使用多个线程进行垃圾搜集。 Parallel ScavengeParallel Scavenge搜集器是一个新生代的多线程搜集器（并行搜集器），它在回收期间不需要暂停其他用户线程，其采用的是Copying算法，该搜集器与前两个搜集器有所不同，它主要是为了达到一个可控的吞吐量。 Parallel OldParallel Old是Parallel Scavenge搜集器的老年代版本（并行搜集器），使用多线程和Mark-Compact算法。 CMSCMS（Current Mark Sweep）搜集器是一种以获取最短回收停顿时间为目标的搜集器，它是一种并发搜集器，采用的是Mark-Sweep算法。 G1G1搜集器是当今搜集器技术发展最前沿的成果，它是一款面向服务端应用的搜集器，它能充分利用多CPU、多核环境。因此它是一款并行与并发搜集器，并且它能建立可预测的停顿时间模型。最后介绍一下有关搜集器设置的JVM常见配置方式：1234567891011-XX:+UseSerialGC: //设置串行搜集器 -XX:+UseParallelGC: //设置并行搜集器 -XX:+UseParalledlOldGC: //设置并行年老代搜集器 -XX:+UseConcMarkSweepGC: //设置并发搜集器 //并行搜集器设置 -XX:ParallelGCThreads=n: //设置并行搜集器搜集时使用的CPU数，并行搜集线程数 -XX:MaxGCPauseMillis=n: //设置并行搜集最大暂停时间 -XX:GCTimeRatio=n: //设置垃圾回收时间占程序运行时间的百分比，公式为1/(1+n) //并发搜集器设置 -XX:+CMSIncrementalMode: //设置为增量模式。适用于单CPU情况 -XX:ParallelGCThreads=n: //设置并发搜集器年轻代搜集方式为并行搜集时，使用的CPU数。并行搜集线程数 Java类加载机制总结 类加载器的组织结构类加载器 ClassLoader是具有层次结构的，也就是父子关系。其中，Bootstrap是所有类加载器的父亲。（1）Bootstrapclass loader： 启动类加载器当运行Java虚拟机时，这个类加载器被创建，它负责加载虚拟机的核心类库，如java.lang.*等。（2）Extensionclass loader：标准扩展类加载器用于加载除了基本 API之外的一些拓展类。（3）AppClassLoader：加载应用程序和程序员自定义的类。运行下面的程序，结果也显示出来了：从运行结果可以看出加载器之间的父子关系，ExtClassLoader的父Loader返回了null原因是BootstrapLoader（启动类加载器）是用C语言实现的，找不到一个确定的返回父Loader的方式。 类的加载机制类被加载到虚拟机内存包括加载、链接、初始化几个阶段。其中链接又细化分为验证、准备、解析。这里需要注意的是，解析阶段在某些情况下可以在初始化阶段之后再开始，这是为了支持Java的运行时绑定。各个阶段的作用整理如下： 加载阶段加载阶段可以使用系统提供的类加载器(ClassLoader)来完成，也可以由用户自定义的类加载器完成，开发人员可以通过定义类加载器去控制字节流的获取方式。（1）通过类的全名产生对应类的二进制数据流（注意，若未找到该类文件，只有在类实际使用时才抛出错误）。（2）分析并将这些二进制数据流转换为方法区的运行时数据结构。（3）创建代表这个类的java.lang.Class对象。作为方法区这些数据的访问入口。 链接阶段（实现 Java 的动态性的重要一步）（1）验证：主要的目的是确保class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身安全。验证点可能包括：class文件格式规范、这个类是否继承了不允许被继承的类(被final修饰的)、如果这个类的父类是抽象类，是否实现了起父类或接口中要求实现的所有方法、不能把一个父类对象赋值给子类数据类型、方法的访问性(private、protected、public、default)是否可被当前类访问等等。（2）准备：准备阶段为类的成员变量分配内存空间并设置类变量初始值的阶段，这些变量所使用的内存都在方法区中分配。所有原始类型的值都为0。如float为0f、 int为0、boolean为0、引用类型为null。（3）解析：解析阶段是把虚拟机中常量池的符号引用替换为直接引用的过程。 初始化类初始化时类加载的最后一步，前面除了加载阶段用户可以通过自定义类加载器参与以外，其余都是虚拟机主导和控制。到了初始化阶段，才是真正执行类中定义Java程序代码。初始化阶段，根据程序中的定制，初始化类变量。初始化过程其实是执行类构造器方法的过程。（类构造器方法是由编译器自动搜集类中所有类变量的赋值动作和静态语句块中的语句合并产生的。）12345678//静态语句块中只能访问定义在静态语句块之前的变量，定义在它之后的变量可以赋值，但不能访问 public class Test&#123; static&#123; i=0;//給变量赋值，可以通过编译 System.out.print(i);//这句编译器会提示非法向前引用 &#125; static int i=1; &#125; 初始化过程会被触发执行的条件汇总：（1）使用new关键字实例化对象、读取或设置一个类的静态字段（被final修饰、已在编译器把结果放入常量池的静态字段除外）的时候，以及调用类的静态方法*的时候。（2）对类进行反射调用的时候。（3）当初始化一个类的时候，如果发现其父类还没有进行过初始化，则进行父类的初始化。（4）JVM启动时，用户指定执行的主类**（包含main方法所在类），虚拟机会先初始化这个类。 【关于构造器方法拓展知识】（可以不看）（1）类构造器&lt;clinit&gt;()方法与类的构造函数不同，它不需要显式调用父类构造，虚拟机会保证在子类&lt;clinit&gt;()方法执行之前，父类的&lt;clinit&gt;()方法已经执行完毕。因此在虚拟机中的第一个执行的&lt;clinit&gt;()方法的类肯定是java.lang.Object。（2）由于父类的&lt;clinit&gt;()方法先执行，也就意味着父类中定义的静态语句块要优先于子类的变量赋值操作。（3）&lt;clinit&gt;()方法对于类或接口来说并不是必须的，如果一个类中没有静态语句，也没有变量赋值的操作，那么编译器可以不为这个类生成&lt;clinit&gt;()方法。（4）接口中不能使用静态语句块，和类不同的是，执行接口的&lt;clinit&gt;()方法不需要先执行父接口的&lt;clinit&gt;()方法。只有当父接口中定义的变量被使用时，父接口才会被初始化。另外，接口的实现类在初始化时也一样不会执行接口的&lt;clinit&gt;()方法。（5）虚拟机会保证一个类的&lt;clinit&gt;()方法在多线程环境中被正确加锁和同步，可能会导致阻塞。 类的整个加载过程触发的的三种方式（1）由 new 关键字创建一个类的实例。（2）调用 Class.forName() 方法，通过反射加载类。（3）调用某个ClassLoader实例的loadClass()方法。 三者的区别汇总如下：（1）方法1和2都是使用的当前类加载器（this.getClass.getClassLoader）。方法3由用户指定类加载器并且加载的类与当前类分属不同的命名空间。（2）方法1是静态加载，2、3是动态加载。（3）对于两种动态加载，区别如下。123Class.forName(className); //实际上是调用的是： Class.forName(className, true, this.getClass().getClassLoader());//第二个参数设置Class被loading后是不是必须被初始化，默认初始化 123ClassLoader.loadClass(className); //实际上调用的是: ClassLoader.loadClass(name, false);//第二个参数指Class是否被链接，默认为false 通过上面的描述，如果程序依赖于Class是否被初始化，就必须用Class.forName(name)了 自定义类加载器 为什么需要自定义类加载器网上的大部分自定义类加载器文章，几乎都是贴一段实现代码，然后分析一两句自定义ClassLoader的原理。但是个人觉得首先得把为什么需要自定义加载器这个问题搞清楚，因为如果不明白它的作用的情况下，还要去学习它显然是很让人困惑的。首先介绍自定义类的应用场景：（1）加密：Java代码可以轻易的被反编译，如果你需要把自己的代码进行加密以防止反编译，可以先将编译后的代码用某种加密算法加密，类加密后就不能再用Java的ClassLoader去加载类了，这时就需要自定义ClassLoader在加载类的时候先解密类，然后再加载。（2）从非标准的来源加载代码：如果你的字节码是放在数据库、甚至是在云端，就可以自定义类加载器，从指定的来源加载类。（3）以上两种情况在实际中的综合运用：比如你的应用需要通过网络来传输 Java 类的字节码，为了安全性，这些字节码经过了加密处理。这个时候你就需要自定义类加载器来从某个网络地址上读取加密后的字节代码，接着进行解密和验证，最后定义出在Java虚拟机中运行的类。 双亲委派模型在实现自己的ClassLoader之前，我们先了解一下系统是如何加载类的，那么就不得不介绍双亲委派模型的特点和实现过程。双亲委派模型特点：该模型要求除了顶层的Bootstrapclassloader启动类加载器外，其余的类加载器都应当有自己的父类加载器。子类加载器和父类加载器不是以继承（Inheritance）的关系来实现，而是通过组合（Composition）关系来复用父加载器的代码。1234567891011121314151617181920212223242526272829//双亲委派模型的工作过程源码 protected synchronized Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException &#123; // First, check if the class has already been loaded Class c = findLoadedClass(name); if (c == null) &#123; try &#123; if (parent != null) &#123; c = parent.loadClass(name, false); &#125; else &#123; c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // ClassNotFoundException thrown if class not found // from the non-null parent class loader //父类加载器无法完成类加载请求 &#125; if (c == null) &#123; // If still not found, then invoke findClass in order to find the class //子加载器进行类加载 c = findClass(name); &#125; &#125; if (resolve) &#123;//判断是否需要链接过程，参数传入 resolveClass(c); &#125; return c; &#125; 双亲委派模型的工作过程如下：（1）代码中一开始的判空操作是当前 ClassLoader从自己已经加载的类中查询是否此类已经加载，如果已经加载则直接返回原来已经加载的类。（每个类加载器都有自己的加载缓存，当一个类被加载了以后就会放入缓存，等下次加载的时候就可以直接返回）（2）当前 ClassLoader的缓存中没有找到被加载的类的时候，它自己不会尝试去加载该类，而是委托父类加载器去加载，如代码c = parent.loadClass(name, false)所示（父类加载器采用同样的策略，递归了loadClass函数），首先查看自己的缓存，没有就委托父类的父类去加载，一直到 BootStrap ClassLoader。如代码所示，如果父加载器为空则默认使用启动类加载器（BootStrap ClassLoader）作为父加载器去加载，如代码findBootstrapClassOrNull(name)所示（为何父类为BootStrap ClassLoader会返回空，原因在Java类加载机制总结中介绍过了）。（3）如果BootStrapClassLoader加载失败（例如在$JAVA_HOME/jre/lib里未查找到该class），会使用ExtClassLoader来尝试加载； 若ExtClassLoader也加载失败，则会使用AppClassLoader来加载，如果AppClassLoader也加载失败，则会抛出ClassNotFoundException。最后再调用当前加载器的findClass()方法进行加载。 双亲委派模型的好处：（1）主要是为了安全性，避免用户自己编写的类动态替换Java的一些核心类，比如 String。（2）同时也避免重复加载，因为 JVM中区分不同类，不仅仅是根据类名，相同的class文件被不同的 ClassLoader加载就是不同的两个类。 自定义类加载器（1）从上面源码可以看出，在调用loadClass方法时，会先根据委派模型在父加载器中加载，如果加载失败，则会调用自己的findClass方法来完成加载。（2）因此我们自定义的类加载器只需要继承ClassLoader，并覆盖findClass方法。（3）下面是一个实际例子，在该例中我们用自定义的类加载器去加载我们事先准备好的class文件。 自定义一个People.java类做例子12345678910111213141516171819202122public class People &#123; //该类写在记事本里，在用javac命令行编译成class文件，放在d盘根目录下 private String name; public People() &#123;&#125; public People(String name) &#123; this.name = name; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public String toString() &#123; return "I am a people, my name is " + name; &#125; &#125; 自定义类加载器自定义一个类加载器，需要继承ClassLoader类，并实现findClass方法。其中defineClass方法可以把二进制流字节组成的文件转换为一个java.lang.Class（只要二进制字节流的内容符合Class文件规范）。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class MyClassLoader extends ClassLoader &#123; public MyClassLoader() &#123; &#125; public MyClassLoader(ClassLoader parent) &#123; super(parent); &#125; protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; File file = new File("D:/People.class"); try&#123; byte[] bytes = getClassBytes(file); //defineClass方法可以把二进制流字节组成的文件转换为一个java.lang.Class Class&lt;?&gt; c = this.defineClass(name, bytes, 0, bytes.length); return c; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return super.findClass(name); &#125; private byte[] getClassBytes(File file) throws Exception &#123; // 这里要读入.class的字节，因此要使用字节流 FileInputStream fis = new FileInputStream(file); FileChannel fc = fis.getChannel(); ByteArrayOutputStream baos = new ByteArrayOutputStream(); WritableByteChannel wbc = Channels.newChannel(baos); ByteBuffer by = ByteBuffer.allocate(1024); while (true)&#123; int i = fc.read(by); if (i == 0 || i == -1) break; by.flip(); wbc.write(by); by.clear(); &#125; fis.close(); return baos.toByteArray(); &#125; &#125; 在主函数里使用123456MyClassLoader mcl = new MyClassLoader(); Class&lt;?&gt; clazz = Class.forName("People", true, mcl); Object obj = clazz.newInstance(); System.out.println(obj); System.out.println(obj.getClass().getClassLoader());//打印出我们的自定义类加载器 运行结果 至此关于自定义ClassLoader的内容总结完毕。 Tomcat与Eclipse性能调优Tomcat服务器优化JDK内存优化根据服务器物理内容情况配置相关参数优化tomcat性能。当应用程序需要的内存超出堆的最大值时虚拟机就会提示内存溢出，并且导致应用服务崩溃。因此一般建议堆的最大值设置为可用内存的最大值的80%。 Tomcat默认可以使用的内存为128MB，在较大型的应用项目中，这点内存是不够的，需要调大。Tomcat默认可以使用的内存为128MB,Windows下,在文件/bin/catalina.bat，Unix下，在文件/bin/catalina.sh的前面，增加如下设置： JAVA_OPTS=’-Xms【初始化内存大小】 -Xmx【可以使用的最大内存】 -XX:PermSize=64M -XX:MaxPermSize=128m’ 需要把几个参数值调大。例如： JAVA_OPTS=’-Xms256m -Xmx512m’ 表示初始化内存为256MB，可以使用的最大内存为512MB。 参数详解：123456-server 启用jdk 的 server 版；-Xms java虚拟机初始化时的最小内存；-Xmx java虚拟机可使用的最大内存；-XX:PermSize 内存永久保留区域-XX:MaxPermSize 内存最大永久保留区域 -Xmn jvm最小内存 32G 内存配置示例：1JAVA_OPTS=&quot;$JAVA_OPTS -Xms10g -Xmx10g -XX:PermSize=1g -XX:MaxPermSize=2g -Xshare:off -Xmn1024m Tomcat线程优化在Tomcat配置文件server.xml中的配置中，和连接数相关的参数有：maxThreads： Tomcat使用线程来处理接收的每个请求。这个值表示Tomcat可创建的最大的线程数。默认值150。acceptCount： 指定当所有可以使用的处理请求的线程数都被使用时，可以放到处理队列中的请求数，超过这个数的请求将不予处理。默认值10。minSpareThreads： Tomcat初始化时创建的线程数。默认值25。maxSpareThreads： 一旦创建的线程超过这个值，Tomcat就会关闭不再需要的socket线程。默认值75。enableLookups： 是否反查域名，默认值为true。为了提高处理能力，应设置为falseconnnectionTimeout： 网络连接超时，默认值60000，单位：毫秒。设置为0表示永不超时，这样设置有隐患的。通常可设置为30000毫秒。maxKeepAliveRequests： 保持请求数量，默认值100。 bufferSize： 输入流缓冲大小，默认值2048 bytes。compression： 压缩传输，取值on/off/force，默认值off。 其中和最大连接数相关的参数为maxThreads和acceptCount。如果要加大并发连接数，应同时加大这两个参数。32G 内存配置示例：123&lt;Connector port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot; connectionTimeout=&quot;20000&quot; maxThreads=&quot;1000&quot; minSpareThreads=&quot;60&quot; maxSpareThreads=&quot;600&quot; acceptCount=&quot;120&quot; redirectPort=&quot;8443&quot; URIEncoding=&quot;utf-8&quot;/&gt; Eclipse调优eclipse.ini配置：12345678910111213141516171819202122232425-startupplugins/org.eclipse.equinox.launcher_1.3.100.v20150511-1540.jar--launcher.libraryplugins/org.eclipse.equinox.launcher.win32.win32.x86_64_1.1.300.v20150602-1417-productorg.eclipse.epp.package.jee.product--launcher.defaultActionopenFile--launcher.XXMaxPermSize512M-showsplashorg.eclipse.platform--launcher.XXMaxPermSize512m--launcher.defaultActionopenFile--launcher.appendVmargs-vmargs-Dosgi.requiredJavaVersion=1.7-Xms2048m-Xmx2048m-Xverify:none-XX:+PrintGCDetails -XX:+PrintGCDateStamps-Xloggc:gc.log 最后 参考并转载于：http://blog.csdn.net/seu_calvin/article/details/51404589http://blog.csdn.net/seu_calvin/article/details/51892567http://blog.csdn.net/seu_calvin/article/details/52301541http://www.importnew.com/23774.htmlhttp://www.importnew.com/23774.html 更多JVM汇总请看： Jvm系列文章 关于Jvm知识看这一篇就够了]]></content>
      <categories>
        <category>Programming</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java开发人员最常犯的10个错误以及35个代码性能优化小结]]></title>
    <url>%2F2017%2Fjava-dev-ten-mistake-and-some-advice%2F</url>
    <content type="text"><![CDATA[前言人非圣贤孰能无过，编程更是一门要求非常严谨的学问，难免会在敲代码时一个不留神就产生一个BUG，解决一个BUG难免又会出现十个BUG。代码优化，一个很重要的课题。可能有些人觉得没用，一些细小的地方有什么好修改的，改与不改对于代码的运行效率有什么影响呢？这个问题我是这么考虑的，就像大海里面的鲸鱼一样，它吃一条小虾米有用吗？没用，但是，吃的小虾米一多之后，鲸鱼就被喂饱了。代码优化也是一样，如果项目着眼于尽快无BUG上线，那么此时可以抓大放小，代码的细节可以不精打细磨；但是如果有足够的时间开发、维护代码，这时候就必须考虑每个可以优化的细节了，一个一个细小的优化点累积起来，对于代码的运行效率绝对是有提升的。下面博主就分享一下Java开发人员最常犯的10个错误以及一些代码优化，也希望自己把这些优化当成习惯融入平时。一、把数组转成ArrayList为了将数组转换为ArrayList，开发者经常会这样做：1List&lt;String&gt; list = Arrays.asList(arr); 使用Arrays.asList()方法可以得到一个ArrayList，但是得到这个ArrayList其实是定义在Arrays类中的一个私有的静态内部类。这个类虽然和java.util.ArrayList同名，但是并不是同一个类。java.util.Arrays.ArrayList类中实现了set(), get(), contains()等方法，但是并没有定义向其中增加元素的方法。也就是说通过Arrays.asList()得到的ArrayList的大小是固定的。 如果在开发过程中，想得到一个真正的ArrayList对象（java.util.ArrayList的实例），可以通过以下方式：1ArrayList&lt;String&gt; arrayList = new ArrayList&lt;String&gt;(Arrays.asList(arr)); java.util.ArrayList中包含一个可以接受集合类型参数的构造函数。因为java.util.Arrays.ArrayList这个内部类继承了AbstractList类，所以，该类也是Collection的子类。 二、判断一个数组是否包含某个值在判断一个数组中是否包含某个值的时候，开发者经常这样做：12Set&lt;String&gt; set = new HashSet&lt;String&gt;(Arrays.asList(arr));return set.contains(targetValue); 在在Java中如何高效的判断数组中是否包含某个元素一文中，深入分析过，以上方式虽然可以实现功能，但是效率却比较低。因为将数组压入Collection类型中，首先要将数组元素遍历一遍，然后再使用集合类做其他操作。 在判断一个数组是否包含某个值的时候，推荐使用for循环遍历的形式或者使用Apache Commons类库中提供的ArrayUtils类的contains方法。 三、在循环中删除列表中的元素在讨论这个问题之前，先考虑以下代码的输出结果：12345ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;(Arrays.asList("a","b","c","d"));for(int i=0;i&lt;list.size();i++)&#123; list.remove(i);&#125;System.out.println(list); 输出结果：1[b,d] 以上代码的目的是想遍历删除list中所有元素，但是结果却没有成功。原因是忽略了一个关键的问题：当一个元素被删除时，列表的大小缩小并且下标也会随之变化，所以当你想要在一个循环中用下标删除多个元素的时候，它并不会正常的生效。 也有些人知道以上代码的问题就由于数组下标变换引起的。所以，他们想到使用增强for循环的形式：123456ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;(Arrays.asList("a","b","c","d"));for(String s:list)&#123; if(s.equals("a"))&#123; list.remove(s); &#125;&#125; 但是，很不幸的是，以上代码会抛出ConcurrentModificationException，有趣的是，如果在remove操作后增加一个break，代码就不会报错：1234567ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;(Arrays.asList(&quot;a&quot;,&quot;b&quot;,&quot;c&quot;,&quot;d&quot;));for(String s:list)&#123; if(s.equals(&quot;a&quot;))&#123; list.remove(s); break; &#125;&#125; 在Java中的fail-fast机制一文中，深入分析了几种在遍历数组的同时删除其中元素的方法以及各种方法存在的问题。其中就介绍了上面的代码出错的原因。 迭代器（Iterator）是工作在一个独立的线程中，并且拥有一个 mutex 锁。迭代器被创建之后会建立一个指向原来对象的单链索引表，当原来的对象数量发生变化时，这个索引表的内容不会同步改变，所以当索引指针往后移动的时候就找不到要迭代的对象，所以按照 fail-fast 原则迭代器会马上抛出java.util.ConcurrentModificationException异常。 所以，正确的在遍历过程中删除元素的方法应该是使用Iterator：123456789ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;(Arrays.asList("a", "b", "c", "d"));Iterator&lt;String&gt; iter = list.iterator();while (iter.hasNext()) &#123; String s = iter.next(); if (s.equals("a")) &#123; iter.remove(); &#125;&#125; next()方法必须在调用remove()方法之前调用。如果在循环过程中先调用remove()，再调用next()，就会导致异常ConcurrentModificationException。原因如上。 四、HashTable 和 HashMap 的选择了解算法的人可能对HashTable比较熟悉，因为他是一个数据结构的名字。但在Java里边，用HashMap来表示这样的数据结构。Hashtable和HashMap的一个关键性的不同是，HashTable是同步的，而HashMap不是。所以通常不需要HashTable，HashMap用的更多。 HashMap完全解读、Java中常见亲属比较等文章中介绍了他们的区别和如何选择。 五、使用原始集合类型在Java里边，原始类型和无界通配符类型很容易混合在一起。以Set为例，Set是一个原始类型，而Set&lt; ? &gt;是一个无界通配符类型。（可以把原始类型理解为没有使用泛型约束的类型） 考虑下面使用原始类型List作为参数的代码：12345678public static void add(List list, Object o)&#123; list.add(o);&#125;public static void main(String[] args)&#123; List&lt;String&gt; list = new ArrayList&lt;String&gt;(); add(list, 10); String s = list.get(0);&#125; 上面的代码将会抛出异常：java.lang.ClassCastException: java.lang.Integer cannot be cast to java.lang.String 使用原始集合类型是很危险的，因为原始集合类型跳过了泛型类型检查，是不安全的。Set、Set&lt; ? &gt;和Set&lt; Object &gt;之间有很大差别。关于泛型，可以参考下列文章：《成神之路-基础篇》Java基础知识——泛型 六、访问级别程序员们经常使用public作为类中的字段的修饰符，因为这样可以很简单的通过引用得到值，但这并不是好的设计，按照经验，分配给成员变量的访问级别应该尽可能的低。参考Java中的四种访问级别 七、ArrayList与LinkedList的选择当程序员们不知道ArrayList与LinkedList的区别时，他们经常使用ArrayList，因为它看起来比较熟悉。然而，它们之前有巨大的性能差别。在ArrayList vs LinkedList vs Vector 区别、Java中常见亲属比较等文章中介绍过，简而言之，如果有大量的增加删除操作并且没有很多的随机访问元素的操作，应该首先LinkedList。（LinkedList更适合从中间插入或者删除（链表的特性）） 八、可变与不可变在为什么Java要把字符串设计成不可变的一文中介绍过，不可变对象有许多的优点，比如简单，安全等等。同时，也有人提出疑问：既然不可变有这么多好处，为什么不把所有类都搞成不可变的呢？ 通常情况下，可变对象可以用来避免产生过多的中间对象。一个经典的实例就是连接大量的字符串，如果使用不可变的字符串，将会产生大量的需要进行垃圾回收的对象。这会浪费CPU大量的时间，使用可变对象才是正确的方案(比如StringBuilder)。1234String result=&quot;&quot;;for(String s: arr)&#123; result = result + s;&#125; StackOverflow中也有关于这个的讨论。 九、父类和子类的构造函数首先，我们都知道： 如果一个类没有定义构造函数，编译器将会插入一个无参数的默认构造函数。 如果一个类中定义了一个带参数的构造函数，那么编译器就不会再帮我们创建无参的构造函数。 Super类中定义了一个带参数的构造函数。编译器将不会插入默认的无参数构造函数。 我们还应该知道： 子类的所有构造函数（无论是有参还是无参）在执行时，都会调用父类的无参构造函数。 所以，编译器试图调用Super类中的无参构造函数。但是父类默认的构造函数未定义，编译器就会报出这个错误信息。要解决这个问题，可以简单的通过 1)在父类中添加一个Super()构造方法，就像这样： 1public Super()&#123;&#125; 2)移除自定义的父类构造函数 3)在子类的构造函数中调用父类的super(value)。 十、””还是构造函数？关于这个问题，也是程序员经常出现困惑的地方，在该如何创建字符串，使用” “还是构造函数？中也介绍过。 如果你只需要创建一个字符串，你可以使用双引号的方式，如果你需要在堆中创建一个新的对象，你可以选择构造函数的方式。 在String d = new String(&quot;abcd&quot;)时，因为字面值“abcd”已经是字符串类型，那么使用构造函数方式只会创建一个额外没有用处的对象。 35个Java代码性能优化总结代码优化的目标是： 减小代码的体积 提高代码运行的效率 1、尽量指定类、方法的final修饰符带有final修饰符的类是不可派生的。在Java核心API中，有许多应用final的例子，例如java.lang.String，整个类都是final的。为类指定final修饰符可以让类不可以被继承，为方法指定final修饰符可以让方法不可以被重写。如果指定了一个类为final，则该类所有的方法都是final的。Java编译器会寻找机会内联所有的final方法，内联对于提升Java运行效率作用重大，具体参见Java运行期优化。此举能够使性能平均提高50%。 2、尽量重用对象特别是String对象的使用，出现字符串连接时应该使用StringBuilder/StringBuffer代替。由于Java虚拟机不仅要花时间生成对象，以后可能还需要花时间对这些对象进行垃圾回收和处理，因此，生成过多的对象将会给程序的性能带来很大的影响。 3、尽可能使用局部变量调用方法时传递的参数以及在调用中创建的临时变量都保存在栈中速度较快，其他变量，如静态变量、实例变量等，都在堆中创建，速度较慢。另外，栈中创建的变量，随着方法的运行结束，这些内容就没了，不需要额外的垃圾回收。 4、及时关闭流Java编程过程中，进行数据库连接、I/O流操作时务必小心，在使用完毕后，及时关闭以释放资源。因为对这些大对象的操作会造成系统大的开销，稍有不慎，将会导致严重的后果。 5、尽量减少对变量的重复计算明确一个概念，对方法的调用，即使方法中只有一句语句，也是有消耗的，包括创建栈帧、调用方法时保护现场、调用方法完毕时恢复现场等。所以例如下面的操作：12for (int i = 0; i &lt; list.size(); i++)&#123;...&#125; 建议替换为：12for (int i = 0, int length = list.size(); i &lt; length; i++)&#123;...&#125; 这样，在list.size()很大的时候，就减少了很多的消耗 6、尽量采用懒加载的策略，即在需要的时候才创建例如：1234String str = "aaa";if (i == 1)&#123;list.add(str);&#125; 建议替换为：123456if (i == 1)&#123;String str = "aaa";list.add(str);&#125; 7、慎用异常异常对性能不利。抛出异常首先要创建一个新的对象，Throwable接口的构造函数调用名为fillInStackTrace()的本地同步方法，fillInStackTrace()方法检查堆栈，收集调用跟踪信息。只要有异常被抛出，Java虚拟机就必须调整调用堆栈，因为在处理过程中创建了一个新的对象。异常只能用于错误处理，不应该用来控制程序流程。 8、不要在循环中使用try…catch…，应该把其放在最外层除非不得已。如果毫无理由地这么写了，只要你的领导资深一点、有强迫症一点，八成就要骂你为什么写出这种垃圾代码来了。 9、如果能估计到待添加的内容长度，为底层以数组方式实现的集合、工具类指定初始长度比如ArrayList、LinkedLlist、StringBuilder、StringBuffer、HashMap、HashSet等等，以StringBuilder为例：（1）StringBuilder() // 默认分配16个字符的空间（2）StringBuilder(int size) // 默认分配size个字符的空间（3）StringBuilder(String str) // 默认分配16个字符+str.length()个字符空间可以通过类（这里指的不仅仅是上面的StringBuilder）的来设定它的初始化容量，这样可以明显地提升性能。比如StringBuilder吧，length表示当前的StringBuilder能保持的字符数量。因为当StringBuilder达到最大容量的时候，它会将自身容量增加到当前的2倍再加2，无论何时只要StringBuilder达到它的最大容量，它就不得不创建一个新的字符数组然后将旧的字符数组内容拷贝到新字符数组中—-这是十分耗费性能的一个操作。试想，如果能预估到字符数组中大概要存放5000个字符而不指定长度，最接近5000的2次幂是4096，每次扩容加的2不管，那么：（1）在4096 的基础上，再申请8194个大小的字符数组，加起来相当于一次申请了12290个大小的字符数组，如果一开始能指定5000个大小的字符数组，就节省了一倍以上的空间（2）把原来的4096个字符拷贝到新的的字符数组中去这样，既浪费内存空间又降低代码运行效率。所以，给底层以数组实现的集合、工具类设置一个合理的初始化容量是错不了的，这会带来立竿见影的效果。但是，注意，像HashMap这种是以数组+链表实现的集合，别把初始大小和你估计的大小设置得一样，因为一个table上只连接一个对象的可能性几乎为0。初始大小建议设置为2的N次幂，如果能估计到有2000个元素，设置成new HashMap(128)、new HashMap(256)都可以。 10、当复制大量数据时，使用System.arraycopy()命令12345public static void arraycopy(Object src, int srcPos, Object dest, int destPos, int length) src:源数组； srcPos:源数组要复制的起始位置；dest:目的数组； destPos:目的数组放置的起始位置； length:复制的长度。 注意：src and dest都必须是同类型或者可以进行转换类型的数组．有趣的是这个函数可以实现自己到自己复制，比如：12int[] fun =&#123;0,1,2,3,4,5,6&#125;; System.arraycopy(fun,0,fun,3,3); 则结果为：{0,1,2,0,1,2,6};实现过程是这样的，先生成一个长度为length的临时数组,将fun数组中srcPos到srcPos+length-1之间的数据拷贝到临时数组中，再执行System.arraycopy(临时数组,0,fun,3,3). 11、乘法和除法使用移位操作例如：12345for (val = 0; val &lt; 100000; val += 5)&#123;a = val * 8;b = val / 2;&#125; 用移位操作可以极大地提高性能，因为在计算机底层，对位的操作是最方便、最快的，因此建议修改为：12345for (val = 0; val &lt; 100000; val += 5)&#123;a = val &lt;&lt; 3;b = val &gt;&gt; 1;&#125; 移位操作虽然快，但是可能会使代码不太好理解，因此最好加上相应的注释。 12、循环内不要不断创建对象引用例如：1234for (int i = 1; i &lt;= count; i++)&#123;Object obj = new Object();&#125; 这种做法会导致内存中有count份Object对象引用存在，count很大的话，就耗费内存了，建议为改为：1Object obj = null;for (int i = 0; i &lt;= count; i++) &#123; obj = new Object(); &#125; 这样的话，内存中只有一份Object对象引用，每次new Object()的时候，Object对象引用指向不同的Object罢了，但是内存中只有一份，这样就大大节省了内存空间了。 13、基于效率和类型检查的考虑，应该尽可能使用array，无法确定数组大小时才使用ArrayList14、尽量使用HashMap、ArrayList、StringBuilder除非线程安全需要，否则不推荐使用Hashtable、Vector、StringBuffer，后三者由于使用同步机制而导致了性能开销 15、不要将数组声明为public static final因为这毫无意义，这样只是定义了引用为static final，数组的内容还是可以随意改变的，将数组声明为public更是一个安全漏洞，这意味着这个数组可以被外部类所改变 16、尽量在合适的场合使用单例使用单例可以减轻加载的负担、缩短加载的时间、提高加载的效率，但并不是所有地方都适用于单例，简单来说，单例主要适用于以下三个方面：（1）控制资源的使用，通过线程同步来控制资源的并发访问（2）控制实例的产生，以达到节约资源的目的（3）控制数据的共享，在不建立直接关联的条件下，让多个不相关的进程或线程之间实现通信 17、尽量避免随意使用静态变量要知道，当某个对象被定义为static的变量所引用，那么gc通常是不会回收这个对象所占有的堆内存的，如：1234public class A&#123; private static B b = new B();&#125; 18、及时清除不再需要的会话为了清除不再活动的会话，许多应用服务器都有默认的会话超时时间，一般为30分钟。当应用服务器需要保存更多的会话时，如果内存不足，那么操作系统会把部分数据转移到磁盘，应用服务器也可能根据MRU（最近最频繁使用）算法把部分不活跃的会话转储到磁盘，甚至可能抛出内存不足的异常。如果会话要被转储到磁盘，那么必须要先被序列化，在大规模集群中，对对象进行序列化的代价是很昂贵的。因此，当会话不再需要时，应当及时调用HttpSession的invalidate()方法清除会话。此时静态变量b的生命周期与A类相同，如果A类不被卸载，那么引用B指向的B对象会常驻内存，直到程序终止。 19、实现RandomAccess接口的集合比如ArrayList，应当使用最普通的for循环而不是foreach循环来遍历这是JDK推荐给用户的。JDK API对于RandomAccess接口的解释是：实现RandomAccess接口用来表明其支持快速随机访问，此接口的主要目的是允许一般的算法更改其行为，从而将其应用到随机或连续访问列表时能提供良好的性能。实际经验表明，实现RandomAccess接口的类实例，假如是随机访问的，使用普通for循环效率将高于使用foreach循环；反过来，如果是顺序访问的，则使用Iterator会效率更高。可以使用类似如下的代码作判断：123456if (list instanceof RandomAccess)&#123; for (int i = 0; i &lt; list.size(); i++)&#123;&#125;&#125;else&#123;Iterator&lt;?&gt; iterator = list.iterable(); while (iterator.hasNext())&#123;iterator.next()&#125;&#125; foreach循环的底层实现原理就是迭代器Iterator，参见Java语法糖1：可变长度参数以及foreach循环原理。所以后半句”反过来，如果是顺序访问的，则使用Iterator会效率更高”的意思就是顺序访问的那些类实例，使用foreach循环去遍历。 20、使用同步代码块替代同步方法这点在多线程模块中的synchronized锁方法块一文中已经讲得很清楚了，除非能确定一整个方法都是需要进行同步的，否则尽量使用同步代码块，避免对那些不需要进行同步的代码也进行了同步，影响了代码执行效率。 21、将常量声明为static final，并以大写命名这样在编译期间就可以把这些内容放入常量池中，避免运行期间计算生成常量的值。另外，将常量的名字以大写命名也可以方便区分出常量与变量 22、不要创建一些不使用的对象，不要导入一些不使用的类这毫无意义，如果代码中出现”The value of the local variable i is not used”、”The import java.util is never used”，那么请删除这些无用的内容 23、程序运行过程中避免使用反射关于，请参见反射。反射是Java提供给用户一个很强大的功能，功能强大往往意味着效率不高。不建议在程序运行过程中使用尤其是频繁使用反射机制，特别是Method的invoke方法，如果确实有必要，一种建议性的做法是将那些需要通过反射加载的类在项目启动的时候通过反射实例化出一个对象并放入内存—-用户只关心和对端交互的时候获取最快的响应速度，并不关心对端的项目启动花多久时间。 24、使用数据库连接池和线程池这两个池都是用于重用对象的，前者可以避免频繁地打开和关闭连接，后者可以避免频繁地创建和销毁线程 25、使用带缓冲的输入输出流进行IO操作带缓冲的输入输出流，即BufferedReader、BufferedWriter、BufferedInputStream、BufferedOutputStream，这可以极大地提升IO效率。 26、顺序插入和随机访问比较多的场景使用ArrayList，元素删除和中间插入比较多的场景使用LinkedList这个，理解ArrayList和LinkedList的原理就知道了 27、不要让public方法中有太多的形参public方法即对外提供的方法，如果给这些方法太多形参的话主要有两点坏处：1、违反了面向对象的编程思想，Java讲求一切都是对象，太多的形参，和面向对象的编程思想并不契合2、参数太多势必导致方法调用的出错概率增加至于这个”太多”指的是多少个，3、4个吧。比如我们用JDBC写一个insertStudentInfo方法，有10个学生信息字段要插如Student表中，可以把这10个参数封装在一个实体类中，作为insert方法的形参。 28、字符串变量和字符串常量equals的时候将字符串常量写在前面这是一个比较常见的小技巧了，如果有以下代码：1234String str = "123";if (str.equals("123")) &#123;...&#125; 建议修改为：12345String str = "123";if ("123".equals(str))&#123;...&#125; 这么做主要是可以避免空指针异常 29、请知道，在java中if (i == 1)和if (1 == i)是没有区别的，但从阅读习惯上讲，建议使用前者平时有人问，”if (i == 1)”和”if (1== i)”有没有区别，这就要从C/C++讲起。在C/C++中，”if (i == 1)”判断条件成立，是以0与非0为基准的，0表示false，非0表示true，如果有这么一段代码：1234567int i = 2;if (i == 1)&#123;...&#125;else&#123;...&#125; C/C++判断”i==1″不成立，所以以0表示，即false。但是如果：1int i = 2;if (i = 1) &#123; ... &#125;else&#123; ... &#125; 万一程序员一个不小心，把”if (i == 1)”写成”if (i = 1)”，这样就有问题了。在if之内将i赋值为1，if判断里面的内容非0，返回的就是true了，但是明明i为2，比较的值是1，应该返回的false。这种情况在C/C++的开发中是很可能发生的并且会导致一些难以理解的错误产生，所以，为了避免开发者在if语句中不正确的赋值操作，建议将if语句写为：1int i = 2;if (1 == i) &#123; ... &#125;else&#123; ... &#125; 这样，即使开发者不小心写成了”1 = i”，C/C++编译器也可以第一时间检查出来，因为我们可以对一个变量赋值i为1，但是不能对一个常量赋值1为i。但是，在Java中，C/C++这种”if (i = 1)”的语法是不可能出现的，因为一旦写了这种语法，Java就会编译报错”Type mismatch: cannot convert from int to boolean”。但是，尽管Java的”if (i == 1)”和”if (1 == i)”在语义上没有任何区别，但是从阅读习惯上讲，建议使用前者会更好些。 33、把一个基本数据类型转为字符串，基本数据类型.toString()是最快的方式、String.valueOf(数据)次之、数据+””最慢把一个基本数据类型转为一般有三种方式，我有一个Integer型数据i，可以使用i.toString()、String.valueOf(i)、i+”&quot;三种方式，三种方式的效率如何，看一个测试：1234567891011121314151617181920212223242526public static void main(String[] args)&#123; int loopTime = 50000;Integer i = 0; long startTime = System.currentTimeMillis(); for (int j = 0; j &lt; loopTime; j++)&#123;String str = String.valueOf(i);&#125;System.out.println("String.valueOf()：" + (System.currentTimeMillis() - startTime) + "ms");startTime = System.currentTimeMillis(); for (int j = 0; j &lt; loopTime; j++)&#123;String str = i.toString();&#125;System.out.println("Integer.toString()：" + (System.currentTimeMillis() - startTime) + "ms");startTime = System.currentTimeMillis(); for (int j = 0; j &lt; loopTime; j++)&#123;String str = i + "";&#125;System.out.println("i + \"\"：" + (System.currentTimeMillis() - startTime) + "ms");&#125; 运行结果为：1String.valueOf()：11ms Integer.toString()：5ms i + ""：25ms 所以以后遇到把一个基本数据类型转为String的时候，优先考虑使用toString()方法。至于为什么，很简单：1、String.valueOf()方法底层调用了Integer.toString()方法，但是会在调用前做空判断2、Integer.toString()方法就不说了，直接调用了3、i + “”底层使用了StringBuilder实现，先用append方法拼接，再用toString()方法获取字符串三者对比下来，明显是2最快、1次之、3最慢。 34、使用最有效率的方式去遍历Map遍历Map的方式有很多，通常场景下我们需要的是遍历Map中的Key和Value，那么推荐使用的、效率最高的方式是：1234567891011121314151617181920public static void main(String[] args)&#123;HashMap&lt;String, String&gt; hm = new HashMap&lt;String, String&gt;();hm.put("111", "222");Set&lt;Map.Entry&lt;String, String&gt;&gt; entrySet = hm.entrySet();Iterator&lt;Map.Entry&lt;String, String&gt;&gt; iter = entrySet.iterator(); while (iter.hasNext())&#123;Map.Entry&lt;String, String&gt; entry = iter.next();System.out.println(entry.getKey() + "\t" + entry.getValue());&#125;&#125; 如果你只是想遍历一下这个Map的key值，那用”Set&lt;String&gt; keySet = hm.keySet();”会比较合适一些 35、对资源的close()建议分开操作意思是，比如我有这么一段代码：1234567891011try&#123;XXX.close();YYY.close();&#125;catch (Exception e)&#123;...&#125; 建议修改为：12345678910try&#123; XXX.close(); &#125;catch (Exception e) &#123; ... &#125;try&#123; YYY.close(); &#125;catch (Exception e) &#123; ... &#125; 虽然有些麻烦，却能避免资源泄露。我们想，如果没有修改过的代码，万一XXX.close()抛异常了，那么就进入了cath块中了，YYY.close()不会执行，YYY这块资源就不会回收了，一直占用着，这样的代码一多，是可能引起资源句柄泄露的。而改为下面的写法之后，就保证了无论如何XXX和YYY都会被close掉。 参考 Top 10 Mistakes Java Developers Makehttp://www.hollischuang.com/archives/1360http://www.jianshu.com/p/436943216526]]></content>
      <categories>
        <category>Programming</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于Hexo搭建个人博客——进阶篇(从入门到入土)]]></title>
    <url>%2F2017%2Fbuild-blog-hexo-advanced%2F</url>
    <content type="text"><![CDATA[前言好久没更新了，因为懒- -前面介绍了Hexo的一些基本搭建→基于Hexo+github+coding搭建个人博客——基础篇(从菜鸟到放弃)对于追求装X的博主来说，基本的搭建是满足不了的，接下来整理了一下各方面的细节优化，包括页面字体大小、配色、背景、SEO(搜索引擎优化)、域名绑定、DNS域名解析实现负载均衡等。关于NexT主题的很多配置、插件都可以在官方文档找到答案，那么博主只是整理了一些官方没怎么提及的细节优化。解决Hexo命令fs.SyncWriteStream问题请看解决Hexo命令fs.SyncWriteStream问题高度定制优化篇集成Mod分享组件Step1、获取 AppKey在 Mob 注册账号后，点击头像进入后台，选择 shareSDK 添加一个 Web应用：Step2、在主题配置文件中添加配置：123mob_share: enable: true appkey: ******** Step3、在next/layout/_partials/share/里面添加mob_share.swig：1234567891011121314151617181920212223242526272829303132333435&lt;!--MOB SHARE BEGIN--&gt;&lt;div class=&quot;-hoofoo-share-title&quot;&gt;分享到：&lt;/div&gt;&lt;div class=&quot;-hoofoo-share-buttons&quot;&gt; &lt;div class=&quot;-mob-share-weibo -hoofoo-share-weibo -hoofoo-share-ui-button&quot;&gt;&lt;i class=&quot;fa fa-weibo&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt;&lt;/div&gt; &lt;div class=&quot;-mob-share-weixin -hoofoo-share-weixin -hoofoo-share-ui-button&quot;&gt;&lt;i class=&quot;fa fa-weixin&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt;&lt;/div&gt; &lt;div class=&quot;-mob-share-qq -hoofoo-share-qq -hoofoo-share-ui-button&quot;&gt;&lt;i class=&quot;fa fa-qq&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt;&lt;/div&gt; &lt;div class=&quot;-mob-share-twitter -hoofoo-share-twitter -hoofoo-share-ui-button&quot;&gt;&lt;i class=&quot;fa fa-twitter&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt;&lt;/div&gt; &lt;div class=&quot;-hoofoo-share-more -hoofoo-share-ui-button -mob-share-open&quot;&gt;&lt;i class=&quot;fa fa-ellipsis-h&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;-mob-share-ui&quot; style=&quot;display: none&quot;&gt; &lt;ul class=&quot;-mob-share-list&quot;&gt; &lt;li class=&quot;-mob-share-weibo&quot;&gt;&lt;p&gt;新浪微博&lt;/p&gt;&lt;/li&gt; &lt;li class=&quot;-mob-share-weixin&quot;&gt;&lt;p&gt;微信&lt;/p&gt;&lt;/li&gt; &lt;li class=&quot;-mob-share-qzone&quot;&gt;&lt;p&gt;QQ空间&lt;/p&gt;&lt;/li&gt; &lt;li class=&quot;-mob-share-qq&quot;&gt;&lt;p&gt;QQ好友&lt;/p&gt;&lt;/li&gt; &lt;li class=&quot;-mob-share-tencentweibo&quot;&gt;&lt;p&gt;腾讯微博&lt;/p&gt;&lt;/li&gt; &lt;li class=&quot;-mob-share-renren&quot;&gt;&lt;p&gt;人人网&lt;/p&gt;&lt;/li&gt; &lt;li class=&quot;-mob-share-kaixin&quot;&gt;&lt;p&gt;开心网&lt;/p&gt;&lt;/li&gt; &lt;li class=&quot;-mob-share-douban&quot;&gt;&lt;p&gt;豆瓣&lt;/p&gt;&lt;/li&gt; &lt;li class=&quot;-mob-share-youdao&quot;&gt;&lt;p&gt;有道云笔记&lt;/p&gt;&lt;/li&gt; &lt;li class=&quot;-mob-share-mingdao&quot;&gt;&lt;p&gt;明道&lt;/p&gt;&lt;/li&gt; &lt;li class=&quot;-mob-share-pengyou&quot;&gt;&lt;p&gt;朋友网&lt;/p&gt;&lt;/li&gt; &lt;li class=&quot;-mob-share-facebook&quot;&gt;&lt;p&gt;Facebook&lt;/p&gt;&lt;/li&gt; &lt;li class=&quot;-mob-share-twitter&quot;&gt;&lt;p&gt;Twitter&lt;/p&gt;&lt;/li&gt; &lt;li class=&quot;-mob-share-pocket&quot;&gt;&lt;p&gt;Pocket&lt;/p&gt;&lt;/li&gt; &lt;li class=&quot;-mob-share-google&quot;&gt;&lt;p&gt;Google+&lt;/p&gt;&lt;/li&gt; &lt;li class=&quot;-mob-share-tumblr&quot;&gt;&lt;p&gt;Tumblr&lt;/p&gt;&lt;/li&gt; &lt;li class=&quot;-mob-share-instapaper&quot;&gt;&lt;p&gt;Instapaper&lt;/p&gt;&lt;/li&gt; &lt;li class=&quot;-mob-share-linkedin&quot;&gt;&lt;p&gt;Linkedin&lt;/p&gt;&lt;/li&gt; &lt;/ul&gt; &lt;div class=&quot;-mob-share-close&quot;&gt;取消&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;-mob-share-ui-bg&quot;&gt;&lt;/div&gt;&lt;script id=&quot;-mob-share&quot; src=&quot;http://f1.webshare.mob.com/code/mob-share.js?appkey=&#123;&#123;theme.mob_share.appkey&#125;&#125;&quot;&gt;&lt;/script&gt;&lt;!--MOB SHARE END--&gt; Step4、在next/layout/post.swig中添加条件分支：1234567891011&#123;% if theme.jiathis %&#125; &#123;% include &apos;_partials/share/jiathis.swig&apos; %&#125; &#123;% elseif theme.baidushare %&#125; &#123;% include &apos;_partials/share/baidushare.swig&apos; %&#125; &#123;% elseif theme.add_this_id %&#125; &#123;% include &apos;_partials/share/add-this.swig&apos; %&#125; &#123;% elseif theme.duoshuo_shortname and theme.duoshuo_share %&#125; &#123;% include &apos;_partials/share/duoshuo_share.swig&apos; %&#125; &#123;% elseif theme.mob_share.enable %&#125; &#123;% include &apos;_partials/share/mob_share.swig&apos; %&#125;&#123;% endif %&#125; Step5、在next/source/css/_common/components/third-party/里添加样式文件mob_share.styl：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980.-hoofoo-share-buttons&#123; display: inline-block;&#125;.-hoofoo-share-title&#123; font-size: 1.1em; font-weight: 200;&#125;.-hoofoo-share-ui-button&#123; cursor: pointer; background-color: #555; color: #fff; font-size: 24px; line-height: 40px; width: 40px; height: 40px; margin: 10px; border-radius: 25px; float: left; transition: background 0.4s; -moz-transition: background 0.4s; /* Firefox 4 */ -webkit-transition: background 0.4s; /* Safari 和 Chrome */ -o-transition: background 0.4s;&#125;.-hoofoo-share-weibo:hover&#123; background-color: #cf3f41;&#125;.-hoofoo-share-weixin:hover&#123; background-color: #18a01a;&#125;.-hoofoo-share-qq:hover&#123; background-color: #950c0c;&#125;.-hoofoo-share-twitter:hover&#123; background-color: #2ab3e6;&#125;.-hoofoo-share-more:hover&#123; background-color: #777;&#125;.-mob-share-weixin-qrcode-content&#123; border-radius: 4px; -webkit-box-shadow: 0 10px 25px rgba(0, 0, 0, 0.5); -moz-box-shadow: 0 10px 25px rgba(0, 0, 0, 0.5); -o-box-shadow: 0 10px 25px rgba(0, 0, 0, 0.5); box-shadow: 0 10px 25px rgba(0, 0, 0, 0.5);&#125;.-mob-share-weixin-qrcode&#123; margin: 5% !important; width: 90% !important; height: auto !important;&#125;.-mob-share-weixin-qrcode-close &#123; background-image: url(&apos;/lib/fancybox/source/fancybox_sprite.png&apos;) !important;//因为兼容问题把vendor改成了lib，根据自己的路径修改&#125;.-mob-share-weixin-qrcode-close &#123; overflow: hidden; line-height: 100px !important; position: absolute !important; top: -18px !important; right: -18px !important; width: 36px !important; height: 36px !important; cursor: pointer !important; z-index: 8040 !important;&#125;/*Retina graphics!*/@media only screen and (-webkit-min-device-pixel-ratio: 1.5), only screen and (min--moz-device-pixel-ratio: 1.5), only screen and (min-device-pixel-ratio: 1.5)&#123; .-mob-share-weixin-qrcode-close &#123; background-image: url(&apos;/lib/fancybox/source/fancybox_sprite@2x.png&apos;) !important;//因为兼容问题把vendor改成了lib，根据自己的路径修改 background-size: 44px 152px !important; /*The size of the normal image, half the size of the hi-res image*/ &#125;&#125;.-mob-share-close&#123; height: 4em !important; font-size: 0.8em !important; line-height: 4em !important; background: #555 !important; color: #fff !important;&#125; Step6、同一目录下的 third-party.styl 中添加：1@import &quot;mob_share&quot;; Step7、在next/layout/_scripts/third-party/里添加脚本文件mob_share.swig： 12345678&#123;% if theme.mob_share.enable %&#125;&lt;script type=&quot;text/javascript&quot;&gt; //微信二维码点击背景关闭 $(&apos;body&apos;).delegate(&apos;.-mob-share-weixin-qrcode-bg&apos;,&apos;click&apos;, function()&#123; $(&quot;.-mob-share-weixin-qrcode-close&quot;).trigger(&quot;click&quot;); &#125;); &lt;/script&gt;&#123;% endif %&#125; Step8、在next/layout/_layout.swig的body标签结束前添加：1&#123;% include &apos;_scripts/third-party/mob_share.swig&apos; %&#125; 添加顶部加载条打开/themes/next/layout/_partials/head.swig文件，添加如下代码：12&lt;script src=&quot;//cdn.bootcss.com/pace/1.0.2/pace.min.js&quot;&gt;&lt;/script&gt;&lt;link href=&quot;//cdn.bootcss.com/pace/1.0.2/themes/pink/pace-theme-flash.css&quot; rel=&quot;stylesheet&quot;&gt; 但是，默认的是粉色的，要改变颜色可以在/themes/next/layout/_partials/head.swig文件中添加如下代码（接在刚才link的后面）12345678910111213&lt;style&gt; .pace .pace-progress &#123; background: #ff009e; /*进度条颜色*/ height: 3px; &#125; .pace .pace-progress-inner &#123; box-shadow: 0 0 10px #ff009e, 0 0 5px #ff009e; /*阴影颜色*/ &#125; .pace .pace-activity &#123; border-top-color: #ff009e; /*上边框颜色*/ border-left-color: #ff009e; /*左边框颜色*/ &#125;&lt;/style&gt; 文章加密访问打开themes-&gt;next-&gt;layout-&gt;_partials-&gt;head.swig文件,插入这样一段代码：12345678910&lt;script&gt; (function()&#123; if(&apos;&#123;&#123; page.password &#125;&#125;&apos;)&#123; if (prompt(&apos;请输入文章密码&apos;) !== &apos;&#123;&#123; page.password &#125;&#125;&apos;)&#123; alert(&apos;密码错误！&apos;); history.back(); &#125; &#125; &#125;)();&lt;/script&gt; 然后在文章上写成类似这样：12345678910---title: Hello Worlddate: 2016/7/13 20:46:25categories:- Diarytags: - Testing - Another Tagpassword: 123456--- 博客更换Disqus评论由于多说即将关闭，本站启用Disqus。既然Disqus已被墙，那么为了对没有梯子的同学标示友好，我们可以选择点击加载Disqus评论的方式，这个问题貌似也得到了主题作者的关注-&gt; (NexT5.2.0)[https://github.com/iissnan/hexo-theme-next/milestone/7]具体做法如下：打开themes/next/layout/_partials/comments.swig，在文件内容 &lt;div id=&quot;disqus_thread&quot;&gt;前面加入下面内容：123&lt;div style=&quot;text-align:center;&quot;&gt; &lt;button class=&quot;btn&quot; id=&quot;load-disqus&quot; onclick=&quot;disqus.load();&quot;&gt;加载 Disqus 评论&lt;/button&gt;&lt;/div&gt; 再打开themes/next/layout/_scripts/third-party/comments/disqus.swig，需要替换原本的 Disqus 的加载的内容，如果希望显示评论数量，就保留 run_disqus_script(‘count.js’) 这一行，这样页面载入时还会加载 disqus 的资源：1234run_disqus_script(&apos;count.js&apos;);&#123;% if page.comments %&#125; run_disqus_script(&apos;embed.js&apos;);&#123;% endif %&#125; 替换为下面的内容：12345678910111213var disqus = &#123; load : function disqus()&#123; if(typeof DISQUS !== 'object') &#123; (function () &#123; var s = document.createElement('script'); s.async = true; s.type = 'text/javascript'; s.src = '//' + disqus_shortname + '.disqus.com/embed.js'; (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s); &#125;()); $('#load-disqus').html("评论加载中，请确保你有梯子，若评论长时间未加载则你可能翻墙失败...").fadeOut(9000); //加载后移除按钮 &#125; &#125;&#125; 前面的 function run_disqus_script(disqus_script){}这一段，不打算显示评论数量的话，可以一起删掉，不显示评论数量的话，那么点击加载按钮之前，网页是不会加载来自 Disqus 的资源的。 NexT启用Disqus-Proxy 不翻墙也能使用Disqus 多说于2017.06.01停止了服务，不得不选择其他的第三方评论服务，试了一下国内的服务发现不是麻烦（例如需要备案）就是不靠谱或者界面不炫酷（装X嫌疑…） 还是使用Disqus吧…But，这个早就被GWF隔离了，虽然自己可以闪现过墙=.=，但游客不一定都会这个技能…那么问题来了，怎么做一个公共的梯子实现人人翻墙？在Gayhub全球最大同性交友网中发现，早就有大神做了这样一个服务，并选择了ciqulover(在此感谢大神的鼎力相助)的Disque-Proxy项目作为梯子。当然也还有其他的Disqus-Proxy -&gt; fooleap、 jiananshi Flow流程就没什么好说的了，如上图，在前端页面上测试 disqus 加载是否成功，如果成功则显示 disqus 的评论框，反之加载独立的评论框…具体请看https://ycwalker.com/2017/06/01/about-diqus-proxy/ Deploy Disqus-Proxy首先你得有一台可以访问Disqus的VPS[1]… 博主用的是Linode Node.js后端采用了Koa 框架和 async/await 语法，Node.js 版本 7.6 以上。 Clone Projectcd到想要安装的目录下，然后：1git clone https://github.com/ciqulover/disqus-proxy Dependency要运行起来首先要安装依赖，cd到项目里面执行：123npm i --production// 或者yarn install --production Configuration配置 server 目录下的config.js：123456789101112module.exports = &#123; // 服务端端口，需要与 disqus-proxy 前端设置一致 port: 5509, // 你的 diqus secret key api_secret: 'your secret key', // 你的 disqus 名称 username:'ciqu', // 服务端 socks5 代理转发，便于在本地测试，生产环境通常为 null socks5Proxy: null, // 日志输出位置, 输出到文件或控制台 'file' | 'console' log: 'console'&#125; Get Api-secretapi-secret 需要你在 Disqus Api 的官方网站上开启 API 权限，申请成功后会得到这个秘钥。 并且需要在后台的 Settings =&gt; Community 里开启访客评论： Start Up使用 pm2 启动：123cd servernpm i pm2 -gpm2 start index.js 如果你在配置文件中选择 log 类型为file, 那么输出的日志文件将在默认为 server 目录下的disqus-proxy.log 使用netstat查看项目监听情况： 1netstat -nutpl 那么后端的工作就完成了～ NexT ConfigurationCopy Static File将disqus-proxy项目中/build/static文件复制到博客../next/source/下。static文件中应该包含main.0d0338ae.js和main.0603c539.css。 _config.yml在主题配置文件中添加：12345678910111213disqus_proxy: enable: true # 如果 disqus 账号名没设置 那么 disqus_proxy 也不会生效 username: ookamiantd # 下面两项你需要更改为自己服务器的域名和端口 server: disqus-proxy.yangbingdong.com port: 5509 # 端口号需要与后端设置一致 # 头像路径设置 defaultAvatar: /images/avatar/avatar-default.jpg adminAvatar: /images/avatar/avatar-admin.jpg # 脚本和 css 路径 js: /static/js/main.0d0338ae.js css: /static/css/main.0603c539.css comment.swig修改/next/layout/_partial/comment.swig，在最后一个&lt;/div&gt;钱加上： 12345678910111213141516171819202122232425&lt;div id="disqus_proxy_thread"&gt;&lt;/div&gt; &lt;div id="disqus_thread"&gt;&lt;/div&gt; &#123;% if theme.disqus_proxy.enable %&#125; &lt;script type="text/javascript"&gt; window.disqusProxy = &#123; username: '&#123;&#123; theme.disqus_proxy.username &#125;&#125;', server: '&#123;&#123; theme.disqus_proxy.server &#125;&#125;', port: '&#123;&#123; theme.disqus_proxy.port &#125;&#125;', defaultAvatar: '&#123;&#123; theme.disqus_proxy.defaultAvatar &#125;&#125;', adminAvatar: '&#123;&#123; theme.disqus_proxy.adminAvatar &#125;&#125;', identifier: '&#123;&#123; page.path &#125;&#125;' &#125;; window.disqus_config = function () &#123; this.page.url = '&#123;&#123; page.permalink &#125;&#125;'; this.page.identifier = '&#123;&#123; page.path &#125;&#125;'; &#125;; window.onload=function()&#123; var s = document.createElement('script'); s.src = "&#123;&#123; theme.disqus_proxy.js &#125;&#125;"; s.async = true; document.body.appendChild(s); &#125; &lt;/script&gt; &lt;link rel="stylesheet" href="&#123;&#123; theme.disqus_proxy.css &#125;&#125;"&gt; &#123;% endif %&#125; 渲染效果：1234567891011121314151617181920212223&lt;div id="disqus_proxy_thread"&gt;&lt;/div&gt;&lt;div id="disqus_thread"&gt;&lt;/div&gt;&lt;script type="text/javascript"&gt; window.disqusProxy = &#123; username: 'ookamiantd', server: 'disqus-proxy.yangbingdong.com', port: '5509', defaultAvatar: '/images/avatar/avatar-default.jpg', adminAvatar: '/images/avatar/avatar-admin.jpg', identifier: '2017/disqus-proxy/' &#125;; window.disqus_config = function () &#123; this.page.url = 'http://ookamiantd.top/2017/disqus-proxy/'; this.page.identifier = '2017/disqus-proxy/'; &#125;; window.onload = function () &#123; var s = document.createElement('script'); s.src = "/static/js/main.0d0338ae.js"; s.async = true; document.body.appendChild(s); &#125;&lt;/script&gt;&lt;link rel="stylesheet" href="/static/css/main.0603c539.css"&gt; custom.styl可能由于改过样式还是本来就不兼容，评论框一开始显示不出来，ciqulover大神帮我加了个样式之后就好了。 在/next/source/css/_custom/custom.styl中添加：12345#disqus_proxy_thread .post&#123; opacity: 1 !important; box-shadow: none !important; -webkit-box-shadow: none !important;&#125; 博主也对评论框乱入了一些样式例如头像旋转…具体请看main.0603c539.css Problem博主使用了hexo-all-minifier进行静态文件压缩，不明原因导致那两个评论框的js和css压缩之后会报错，所以对压缩选项作设置，在站点配置文件中添加：123456789101112131415161718192021222324html_minifier: enable: true exclude: css_minifier: enable: true exclude: - '/home/ybd/GitRepo/blog/themes/next/source/static/css/main.0603c539.css'js_minifier: enable: true mangle: true output: compress: exclude: - '/home/ybd/GitRepo/blog/themes/next/source/static/js/*.*.js'image_minifier: enable: true interlaced: false multipass: false optimizationLevel: 2 pngquant: false progressive: false Show这是翻墙状态：这是disqus_proxy： 修改文章页宽打开themes/next/source/css/_variables/base.styl，找到以下字段并修改为合适的宽度：1$content-desktop-large = 1000px 修改小型代码块颜色修改\themes\next\source\css\ _variables\base.styl文件，加入自定义颜色：123456789$black-deep = #222$red = #ff2a2a$blue-bright = #87daff$blue = #0684bd$blue-deep = #262a30$orange = #fc6423// 下面是我自定义的颜色$my-code-foreground = #dd0055 // 用``围出的代码块字体颜色$my-code-background = #eee // 用``围出的代码块背景颜色 修改$code-background和$code-foreground的值：123456// Code &amp; Code Blocks // 用``围出的代码块 // -------------------------------------------------- $code-font-family = $font-family-monospace $code-font-size = 15px $code-background = $my-code-background $code-foreground = $my-code-foreground $code-border-radius = 4px 文章末尾追加版权信息找到themes/next/layout/_macro/post.swig，在footer之前添加如下代码(添加之前确保已添加样式)：12345678&lt;div&gt; &lt;p id=&quot;div-border-left-red&quot;&gt; &lt;b&gt;本文基于&lt;a target=&quot;_blank&quot; title=&quot;Creative Commons Attribution-ShareAlike 4.0 International (CC BY-SA 4.0)&quot; href=&quot;http://creativecommons.org/licenses/by-sa/4.0/&quot;&gt; 知识共享署名-相同方式共享 4.0 &lt;/a&gt;国际许可协议发布&lt;/b&gt;&lt;br/&gt; &lt;span&gt; &lt;b&gt;本文地址：&lt;/b&gt;&lt;a href=&quot;&#123;&#123; url_for(page.path) &#125;&#125;&quot; title=&quot;&#123;&#123; page.title &#125;&#125;&quot;&gt;&#123;&#123; page.permalink &#125;&#125;&lt;/a&gt;&lt;br/&gt;&lt;b&gt;转载请注明出处，谢谢！&lt;/b&gt; &lt;/span&gt; &lt;/p&gt;&lt;/div&gt; 添加文章结束标记同样在themes/next/layout/_macro/post.swig中，在wechat-subscriber.swig之前添加如下代码：1&lt;div style=&quot;text-align:center;color: #ccc;font-size:14px;&quot;&gt;---------------- The End ----------------&lt;/div&gt; 添加热度在/themes/hexo-theme-next/layout/_macro/post.swig里面的下面的位置加上如下代码：12345678910111213141516171819&#123;% if post.categories and post.categories.length %&#125; &lt;span class=&quot;post-category&quot; &gt; &lt;/span&gt; &#123;% endif %&#125; &lt;!-- 在下面的位置加上如下代码 --&gt; &lt;span id=&quot;busuanzi_container_page_pv&quot;&gt; &amp;nbsp; | &amp;nbsp; 热度&amp;nbsp; &lt;span id=&quot;busuanzi_value_page_pv&quot;&gt;&lt;/span&gt;°C &lt;/span&gt; &lt;!-- 在上面的位置加上如上代码 --&gt; &#123;% if post.comments %&#125; &#123;% if (theme.duoshuo and theme.duoshuo.shortname) or theme.duoshuo_shortname %&#125; &lt;span class=&quot;post-comments-count&quot;&gt; &amp;nbsp; | &amp;nbsp; &lt;a href=&quot;&#123;&#123; url_for(post.path) &#125;&#125;#comments&quot; itemprop=&quot;discussionUrl&quot;&gt; &lt;span class=&quot;post-comments-count ds-thread-count&quot; data-thread-key=&quot;&#123;&#123; post.path &#125;&#125;&quot; itemprop=&quot;commentsCount&quot;&gt;&lt;/span&gt; &lt;/a&gt; &lt;/span&gt; 但是这有一个缺陷。就是我们会发现在主页时显示的热度和进入博客后的热度不一样，那是因为在主页时他显示的是主页这个页面的阅读量，而不是博客的阅读量，所以我们需要改变一些： 我们在/themes/hexo-theme-next/layout/_macro/目录下新建post-article.swig,把这些post.swig中的内容复制过去，而且加上上面的统计代码，然后在/themes/hexo-theme-next/layout/post.swig上面% import &#39;_macro/post.swig&#39; as post_template %中的post.swig改成post-article.swig，这样子就解决啦。就是在主页上的博客名字下面不会有阅读人数，进入博客才能看见 添加最近访客多说评论关闭 添加Fork me on GitHub去网址https://github.com/blog/273-github-ribbons挑选自己喜欢的样式，并复制代码，添加到themes\next\layout\_layout.swig的body标签之内即可记得把里面的url换成自己的! 把侧边栏头像变成圆形，并且鼠标停留在上面发生旋转效果 修改themes\next\source\css\_common\components\sidebar\sidebar-author.styl：1234567891011121314151617181920212223242526272829.site-author-image &#123; display: block; margin: 0 auto; padding: $site-author-image-padding; max-width: $site-author-image-width; height: $site-author-image-height; border: site-author-image-border-color; /* start*/ border-radius: 50% webkit-transition: 1.4s all; moz-transition: 1.4s all; ms-transition: 1.4s all; transition: 1.4s all; /* end */&#125;/* start */.site-author-image:hover &#123; background-color: #55DAE1; webkit-transform: rotate(360deg) scale(1.1); moz-transform: rotate(360deg) scale(1.1); ms-transform: rotate(360deg) scale(1.1); transform: rotate(360deg) scale(1.1);&#125;/* end */ 修改链接文字样式打开themes\next\source\css\_common\components\post\post.styl添加以下代码：12345678910.post-body p a&#123; color: #0593d3; border-bottom: none; &amp;:hover &#123; color: #ff106c; text-decoration: underline; &#125;&#125; themes/next/source/css/_common/components/post/post-title.styl修改为：123456789.posts-expand .post-title-link &#123; display: inline-block; border-bottom: none; line-height: 1.2; vertical-align: top; &amp;::before &#123; ...... 为next主题的主页文章添加阴影效果打开themes/next/source/css/_custom/custom.styl文件添加：1234567.post &#123; margin-top: 60px; margin-bottom: 60px; padding: 25px; -webkit-box-shadow: 0 0 5px rgba(202, 203, 203, .5); -moz-box-shadow: 0 0 5px rgba(202, 203, 204, .5); &#125; 为next主题添加nest背景特效背景的几何线条是采用的nest效果，一个基于html5 canvas绘制的网页背景效果，非常赞！来自github的开源项目canvas-nest 特性 不依赖任何框架或者内库，比如不依赖jQuery，使用原生的javascript。 非常小，只有1.66kb，如果开启gzip，可以更小。 非常容易实现，配置简单，即使你不是web开发者，也能简单搞定。 使用非常简单 color: 线条颜色, 默认: ‘0,0,0’ ；三个数字分别为(R,G,B)，注意用,分割 opacity: 线条透明度（0~1）, 默认: 0.5 count: 线条的总数量, 默认: 150 zIndex: 背景的z-index属性，css属性用于控制所在层的位置, 默认: -1 eg : 1&lt;script type=&quot;text/javascript&quot; color=&quot;255,132,0&quot; opacity=&apos;0.6&apos; zIndex=&quot;-2&quot; count=&quot;99&quot; src=&quot;//cdn.bootcss.com/canvas-nest.js/1.0.1/canvas-nest.min.js&quot;&gt;&lt;/script&gt; 不足: CPU占用过高 如何添加?修改代码打开next/layout/_layout.swig，在&lt;/body&gt;之前添加如下代码：12345&#123;% if theme.canvas_nest %&#125;&lt;script type=&quot;text/javascript&quot; src=&quot;//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js&quot;&gt;&lt;/script&gt;&#123;% endif %&#125; 修改主题配置文件打开/next/_config.yml，添加以下代码：123456# --------------------------------------------------------------# background settings# --------------------------------------------------------------# add canvas-nest effect# see detail from https://github.com/hustcc/canvas-nest.jscanvas_nest: true 至此，大功告成，运行hexo clean 和 hexo g hexo s之后就可以看到效果了 多说评论优化以及美化update：由于多说即将关闭，此博客将使用Disqus作为评论系统 添加音乐去往网易云音乐搜索喜欢的音乐，点击生成外链播放器，复制代码直接放到博文末尾即可，height设为0可隐藏播放器，但仍然可以播放音乐，auto设成0可手动播放，默认是1自动播放，可把代码放到themes/next/layout/_custom/sidebar.swig文件里，播放器会显示在站点预览中 添加注脚安装插件：1npm install hexo-reference --save 用法如下：1this is a basic footnote[/^1] ##用的时候把/去掉 在文章末尾添加：1[/^1]: basic footnote content ##用的时候把/去掉 eg:this is a basic footnote[1] 自定义页面执行hexo new page &quot;guestbook&quot;之后，那怎么在博客中加进去呢？找到\next\_config.yml下的memu，把guestbook加进去：1234567menu: home: / categories: /categories #about: /about archives: /archives tags: /tags guestbook: /guestbook 图标网站：http://fontawesome.io/icons/ 在/themes/hexo-theme-next/languages/zh-Hans.yml的目录下（这里默认你使用的是简体中文，若是其他语言更改相应的yml就行），在memu下加一句即可：1guestbook: 留言 添加字数统计和阅读时间安装插件1npm install hexo-wordcount --save 通过以上安装后，你可以在你的模板文件后者.md文件加入以下相关的标签实现本插件的功能字数统计:WordCount阅读时长预计:Min2Read总字数统计: TotalCount 修改post.swig模板找到themes\next\layout\_macro\post.swig并打开插入以下代码：12345678910111213141516171819202122232425262728293031323334&#123;# LeanCould PageView #&#125; &#123;% if theme.leancloud_visitors.enable %&#125; &lt;span id=&quot;&#123;&#123; url_for(post.path) &#125;&#125;&quot; class=&quot;leancloud_visitors&quot; data-flag-title=&quot;&#123;&#123; post.title &#125;&#125;&quot;&gt; &amp;nbsp; | &amp;nbsp; &lt;span class=&quot;post-meta-item-icon&quot;&gt; &lt;i class=&quot;fa fa-eye&quot;&gt;&lt;/i&gt; &lt;/span&gt; &lt;span class=&quot;post-meta-item-text&quot;&gt;&#123;&#123;__(&apos;post.visitors&apos;)&#125;&#125; &lt;/span&gt; &lt;span class=&quot;leancloud-visitors-count&quot;&gt;&lt;/span&gt; &lt;/span&gt; &#123;% endif %&#125; #以下部分为：字数统计、阅读时长插入代码 &lt;span class=&quot;post-time&quot;&gt; &amp;nbsp; | &amp;nbsp; &lt;span class=&quot;post-meta-item-icon&quot;&gt; &lt;i class=&quot;fa fa-calendar-o&quot;&gt;&lt;/i&gt; &lt;/span&gt; &lt;span class=&quot;post-meta-item-text&quot;&gt;字数统计:&lt;/span&gt; &lt;span class=&quot;post-count&quot;&gt;&#123;&#123; wordcount(post.content) &#125;&#125;(字)&lt;/span&gt; &lt;/span&gt; &lt;span class=&quot;post-time&quot;&gt; &amp;nbsp; | &amp;nbsp; &lt;span class=&quot;post-meta-item-icon&quot;&gt; &lt;i class=&quot;fa fa-calendar-o&quot;&gt;&lt;/i&gt; &lt;/span&gt; &lt;span class=&quot;post-meta-item-text&quot;&gt;阅读时长:&lt;/span&gt; &lt;span class=&quot;post-count&quot;&gt;&#123;&#123; min2read(post.content) &#125;&#125;(分)&lt;/span&gt; &lt;/span&gt;#以上部分为：字数统计、阅读时长插入代码 修改footer修改之后的样子大概是这样的： 1、找到 \themes\next\layout\partials\下面的footer.swig文件，打开会发现，如下图的语句： 第一个框 是下面侧栏的“日期❤ XXX”如果想像我一样加东西，一定要在双大括号外面写。如：xxx,当然你要是想改彻底可以变量都删掉，看个人意愿。 第二个，是图一当中 “由Hexo驱动” 的Hexo链接，先给删掉防止跳转，如果想跳转当然也可以自己写地址，至于中文一会处理。注意删除的时候格式不能错，只把&lt;a&gt;...&lt;/a&gt;标签这部分删除即可，留着两个单引号’’,否则会出错哦。 第三个框也是最后一个了，这个就是更改图一后半部分“主题-Next.XX”,这个比较爽直接将..都删掉，同样中文“主题”一会处理，删掉之后在上一行 ‘-’后面可以随意加上你想显示的东西，不要显示敏感信息哟，请自重。 2、接下来，处理剩余的中文信息。找到这个地方\themes\next\languages\ 下面的语言文件zh-Hans.yml（这里以中文为例，有的习惯用英文的配置文件，道理一样，找对应位置即可）打开之后，如图： 看到了吧，这个就是传值传过去的，你想显示什么就在这里面大肆的去改动吧。其实在第二个框中，就可以把值都改掉，不用接受传值的方式，完全自己可以重写。不过我不建议那样做，因为传值这样只要是后续页面需要这几个值那么就都会通过取值去传过去，要是在刚才footer文件中直接写死，后续不一定哪个页面需要传值，但是值为空了或者还是原来的，可就尴尬了。所以还是这样改动吧。 元素微调自定义篇那么如何把字体、页宽、按钮大小等等一些细节的东西调到自己喜欢的样式呢？那就是通过浏览器元素定位，调到自己喜欢的样式，然后加到themes/next/source/css/_custom/custom.styl文件下面。 定位元素用谷歌或者火狐浏览器打开博客页面，按下F12进入调试先点击定位按钮，然后选择元素，然后在定位出来的样式进行修改，调到自己喜欢的样子，就像这样↓ 添加到样式文件打开themes/next/source/css/_custom/custom.styl，把调试好的样式加进去，保存后Ctrl+F5就能看到效果了，前提是在本地运行的，下面列出博主的一些自定义样式：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697// Custom styles.// 页面头部背景.header &#123; background:url(http://ojoba1c98.bkt.clouddn.com/img/header/header_background.jpg);&#125;// 子标题.site-subtitle&#123; font-size: 15px; color: white; &#125;// 标题.site-title &#123; font-size: 40px; font-weight: bold;&#125;// 标题背景.brand&#123; background: transparent;&#125;// 菜单栏.menu &#123; margin-top: 20px; padding-left: 0; text-align: center; background: rgba(240, 240, 240, 0.5); margin-left: auto; margin-right: auto; width: 530px; border-radius: initial;&#125;// 菜单图表链接 以及 超链接样式a &#123; color: rgba(0,0,0,0.8);&#125;a:hover &#123; color: #ff106c; border-bottom-color: #ff106c;&#125;// 菜单字体大小.menu .menu-item a &#123; font-size: 14px;&#125;.menu .menu-item a:hover &#123; border-bottom-color: #ff106c;&#125;// 文章背景框框.post &#123; margin-top: 10px; margin-bottom: 40px; padding: 18px; -webkit-box-shadow: 0 0 5px rgba(202, 203, 203, 0.8); &#125;// 站点描述.site-description &#123; font-size: 16px;&#125;// 头部inner.header-inner &#123; padding: 45px 0 25px; width: 700px;&#125;// 作者名.site-author-name &#123; font-family: &apos;Comic Sans MS&apos;, sans-serif; font-size: 20px;&#125;// 文章之间的分割线.posts-expand .post-eof &#123; margin: 40px auto 40px; background: white;&#125;// 按钮样式.btn &#123; margin-top: 20px;&#125;// ``代码块样式code &#123; color: #E6006B; background: white; border-radius: 3px;&#125;body &#123; color: #444; font-size: 16px;&#125; 但并不是所有的样式都能调，像页宽，多说评论的样式在custom.styl文件是无效的。 好玩的样式先在themes/next/source/css/_custom/custom.styl中添加以下样式：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221// 下载样式a#download &#123;display: inline-block;padding: 0 10px;color: #000;background: transparent;border: 2px solid #000;border-radius: 2px;transition: all .5s ease;font-weight: bold;&amp;:hover &#123;background: #000;color: #fff;&#125;&#125;/ /颜色块-黄span#inline-yellow &#123;display:inline;padding:.2em .6em .3em;font-size:80%;font-weight:bold;line-height:1;color:#fff;text-align:center;white-space:nowrap;vertical-align:baseline;border-radius:0;background-color: #f0ad4e;&#125;// 颜色块-绿span#inline-green &#123;display:inline;padding:.2em .6em .3em;font-size:80%;font-weight:bold;line-height:1;color:#fff;text-align:center;white-space:nowrap;vertical-align:baseline;border-radius:0;background-color: #5cb85c;&#125;// 颜色块-蓝span#inline-blue &#123;display:inline;padding:.2em .6em .3em;font-size:80%;font-weight:bold;line-height:1;color:#fff;text-align:center;white-space:nowrap;vertical-align:baseline;border-radius:0;background-color: #2780e3;&#125;// 颜色块-紫span#inline-purple &#123;display:inline;padding:.2em .6em .3em;font-size:80%;font-weight:bold;line-height:1;color:#fff;text-align:center;white-space:nowrap;vertical-align:baseline;border-radius:0;background-color: #9954bb;&#125;// 左侧边框红色块级p#div-border-left-red &#123;display: block;padding: 10px;margin: 10px 0;border: 1px solid #ccc;border-left-width: 5px;border-radius: 3px;border-left-color: #df3e3e;&#125;// 左侧边框黄色块级p#div-border-left-yellow &#123;display: block;padding: 10px;margin: 10px 0;border: 1px solid #ccc;border-left-width: 5px;border-radius: 3px;border-left-color: #f0ad4e;&#125;// 左侧边框绿色块级p#div-border-left-green &#123;display: block;padding: 10px;margin: 10px 0;border: 1px solid #ccc;border-left-width: 5px;border-radius: 3px;border-left-color: #5cb85c;&#125;// 左侧边框蓝色块级p#div-border-left-blue &#123;display: block;padding: 10px;margin: 10px 0;border: 1px solid #ccc;border-left-width: 5px;border-radius: 3px;border-left-color: #2780e3;&#125;// 左侧边框紫色块级p#div-border-left-purple &#123;display: block;padding: 10px;margin: 10px 0;border: 1px solid #ccc;border-left-width: 5px;border-radius: 3px;border-left-color: #9954bb;&#125;// 右侧边框红色块级p#div-border-right-red &#123;display: block;padding: 10px;margin: 10px 0;border: 1px solid #ccc;border-right-width: 5px;border-radius: 3px;border-right-color: #df3e3e;&#125;// 右侧边框黄色块级p#div-border-right-yellow &#123;display: block;padding: 10px;margin: 10px 0;border: 1px solid #ccc;border-right-width: 5px;border-radius: 3px;border-right-color: #f0ad4e;&#125;// 右侧边框绿色块级p#div-border-right-green &#123;display: block;padding: 10px;margin: 10px 0;border: 1px solid #ccc;border-right-width: 5px;border-radius: 3px;border-right-color: #5cb85c;&#125;// 右侧边框蓝色块级p#div-border-right-blue &#123;display: block;padding: 10px;margin: 10px 0;border: 1px solid #ccc;border-right-width: 5px;border-radius: 3px;border-right-color: #2780e3;&#125;// 右侧边框紫色块级p#div-border-right-purple &#123;display: block;padding: 10px;margin: 10px 0;border: 1px solid #ccc;border-right-width: 5px;border-radius: 3px;border-right-color: #9954bb;&#125;// 上侧边框红色p#div-border-top-red &#123;display: block;padding: 10px;margin: 10px 0;border: 1px solid #ccc;border-top-width: 5px;border-radius: 3px;border-top-color: #df3e3e;&#125;// 上侧边框黄色p#div-border-top-yellow &#123;display: block;padding: 10px;margin: 10px 0;border: 1px solid #ccc;border-top-width: 5px;border-radius: 3px;border-top-color: #f0ad4e;&#125;// 上侧边框绿色p#div-border-top-green &#123;display: block;padding: 10px;margin: 10px 0;border: 1px solid #ccc;border-top-width: 5px;border-radius: 3px;border-top-color: #5cb85c;&#125;// 上侧边框蓝色p#div-border-top-blue &#123;display: block;padding: 10px;margin: 10px 0;border: 1px solid #ccc;border-top-width: 5px;border-radius: 3px;border-top-color: #2780e3;&#125;// 上侧边框紫色p#div-border-top-purple &#123;display: block;padding: 10px;margin: 10px 0;border: 1px solid #ccc;border-top-width: 5px;border-radius: 3px;border-top-color: #9954bb;&#125; 用法如下： 文字增加背景色块站点配置文件 ，主题配置文件12&lt;span id=&quot;inline-blue&quot;&gt;站点配置文件&lt;/span&gt;， &lt;span id=&quot;inline-purple&quot;&gt;主题配置文件&lt;/span&gt; 引用边框变色如果没有安装成功，那可能就是墙的原因。建议下载 Node.js 直接安装。 关于更多基本操作和基础知识，请查阅 Hexo 与 NexT 官方文档.12&lt;p id=&quot;div-border-left-red&quot;&gt;如果没有安装成功，那可能就是墙的原因。建议下载 `Node.js` 直接安装。&lt;/p&gt;&lt;p id=&quot;div-border-top-blue&quot;&gt;关于更多基本操作和基础知识，请查阅 [Hexo](https://hexo.io/zh-cn/) 与 [NexT](http://theme-next.iissnan.com/) 官方文档.&lt;/p&gt; 在文档中增加图标 支持MarkdownHexo 支持 GitHub Flavored Markdown 的所有功能，甚至可以整合 Octopress 的大多数插件。 一件部署只需一条指令即可部署到Github Pages，或其他网站 丰富的插件Hexo 拥有强大的插件系统，安装插件可以让 Hexo 支持 Jade, CoffeeScript。 123456- &lt;i class=&quot;fa fa-pencil&quot;&gt;&lt;/i&gt;支持Markdown&lt;i&gt;Hexo 支持 GitHub Flavored Markdown 的所有功能，甚至可以整合 Octopress 的大多数插件。&lt;/i&gt;- &lt;i class=&quot;fa fa-cloud-upload&quot;&gt;&lt;/i&gt;一件部署&lt;i&gt;只需一条指令即可部署到Github Pages，或其他网站&lt;/i&gt;- &lt;i class=&quot;fa fa-cog&quot;&gt;&lt;/i&gt;丰富的插件&lt;i&gt;Hexo 拥有强大的插件系统，安装插件可以让 Hexo 支持 Jade, CoffeeScript。&lt;/i&gt; &lt;i class=&quot;fa fa-github&quot;&gt;&lt;/i&gt;&lt;i class=&quot;fa fa-github fa-lg&quot;&gt;&lt;/i&gt;&lt;i class=&quot;fa fa-github fa-2x&quot;&gt;&lt;/i&gt; 采用的是Font Awesome的图标。 图形边框效果 Download Now12&lt;a id=&quot;download&quot; href=&quot;https://git-scm.com/download/win&quot;&gt;&lt;i class=&quot;fa fa-download&quot;&gt;&lt;/i&gt;&lt;span&gt; Download Now&lt;/span&gt;&lt;/a&gt; 这也是调用了Font Awesome的方法。 域名绑定篇博客托管在Github和Coding，所以个人博客地址是Github或Coding的二级域名，不容易让人记住，也很难让百度收录，所以很多人都自己注册域名，和博客地址绑定，这样只要输入自己申请的域名，就能跳转到博客首页，也算是真正拥有了个人网站了 购买域名博主选择万网购买的域名，可以淘宝账号登陆，之后支付宝付款至于怎么实名认证博主就略过了～搜索自己想好的域名，没被注册的话，点击购买，top顶级域名第一年只要四元，选其他更高逼格的也可以，看个人喜好 域名解析购买玩以后进入工作台，点击域名，然后解析第一次可能需要填写个人信息，填完了，点击上面的域名解析-&gt;解析设置-&gt;添加解析，记录类型选A或CNAME，A记录的记录值就是ip地址，Github提供了两个IP地址，192.30.252.153和192.30.252.154，随便填一个就行，解析记录设置两个www和不填，线路就默认就行了，CNAME记录值填你的Coding的博客网址。如果选择A（下图的Github地址）记录，就要在网站根目录新建CNAME文件，里面填写注册的域名ookamiantd.top，之后修改站点配置文件，把站点地址更新成新的绑定的域名即可123# URL## If your site is put in a subdirectory, set url as &apos;http://yoursite.com/child&apos; and root as &apos;/child/&apos;url: http://www.ookamiantd.top 博主的是这样的↓ 一般解析配置好并不能马上访问，得看人品= =，博主的是第二天才访问到的，祝你好运 站点加速篇更改默认Google字体库访问系统总是会耗费一大部分的时间在加载google字体库上，而且经常加载不成功。 方法一：用国内的CDN库来替代主题中的google字体库，到主题配置文件中设置默认字体库：1host: fonts.useso.com 方法二：关掉字体库的引用，默认加载本地字体库，到主题配置文件设置：12font: enable: false 使用云盘存放图片资源由于Github的服务器在海外，那么如果把图片也放到Github显然是不科学的，而且Github的存储空间也有局限，那么在这里博主推荐使用七牛云储存具体怎么做在之前的基础篇已经介绍过了，详情请看→传送门 压缩代码安装插件：1npm install hexo-all-minifier --save 之后执行hexo g就会自动压缩但这有一个缺点，就是本地运行也就是执行hexo s之后浏览器打开本地项目会很慢，原因是每次点击一个链接它就会重新压缩一次，所以建议本地调试的时候把项目根目录下的package.json中的&quot;hexo-all-minifier&quot;: &quot;0.0.14&quot;先删掉再调试,或者改成注释：123456789&quot;dependencies&quot;: &#123; . . . &quot;hexo-server&quot;: &quot;^0.2.0&quot;, &quot;hexo-wordcount&quot;: &quot;^2.0.1&quot;, &quot;this-is-compress-plugin&quot;: &#123; &quot;hexo-all-minifier&quot;: &quot;0.0.14&quot; &#125; 其实也没必要压缩代码，牺牲了性能，每次生成静态文件都太慢了，得不偿失的感觉 SEO(搜索引擎优化)篇网站验证以下是几个搜索引擎的提交入口： 百度提交入口 Google提交入口 360提交入口 以百度为例，谷歌的太简单就不说了：打开百度站长验证网站方式一：文件验证 登录百度站长选择添加网站，使用方式为文件验证 将下载的文件放到source文件下 由于hexo自动会对html文件进行渲染，所以在站点配置文件中找到skip_render: 在后面添加文件名字，如有多个用[a.html,b.html]，eg:skip_render:[baidu_verify_tdOGHi8IQG.html, baidu_verify_vcJkI72f1e.html] 重新渲染文件 12hexo cleanhexo d -g 然后可以点击百度站长的验证按钮了 方式二：CNAME验证 去站长添加网站选择CNAME验证 把地址解析到zz.baidu.com 完成验证 就像这样↓ 添加并提交sitemap安装hexo的sitemap网站地图生成插件:12npm install hexo-generator-sitemap --savenpm install hexo-generator-baidu-sitemap --save 在站点配置文件中添加如下代码。123456# hexo sitemapsitemap: path: sitemap.xmlbaidusitemap: path: baidusitemap.xml 配置成功后，会生成sitemap.xml和baidusitemap.xml，前者适合提交给谷歌搜素引擎，后者适合提交百度搜索引擎。百度sitemap提交如下↓ 验证成功之后就可以开始推送了，这里说一下，Google的收录真的快的不要不要的，第二天就能搜得到，百度就不想说了，不知道要等到猴年马月 主动推送安装主动推送插件：1 npm install hexo-baidu-url-submit --save 在根目录下，把以下内容配置到站点配置文件中:12345baidu_url_submit: count: 3 ## 比如3，代表提交最新的三个链接 host: www.henvyluk.com ## 在百度站长平台中注册的域名 token: your_token ## 请注意这是您的秘钥，请不要发布在公众仓库里! path: baidu_urls.txt ## 文本文档的地址，新链接会保存在此文本文档里 至于上面提到的your_token可在百度站长如下位置找到↓其次，记得查看站点配置文件中url的值， 必须包含是百度站长平台注册的域名（一般有www）， 比如:123url: http://www.ookamiantd.toproot: /permalink: :year/:month/:day/:title/ 接下来添加一个新的deploy的类型：12345678# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy:- type: baidu_url_submitter- type: git repo: github: git@github.com:masteranthoneyd/masteranthoneyd.github.io.git,master coding: git@git.coding.net:ookamiantd/ookamiantd.git,master 执行hexo deploy的时候，新的连接就会被推送了。这里讲一下原理： 新链接的产生，hexo generate会产生一个文本文件，里面包含最新的链接 新链接的提交，hexo deploy会从上述文件中读取链接，提交至百度搜索引擎 自动推送把next主题配置文件中的baidu_push设置为true，就可以了。 添加蜘蛛协议在/source/目录下新建一个robots.txt文件，添加下面的一段代码：12345678910111213141516#hexo robots.txtUser-agent: *Allow: /Allow: /archives/Disallow: /vendors/Disallow: /js/Disallow: /css/Disallow: /fonts/Disallow: /vendors/Disallow: /fancybox/Sitemap: http://blog.tangxiaozhu.com/search.xmlSitemap: http://blog.tangxiaozhu.com/sitemap.xmlSitemap: http://blog.tangxiaozhu.com/baidusitemap.xml 然后到百度站长更新一下，就像这样↓ 修改文章链接hexo默认的文章链接形式为domain/year/month/day/postname，默认就是一个四级url，并且可能造成url过长，对搜索引擎是十分不友好的，我们可以改成domain/postname的形式。编辑站点配置文件文件，修改其中的permalink字段为permalink: :title.html即可。 更改首页标题格式为「关键词-网站名称 - 网站描述」打开\themes\next\layout\index.swig文件，找到这行代码：1&#123;% block title %&#125; &#123;&#123; config.title &#125;&#125; &#123;% endblock %&#125; 把它改成：123&#123;% block title %&#125; &#123;&#123; theme.keywords &#125;&#125; - &#123;&#123; config.title &#125;&#125; - &#123;&#123; theme.description &#125;&#125;&#123;% endblock %&#125; 自动给所有外部链接添加nofollow安装hexo-autonofollow，在站点的根目录下执行以下命令：1npm install hexo-autonofollow --save 编辑站点配置文件，新增以下内容到任意位置：12345nofollow: enable: true exclude: - exclude1.com - exclude2.com 多PC同步源码篇1.准备工作：公司电脑和家里电脑配置git ssh密钥连接 2.上传blog到git：此项建议先在blog进度最新的PC上进行，否则会有版本冲突，解决也比较麻烦。在PC上建立git ssh密钥连接和建立新库respo在此略过： 编辑.gitignore文件：.gitignore文件作用是声明不被git记录的文件，blog根目录下的.gitignore是hexo初始化是创建的，可以直接编辑，建议.gitignore文件包括以下内容： 1234567.DS_Store Thumbs.db db.json *.log node_modules/ public/ .deploy*/ public内的文件可以根据source文件夹内容自动生成的，不需要备份。其他日志、压缩、数据库等文件也都是调试等使用，也不需要备份。 初始化仓库：12git init git remote add origin &lt;server&gt; server是仓库的在线目录地址，可以从git上直接复制过来，origin是本地分支，remote add会将本地仓库映射到托管服务器的仓库上。 添加本地文件到仓库并同步到git上：123git add . #添加blog目录下所有文件，注意有个&apos;.&apos;(.gitignore里面声明的文件不在此内) git commit -m &quot;hexo source first add&quot; #添加更新说明 git push -u origin master #推送更新到git上 至此，git库上备份已完成。 3.将git的内容同步到另一台电脑：假设之前将公司电脑中的blog源码内容备份到了git上，现在家里电脑准备同步源码内容。注意，在同步前也要事先建好hexo的环境，不然同步后本地服务器运行时会出现无法运行错误。在建好的环境的主目录运行以下命令：1234git init #将目录添加到版本控制系统中 git remote add origin &lt;server&gt; #同上 git fetch --all #将git上所有文件拉取到本地 git reset --hard origin/master #强制将本地内容指向刚刚同步git云端内容 reset对所拉取的文件不做任何处理，此处不用pull是因为本地尚有许多文件，使用pull会有一些版本冲突，解决起来也麻烦，而本地的文件都是初始化生成的文件，较拉取的库里面的文件而言基本无用，所以直接丢弃。 4.家里电脑生成完文章并部署到服务器上后，此时需要将新的blog源码文件更新到git托管库上，不然公司电脑上无法获取最新的文章。在本地文件中运行以下命令： 1git add . #将所有更新的本地文件添加到版本控制系统中 此时可以使用git status查看本地文件的状态。然后对更改添加说明更推送到git托管库上： 12git commit -m &apos;更新信息说明&apos; git push 至此，家里电脑更新的备份完成。在公司电脑上使用时，只需先运行:1git pull 获取的源码即为最新文件 插件总结篇部署插件1npm install hexo-deployer-git --save rss1npm install hexo-generator-feed --save Algolia此处有两个版本 第一（以0.2.0为例）： 在站点找到package.json， 把添加一行&quot;hexo-algolia&quot;: &quot;^0.2.0&quot;，然后： 1npm install hexo-algolia --save 这个为旧版的algolia，优点是全文索引，缺点是字数太多会索引失败 第二：直接安装 1npm install hexo-algolia --save hexo algolia 此处安装的应该是1.0.0之后的版本了，优点是没有字数限制了（因为没有了全文索引），只会索引文章开头的部分字段。但是需要在官网注册新key并且设置环境变量，方法：https://github.com/iissnan/theme-next-docs/issues/162 sitemap12npm install hexo-generator-sitemap --savenpm install hexo-generator-baidu-sitemap --save 百度主动推送1npm install hexo-baidu-url-submit --save 分页插件1234npm install hexo-generator-index --savenpm install hexo-generator-archive --savenpm install hexo-generator-category --savenpm install hexo-generator-tag --save 站点配置文件：12345678910index_generator: per_page: 6archive_generator: per_page: 10 ##归档页面默认20篇文章标题 yearly: true ##生成年视图 monthly: true ##生成月视图tag_generator: per_page: 10 压缩插件1npm install hexo-all-minifier --save 七牛admin插件123npm install --save hexo-admin-qiniuhexo server -dopen http://localhost:4000/admin/ 站点配置文件：1234567admin: qiniuCfg: imageslim: true # 启动图片瘦身，仅华东区bucket可以使用 AccessKey: &apos;your qiniu AK&apos; SecretKey: &apos;your qiniu SK&apos; BucketName: &apos;your BK Name&apos; bucketHost: &apos;you BK Host&apos; 注脚插件1npm install hexo-reference --save 字数与阅读时间插件1npm install hexo-wordcount --save 主题升级备份对于升级主题，我们需要重新配置主题配置文件，那么每次升级都要这么干吗？超麻烦！ NexT作者给我们的建议就是使用Data Files，具体详情请戳进 Theme configurations using Hexo data files #328 最后一路摸爬滚打下来也挺折腾的，不过确实满满的成就感，学到了很多同时还要感谢很多很多的大神们的文章，有一些都忘了收藏记录下来，由衷地感谢 参考http://codepub.cn/2015/04/06/Github-Pages-personal-blog-from-Octopress-to-Hexo/http://codepub.cn/2016/03/20/Hexo-blog-theme-switching-from-Jacman-to-NexT-Mist/http://www.shellsec.com/news/34054.htmlhttps://www.0101tx.com/pages/hexonextsanf.html 1.basic footnote content ↩]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Node.js</tag>
        <tag>Github</tag>
        <tag>Coding</tag>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu的Java开发环境基本搭建]]></title>
    <url>%2F2017%2Fubuntu-dev-environment-to-build%2F</url>
    <content type="text"><![CDATA[前言最近公司的电脑由于不明原因老是奔溃，重装过两次，在家里也比较喜欢折腾系统，为了不用每次都度娘谷歌，记录下来，一条龙走过。博主是搞爪哇开发的，那么以下搭建针对的是爪哇环境开发安装JDK以及配置环境变量安装JDK安装之前当然是老规矩地下载jdk：Oracle JDK官方下载1234567# 把jdk的文件移动到 /usr/local/ 目录下sudo mv ~/jdk*.tar.gz /usr/local/# 解压文件cd /usr/local/# sudo tar -zxvf jdk-8u101-linux-x64.tar.gz# 创建软链接sudo ln -s jdk1.8.0_101 jdk 如需更换jdk，删除旧版本的软链接，重新创建软链接指向新版即可 12sudo rm -rf jdksudo ln -s jdk* jdk 配置环境变量 放到 /usr/local 里面的程序，建议使用系统变量。 用户变量 ~/.profile 文件是用户的私有配置文件 ~/.bashrc 是在bash里面使用的私有配置文件，优先级在 .profile 文件之后 系统变量 /etc/profile 文件是系统的公用配置文件 /etc/bash.bashrc 是bash专用的配置文件，优先级在 profile 文件之后 系统变量的配置，不建议修改前面说到的两个文件，而是建议在 /etc/profile.d/ 目录下，创建一个 .sh 结尾 的文件。 1sudo vi /etc/profile.d/jdk.sh 环境变量的配置内容如下： 设置一个名为JAVA_HOME的变量，并且使用export命令导出为环境变量, 如果不使用 export ，仅在当前shell里面有效 1export JAVA_HOME=/usr/local/jdk PATH不需要export，因为早在其他的地方，已经export过了！，\$JAVA_HOME 表示引用前面配置的 JAVA_HOME 变量，分隔符一定是冒号，Windows是分号,最后再引用原来的PATH的值 1PATH=$JAVA_HOME/bin:$PATH 配置以后，可以重新登录让配置生效，也可以使用source临时加载配置文件。使用source命令加载的配置，仅在当前shell有效，关闭以后失效。 1source /etc/profile.d/jdk.sh 查看jdk是否安装成功，一下两条命令成功则安装成功 12java -versionjavac -version 安装Scala环境更上面安装JDK类似 1、去 官网 下载最新地SDK 2、解压到 /usr/local 目录，并创建软链接为 scala 3、在 /etc/profile.d 目录下创建 scala.sh ，输入以下信息： 12export SCALA_HOME=/usr/local/scalaPATH=$PATH:$SCALA_HOME/bin 4、查看是否安装成功12source /etc/profile.d/scala.shscala -version 安装IDEEclipse直接在 Eclipse官方网站 下载相关版本Eclipse解压1sudo tar zxvf eclipse-jee-mars-2-linux-gtk-x86_64.tar.gz -C ~/IDE 创建快捷方式1. 在终端中执行如下命令1sudo gedit /usr/share/applications/eclipse.desktop 2. 粘贴并保存如下内容(注意更改相应的名字和目录)12345678910[Desktop Entry] Name=Eclipse Mars.2 Type=Application Exec=/home/ybd/IDE/eclipse Terminal=false Icon=/home/ybd/IDE/icon.xpm Comment=Integrated Development Environment NoDisplay=false Categories=Development;IDE; Name[en]=Eclipse Mars.2 通用设置window → preferences → 设置字体：general → appearance → color and font → basic → text font 编辑器背景颜色：general → editors → text editors → background color → RGB:85,123,208,#C7EDCC 工作空间字符编码：general → workspace 作者签名：java → code style → code templates → types 签名快捷键：alt + shift + j MyEclipseMyEclipse安装请看：Ubuntu16.04下MyEclipse安装与破解 IntelliJ IDEA之前听说过IDE[1]，都是大公司用的，并没有用过日后再研究补上官网：http://www.jetbrains.com/idea/ 新公司好多大牛，用的都是IDEA，于是乎“近墨者黑”，那么既然有机会跟大牛接触，我也开始真正意义上的学习IDEA了 安装进过查阅，我选择官方的盒子下载：http://www.jetbrains.com/toolbox/app/?fromMenu优点是可以自动更新 激活博主使用授权服务器，可以自己搭建，详情请看 这里 部署Tomcat若是服务器版切换root用户解压到 /opt/ 或者 /usr/local/ 下直接运行tomcat目录下bin/start.sh即可开启，前提是配置好JDK 桌面版个人使用就解压到/home/{user}目录下就可以了 安装MySQL以及GUI工具 以mysql5.7以上版本为例 –&gt; mysql-5.7.10-linux-glibc2.5-x86_64.tar.gz 必须要先安装依赖的libaio才能正常按照mysql12sudo apt-get updatesudo apt-get install libaio-dev 创建用户组以及用户12sudo groupadd mysqlsudo useradd -r -g mysql -s /bin/false mysql 尽量把mysql安装到/usr/local目录下面123456cd /usr/localsudo cp /home/data/software/DataBase/mysql/mysql-5.7.10-linux-glibc2.5-x86_64.tar.gz ./&lt;-- 解压缩安装包 --&gt;sudo tar zxvf mysql-5.7.10-linux-glibc2.5-x86_64.tar.gz&lt;-- 创建软连接 --&gt;sudo ln -s mysql-5.7.10-linux-glibc2.5-x86_64 mysql 创建必须的目录和进行授权12345cd mysqlsudo mkdir mysql-filessudo chmod 770 mysql-filessudo chown -R mysql .sudo chgrp -R mysql . 执行安装脚本12sudo bin/mysqld --initialize --user=mysql sudo bin/mysql_ssl_rsa_setup 在初始化的时候，一定要仔细看屏幕，最后大概有一行:[Note] A temporary password is generated for root@localhost: kklNBwkei1.t注意这是root的临时密码,记录下来以便后面修改密码！ 重新对一些主要的目录进行授权，确保安全性12sudo chown -R root .sudo chown -R mysql data mysql-files 从默认的模板创建配置文件，需要在文件中增加 skip-grant-tables ，以便启动mysql以后修改root用户的密码1sudo cp support-files/my-default.cnf ./my.cnf 测试启动，修改密码1234# 后台启动mysqlsudo bin/mysqld_safe --user=mysql &amp; # 启动./bin/mysql -u root -p 方式一因为前面修改了my.cnf文件，增加了 skip-grant-tables 参数，所以不需要用户名即可登陆进去后立即修改root用户的密码，密码的字段是 authentication_string1update mysql.user set authentication_string=password(&apos;root&apos;) where user=&apos;root&apos;; 修改密码后，再把my.cnf里面的 skip-grant-tables 去掉 方式二修改密码也可以使用安装到时候提示到随机密码进行登录，然后使用下面到命令修改密码。建议用下面的方式设置数据库的密码1alter user user() identified by &apos;root&apos;; 复制启动脚本到合适的位置1sudo cp support-files/mysql.server /etc/init.d/mysql (Optional)增加自动启动1sudo update-rc.d -f mysql defaults 增加mysql命令的路径到PATH环境变量1234sudo touch /etc/profile.d/mysql.shsudo chmod 777 /etc/profile.d/mysql.shsudo echo &quot;PATH=/usr/local/mysql/bin:\$PATH&quot; &gt; /etc/profile.d/mysql.shsudo chmod 644 /etc/profile.d/mysql.sh 到此，mysql的安装基本完成 修复乱码以及忽略大小写，找到MySQL文件里的my.cnf在末尾添加12lower_case_table_names=1character_set_server=utf8 查看以及修改MySQL字符编码查看123mysql&gt; show variables like &apos;collation_%&apos;;mysql&gt; show variables like &apos;character_set_%&apos;; 修改1234567891011121314151617181920212223242526mysql&gt; set character_set_client=utf8;Query OK, 0 rows affected (0.00 sec)mysql&gt; set character_set_connection=utf8;Query OK, 0 rows affected (0.00 sec)mysql&gt; set character_set_database=utf8;Query OK, 0 rows affected (0.00 sec)mysql&gt; set character_set_results=utf8;Query OK, 0 rows affected (0.00 sec)mysql&gt; set character_set_server=utf8;Query OK, 0 rows affected (0.00 sec)mysql&gt; set character_set_system=utf8;Query OK, 0 rows affected (0.01 sec)mysql&gt; set collation_connection=utf8_general_ci;Query OK, 0 rows affected (0.01 sec)mysql&gt; set collation_database=utf8mb4_general_ci;Query OK, 0 rows affected (0.01 sec)mysql&gt; set collation_server=utf8mb4_general_ci;Query OK, 0 rows affected (0.01 sec) 如果登录mysql出现以下错误则可能配置未加载或服务未启动，请重启系统，然后启动mysql服务1sudo service mysql start 结束mysql服务1sudo service mysql stop 开启远程链接链接mysql后：12345678use mysql// 下面两个root分别是帐号密码GRANT ALL PRIVILEGES ON *.* TO &apos;root&apos;@&apos;%&apos; IDENTIFIED BY &apos;root&apos; WITH GRANT OPTION;// 刷新特权flush privileges;// 查看修改是否成功select host,user from user; 附加：基于Docker拉取镜像1docker pull mysql:5.7 运行实例1MYSQL=/home/ybd/data/docker/mysql &amp;&amp; docker run --name=mysql -p 3306:3306 -v $MYSQL/data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=root -d mysql --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci --sql-mode=STRICT_TRANS_TABLES,NO_ENGINE_SUBSTITUTION --lower-case-table-names=1 终端客户端1234sudo apt-get install mysql-client// 链接mysql -h 127.0.0.1 -P 3306 -u root -p Navicat Premium破解 到官网下载对应系统版本，这里选择linux版本，并解压 到Github下载注册机，并解压 CHS - &gt; Navicat简体中文版。CHT - &gt; Navicat繁体中文版。ENG - &gt; Navicat英文版 安装wine 123sudo add-apt-repository ppa:ubuntu-wine/ppasudo apt-get updatesudo apt-get install wine1.8 进入注册机解压目录，在此目录下打开命令窗口输入 1wine navicat-patcher.exe &lt;navicat.exe path&gt; &lt;navicat.exe path&gt;就是navicat.exe的路径，最好是完整的。 可能会出现N个error日志信息不用鸟他 能正常success就行之后在当前目录下会生成对应的私钥文件RegPrivateKey.pem 接着再用navicat-keygen.exe生成注册码，使用命令 1wine navicat-keygen.exe RegPrivateKey.pem 先填名字和组织名称，之后会生成一个序列号，并要求填入请求码。 打开navicat，然后断网 在注册界面填入序列号，然后激活。这时会提示要手动激活，ok就选这个接下来会有请求码，复制然后贴入控制台，就可以得到注册码了。 创建快捷方式123cd /usr/share/applications/sudo touch navicat.desktopsudo vi navicat.desktop 加入以下内容12345678910[Desktop Entry]Encoding=UTF-8Name=NavicatComment=The Smarter Way to manage dadabaseExec=/bin/sh &quot;/home/ybd/Data/soft/application/navicat112_mysql_en_x64/start_navicat&quot;Icon=/home/ybd/Data/soft/application/navicat112_mysql_en_x64/Navicat/navicat.pngCategories=Application;Database;MySQL;navicatVersion=1.0Type=ApplicationTerminal=0 参考：https://www.52pojie.cn/thread-705020-1-1.html 后台运行1nohup /home/ybd/data/application/navicat/navicat120_premium_en_x64/start_navicat &gt; /dev/null 2&gt;&amp;1 &amp; 安装Redis安装终端执行：12sudo apt-get updatesudo apt-get install redis-server 启动1redis-server 查看是否启动成功1redis-cli HelloWorld12set k1 hellowordget k1 配置相关/etc/redis：存放redis配置文件/var/redis/端口号：存放redis的持久化文件 通过下面的命令停止/启动/重启redis：123/etc/init.d/redis-server stop/etc/init.d/redis-server start/etc/init.d/redis-server restart 如果是通过源码安装的redis，则可以通过redis的客户端程序redis-cli的shutdown命令来重启redis1redis-cli -h 127.0.0.1 -p 6379 shutdown 如果上述方式都没有成功停止redis，则可以使用终极武器 kill -9 开启远程访问找到redis.conf文件，一般在/etc下面：123➜ ~ sudo find /etc -name redis.conf/etc/redis/redis.conf➜ ~ sudo gedit /etc/redis/redis.conf 找到bind 127.0.0.1注释掉注释掉本机,局域网内的所有计算机都能访问。band localhost 只能本机访问,局域网内计算机不能访问。bind 局域网IP 只能局域网内IP的机器访问, 本地localhost都无法访问。 博主选择将bind 127.0.0.1 改成了bind 0.0.0.0 开启发布订阅监听还是修改redis.conf文件，找到notify-keyspace-events &quot;&quot;，修改为notify-keyspace-events Ex或者notify-keyspace-events AKE，然后重启。 附加：基于Docker拉取镜像： 1docker pull redis:latest 运行实例： 1REDIS=/home/ybd/data/docker/redis &amp;&amp; docker run -p 6379:6379 --restart=always -v $REDIS/redis.conf:/usr/local/etc/redis/redis.conf -v $REDIS/data:/data --name redis -d redis redis-server /usr/local/etc/redis/redis.conf --appendonly yes 安装链接工具： 1234sudo apt-get install redis-tools// 链接redis-cli 安装Maven下载官网下载或者点击镜像获取 配置1、下载解压到自己的指定的目录后，将命令放到/bin下：1sudo ln -s /自定义目录/apache-maven-3.3.9/bin/mvn /bin/mvn 2、添加环境变量老规矩，在/etc/profile.d下创建一个maven.sh的文件：12sudo touch /etc/profile.d/maven.shsudo vi /etc/profile.d/maven.sh 输入以下内容：12export M2_HOME=/自定义目录/apache-maven-3.3.9export PATH=$&#123;M2_HOME&#125;/bin:$PATH 然后source一下：1source /etc/profile.d/maven.sh 查看是否配置成功：1mvn -v 输入内容如下：123456Apache Maven 3.3.9 (bb52d8502b132ec0a5a3f4c09453c07478323dc5; 2015-11-11T00:41:47+08:00)Maven home: /home/ybd/Data/application/maven/apache-maven-3.3.9Java version: 1.8.0_65, vendor: Oracle CorporationJava home: /usr/local/jdk1.8.0_65/jreDefault locale: zh_CN, platform encoding: UTF-8OS name: &quot;linux&quot;, version: &quot;4.4.0-67-generic&quot;, arch: &quot;amd64&quot;, family: &quot;unix&quot; 淘宝镜像12345678&lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;alimaven&lt;/id&gt; &lt;name&gt;aliyun maven&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;/mirror&gt;&lt;/mirrors&gt; MongoDB安装12345678sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv 0C49F3730359A14518585931BC711F9BA15703C6#下面命令针对ubuntu16.04版本，在其他ubuntu版本系统请查看MongoDB官网echo &quot;deb [ arch=amd64,arm64 ] http://repo.mongodb.org/apt/ubuntu xenial/mongodb-org/3.4 multiverse&quot; | sudo tee /etc/apt/sources.list.d/mongodb-org-3.4.listsudo apt-get updatesudo apt-get install -y mongodb-org 安装完成后查看版本：1mongo -version 启动、重新启动和关闭mongodb命令:123sudo service mongod startsudo service mongod stopsudo service mongod restart 查看是否启动成功:1sudo cat /var/log/mongodb/mongod.log 在 mongod.log 日志中若出现如下信息，说明启动成功:1[initandlisten] waiting for connections on port 27017 MongoDB 卸载删除 mongodb 包1sudo apt-get purge mongodb-org* 删除 MongoDB 数据库和日志文件12sudo rm -r /var/log/mongodbsudo rm -r /var/lib/mongodb MongoDB 使用shell命令模式输入mongo进入shell命令模式，默认连接的数据库是test数据库，命令如下：1➜ ~ mongo 常用操作命令： show dbs：显示数据库列表show collections：显示当前数据库中的集合（类似关系数据库中的表table）show users：显示所有用户use yourDB：切换当前数据库至yourDBdb.help() ：显示数据库操作命令db.yourCollection.help() ：显示集合操作命令，yourCollection是集合名 官方文档：https://docs.mongodb.com/master/tutorial/install-mongodb-on-ubuntu/ GUI客户端Robomongo RabbitMQ选择Docker安装。。。不折腾了。。 12docker pull rabbitmq:3-managementdocker run -d --name rabbitmq -p 5673:5672 -p 15673:15672 --restart=always rabbitmq:3-management (注意版本，是management) 浏览器打开localhost:15673，默认帐号密码都是guest 集群：https://www.jianshu.com/p/624871c646b9 Kafka&amp;Zookeeper集群docker-compose.yml: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677version: &apos;3&apos;services: kafka1: image: wurstmeister/kafka:1.0.0 depends_on: - zoo1 - zoo2 - zoo3 ports: - &quot;9092:9092&quot; environment: KAFKA_LOG_DIRS: /kafka KAFKA_BROKER_ID: 1 KAFKA_CREATE_TOPICS: test:6:1 KAFKA_ADVERTISED_HOST_NAME: 192.168.6.113 KAFKA_ADVERTISED_PORT: 9092 KAFKA_ZOOKEEPER_CONNECT: zoo1:2181,zoo2:2181,zoo3:2181 kafka2: image: wurstmeister/kafka:1.0.0 depends_on: - zoo1 - zoo2 - zoo3 ports: - &quot;9093:9092&quot; environment: KAFKA_LOG_DIRS: /kafka KAFKA_BROKER_ID: 2 KAFKA_ADVERTISED_HOST_NAME: 192.168.6.113 KAFKA_ADVERTISED_PORT: 9093 KAFKA_ZOOKEEPER_CONNECT: zoo1:2181,zoo2:2181,zoo3:2181 kafka3: image: wurstmeister/kafka:1.0.0 depends_on: - zoo1 - zoo2 - zoo3 ports: - &quot;9094:9092&quot; environment: KAFKA_LOG_DIRS: /kafka KAFKA_BROKER_ID: 3 KAFKA_ADVERTISED_HOST_NAME: 192.168.6.113 KAFKA_ADVERTISED_PORT: 9094 KAFKA_ZOOKEEPER_CONNECT: zoo1:2181,zoo2:2181,zoo3:2181 zoo1: image: zookeeper:latest environment: ZOO_MY_ID: 1 SERVERS: zoo1,zoo2,zoo3 ports: - &quot;2181:2181&quot; - &quot;2888&quot; - &quot;3888&quot; zoo2: image: zookeeper:latest environment: ZOO_MY_ID: 2 SERVERS: zoo1,zoo2,zoo3 ports: - &quot;2182:2181&quot; - &quot;2888&quot; - &quot;3888&quot; zoo3: image: zookeeper:latest environment: ZOO_MY_ID: 3 SERVERS: zoo1,zoo2,zoo3 ports: - &quot;2183:2181&quot; - &quot;2888&quot; - &quot;3888&quot; 启动：1docker-compose up -d 测试： 1234567891011#创建主题docker exec -it $&#123;CONTAINER_ID&#125; /opt/kafka/bin/kafka-topics.sh --create --zookeeper zoo1:2181 --replication-factor 1 --partitions 1 --topic test#查看topic列表docker exec -it $&#123;CONTAINER_ID&#125; /opt/kafka/bin/kafka-topics.sh --list --zookeeper zoo1:2181#生产者docker exec -it $&#123;CONTAINER_ID&#125; /opt/kafka/bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test#消费者docker exec -it $&#123;CONTAINER_ID&#125; /opt/kafka/bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning 搭建ngrok配置 ngrok 是一个反向代理，通过在公共的端点和本地运行的 Web 服务器之间建立一个安全的通道。ngrok 可捕获和分析所有通道上的流量，便于后期分析和重放。可以被使用来进行微信借口的本地调试。在ngrok被墙之后，我们需要通过ngrok开源的源码自行搭建ngrok服务。 参考地址：Ubuntu下配置安装ngrok搞了一上午，服务运行起来了，客户端也运行起来了，浏览器就是访问不到！！不知道是不是因为个人电脑没有域名所以才访问不到，日后再深究。无奈，还好互联网开源精神无处不在，某大神搭建的ngrok：http://www.qydev.com/客户端和教程都在里面哦。 Update:Ngrok已搭建成功～ ，记录于self-hosted-build-ngrok-server 其他tunnel的代理服务器：natapp.cnwww.ngrok.cc 1.IDEA 全称IntelliJ IDEA，是java语言开发的集成环境，IntelliJ在业界被公认为最好的java开发工具之一，尤其在智能代码助手、代码自动提示、重构、J2EE支持、Ant、JUnit、CVS整合、代码审查、 创新的GUI设计等方面的功能可以说是超常的。IDEA是JetBrains公司的产品，这家公司总部位于捷克共和国的首都布拉格，开发人员以严谨著称的东欧程序员为主 ↩]]></content>
      <categories>
        <category>OperatingSystem</category>
        <category>Ubuntu</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>IDE</tag>
        <tag>JDK</tag>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git学习笔记]]></title>
    <url>%2F2017%2Fnote-of-learning-git%2F</url>
    <content type="text"><![CDATA[前言What is Git?Git是目前世界上最先进的分布式版本控制系统（没有之一），而且是一款免费、开源的分布式版本控制系统，用于敏捷高效地处理任何或小或大的项目一直以来，博主开发项目用的版本管理系用都是SVN[1]，其实早就听闻过Git，一直没用过，后来接触Github和Hexo博客框架，才真正意义上开始接触Git，感受就是高端大气上档次！简介Git是Linux系统的开发者Linus在2005年的时候，BitKeeper[2]的东家BitMover公司回收了Linux社区的免费使用权的情况下，在仅仅的两周内Linus用C写出了一个分布式版本控制系统，这就是Git（超级牛X）！从此，Linux系统的源码已经由Git管理了。逐渐地，Git迅速成为最流行的分布式版本控制系统，尤其是在Github上线之后，无数开源项目开始迁移至GitHub，包括jQuery，PHP，Ruby等等Git安装在Debian或者Ubuntu Linux下的Git安装非常简单，直接一条命令搞定1sudo apt-get install git Windows下的模拟环境安装起来比较复杂，那么可以用牛人封装好的模拟环境加Git，叫msysgit，只需要下载一个exe然后双击安装可从https://git-for-windows.github.io/ 下载，或者从廖雪峰老师的镜像 下载，然后按默认选项安装安装完成后，在开始菜单里找到“Git”-&gt;“Git Bash”，蹦出一个类似命令行窗口的东西，就说明Git安装成功 成功安装之后，还需要配置一下全局个人信息：12git config --global user.name &quot;Your Name&quot;git config --global user.email &quot;email@example.com&quot; 每次提交，都会记录这两个值，--global 参数，表示你这台机器上所有的Git仓库都会使用这个配置可使用 git config -l 查看全局配置信息 运行前配置一般在新的系统上，我们都需要先配置下自己的 Git 工作环境。配置工作只需一次，以后升级时还会沿用现在的配置。 配置文件如何生效对于 Git 来说，配置文件的权重是仓库&gt;全局&gt;系统。Git 会使用这一系列的配置文件来存储你定义的偏好，它首先会查找 /etc/gitconfig 文件（系统级），该文件含有对系统上所有用户及他们所拥有的仓库都生效的配置值。接下来 Git 会查找每个用户的 ~/.gitconfig 文件（全局级）。最后 Git 会查找由用户定义的各个库中Git目录下的配置文件 .git/config（仓库级），该文件中的值只对当前所属仓库有效。以上阐述的三 层配置从一般到特殊层层推进，如果定义的值有冲突，以后面层中定义的为准，例如：.git/config 和 /etc/gitconfig 的较量中， .git/config 取得了胜利。 查看配置格式：git config [--local|--global|--system] -l example: 1234567891011# 查看当前生效的配置git config -l# 查看仓库级的配置git config --local -l# 查看全局级的配置git config --global -l# 查看系统级的配置git config --system -l 修改配置格式：git config [--local|--global|--system] key value example: 12git config --global user.name ybdgit config --global user.email yangbingdong1994@gmail.com 创建仓库（Repository）创建一个目录并进入，进行初始化仓库123mkdir repocd repogit init 目录下会多一个 .git 的隐藏文件，现在要创建一个文件并提交到仓库1234567touch readvi read # 按a进入编辑 # 输入Git is a distributed version control system # 按下Esc，并输入 &quot;:wq&quot; 保存退出git add README.md #添加文件到缓存区git commit -m &quot;first commit&quot; #将缓存区的文件提交到本地仓库 多个文件提交可用 git add -A 然后再 commit1234➜ repo git:(master) ✗ git commit -m &quot;first commit&quot;[master （根提交） 20717f5] first commit 1 file changed, 2 insertions(+) create mode 100644 read 操作的自由穿越要随时掌握工作区的状态：git status查看修改内容：git diff read查看版本历史信息 got log 或 git log --pretty=oneline 版本穿越退到上一个版本：1git reset --hard HEAD^ 上上一个版本就是 HEAD^^，当然往上100个版本写100个^比较容易数不过来，所以写成 HEAD~100要重返未来，查看命令历史：git reflog 修改管理添加文件到缓存区：git add read 或 git add -A然后提交：git commit -m &quot;msg&quot;查看状态：git status每次修改，如果不add到暂存区，那就不会加入到commit中 撤销修改当你发现工作区的修改有错误的时候，可丢弃工作区的修改：1git checkout -- read 命令 git checkout -- read 意思就是，把 read 文件在工作区的修改全部撤销，这里有两种情况： 一种是 read 自修改后还没有被放到暂存区，现在，撤销修改就回到和版本库一模一样的状态 一种是 read 已经添加到暂存区后，又作了修改，现在，撤销修改就回到添加到暂存区后的状态 总之，就是让这个文件回到最近一次 git commit 或 git add 时的状态注意！ git checkout -- file 命令中的 -- 很重要，没有 -- 就变成了切换分支了 当你发现该文件修改错误并且已经提交到了缓存区，这个时候可以把暂存区的修改撤销掉（unstage），重新放回工作区：1git reset HEAD read 然后再丢弃工作区中的修改：1git checkout -- read git reset命令既可以回退版本，也可以把暂存区的修改回退到工作区。当我们用HEAD时，表示最新的版本 删除文件如果把工作区中的文件删除了，那么工作区和版本库就不一致，git status 命令会立刻告诉你哪些文件被删除了现在有两个选择 一是确实要从版本库中删除该文件，那就用命令删掉，并且提交： 12git rm readgit commit -m &quot;delete&quot; 另一种情况是删错了，因为版本库里还有呢，所以可以很轻松地把误删的文件恢复到最新版本： 1git checkout -- read git checkout 其实是用版本库里的版本替换工作区的版本，无论工作区是修改还是删除，都可以“一键还原” 远程仓库那么学会了Git的基本操作之后，对于分布式管理我们还需要有一个远程仓库供大家一起共同开发，好在有一个全世界最大最神奇的同性交友网—— Github那么在使用Github之前呢，我们需要设置一下与Github的SSH通讯：1. 创建SSH Key（已有.ssh目录的可以略过）1ssh-keygen -t rsa -C &quot;youremail@example.com&quot; 你需要把邮件地址换成你自己的邮件地址，然后一路回车，使用默认值即可，由于这个Key也不是用于军事目的，所以也无需设置密码如果一切顺利的话，可以在用户主目录里找到 .ssh 目录，里面有 id_rsa 和 id_rsa.pub 两个文件，这两个就是SSH Key的秘钥对，id_rsa 是私钥，不能泄露出去，id_rsa.pub 是公钥，可以放心地告诉任何人 2. 登陆GitHub，打开“Account settings”，“SSH Keys”页面，然后，点“Add SSH Key”，填上任意Title，在Key文本框里粘贴id_rsa.pub文件的内容，最后点“Add Key” 添加远程仓库首先到Github创建一个仓库然后与本地关联：1git remote add origin git@github.com:your-name/repo-name.git 远程库的名字就是origin，这是Git默认的叫法，也可以改成别的，但是origin这个名字一看就知道是远程库 下一步，就可以把本地库的所有内容推送到远程库上：1git push -u origin master 把本地库的内容推送到远程，用 git push 命令，实际上是把当前分支 master 推送到远程由于远程库是空的，我们第一次推送 master 分支时，加上了 -u 参数，Git不但会把本地的 master 分支内容推送的远程新的 master 分支，还会把本地的 master 分支和远程的 master 分支关联起来，在以后的推送或者拉取时就可以简化命令 此后的推送都可以使用：1git push 从远程仓库克隆1git git@github.com:your-name/repo-name.git 标签管理查看tag列出所有tag：1git tag 这样列出的tag是按字母排序的，和创建时间没关系。如果只是想查看某些tag的话，可以加限定：1git tag -l v1.* 这样就只会列出1.几的版本。 创建tag创建轻量级tag：1git tag 1.0.1 这样创建的tag没有附带其他信息，与之相应的是带信息的tag,-m后面带的就是注释信息，这样在日后查看的时候会很有用，这种是普通tag，还有一种有签名的tag：1git tag -a 1.0.1 -m &apos;first version&apos; 除了可以为当前的进度添加tag，我们还可以为以前的commit添加tag：首先查看以前的commit1git log --oneline 假如有这样一个commit：8a5cbc2 updated readme这样为他添加tag1git tag -a v1.1 8a5cbc2 删除tag很简单，知道tag名称后：1git tag -d v1.0 删除远程分支：1git push origin --delete tag &lt;tagname&gt; 共享tag我们在执行git push的时候，tag是不会上传到服务器的，比如现在的github，创建tag后git push，在github网页上是看不到tag的，为了共享这些tag，你必须这样：1git push origin --tags 分支管理分支相当与平行宇宙，互不干扰，哪天合并了就拥有了所有平行宇宙的特性 创建与合并分支 每次提交，Git都把它们串成一条时间线，这条时间线就是一个分支。截止到目前，只有一条时间线，在Git里，这个分支叫主分支，即 master 分支 一开始的时候，master 分支是一条线，Git用 master 指向最新的提交，再用 HEAD 指向 master ，就能确定当前分支，以及当前分支的提交点 当我们创建新的分支，例如 dev 时，Git新建了一个指针叫 dev ，指向 master 相同的提交，再把 HEAD 指向 dev ，就表示当前分支在 dev 上 Git创建一个分支很快，因为除了增加一个 dev 指针，改改 HEAD 的指向，工作区的文件都没有任何变化 当 HEAD 指向 dev ，对工作区的修改和提交就是针对 dev 分支了，比如新提交一次后， dev 指针往前移动一步，而 master 指针不变 查看分支：git branch创建分支：git branch &lt;name&gt;切换分支：git checkout &lt;name&gt;创建+切换分支：git checkout -b &lt;name&gt;合并某分支到当前分支：git merge &lt;name&gt;删除分支：git branch -d &lt;name&gt; 解决冲突合并分支并不是每次都不会出问题，如不同的分支对同一个文件同一行都被修改过，就会出现以下情况那么再次合并有可能会冲突123456789101112131415➜ repo git:(master) git merge feature1 自动合并 read冲突（内容）：合并冲突于 read自动合并失败，修正冲突然后提交修正的结果。➜ repo git:(master) ✗ git status 位于分支 master您有尚未合并的路径。 （解决冲突并运行 &quot;git commit&quot;）未合并的路径： （使用 &quot;git add &lt;文件&gt;...&quot; 标记解决方案） 双方修改： read修改尚未加入提交（使用 &quot;git add&quot; 和/或 &quot;git commit -a&quot;） 这种情况必须手动解决然后再次 git add .，git commit -m &quot;commit&quot;，打开文件可看到123456Git is a version control&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEADCreating a new branch is quick &amp; simple.=======Creating a new branch is quick AND simple.&gt;&gt;&gt;&gt;&gt;&gt;&gt; feature1 Git用&lt;&lt;&lt;&lt;&lt;&lt;&lt;，=======，&gt;&gt;&gt;&gt;&gt;&gt;&gt;标记出不同分支的内容，那么经过合意，不好意思，大师兄说了，在座的各位都是垃圾，于是改成1Git,too fast too simple 再提交1234➜ repo git:(master) ✗ git add read ➜ repo git:(master) ✗ git commit -m &quot;conflict fixed&quot;[master 8933f88] conflict fixed➜ repo git:(master) ok了，再次 add 和 commit ，现在 master 分支和feature1分支变成了这样 多PC协同开发当你从远程仓库克隆时，实际上Git自动把本地的 master 分支和远程的 master 分支对应起来了，并且，远程仓库的默认名称是 origin 查看远程库的信息：查看简单信息：git remote查看详细信息：git remote -v查看远程仓库分支：git branch -r查看本地分支与远程分支的对应关系：git branch -vv 推送分支123git push origin &lt;branch&gt; git push -u origin &lt;branch&gt; # 第一次推送加-u可以把当前分支与远程分支关联起来 克隆分支并关联1234git clone git@github.com:youName/program.git # 默认克隆master分支到当前目录（包含分支文件目录）git clone -b &lt;branch&gt; git@github.com:youName/program.git ./# 克隆指定分支到指定文件目录下（不包含分支文件目录） 创建远程 origin 的 dev 分支到本地1git checkout -b &lt;branch&gt; origin/&lt;branch&gt; 关联本地分支与远程仓库分支1git branch --set-upstream &lt;branch&gt; origin/&lt;branch&gt; 同步更新Github Fork的项目1、fork项目并clone到本地 2、进入项目根目录 3、添加remote指向上游仓库 1git remote add upstream https://github.com/ORIGINAL_OWNER/ORIGINAL_REPOSITORY.git 4、把上游项目fetch下来 1git fetch upstream 5、merge到master 12git checkout mastergit merge upstream/master 6、push到自己的远程仓库，搞定～ 最后Git真的异常强大，但命令繁多，需多加练习 参考：廖雪峰老师的教程 附命令图一张： 1.集中式版本管理系统之一 ↩2.一个商业的版本控制系统 ↩]]></content>
      <categories>
        <category>Git/Github</category>
      </categories>
      <tags>
        <tag>Github</tag>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于Hexo+Github+Coding搭建个人博客——基础篇(从菜鸟到放弃)]]></title>
    <url>%2F2017%2Fbuild-blog-hexo-base%2F</url>
    <content type="text"><![CDATA[前言搭建此博客的动机以及好处在此就不多谈了，之前已经表达过，详情请看Start My Blog Trip — Power By Hexo记录一下搭建的基本过程以及遇到的一些问题，仅供参考= =废话不多说，进入主题Hexo博客搭建的基础大致流程为：安装Node.js →安装Git → 安装Hexo → 安装主题 → 本地测试运行 → 注册给github与coding并创建pages仓库 → 部署这是博主的系统环境与版本:OS: Ubuntu16.04Node.js: 6.2.0Npm: 3.8.9Hexo: 3.2.2主题NexT: 5.1.0Git: 2.7.4对于使用windows的童鞋，可参考文章末尾处的参考链接，步骤大同小异以下提到的站点配置文件指的是博客文件根目录下的 _config.yml，主题配置文件是主题文件夹下的 _config.yml，童鞋们不要混淆了安装Node.jsNode.js的安装有很多种方式，Hexo的官方文档 建议是用nvm 安装，但好多人都说不行，所以找了另外两种方式安装windows的童鞋可参考安装Node.js方法一：二进制包直接解压配置在node.js的官网 下载二进制包来安装的，下载过后，解压，设置软链接，要不然每次都执行命令都要加上路径，好麻烦123sudo ln -s /home/ybd/Data/soft/application/node-v6.2.0-linux-x64/bin/node /usr/local/bin/nodesudo ln -s /home/ybd/Data/soft/application/node-v6.2.0-linux-x64/bin/npm /usr/local/bin/npm 注意！源文件要写绝对路径，否则会报错：链接层数过多。也可以直接将node可执行文件拷贝到 /usr/local/bin 目录下。 接下来就可以查看是否成功配置了12node -vnpm -v 方法二：换源下载安装 6.x 版本：12curl -sL https://deb.nodesource.com/setup_6.x | sudo -E bash -sudo apt-get install -y nodejs 安装 8.x 版本：12curl -sL https://deb.nodesource.com/setup_8.x | sudo -E bash -sudo apt-get install -y nodejs npm 更换淘宝镜像：1npm config set registry https://registry.npm.taobao.org/ 方法三：源文件编译安装在安装前，首先需要配置安g++编译器1sudo apt-get install build-essential 去官网 下载源代码，选择最后一项，Source Code解压到某一目录，然后进入此目录,依次执行以下3条命令123./configuremakesudo make install 执行以下命令，检测是否已经装好node.js1node -v npm安装，一条命令即可解决1curl http://npmjs.org/install.sh | sudo sh 博主安装Node.js遇到的问题就是多次安装了不同版本的Node.js，有的是安装在用户变量上，有的是系统变量，所以每次用的时候都要切换到root用户，就算赋权 sudo chmod 777 file 都没有用，所以折腾了很久才把Node.js完全卸载，再重新安装 安装GitUbuntu系统下安装Git非常简单，只需一条命令：1sudo apt-get install git windows下就直接到Git官网 下载安装即可 然后终端执行 git --version 查看是否安装成功 安装Hexo 什么是 Hexo？Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。 所有以上必备的应用程序安装完成后，无论是在哪个操作系统，之后的操作都一样 安装Hexo的非常简单，只要一条命令，前提是安装好Node.js与Git1npm install -g hexo-cli 如果npm安装hexo失败，则很有可能是权限问题，或者npm与node的版本不兼容（很少出现） 如果顺利安装完成，理论上Hexo已经安装完成，但在Ubuntu系统中，比较坑的地方就是 hexo 命令居然放在了Node.js安装目录的 bin 文件夹下，不能快捷地在终端把命令敲出来，所以还是老规矩，软链接走起1sudo ln -s /home/ybd/data/application/node-v7.4.0-linux-x64/bin/hexo /usr/local/bin/hexo 到此，Hexo的安装已基本完成，可以先试一下Hello World。 解决Hexo命令fs.SyncWriteStream问题 nodejs版本更新到8.0之后，运行hexo相关命令总会出现这么一行鬼东西：(node:538) [DEP0061] DeprecationWarning: fs.SyncWriteStream is deprecated.虽然不怎么影响大局，当对于强迫症来说是一个噩梦！ nodejs从8.0开始已经弃用了fs.SyncWriteStream方法，但是某些插件里面还是用到这个方法。查看Hexo项目也有这个一条issue，在hexo项目中其中有一个hexo-fs的插件调用了这个方法，所以需要更新hexo-fs插件，更新方法如下：1npm install hexo-fs --save 当然还有一些插件： 123npm install hexo-deployer-git@0.3.1 --savenpm install hexo-renderer-ejs@0.3.1 --savenpm install hexo-server@0.2.2 --save But，问题木有得到解决啊！hexo命令有个-debug参数，运行命令的时候加上这个参数，可以定位问题： 123456789101112131415161718192021222324252627282930313233ybd@15ffab36a16c:~/blog$ hexo clean --debug03:01:16.464 DEBUG Hexo version: 3.3.903:01:16.467 DEBUG Working directory: ~/blog/03:01:16.539 DEBUG Config loaded: ~/blog/_config.yml03:01:16.613 DEBUG Plugin loaded: hexo-admin-qiniu(node:538) [DEP0061] DeprecationWarning: fs.SyncWriteStream is deprecated.03:01:16.655 DEBUG Plugin loaded: hexo-algolia03:01:16.657 DEBUG Plugin loaded: hexo-baidu-url-submit03:01:16.668 DEBUG Plugin loaded: hexo-deployer-git03:01:16.672 DEBUG Plugin loaded: hexo-fs03:01:16.674 DEBUG Plugin loaded: hexo-generator-archive03:01:16.677 DEBUG Plugin loaded: hexo-generator-baidu-sitemap03:01:16.678 DEBUG Plugin loaded: hexo-generator-category03:01:16.680 DEBUG Plugin loaded: hexo-generator-feed03:01:16.681 DEBUG Plugin loaded: hexo-generator-index03:01:16.682 DEBUG Plugin loaded: hexo-generator-tag03:01:16.826 DEBUG Plugin loaded: hexo-inject03:01:16.828 DEBUG Plugin loaded: hexo-renderer-ejs03:01:16.829 DEBUG Plugin loaded: hexo-generator-sitemap03:01:16.834 DEBUG Plugin loaded: hexo-renderer-marked03:01:16.836 DEBUG Plugin loaded: hexo-renderer-stylus03:01:16.881 DEBUG Plugin loaded: hexo-server03:01:16.912 DEBUG Plugin loaded: hexo-wordcount03:01:16.943 DEBUG Plugin loaded: hexo-reference03:01:16.946 DEBUG Script loaded: themes/next/scripts/merge-configs.js03:01:16.947 DEBUG Script loaded: themes/next/scripts/tags/button.js03:01:16.947 DEBUG Script loaded: themes/next/scripts/tags/center-quote.js03:01:16.947 DEBUG Script loaded: themes/next/scripts/tags/full-image.js03:01:16.947 DEBUG Script loaded: themes/next/scripts/tags/note.js03:01:16.948 DEBUG Script loaded: themes/next/scripts/tags/group-pictures.js03:01:16.949 DEBUG [hexo-inject] firing inject_ready03:01:16.951 INFO Deleted database.03:01:16.956 DEBUG Database saved 发现问题在hexo-admin-qiniu这个插件=.= 貌似也没怎么用这个插件，那么就删掉吧：1nmp uninstall hexo-admin-qiniu --save 那个报错终于消失啦～～～ 本地启动Hello World与Hexo简单使用初始化随便建一个文件夹，名字随便取，博主取其名为blog，cd 到文件夹里，先安装必要的文件，执行以下命令：12hexo init # hexo会在目标文件夹建立网站所需要的所有文件npm install # 安装依赖包 本地启动有了必要的各种配置文件之后就可以在本地预览效果了12hexo g # 等同于hexo generate，生成静态文件hexo s # 等同于hexo server，在本地服务器运行 之后打开浏览器并输入IP地址 http://localhost:4000/ 查看，效果如下 新建文章与页面12hexo new &quot;title&quot; # 生成新文章：\source\_posts\title.mdhexo new page &quot;title&quot; # 生成新的页面，后面可在主题配置文件中配置页面 生成文章或页面的模板放在博客文件夹根目录下的 scaffolds/ 文件夹里面，文章对应的是 post.md ，页面对应的是page.md，草稿的是draft.md 编辑文章打开新建的文章\source\_posts\postName.md，其中postName是hexo new &quot;title&quot;中的title12345678910title: Start My Blog Trip — Power By Hexo # 文章页面上的显示名称，可以任意修改，不会出现在URL中date: 2017-01-10 23:49:28 # 文章生成时间，一般不改categories: diary # 文章分类目录，多个分类使用[a,b,c]这种格式tags: [Hexo,diary] # 文章标签---#这里开始使用markdown格式输入你的正文。&lt;!--more--&gt; #more标签以下的内容要点击“阅读全文”才能看见 插入图片插入图片有三种方式 方式一在博客根目录的 source 文件夹下新建一个 img 文件夹专门存放图片，在博文中引用的图片路径为 /img/图片名.后缀 1![](图片路径) 方式二对于那些想要更有规律地提供图片和其他资源以及想要将他们的资源分布在各个文章上的人来说，Hexo也提供了更组织化的方式来管理资源，将站点配置文件中的 post_asset_folder 选项设为 true 来打开文章资源文件夹 1post_asset_folder: true 然后再博文中通过相对路径引用1&#123;% asset_img 图片文件名 %&#125; 方式三使用七牛云储存，因为Github跟Coding项目容量有限，而且Github的主机在国外，访问速度较慢，把图片放在国内的图床上是个更好的选择，免费用户实名审核之后，新建空间，专门用来放置博客上引用的资源，进入空间后点击「内容管理」，再点击「上传」 上传完成之后点击关闭回到管理页面，选中刚上传的图片，最右边的操作点击复制链接即可然后在博文中通过地址引用1![](图片地址如：http://ojoba1c98.bkt.clouddn.com/img/build-hexo/copyUrl.png) 简单的命令总结一下简单的使用命令1234567hexo init [folder] # 初始化一个网站。如果没有设置 folder ，Hexo 默认在目前的文件夹建立网站hexo new [layout] &lt;title&gt; # 新建一篇文章。如果没有设置 layout 的话，默认使用 _config.yml 中的 default_layout 参数代替。如果标题包含空格的话，请使用引号括起来hexo version # 查看版本hexo clean # 清除缓存文件 (db.json) 和已生成的静态文件 (public)hexo g # 等于hexo generate # 生成静态文件hexo s # 等于hexo server # 本地预览hexo d # 等于hexo deploy # 部署，可与hexo g合并为 hexo d -g 安装主题（以NexT为例）更多主题请看知乎专栏 复制主题Hexo 安装主题的方式非常简单，只需要将主题文件拷贝至站点目录的 themes 目录下， 然后修改下配置文件即可在这我们使用git克隆最新版12cd your-hexo-sitegit clone https://github.com/iissnan/hexo-theme-next themes/next 启用主题打开站点配置文件， 找到 theme 字段，并将其值更改为 next1theme: next 然后 hexo s 即可预览主题效果 更换主题外观NexT有三个外观，博主用的是 Muse，直接更改主题配置文件的 scheme 参数即可，如果显示的是繁体中文，那么站点配置文件中的 language: zh-CN123scheme: Muse#scheme: Mist#scheme: Pisces 在次执行 hexo clean 和 heox s 可预览效果大部分的设定都能在NexT的官方文档 里面找到，如侧栏、头像、打赏、评论等等，在此就不多讲了，照着文档走就行了，接下只是个性定制的问题 注册Github和Coding并分别创建Pages在本地运行没有问题的话，那么可以部署到外网去，在此之前，先得有服务器让你的项目可以托管，那么Github Page与Coding Page就是个很好的东西，它们可以让我们访问静态文件，而Hexo生成的恰恰是静态文件具体请查看 Coding Page 、 Github Page 那为什么要注册两个网站呢？因为Github是国外的服务器，访问速度比较慢，而Coding是国内的，速度相对来说比较快，在后面DNS解析的时候可以把国内的解析到Coding，国外的解析到Github，完美 GitHub注册Github帐号进入Github 首页进行注册，用户名、邮箱和密码之后都需要用到，自己记好，不知道怎么注册的童鞋去问问度娘 创建Repository(Github Pages)Repository相当于一个仓库，用来放置你的代码文件。首先，登陆进入Github，选择首页中的 New repository 按钮创建时，只需要填写Repository name即可，可以顺便创建README文件，就是红色那个钩，当然这个名字的格式必须为{user_name}.github.io，其中{user_name}必须与你的用户名一样，这是github pages的特殊命名规范，如下图请忽视红色警告，那是因为博主已经有了一个pages项目 Coding注册Coding帐号国内的网站，绝大部分都是中文的，注册什么的就不说了,进入Coding 滚键盘就是了= = 创建项目(Coding Pages)Coding Pages请看 Coding Pages注册之后进入主页，点击项目，点击+，项目名为你的用户名查看Pages 服务是否开启：点击项目 -&gt; 代码 -&gt; Pages 服务，若没有开启则点开启 配置SSH与Git那么我们有了两个免费的服务器之后，就要绑定个人电脑与它们联系，那就是SSH与Git绑定之后我们每次部署项目就不用输入帐号和密码 生成SSH Key1ssh-keygen -t rsa -C your_email@youremail.com 后面的 your_email@youremail.com 改为你的邮箱，之后会要求确认路径和输入密码，我们这使用默认的一路回车就行。成功的话会在~/下生成 .ssh 文件夹，进去，打开 id_rsa.pub，复制里面的key，粗暴点就是 Ctrl+a 然后 Ctrl+c 添加SSH Key首先是Github，登录Github，右上角 头像 -&gt; Settings —&gt; SSH nd GPG keys —&gt; New SSH key 。把公钥粘贴到key中，填好title并点击 Add SSH key 至于Coding，登录进入主页，点击 账户 —&gt; SSH公钥 —&gt; 输入key再点击 添加 验证成功与否验证github1ssh -T git@github.com 如果是第一次的会提示是否continue，输入yes就会看到：You’ve successfully authenticated, but GitHub does not provide shell access 。这就表示已成功连上github!之前博主就是因为没有输入yes，导致几次失败，粗心地一路回车= =验证coding1ssh -T git@git.coding.net 同上，按yes接下来我们要做的就是把本地仓库传到github上去，在此之前还需要设置username和email，因为github每次commit都会记录他们12git config --global user.name your namegit config --global user.email your_email@youremail.com 关于git可参考：史上最全github使用方法：github入门到精通Git学习笔记 部署到Github与Coding在此之前，先安装Git部署插件1npm install hexo-deployer-git --save 打开站点配置文件，拉到底部，修改部署配置：1234567# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repo: github: git@github.com:masteranthoneyd/masteranthoneyd.github.io.git,master coding: git@git.coding.net:ookamiantd/ookamiantd.git,master 注意冒号后面是网站对应的用户名，接着就是/，然后再是你的项目名加上 .git,master保存后终端执行123hexo cleanhexo ghexo d 稍等片刻，可能会由于环境、网络等原因，部署的时间会有偏差，有的人快有的慢部署完成后可在浏览器输入 yourName.github.io 或者 yourName.coding.me 都可以浏览到一个属于自己的博客了 ～ 总结最后用拙劣的语言总结一下博主搭建Hexo博客的体会，六个字：简洁但，不简单。再六个字，正如NexT官方说的：精于心，简于形= =貌似这个博客也不怎么简洁，有点花俏，装X嫌疑但无论怎样，折腾这个博客让我受益匪浅，正如之前听到的一句名言，忘了谁说的：不努力试一把，又怎么会知道绝望…好像很有道理，绝望中寻找光芒，绝处逢生…嘿嘿嘿 参考 使用Hexo搭建个人博客(基于hexo3.0) Github Pages个人博客，从Octopress转向HexoHexo 3.1.1 静态博客搭建指南Hexo官方文档NexT官方文档]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Node.js</tag>
        <tag>Github</tag>
        <tag>Coding</tag>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu主题美化、个性化设置与常用软件]]></title>
    <url>%2F2017%2Fubuntu-todo-after-install%2F</url>
    <content type="text"><![CDATA[前言鉴于 Ubuntu 18.04 LTS 版本即将到来，本篇的16.04也将升级到18.04 GNOME 版本可能会存在兼容问题，本篇将持续更新系统清理篇系统更新安装完系统之后，需要更新一些补丁。Ctrl+Alt+T调出终端，执行一下代码：1sudo apt update &amp;&amp; sudo apt upgrade -y 卸载libreOffice1sudo apt remove --purge libreoffice-common 删除Amazon的链接1sudo apt remove --purge ubuntu-web-launchers 删除不常用的软件12sudo apt remove --purge thunderbird totem rhythmbox transmission gnome-mines gnome-mahjongg gnome-sudokusudo apt autoremove 科学上网篇方式一：下载Lantern如果为了更方便地科学上网，建议下载Lantern （免费版限流）可在github（免翻墙）找到开源项目，拉到下面README下载对应版本 12sudo dpkg -i lantern.debsudo chmod -R 777 /usr/bin/lantern 方式二：自搭建ShadowsocksAccess Blocked Sites(翻墙):VPS自搭建ShadowSocks与加速 主题美化篇16.04 Unity 桌面环境安装unity-tweak-tool调整 Unity 桌面环境，还是推荐使用Unity Tweak Tool，这是一个非常好用的 Unity 图形化管理工具，可以修改工作区数量、热区等。 1sudo apt install unity-tweak-tool 安装Flatabulous主题Flatabulous主题是一款Ubuntu下扁平化主题，也是我试过众多主题中最喜欢的一个！最终效果如上述图所示。 执行以下命令安装Flatabulous主题： 123sudo add-apt-repository ppa:noobslab/themes sudo apt update sudo apt install flatabulous-theme 该主题有配套的图标，安装方式如下：123sudo add-apt-repository ppa:noobslab/icons sudo apt update sudo apt install ultra-flat-icons 安装完成后，打开unity-tweak-tool软件，修改主题和图标 进入Theme，修改为Flatabulous： 在此界面下进入Icons栏，修改为Ultra-flat: 17.10以后的 GNOME 桌面环境安装原生 GNOME 环境1sudo apt install -y gnome-session gnome-weather gnome-photos gnome-music gnome-backgrounds 恢复原生 gdm 登录界面： 1sudo update-alternatives --config gdm3.css 然后选择第二个 gnome-shell.css ， 输入 1 主题选择一款叫 Arc-Theme 的主题，包括了 GNOME Shell 主题和 GTK 主题。安装前需要以下依赖包（直接使用 sudo apt install 安装即可）： autoconf automake pkg-config libgtk-3-dev git 从 Github 上获取项目1git clone https://github.com/horst3180/arc-theme --depth 1 &amp;&amp; cd arc-theme 构建项目并安装12./autogen.sh --prefix=/usrsudo make install 其它选项123456789101112--disable-transparency 在 GTK3 主题中禁用透明度--disable-light 禁用 Arc Light--disable-darker 禁用 Arc Darker--disable-dark 禁用 Arc Dark--disable-cinnamon 禁用 Cinnamon--disable-gnome-shell 禁用 GNOME Shell--disable-gtk2 禁用 GTK2--disable-gtk3 禁用 GTK3--disable-metacity 禁用 Metacity--disable-unity 禁用 Unity--disable-xfwm 禁用 XFWM--with-gnome=&lt;version&gt; 为特定的 GNOME 版本 (3.14, 3.16, 3.18, 3.20, 3.22) 构建主题 选择主题安装完成后打开自带的 GNOME Tweak Tool 工具选择对应的 Arc 主题即可。 如果没有这个工具那就： 1sudo apt install gnome-tweak-tool gnome-shell-extensions 注意 :对于高分屏，可能使用 Arc-Theme 显示 GNOME Shell 的字体过小，可通过修改 /usr/share/themes/[对应 Arc 主题]/gnome-shell/gnome-shell.css 修改 stage 的 font-size 。 项目地址 ，其他热门主题 Numix 、 Paper IconNumix123sudo add-apt-repository ppa:numix/ppasudo apt updatesudo apt install numix-icon-theme 项目地址 Paper123456sudo add-apt-repository ppa:snwh/pulpsudo apt updatesudo apt install paper-icon-theme# 同时也可以安装 GTK 和 Cursor 主题sudo apt install paper-gtk-themesudo apt install paper-cursor-theme 项目地址 Papirus123sudo add-apt-repository ppa:papirus/papirussudo apt updatesudo apt install papirus-icon-theme 或者下载最新的 deb 安装包项目地址 GNOME Shell Extensions先上图… 下安装一下Chrome支持： 1sudo apt install chrome-gnome-shell Weather 天气插件 System Monitor 系统监视器 这个先要安装依赖： 1sudo apt install gir1.2-gtop-2.0 libgtop2-dev Topicons Plus 任务图标栏 任务图标栏使用默认的图标，如何让他使用自定义的图标主题呢？比如使用 Papirus ，它支持 hardcode-tray 脚本来实现 安装 hardcode-tray 123sudo add-apt-repository ppa:andreas-angerer89/sni-qt-patchedsudo apt updatesudo apt install sni-qt sni-qt:i386 hardcode-tray inkscape 转换图标 1hardcode-tray --conversion-tool Inkscape Nvidia GPU Temperature Indicator 显卡温度指示器 Dash To Dock 可定制的 Dock 中文输入法可更换成ibus-pinyin: 1234sudo apt remove --purge ibus-sunpinyinsudo apt install ibus-pinyinsudo ibus-daemon -d -x -r现在可以在 Settings &gt; Region &amp; Language &gt; Input sources 中添加 pinyin 输入法 Fix Curl装了GNOME后，发现没有curl…对，下载源码安装：https://curl.haxx.se/download.html装好之后又尴尬了，不支持https！！！一番查阅后，已解决：step1，安装openssl： 12sudo apt install opensslsudo apt-get install libssl-dev 安装默认路径：/usr/lib/ssl step2，进入解压的curl源码包： 123./configure --with-ssl=/usr/lib/sslmakesudo make install 搞定～ 安装Oh-My-Zsh终端采用zsh和oh-my-zsh，既美观又简单易用，主要是能提高你的逼格！！！ 首先，安装zsh： 1sudo apt-get install zsh 接下来我们需要下载 oh-my-zsh 项目来帮我们配置 zsh，采用wget安装(需要先安装git)12sudo apt-get install gitwget https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh -O - | sh 查看shells1cat /etc/shells 所以这时的zsh 基本已经配置完成,你需要一行命令就可以切换到 zsh 模式，终端下输入以下命令1chsh -s /bin/zsh 或者一键安装…1sh -c &quot;$(wget https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh -O -)&quot; 最后，修改以下配色，会让你的终端样式看起来更舒服，在终端任意地方右键，进入配置文件(profile)-&gt;外观配置(profile Preferences)，弹出如下界面，进入colors一栏: 其中，文字和背景采用系统主题，透明度设为10%，下面的palette样式采用Tango，这样一通设置后，效果如下： 配色： 文本颜色：#00FF00 粗体字颜色：与文本颜色相同 背景颜色：#002B36 主题： 在~/.oh-my-zsh/themes中查看主题。 然后编辑~/.zshrc，找到ZSH_THEME修改为你想要的主题即可。 安装字体Ubuntu自带的字体不太好看，所以采用文泉译微米黑字体替代，效果会比较好，毕竟是国产字体！1sudo apt-get install fonts-wqy-microhei 然后通过unity-tweak-tool来替换字体 到此，主题已经比较桑心悦目了，接下来推荐一些常用的软件，提高你的工作效率！ 软件篇Wechat for Ubuntu下载地址：https://github.com/geeeeeeeeek/electronic-wechat/releases博主的百度盘 (密码: 9bpi) (提取路径：UbuntuTools -&gt; wechat4Ubuntu) 下载最新版本，解压后打开目录里面的electronic-wechat，然后创建个软连接换个图标拉倒桌面就可以了 QQ轻聊版虽然不太想安装QQ，但工作时候团队交流需要，QQ国际版又太难看，所以装个Deepin的轻聊版。工具包下载：博主的百度盘 (密码: 9bpi) (提取路径：UbuntuTools&gt;qq4Ubuntu) 内含文件： crossover_16.0.0-1.deb 、 crossover16crack.tar.gz 和 apps.com.qq.im.light_7.9.14308deepin0_i386.deb crossover安装与破解这个轻聊版是Deepin的作品，要在Ubuntu上使用，就要安装crossover，很不幸这玩意是收费的，很幸运的是这玩意是可以破解的。1、安装的工具包下载下来解压后会有三个文件，首先先安装crossover_16.0.0-1.deb，缺少依赖就执行一下sudo apt -f install，安装完后先不要打开crossover。2、在命令行输入sudo nautilus打开一个root权限的文件管理器3、把破解文件 (crossover16crack-&gt;winewrapper.exe.so) 替换路径: /opt/cxoffice/lib/wine下的winewrapper.exe.so文件。提示已有文件，点“替换”破解完成。 Deepin QQ轻聊版1、用归档管理器打开apps.com.qq.im.light_7.9.14308deepin0_i386.deb2、点开 data.tar.xz 找到 ./opt/cxoffice/support3、把 apps.com.qq.im.light 这个文件夹提取出来4、在命令行输入sudo nautilus打开一个root权限的文件管理器5、然后将这个文件夹复制到系统的 /opt/cxoffice/support 下6、然后打开 crossover ，发现多了一个容器 ，点击图标即可运行QQ轻聊版7、如果运行后出现乱码，把 Windows 系统下的 %systemroot%\fonts\simsun.ttf (simsun.ttc) 复制到容器的对应文件夹就可以 搜狗输入法安装与崩溃处理安装点击下载 Sogou For Linux -&gt; Download Now然后dpkg -i 就可以安装了，中间如有冲突就sudo apt -f install进行修复。 搜狗输入法不能输入中文解决（linux下常见软件崩溃问题解决方案）先关闭fcitx：12killall fcitxkillall sogou-qinpanel 然后删除搜狗配置文件，ubuntu下搜狗的配置文件在 ~/.config下的3个文件夹里：SogouPY、SogouPY.users、sogou-qimpanel删除这3个文件夹，然后重启搜狗：1fcitx 解决！ 版本控制系统GUI-SmartGit123sudo add-apt-repository ppa:eugenesan/ppasudo apt updatesudo apt install smartgithg 卸载：1sudo apt remove smartgithg Typora(Markdown编辑器)官方安装方法如下：1234567# optional, but recommendedsudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys BA300B7755AFCFAE# add Typora&apos;s repositorysudo add-apt-repository &apos;deb http://typora.io linux/&apos;sudo apt update# install typorasudo apt install typora GIF制作软件 Peek123sudo add-apt-repository ppa:peek-developers/stablesudo apt updatesudo apt install peek 终端执行peek即可运行 StarUml这个一款绘图工具下载：http://staruml.io/download安装依赖：https://launchpad.net/ubuntu/trusty/amd64/libgcrypt11/1.5.3-2ubuntu4.5然后dpkg安装就好了，如果还有依赖直接apt install -f修复一下就好。安装好之后修改LicenseManagerDomain.js查找：1dpkg -S staruml | grep LicenseManagerDomain.js 修改：1sudo gedit /opt/staruml/www/license/node/LicenseManagerDomain.js 如下：12345678910111213141516171819202122232425262728293031323334(function () &#123; &quot;use strict&quot;; var NodeRSA = require(&apos;node-rsa&apos;); function validate(PK, name, product, licenseKey) &#123; var pk, decrypted; return &#123; name: &quot;yangbingdong&quot;, product: &quot;StarUML&quot;, licenseType: &quot;vip&quot;, quantity: &quot;yangbingdong.com&quot;, licenseKey: &quot;later equals never!&quot; &#125;; try &#123; pk = new NodeRSA(PK); decrypted = pk.decrypt(licenseKey, &apos;utf8&apos;); &#125; catch (err) &#123; return false; &#125; var terms = decrypted.trim().split(&quot;\n&quot;); if (terms[0] === name &amp;&amp; terms[1] === product) &#123; return &#123; name: name, product: product, licenseType: terms[2], quantity: terms[3], licenseKey: licenseKey &#125;; &#125; else &#123; return false; &#125; &#125; ...... 改完打开StarUml -&gt; Help -&gt; Enter License，不是输入任何东西直接确定 虚拟机1sudo apt-get install virtualbox wiznote(为知笔记)一款linux下强大的笔记软件 123sudo add-apt-repository ppa:wiznote-team sudo apt update sudo apt install wiznote Vim系统并没有集成vim，可以执行以下代码安装：1sudo apt install vim Wps去wps官网 下载wps for Linux。先不要执行dpkg -i 去执行安装。这个地方有个问题，就是ubuntu 16 版本不支持32位的支持库，所以需要安装一下支持库。32位的支持库名为：ia32-libs安装的时候会提示有替代包，需要安装替代包。1sudo apt install lib32ncurses5 lib32z1 还是不要执行dpkg -i ，因为即使现在安装还是会缺少一个依赖。这个依赖是libpng-12.0。不过这个在默认的apt 仓库里没有。所以需要手动下载一下。下载地址：https://packages.debian.org/zh-cn/wheezy/amd64/libpng12-0/download1sudo dpkg -i libpng12-0_1.2.49-1+deb7u2_amd64.deb 最后：1sudo dpkg -i wps-office_10.1.0.5672~a21_amd64.deb Chrome到chrome官网 下载linux版的chrome。不能翻墙的小朋友可以到博主的百度盘 (密码: 9bpi)1sudo dpkg -i google-chrome-stable_current_amd64.deb Xmind一款思维导图软件，再xmind官网下载deb安装包1sudo dpkg -i xmind-7.5-linux_amd64.deb ShutterUbuntu下很强大的一款截图软件1sudo apt install shutter 设置快捷键：打开系统设置 -&gt; 键盘 -&gt; 快捷键 -&gt; 自定义快捷键 -&gt; 点击&quot; + &quot;名字随便起，命令：shutter -s点击确定，再点禁用，键盘按下ctrl+alt+a，完成设置 系统清理软件 BleachBit123sudo add-apt-repository ppa:n-muench/programs-ppasudo apt update sudo apt install bleachbit 多协议下载器 Aria2一般在Linux环境中下载东西都是比较不友好的，不支持多种协议，方式单一，但这款Aria2就是为了解决多协议问题而诞生的，配合UI界面可以很方便地随心所欲地下载。 搭建 Aria2 以及 AriaNg Web UI 博主选择使用Docker 参考 aria2-ariang-docker 以及 aria2-ariang-x-docker-compose 配置aria2.conf这个文件是从作者地 Github下载下来的，主要加了代理，而这个代理是 sock5 通过 privoxy 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566#所有协议代理all-proxy=http://192.168.6.113:8118#用户名#rpc-user=user#密码#rpc-passwd=passwd#上面的认证方式不建议使用,建议使用下面的token方式#设置加密的密钥#rpc-secret=token#允许rpcenable-rpc=true#允许所有来源, web界面跨域权限需要rpc-allow-origin-all=true#允许外部访问，false的话只监听本地端口rpc-listen-all=true#RPC端口, 仅当默认端口被占用时修改#rpc-listen-port=6800#最大同时下载数(任务数), 路由建议值: 3max-concurrent-downloads=5#断点续传continue=true#同服务器连接数max-connection-per-server=5#最小文件分片大小, 下载线程数上限取决于能分出多少片, 对于小文件重要min-split-size=10M#单文件最大线程数, 路由建议值: 5split=10#下载速度限制max-overall-download-limit=0#单文件速度限制max-download-limit=0#上传速度限制max-overall-upload-limit=0#单文件速度限制max-upload-limit=0#断开速度过慢的连接#lowest-speed-limit=0#验证用，需要1.16.1之后的release版本#referer=*#文件保存路径, 默认为当前启动位置# dir=/user-files/superuser/dir=/data#文件缓存, 使用内置的文件缓存, 如果你不相信Linux内核文件缓存和磁盘内置缓存时使用, 需要1.16及以上版本#disk-cache=0#另一种Linux文件缓存方式, 使用前确保您使用的内核支持此选项, 需要1.15及以上版本(?)#enable-mmap=true#文件预分配, 能有效降低文件碎片, 提高磁盘性能. 缺点是预分配时间较长#所需时间 none &lt; falloc ? trunc « prealloc, falloc和trunc需要文件系统和内核支持file-allocation=prealloc# General Optionslog=/var/log/aria2.log#You can set either debug, info, notice, warn or error.log-level=error## 进度保存相关 ### 从会话文件中读取下载任务input-file=/root/conf/aria2.session# 在Aria2退出时保存`错误/未完成`的下载任务到会话文件save-session=/root/conf/aria2.session# 定时保存会话, 0为退出时才保存, 需1.16.1以上版本, 默认:0save-session-interval=10# BT trackers from https://raw.githubusercontent.com/ngosang/trackerslist/master/trackers_best.txt# echo `wget -qO- https://raw.githubusercontent.com/ngosang/trackerslist/master/trackers_best.txt|awk NF|sed &quot;:a;N;s/\n/,/g;ta&quot;`bt-tracker=udp://tracker.coppersurfer.tk:6969/announce,udp://tracker.leechers-paradise.org:6969/announce,udp://9.rarbg.to:2710/announce,udp://p4p.arenabg.com:1337/announce,http://p4p.arenabg.com:1337/announce,udp://tracker.internetwarriors.net:1337/announce,http://tracker.internetwarriors.net:1337/announce,udp://tracker.skyts.net:6969/announce,udp://tracker.safe.moe:6969/announce,udp://tracker.piratepublic.com:1337/announce,udp://tracker.opentrackr.org:1337/announce,http://tracker.opentrackr.org:1337/announce,udp://wambo.club:1337/announce,udp://trackerxyz.tk:1337/announce,udp://tracker4.itzmx.com:2710/announce,udp://tracker2.christianbro.pw:6969/announce,udp://tracker1.wasabii.com.tw:6969/announce,udp://tracker.zer0day.to:1337/announce,udp://public.popcorn-tracker.org:6969/announce,udp://peerfect.org:6969/announce,udp://tracker.mg64.net:6969/announce,udp://mgtracker.org:6969/announce,http://tracker.mg64.net:6881/announce,http://mgtracker.org:6969/announce,http://t.nyaatracker.com:80/announce,http://retracker.telecom.by:80/announce,ws://tracker.btsync.cf:2710/announce,udp://zephir.monocul.us:6969/announce,udp://z.crazyhd.com:2710/announce,udp://tracker.xku.tv:6969/announce,udp://tracker.vanitycore.co:6969/announce,udp://tracker.tvunderground.org.ru:3218/announce,udp://tracker.torrent.eu.org:451/announce,udp://tracker.tiny-vps.com:6969/announce,udp://tracker.swateam.org.uk:2710/announce,udp://tracker.halfchub.club:6969/announce,udp://tracker.grepler.com:6969/announce,udp://tracker.files.fm:6969/announce,udp://tracker.dutchtracking.com:6969/announce,udp://tracker.dler.org:6969/announce,udp://tracker.desu.sh:6969/announce,udp://tracker.cypherpunks.ru:6969/announce,udp://tracker.cyberia.is:6969/announce,udp://tracker.christianbro.pw:6969/announce,udp://tracker.bluefrog.pw:2710/announce,udp://tracker.acg.gg:2710/announce,udp://thetracker.org:80/announce,udp://sd-95.allfon.net:2710/announce,udp://santost12.xyz:6969/announce,udp://sandrotracker.biz:1337/announce,udp://retracker.nts.su:2710/announce,udp://retracker.lanta-net.ru:2710/announce,udp://retracker.coltel.ru:2710/announce,udp://oscar.reyesleon.xyz:6969/announce,udp://open.stealth.si:80/announce,udp://ipv4.tracker.harry.lu:80/announce,udp://inferno.demonoid.pw:3418/announce,udp://allesanddro.de:1337/announce,http://tracker2.itzmx.com:6961/announce,http://tracker.vanitycore.co:6969/announce,http://tracker.torrentyorg.pl:80/announce,http://tracker.city9x.com:2710/announce,http://torrentsmd.me:8080/announce,http://sandrotracker.biz:1337/announce,http://retracker.mgts.by:80/announce,http://open.acgtracker.com:1096/announce,http://omg.wtftrackr.pw:1337/announce,wss://tracker.openwebtorrent.com:443/announce,wss://tracker.fastcast.nz:443/announce,wss://tracker.btorrent.xyz:443/announce,udp://tracker.uw0.xyz:6969/announce,udp://tracker.kamigami.org:2710/announce,udp://tracker.justseed.it:1337/announce,udp://tc.animereactor.ru:8082/announce,udp://packages.crunchbangplusplus.org:6969/announce,udp://explodie.org:6969/announce,udp://bt.xxx-tracker.com:2710/announce,udp://bt.aoeex.com:8000/announce,udp://104.238.198.186:8000/announce,https://open.acgnxtracker.com:443/announce,http://tracker.tfile.me:80/announce,http://share.camoe.cn:8080/announce,http://retracker.omsk.ru:2710/announce,http://open.acgnxtracker.com:80/announce,http://explodie.org:6969/announce,http://agusiq-torrents.pl:6969/announce,http://104.238.198.186:8000/announce 使用h5ai作为文件管理器1234567891011121314151617181920212223242526272829version: &apos;3.4&apos;services: h5ai: image: bixidock/h5ai volumes: - /home/ybd/data/docker/aria2/data:/var/www restart: always aria2: image: wahyd4/aria2-ui:h5ai ports: - &quot;8000:80&quot; - &quot;6800:6800&quot; volumes: # - /some_folder:/root/conf/key - /home/ybd/data/docker/aria2/config/aria2.conf:/root/conf/aria2.conf - /home/ybd/data/docker/aria2/config/aria2.session:/root/conf/aria2.session - /home/ybd/data/docker/aria2/cache/dht.dat:/root/.cache/aria2/dht.dat - /home/ybd/data/docker/aria2/data:/data environment: - DOMAIN=:80 # - SSL=true # - RPC_SECRET=Hello # - ARIA2_USER=admin # - ARIA2_PWD=password # - ENABLE_AUTH=true links: - h5ai:file-manager restart: always 使用nextcloud作为文件管理器docker-compose.yml : 12345678910111213141516171819202122232425262728version: &apos;3.4&apos;services: nextcloud: image: wonderfall/nextcloud volumes: - /home/ybd/data/docker/aria2/nextcloud:/data - /home/ybd/data/docker/aria2/data:/user-files restart: always aria2: image: wahyd4/aria2-ui:nextcloud ports: - &quot;8000:80&quot; - &quot;6800:6800&quot; volumes: - /home/ybd/data/docker/aria2/config/aria2.conf:/root/conf/aria2.conf - /home/ybd/data/docker/aria2/config/aria2.session:/root/conf/aria2.session - /home/ybd/data/docker/aria2/data:/data environment: - DOMAIN=:80 # - SSL=true # - RPC_SECRET=Hello # - ARIA2_USER=admin # - ARIA2_PWD=password # - ENABLE_AUTH=true links: - nextcloud:file-manager restart: always 使用nettcloud作为文件管理还需要手动配置一下： https://github.com/wahyd4/aria2-ariang-x-docker-compose/tree/master/nextcloud#nextcloud-%E9%85%8D%E7%BD%AE-external-storage 百度网盘直接下载助手1、安装 Tampermonkey Chrome插件，这个主要是管理脚本的，下面安装百度云盘脚本需要用到 2、进入 百度网盘直接下载助手(显示直接下载入口) ，点击安装或者install,完了直接刷新界面，进入到自己的百度云盘选择所需的下载文件即可。 BaiduExporter 博主使用的是BaiduExporter，上面那个下载助手导出来链接在我这边并不能下载成功。。囧 官方是这么说明的 Chrome : Click Settings -&gt; Extensions, drag BaiduExporter.crx file to the page, install it, or check Developer mode -&gt; Load unpacked extension, navigate to the chrome/release folder. Firefox : Open about:debugging in Firefox, click “Load Temporary Add-on” and navigate to the chrome/release folder, select manifest.json, click OK. 1、到 Github 下载与源码 2、打开Chrome -&gt; 扩展程序 -&gt; 勾选开发者模式 -&gt; 加载已解压的扩展程序 ，然后会弹出文件框，找到刚才下载的源码，找到chrome -&gt; release，添加成功！ 3、打开百度云盘网页版，勾选需要下载的文件，在上方会出现导出下载地选项，通过设置可以修改RCP地址 Stardict火星译王1sudo apt install stardict 安装词库：进入http://download.huzheng.org/选择所需词库并下载，a为下载的词库名，然后重启stardict12tar -xjvf a.tar.bz2mv a /usr/share/stardict/dic Filezilla12sudo apt install filezillasudo apt install filezilla-locales rar安装与使用安装1sudo apt install rar 使用解压到当前目录：1unrar e update.rar 解压到指定目录：1unrar x update.rar update/ 压缩：1rar a pg_healthcheck.rar1 pg_healthcheck/ 备份工具123sudo add-apt-repository ppa:nemh/systembacksudo apt updatesudo apt install systemback 键盘输入声音特效（Tickys）官网 或者 博主的百度盘 (密码: 9bpi)下载tickys之后执行:1sudo apt install tickys 然后通过sudo tickeys来打开 (sudo tickeys -c 打开CLI版本) 硬件信息I-Nex这是一个类似CPU-Z的工具 下载链接：https://launchpad.net/i-nex/+download Hardinfo1sudo apt-get install hardinfo -y 其他设置篇点击图标最小化Ubuntu 16.04 LTS 也支持了点击应用程序 Launcher 图标即可「最小化」的功能，不过还是需要用户进行手动启用。方法有两种，你可以安装 Unity Tweak Tool 图形界面工具之后在 「Unity」-「Launcher」-「Minimise」中进行配置，或直接在终端中使用如下命令启用。 exfat驱动1sudo apt install exfat-fuse 设置grub2引导等待时间Ubuntu系统的Grub2菜单的相关信息在读取/boot/grub/grub.cfg文件，不过Ubuntu官方不建议直接修改这个文件，想要修改Grub2的等待时间还可以修改/etc/deafalt/grub来实现。具体的修改方法如下：1sudo gedit /etc/default/grub 将GRUB_TIMEOUT=10中的10改为你想要修改的等待时间，比如3，网上很多的教程都是到这一步，其实是不行的，估计都是乱转一气。到这里还有最重要的一步，就是使用#号将GRUB_HIDDEN_TIMEOUT=0标注,然后再次回到终端，输入下面的命令刷新/boot/grub/grub.cfg文件：1sudo update-grub2 启动项管理1gnome-session-properties 好玩的Docky1sudo apt install docky 提高逼格12sudo apt install cmatrixcmatrix -b]]></content>
      <categories>
        <category>OperatingSystem</category>
        <category>Ubuntu</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu16.04下MyEclipse安装与破解]]></title>
    <url>%2F2017%2Fubuntu-myeclipse-crack%2F</url>
    <content type="text"><![CDATA[前言之前一直用的是Eclipse Luna，没有用MyEclipse是因为它收钱的- -，去新公司工作需要用到MyEclipse，下载安装happy地试用了将近一个月，不幸，试用期已过。身为一个开源爱好者，不想去用破解的（虚伪 - -），也不想出钱，博主秉着屌丝的意志，一番折腾过后，搞定。以下是经过参考与总结得到的操作步骤，博主用的是Linux的发行版Ubuntu，所以以下步骤针对Ubuntu系统，win与mac的步骤也大同小异。下载与安装首先，请前往MyEclipse的官网 下载相应系统的版本，我选择的是MyEclipse-2015-stable-3.0-offline-installer-linux.run，进入放置安装文件的目录，右键在终端打开安装文件1./MyEclipse-2015-stable-3.0-offline-installer-linux.run 按Nest设置一下安装路径完成安装，安装完之后不要选择运行MyEclipse 破解之前请不要开启你的MyEclipse，要保持刚安装完的状态，如果你已经开过了，卸载重装吧——否则你就会遭遇打开编译器，然后校验失败，报错关闭 破解与运行首先请前往博主的百度盘（密码：kv25）下载对应的破解工具，我的MyEclipse版本是2015-stable-3.0，所以在这以此版本作为示范。 下载到本地解压后并进入目录会有以下文件 打开注册机进入MyEclipse2015_keygen，双击打开注册机cracker2015.jar，失败的话，用java命令打开cracker2015.jar，前提都是你要安装了JDK并且配置好环境，JDK版本最好不要太旧，我的是1.8 当前目录终端执行： 1java -jar cracker2015.jar 运行之后出现如下界面 ↓ 开始生成注册信息 在算号器填好Usercode,UserCode可以随意输入 选择版本：由于Bling版功能最全，所以我选择了这个版本（其他版本也可以） 然后点击”SystemId”按钮，就会出现一行ID值，如果提示 Cannot find JNIWrapper native library (jniwrap.dll) in java.library.path:这样的错误，不要紧，再点一下应该就出来了，还是没有的话请注意权限问题 点击Active 保存破解信息：点Tools下的SaveProperites把破解信息（注册码）保存到文件 （注意不要手残去点RebuildKey- - !） copy文件把plugins文件中的文件复制到MyEclipse的plugins文件夹中，覆盖原文件 运行MyEclipse打开了MyEclipse，点击菜单栏中的MyEclipse-&gt;Subscription information，激活成功，激动ing=.= 最后以上是博主在Ubuntu中安装破解MyEclipse的总结过程，对于不同的环境，不同的版本，不同的操作，有可能会导致一些不一样的小问题，那么可以在一下参考中找到一些答案 参考：Myeclipse 2015 stable 1.0 完美破解方法Myeclipse 2016 CI 6 破解]]></content>
      <categories>
        <category>IDE</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>IDE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Start My Blog Trip — Power By Hexo]]></title>
    <url>%2F2017%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Life is a generic method like [ publicLife doSomething(T t){} ],T is the part of life that requires you to play in a period of time,and the method will return a life you expect if you to be T.—— 沃·兹基硕德为什么要写博客？除了可以将自己在工作学习中的一些知识及经验记录下来。不断积累知识，不断总结经验以外，更重要的是 为了保持逼格，不要停止写作 。虽然高中的语文从来都没有及格过，作文也写得挺烂，但我会尽力得用我拙劣的语言把每一篇博客都写好…引用一下别人的话喜欢写Blog的人，会经历三个阶段第一阶段，刚接触Blog，觉得很新鲜，试着选择一个免费空间来写。第二阶段，发现免费空间限制太多，就自己购买域名和空间，搭建独立博客。第三阶段，觉得独立博客的管理太麻烦，最好在保留控制权的前提下，让别人来管，自己只负责写文章。之前学习的时候，看别人的一些文章、博客跟着造轮子，然而过几天就不记得了又要到搜索引擎翻一番看一看，觉得很麻烦（因为博主比较懒= =）。然后决定自己注册一个博客论坛整理一下知识点，之后发现大神们都有自己的搭建博客，都很不错，于是乎跟着造轮子，几天折腾，总算把这个博客搭建完成并且做了一些优化。语文不好，废话也不多说了，我个人搭建Hexo博客的过程-&gt;传送门。最后，请允许我分享一篇很好的文章：《为什么你要写博客？》为什么你要写博客？一个选择我知道现在可能说这话有点不合时宜，毕竟博客时代都已经过去了，再号召大家用过就好像时的东西是不是有点逆流而上？我曾经也问过自己这个问题，但是我觉得，博客时代过去跟我们要开博客是没有多大关系的，就好像你的读书时代已经过去你就不再读书一样。判断一件事情值不值得去做有一个方法：在一张白纸的左边写不值得做的原因，然后在右边写值得做的原因，写完一比较，一权衡，自然能够得出结果。大家都成年人了，你会觉得这样思考分析总结的过程才是正确的思考的方法吧？所以，我在这里列出要写（独立）博客的原因，供大家去选择，然后填在你白纸的右边。注意，我不是给你一个建议，而是提供一个选择，这个选择蕴藏着我也不知道的可能。博客的内容写博客不难，你可以当作是生活的记录，但是这样的记录没有任何的意义。写要对得住写本身，写出来的东西应该是思考的结果。我认为，如果你要开一个博客，博客的内容应该是这样的：1、 不是生活杂记、不是流水账、不是牢骚、不是抱怨、不是心情琐记……；2、 有目的地写，要务实，追求质量；3、 承认真实的自己，不要吹嘘，不要装逼，无需讨好读者；4、 记录自己学习、思考、总结的过程；5、 分享你的故事、所得、感想、经验；6、你对钱怎么看，你认为赚到多少钱是足够的？如果你明天一早醒来，已经有足够的钱，你将会如何继续安排自己的生活？7、对你来说，什么是理想的性生活？什么是理想的性道德，在你的性道德观中，什么样的性生活是禁忌的，需要避免的，什么样的性生活是美好的，需要得到鼓励和发展的？8、你的择友标准是什么？什么样的人你会愿意交往，什么样的人你会拒绝和他交往？9、你对死亡怎么看？你希望自己活到多少岁，你准备怎么度过从现在到死亡的这段时间？如果你要立遗嘱，这份遗嘱会怎么写？以上的这九个问题摘自《很少人能顺畅回答这9个问题——心理治疗刚开始医生常常会先问你的 》by 李孟潮。这些问题的答案你可以选择不发，但是我强烈地建议写下来，只有在写的时候你才可以慎重地思考这些问题，而不会回避跳过或者留下空白，这是接受自己的第一步。提供持续学习的动力例如，我为自己设限每天写一千字，信息的不断输出给我带来恐惧，我害怕有一天我写无可写，于是我不停地阅读，通过个人的知识管理促使自己不断学习，提高核心竞争力。详细的知识管理可以看我的这篇文章：《个人知识管理的方法》，回复「知识」可见积累更多的知识写并不是单纯的写。例如你写着写着，你突然忘记了一个概念，于是上网找，找回来这个概念的时候，你重温这个概念，可能还会顺便看了一下这个概念的其他东西。例如你需要获取第一手的资料，寻找信息来源本身就是一个知识积累的过程，同时，你慢慢就学会了鉴别知识：什么是没有用的心灵鸡汤，什么是不值得关注的吐槽名人，还有，在这个过程中，你还养成你的心智。提高将事情讲清楚的能力很多东西你以为懂了，但当你在写下来的时候，你就觉得无从下手了。如果一件事情你不能讲清楚，十有八九你还没有完全理解。将事情写下来，慢慢就可以提高你的逻辑思维能力，分析能力，写会迫使你在你脑中搭建一个有条理的框架。例如我写这篇文章一样，我就将值得写博客的原因一点一点地罗列出来，事情就更加清晰，你也可以更好的思考问题。分享带来的连锁反应“通过分享，你获得了直接而快速的回报，你最终或许会发现你已将版权和“保留所有权利”抛诸脑后。新的经济学准则是：参与你作品的人越多，回报越高。在分享主义里，如果你愿意你可以保留所有权，但是我乐于分享。” by 毛向辉 《分享主义：一场思维革命》互联网精神其中最重要的就是分享主义，基于分享主义，你可以享受到社会化及互联网给你带来的种种便利和好处，你分享了一个知识，你就成为了互联网中的一个点，这个点的大小由你自己来决定，互联网的大潮会将你的这个点推送到它所能触及的每个角落，让需要的人得到，同时，你的这个点也会继续扩大，连接到整个网络，这个点有可能连接成一张网，而你就是这张网的中心。帮你找到志同道合的人在微博，在朋友圈，你可能找不到跟你志同道合的人，而在博客，你可以通过看他的几篇文章就迅速地理解认同这个人，即使你没有见过这个人，但你也可以通过这种关联来相互学习。如果你在一个领域有相当的了解，你将这些内容发在网络上，网络上跟你志趣相投的人也会被你吸引过来，根据吸引力法则，你是怎样的人你就被怎么样的人吸引，这就是博客所能赋予你的魅力。即使博客没有被他人关注，我们依然可以找到同好，你可以自己将博文转载到其他站点，人们会通过搜索引擎找到你，有邮件、微博等工具，我们不乏与他人交流的途径。by Gabriel Weinberg《Why I blog》记录成长隔一段时间，你再回头看你写的博客，你会发现自己正在通过这样的方式在不断的成长，这种成长在自己眼里是一种财富，在别人眼里是一张地图，你得到了收获，不断修正自己的错误，别人得到了指引，避免走弯路。更多的情况是当你回望自己的时候你会发现自己是一个傻逼，so what，that is what I am！培养持续做一件事情的能力开始是坚持，后来是习惯，接着喜欢。以后当有人对你说，「你写那么多有用的东西，你真的很厉害啊！」你可以笑而不语，也可以大声说道：「你妹，你不知道我开始的时候多么痛苦！」让你长久地去跑步，你可能做不到；让你每个月看一本书，你也可能做不到；但让你持续地写一个博客，你可以做得到。你不相信？你不试试你怎么知道？默默地持续做一件事是一种难得的能力，也是一种难得的品质。讨论反思每人都会有思维的盲点，就好像这篇文章一样，可能你觉得我可能说得不对，你可以反驳我，我欢迎这种讨论，因为讨论的过程中会产生各种的思维的碰撞，这种碰撞会让你反思，也会激发出你新的灵感，这种讨论反思给自己的带来巨大的受益。互联网给你的反馈就是让你承受更多，接受更多，成为一个更好的人。搜寻到你意想不到东西世界不止是你的家，你的公司，你的朋友圈，你应该去发现一个更大的世界，通过写博客，你会知道世界上还有很多人像你一样在写博客，这些人和知识正在世界的某个角落在等着你。例如，在写这篇文章的过程中，我才知道了Gabriel Weinberg，我才要将阳志平的博客重读一遍。写的过程会让你有很多新的发现，这些新的发现都值得你去再写下来，总结分享出去。一个人在做一件属于自己的事很多你认为自己很牛逼的事情都是自己一个人做出来。别人在刷微博，你在看书，别人在看穿越剧，你在学英文，别人在去唱K，你在写个人总结。吃饭也要找同伴，出游要找同伴，看电影要找同伴，你上一次一个人在做一件属于自己的事是在什么时候？如果你想要清晰地思考，就必须远离人群。但是走得越远，你的处境就会越困难，收到的阻力也会越大。因为你没有迎合社会习俗，而是一步步地与它背道而驰。如果自己就是潮水的一部分 ，怎么能看见潮流的方向呢？你只能永远保持质疑，问自己，什么话是我不能说的？为什么？——Paul Graham《不能说的话》互联网的身份识别一个长期的价值博客是一份很好的简历。这里的“简历”并非是狭义上的求职简历，毕竟现在还没有到价值博客的时代，很多人写博客都是到处转载或者干脆碎碎念，正因此面试官未必拿个人博客当成了解一个人的更可靠窗口。这里的“简历”是指一个让别人了解自己的窗口，虽然我们未必做得到像罗永浩、Keso这样的博客，个人的影响力已经足以支撑出一份事业（牛博和5gme），但至少你会因此而结识更多的人，你的博客价值越高，你结识的人就越牛，跟牛人交流又会让你的眼界得到极大的开阔，打开一扇又一扇你原本不知道的门，于是你就变得更牛… 这是一个良性循环。by 刘未鹏最后你可能想不到在白纸的左边（不值得写博客的原因）写什么了，想不到写个「博客时代已经过去」或者「我没有时间」也可以，但与此同时，你也可以用那些时间去思考一下「怎么做到长期写一个价值博客」。如果你不想思考，也可以回复「价值」看看别人的建议。]]></content>
      <categories>
        <category>Essay</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
</search>
